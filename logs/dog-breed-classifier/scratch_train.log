Training Started: 2019-01-07 00:17:48.769216
Epoch: 1 	Training Loss: 4.877051 	Validation Loss: 4.841412	Elapsed: 0:03:13.834452
Validation loss decreased (inf --> 4.841412). Saving model ...
Epoch: 2 	Training Loss: 4.820985 	Validation Loss: 4.747336	Elapsed: 0:03:01.535938
Validation loss decreased (4.841412 --> 4.747336). Saving model ...
Epoch: 3 	Training Loss: 4.767189 	Validation Loss: 4.684055	Elapsed: 0:03:01.574621
Validation loss decreased (4.747336 --> 4.684055). Saving model ...
Epoch: 4 	Training Loss: 4.728553 	Validation Loss: 4.607475	Elapsed: 0:03:02.878120
Validation loss decreased (4.684055 --> 4.607475). Saving model ...
Epoch: 5 	Training Loss: 4.643230 	Validation Loss: 4.515298	Elapsed: 0:03:01.719175
Validation loss decreased (4.607475 --> 4.515298). Saving model ...
Epoch: 6 	Training Loss: 4.601643 	Validation Loss: 4.451782	Elapsed: 0:03:02.711892
Validation loss decreased (4.515298 --> 4.451782). Saving model ...
Epoch: 7 	Training Loss: 4.563049 	Validation Loss: 4.390049	Elapsed: 0:03:02.421659
Validation loss decreased (4.451782 --> 4.390049). Saving model ...
Epoch: 8 	Training Loss: 4.525313 	Validation Loss: 4.401180	Elapsed: 0:03:00.623633
Epoch: 9 	Training Loss: 4.494441 	Validation Loss: 4.316231	Elapsed: 0:03:03.307759
Validation loss decreased (4.390049 --> 4.316231). Saving model ...
Epoch: 10 	Training Loss: 4.462459 	Validation Loss: 4.309952	Elapsed: 0:03:01.247355
Validation loss decreased (4.316231 --> 4.309952). Saving model ...
Epoch: 11 	Training Loss: 4.440028 	Validation Loss: 4.282603	Elapsed: 0:03:01.817202
Validation loss decreased (4.309952 --> 4.282603). Saving model ...
Epoch: 12 	Training Loss: 4.408276 	Validation Loss: 4.256291	Elapsed: 0:03:02.940067
Validation loss decreased (4.282603 --> 4.256291). Saving model ...
Epoch: 13 	Training Loss: 4.382314 	Validation Loss: 4.230955	Elapsed: 0:03:01.484585
Validation loss decreased (4.256291 --> 4.230955). Saving model ...
Epoch: 14 	Training Loss: 4.339535 	Validation Loss: 4.178119	Elapsed: 0:03:01.819115
Validation loss decreased (4.230955 --> 4.178119). Saving model ...
Epoch: 15 	Training Loss: 4.314611 	Validation Loss: 4.172305	Elapsed: 0:03:01.862936
Validation loss decreased (4.178119 --> 4.172305). Saving model ...
Epoch: 16 	Training Loss: 4.294925 	Validation Loss: 4.179273	Elapsed: 0:03:02.859107
Epoch: 17 	Training Loss: 4.269919 	Validation Loss: 4.121323	Elapsed: 0:03:02.187248
Validation loss decreased (4.172305 --> 4.121323). Saving model ...
Epoch: 18 	Training Loss: 4.229653 	Validation Loss: 4.078084	Elapsed: 0:03:02.005417
Validation loss decreased (4.121323 --> 4.078084). Saving model ...
Epoch: 19 	Training Loss: 4.211623 	Validation Loss: 4.075537	Elapsed: 0:03:02.023912
Validation loss decreased (4.078084 --> 4.075537). Saving model ...
Epoch: 20 	Training Loss: 4.176366 	Validation Loss: 4.071403	Elapsed: 0:03:02.443931
Validation loss decreased (4.075537 --> 4.071403). Saving model ...
Epoch: 21 	Training Loss: 4.162033 	Validation Loss: 4.060058	Elapsed: 0:03:01.880442
Validation loss decreased (4.071403 --> 4.060058). Saving model ...
Epoch: 22 	Training Loss: 4.152350 	Validation Loss: 4.017785	Elapsed: 0:03:02.961102
Validation loss decreased (4.060058 --> 4.017785). Saving model ...
Epoch: 23 	Training Loss: 4.126623 	Validation Loss: 4.061260	Elapsed: 0:03:02.727963
Epoch: 24 	Training Loss: 4.099212 	Validation Loss: 3.992973	Elapsed: 0:03:01.699973
Validation loss decreased (4.017785 --> 3.992973). Saving model ...
Epoch: 25 	Training Loss: 4.075190 	Validation Loss: 3.998641	Elapsed: 0:03:01.713804
Epoch: 26 	Training Loss: 4.046143 	Validation Loss: 3.997265	Elapsed: 0:03:02.571748
Epoch: 27 	Training Loss: 4.043575 	Validation Loss: 3.949613	Elapsed: 0:03:01.425152
Validation loss decreased (3.992973 --> 3.949613). Saving model ...
Epoch: 28 	Training Loss: 4.015487 	Validation Loss: 3.961522	Elapsed: 0:03:02.782270
Epoch: 29 	Training Loss: 3.998070 	Validation Loss: 3.948969	Elapsed: 0:03:02.048881
Validation loss decreased (3.949613 --> 3.948969). Saving model ...
Epoch: 30 	Training Loss: 3.991606 	Validation Loss: 3.938675	Elapsed: 0:03:02.713836
Validation loss decreased (3.948969 --> 3.938675). Saving model ...
Epoch: 31 	Training Loss: 3.963830 	Validation Loss: 3.918792	Elapsed: 0:03:01.697762
Validation loss decreased (3.938675 --> 3.918792). Saving model ...
Epoch: 32 	Training Loss: 3.930790 	Validation Loss: 3.897582	Elapsed: 0:03:01.460303
Validation loss decreased (3.918792 --> 3.897582). Saving model ...
Epoch: 33 	Training Loss: 3.896765 	Validation Loss: 3.963304	Elapsed: 0:03:02.224769
Epoch: 34 	Training Loss: 3.879835 	Validation Loss: 3.893857	Elapsed: 0:03:02.983978
Validation loss decreased (3.897582 --> 3.893857). Saving model ...
Epoch: 35 	Training Loss: 3.888119 	Validation Loss: 3.900615	Elapsed: 0:03:02.187086
Epoch: 36 	Training Loss: 3.839318 	Validation Loss: 3.884181	Elapsed: 0:03:02.805424
Validation loss decreased (3.893857 --> 3.884181). Saving model ...
Epoch: 37 	Training Loss: 3.814765 	Validation Loss: 3.863985	Elapsed: 0:03:03.838610
Validation loss decreased (3.884181 --> 3.863985). Saving model ...
Epoch: 38 	Training Loss: 3.801056 	Validation Loss: 3.873780	Elapsed: 0:03:03.033119
Epoch: 39 	Training Loss: 3.797330 	Validation Loss: 3.827120	Elapsed: 0:03:02.329334
Validation loss decreased (3.863985 --> 3.827120). Saving model ...
Epoch: 40 	Training Loss: 3.776431 	Validation Loss: 3.852023	Elapsed: 0:03:03.616306
Epoch: 41 	Training Loss: 3.747829 	Validation Loss: 3.814612	Elapsed: 0:03:03.231390
Validation loss decreased (3.827120 --> 3.814612). Saving model ...
Epoch: 42 	Training Loss: 3.713182 	Validation Loss: 3.811580	Elapsed: 0:03:00.355972
Validation loss decreased (3.814612 --> 3.811580). Saving model ...
Epoch: 43 	Training Loss: 3.705967 	Validation Loss: 3.811339	Elapsed: 0:03:11.512757
Validation loss decreased (3.811580 --> 3.811339). Saving model ...
Epoch: 44 	Training Loss: 3.677942 	Validation Loss: 3.763790	Elapsed: 0:03:06.798942
Validation loss decreased (3.811339 --> 3.763790). Saving model ...
Epoch: 45 	Training Loss: 3.670521 	Validation Loss: 3.804585	Elapsed: 0:03:09.111308
Epoch: 46 	Training Loss: 3.616001 	Validation Loss: 3.791811	Elapsed: 0:03:07.913439
Epoch: 47 	Training Loss: 3.605779 	Validation Loss: 3.818132	Elapsed: 0:03:08.180969
Epoch: 48 	Training Loss: 3.578845 	Validation Loss: 3.802942	Elapsed: 0:03:07.502958
Epoch: 49 	Training Loss: 3.569269 	Validation Loss: 3.763015	Elapsed: 0:03:08.838610
Validation loss decreased (3.763790 --> 3.763015). Saving model ...
Epoch: 50 	Training Loss: 3.551981 	Validation Loss: 3.727734	Elapsed: 0:03:07.301504
Validation loss decreased (3.763015 --> 3.727734). Saving model ...
Epoch: 51 	Training Loss: 3.539640 	Validation Loss: 3.763292	Elapsed: 0:03:08.697944
Epoch: 52 	Training Loss: 3.514974 	Validation Loss: 3.789170	Elapsed: 0:03:07.824023
Epoch: 53 	Training Loss: 3.478333 	Validation Loss: 3.730328	Elapsed: 0:03:08.594196
Epoch: 54 	Training Loss: 3.474018 	Validation Loss: 3.710677	Elapsed: 0:03:08.306823
Validation loss decreased (3.727734 --> 3.710677). Saving model ...
Epoch: 55 	Training Loss: 3.455741 	Validation Loss: 3.666004	Elapsed: 0:03:07.551808
Validation loss decreased (3.710677 --> 3.666004). Saving model ...
Epoch: 56 	Training Loss: 3.385648 	Validation Loss: 3.755735	Elapsed: 0:03:07.685431
Epoch: 57 	Training Loss: 3.391713 	Validation Loss: 3.739904	Elapsed: 0:03:09.560812
Epoch: 58 	Training Loss: 3.385832 	Validation Loss: 3.679237	Elapsed: 0:03:07.951572
Epoch: 59 	Training Loss: 3.345478 	Validation Loss: 3.698172	Elapsed: 0:03:07.605253
Epoch: 60 	Training Loss: 3.325256 	Validation Loss: 3.702598	Elapsed: 0:03:06.575649
Epoch: 61 	Training Loss: 3.329898 	Validation Loss: 3.687313	Elapsed: 0:03:06.961018
Epoch: 62 	Training Loss: 3.332215 	Validation Loss: 3.722676	Elapsed: 0:03:08.430620
Epoch: 63 	Training Loss: 3.290568 	Validation Loss: 3.698964	Elapsed: 0:03:08.096713
Epoch: 64 	Training Loss: 3.308631 	Validation Loss: 3.693485	Elapsed: 0:03:06.612021
Epoch: 65 	Training Loss: 3.242924 	Validation Loss: 3.676528	Elapsed: 0:03:02.644056
Epoch: 66 	Training Loss: 3.210221 	Validation Loss: 3.672967	Elapsed: 0:03:02.000280
Epoch: 67 	Training Loss: 3.248309 	Validation Loss: 3.700498	Elapsed: 0:03:02.847392
Epoch: 68 	Training Loss: 3.186689 	Validation Loss: 3.672294	Elapsed: 0:03:04.354137
Epoch: 69 	Training Loss: 3.148231 	Validation Loss: 3.709312	Elapsed: 0:03:05.193586
Epoch: 70 	Training Loss: 3.167838 	Validation Loss: 3.735657	Elapsed: 0:03:04.797756
Epoch: 71 	Training Loss: 3.154821 	Validation Loss: 3.683042	Elapsed: 0:03:07.263391
Epoch: 72 	Training Loss: 3.151534 	Validation Loss: 3.803930	Elapsed: 0:03:02.779610
Epoch: 73 	Training Loss: 3.157296 	Validation Loss: 3.690141	Elapsed: 0:03:05.410248
Epoch: 74 	Training Loss: 3.101250 	Validation Loss: 3.771072	Elapsed: 0:03:03.327209
Epoch: 75 	Training Loss: 3.052344 	Validation Loss: 3.676567	Elapsed: 0:03:01.068909
Epoch: 76 	Training Loss: 3.043009 	Validation Loss: 3.728986	Elapsed: 0:03:01.663287
Epoch: 77 	Training Loss: 3.035244 	Validation Loss: 3.787941	Elapsed: 0:03:02.757887
Epoch: 78 	Training Loss: 3.024287 	Validation Loss: 3.795896	Elapsed: 0:03:01.845504
Epoch: 79 	Training Loss: 2.992325 	Validation Loss: 3.716417	Elapsed: 0:03:02.454654
Epoch: 80 	Training Loss: 2.985272 	Validation Loss: 3.665017	Elapsed: 0:03:01.616717
Validation loss decreased (3.666004 --> 3.665017). Saving model ...
Epoch: 81 	Training Loss: 2.972644 	Validation Loss: 3.750383	Elapsed: 0:03:02.581951
Epoch: 82 	Training Loss: 2.948319 	Validation Loss: 3.790278	Elapsed: 0:03:02.529694
Epoch: 83 	Training Loss: 2.955792 	Validation Loss: 3.807737	Elapsed: 0:03:02.909021
Epoch: 84 	Training Loss: 2.953483 	Validation Loss: 3.884490	Elapsed: 0:03:00.926423
Epoch: 85 	Training Loss: 2.907973 	Validation Loss: 3.876141	Elapsed: 0:03:01.702236
Epoch: 86 	Training Loss: 2.886144 	Validation Loss: 3.806277	Elapsed: 0:03:02.415406
Epoch: 87 	Training Loss: 2.895160 	Validation Loss: 3.768452	Elapsed: 0:03:02.365341
Epoch: 88 	Training Loss: 2.878172 	Validation Loss: 3.794703	Elapsed: 0:03:01.910776
Epoch: 89 	Training Loss: 2.850065 	Validation Loss: 3.784806	Elapsed: 0:03:01.821389
Epoch: 90 	Training Loss: 2.808656 	Validation Loss: 3.834159	Elapsed: 0:03:02.931420
Epoch: 91 	Training Loss: 2.807267 	Validation Loss: 3.879032	Elapsed: 0:03:01.804976
Epoch: 92 	Training Loss: 2.773044 	Validation Loss: 3.779162	Elapsed: 0:03:03.069339
Epoch: 93 	Training Loss: 2.787731 	Validation Loss: 3.912086	Elapsed: 0:03:01.484451
Epoch: 94 	Training Loss: 2.741030 	Validation Loss: 3.782457	Elapsed: 0:03:01.528688
Epoch: 95 	Training Loss: 2.777800 	Validation Loss: 3.873816	Elapsed: 0:03:02.658232
Epoch: 96 	Training Loss: 2.748137 	Validation Loss: 3.923467	Elapsed: 0:03:01.510292
Epoch: 97 	Training Loss: 2.725654 	Validation Loss: 3.989069	Elapsed: 0:03:02.315783
Epoch: 98 	Training Loss: 2.723776 	Validation Loss: 3.946343	Elapsed: 0:03:01.279152
Epoch: 99 	Training Loss: 2.662464 	Validation Loss: 3.885177	Elapsed: 0:03:02.807385
Epoch: 100 	Training Loss: 2.714636 	Validation Loss: 3.916170	Elapsed: 0:03:01.294095
Training Ended: 2019-01-07 05:24:48.263423
Total Training Time: 5:06:59.494207
