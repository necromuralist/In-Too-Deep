<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/" rel="canonical">
<link href="index-10.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<link href="posts/nlp/implementing-twitter-logistic-regression/" rel="prefetch" type="text/html">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item active"><a class="nav-link" href=".">Cloistered Monkey <span class="sr-only">(active)</span></a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/implementing-twitter-logistic-regression/">Implementing Logistic Regression for Tweet Classification</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/implementing-twitter-logistic-regression/" rel="bookmark"><time class="published dt-published" datetime="2020-07-14T16:16:22-07:00" itemprop="datePublished" title="2020-07-14 16:16">2020-07-14 16:16</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org3362661">Beginning</a>
<ul>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org62e3246">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org7789908">Middle</a>
<ul>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org08ed8ce">The Tweet Vectorizer</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orga26b293">Setup the Training and Testing Sets</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orgfe17386">Logistic Regression</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orgd8bb421">Train the Model</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orge7292ca">Test the Model</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org418194b">The Wrong Stuff</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orgde4c76b">Some Fresh Tweets</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orgc732053">Compare to SKLearn</a></li>
</ul>
</li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org8da45c0">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org3362661">
<h2 id="org3362661">Beginning</h2>
<div class="outline-text-2" id="text-org3362661">
<p>This will implement a Logistic Regression model to train on our word counts to classify tweets by sentiment.</p>
</div>
<div class="outline-3" id="outline-container-org62e3246">
<h3 id="org62e3246">Set Up</h3>
<div class="outline-text-3" id="text-org62e3246"></div>
<div class="outline-4" id="outline-container-orgb9a704e">
<h4 id="orgb9a704e">Imports</h4>
<div class="outline-text-4" id="text-orgb9a704e">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">equal</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># this package</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.sentiment</span> <span class="kn">import</span> <span class="n">TweetSentiment</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>

<span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org923c61b">
<h4 id="org923c61b">The Data</h4>
<div class="outline-text-4" id="text-org923c61b">
<p>Download the data (if it hasn't been downloaded before).</p>
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"twitter_samples"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">positive</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"positive_tweets.json"</span><span class="p">)</span>
<span class="n">negative</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"negative_tweets.json"</span><span class="p">)</span>

<span class="n">Sentiment</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">positive_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">positive</span><span class="p">)</span>
<span class="n">negative_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org27edbb9">
<h4 id="org27edbb9">For Plotting</h4>
<div class="outline-text-4" id="text-org27edbb9">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"implementing-twitter-logistic-regression"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">990</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">780</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
    <span class="n">font_scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">color_cycle</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Cycle</span><span class="p">([</span><span class="s2">"#4687b7"</span><span class="p">,</span> <span class="s2">"#ce7b6d"</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org272f149">
<h4 id="org272f149">Types</h4>
<div class="outline-text-4" id="text-org272f149">
<p>Some stuff for type hinting.</p>
<div class="highlight">
<pre><span></span><span class="n">Tweet</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
<span class="n">PositiveProbability</span> <span class="o">=</span> <span class="n">Tweet</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7789908">
<h2 id="org7789908">Middle</h2>
<div class="outline-text-2" id="text-org7789908"></div>
<div class="outline-3" id="outline-container-org08ed8ce">
<h3 id="org08ed8ce">The Tweet Vectorizer</h3>
<div class="outline-text-3" id="text-org08ed8ce"></div>
<div class="outline-4" id="outline-container-orgcdacc5e">
<h4 id="orgcdacc5e">The Testing</h4>
<div class="outline-text-4" id="text-orgcdacc5e">
<div class="highlight">
<pre><span></span>Feature: A Tweet Count Vectorizer

&lt;&lt;extract-features-feature&gt;&gt;

&lt;&lt;get-vectors-feature&gt;&gt;

&lt;&lt;reset-vectors-feature&gt;&gt;

&lt;&lt;check-rep-vectorizer-tweets-feature&gt;&gt;

&lt;&lt;check-rep-vectorizer-counter-feature&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be</span><span class="p">,</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">contain_exactly</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">raise_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">when</span><span class="p">,</span>
    <span class="n">then</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this testing</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">Columns</span><span class="p">,</span> <span class="n">TweetVectorizer</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="n">and_also</span> <span class="o">=</span> <span class="n">then</span>
<span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/tweet_vectorizer.feature"</span><span class="p">)</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">extract</span><span class="o">-</span><span class="n">features</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectors</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">reset</span><span class="o">-</span><span class="n">vectors</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectorizer</span><span class="o">-</span><span class="n">tweets</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">rep</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectorizer</span><span class="o">-</span><span class="n">counter</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">rep</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org7dd0b8b"></a>Extract Features<br>
<div class="outline-text-5" id="text-org7dd0b8b">
<p>I don't really like the way the coursera people code - but to get a method closer to what's in the assignment I'm going to add this method and call in it the vectors property.</p>
<div class="highlight">
<pre><span></span>Scenario: A user converts a tweet to a feature-vector

Given a Tweet Vectorizer
When the user converts a tweet to a feature-vector
Then it's the expected feature-vector
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: A user converts a tweet to a feature-vector</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_tweet_vectorizer</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">TWEETS</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">TOKENS</span> <span class="o">=</span> <span class="s2">"A B C"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKENS</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">processed</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                          <span class="n">counter</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'B'</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">2</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">3</span><span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="s2">"A B C"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user converts a tweet to a feature-vector"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"A B C"</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"A B C"</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected_array</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it's the expected feature-vector"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_feature_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">expected_array</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span>

    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org517d514"></a>Get the Vectors<br>
<div class="outline-text-5" id="text-org517d514">
<div class="highlight">
<pre><span></span>Scenario: A user retrieves the count vectors
Given a user sets up the Count Vectorizer with tweets
When the user checks the count vectors
Then the first column is the bias colum
And the positive counts are correct
And the negative counts are correct
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Feature: A Tweet Count Vectorizer</span>

<span class="c1"># Scenario: A user retrieves the count vectors</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a user sets up the Count Vectorizer with tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_vectorizer</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">TWEETS</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">TOKENS</span> <span class="o">=</span> <span class="s2">"A B C"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKENS</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                          <span class="n">counter</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'B'</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">2</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">3</span><span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">negative</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
                                      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">TOKENS</span><span class="p">])</span>
                                      <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)])</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">positive</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
                                      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">TOKENS</span><span class="p">])</span>
                                     <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)])</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the count vectors"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_count_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="c1"># kind of silly, but useful for troubleshooting</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the first column is the bias colum"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_bias</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">bias</span><span class="p">]</span><span class="o">==</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@and_also</span><span class="p">(</span><span class="s2">"the positive counts are correct"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_positive_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">positive</span><span class="p">]</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">positive</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@and_also</span><span class="p">(</span><span class="s2">"the negative counts are correct"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_negative_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">negative</span><span class="p">]</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">negative</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">negative</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org6c4f036"></a>Reset the Vectors<br>
<div class="outline-text-5" id="text-org6c4f036">
<div class="highlight">
<pre><span></span>Scenario: The vectors are reset
Given a Tweet Vectorizer with the vectors set
When the user calls the reset method
Then the vectors are gone
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The vectors are reset</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with the vectors set"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()],</span> <span class="n">counter</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user calls the reset method"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_reset</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span><span class="p">))</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the vectors are gone"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_vectors_gone</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org4e1bacf"></a>Check Rep<br>
<div class="outline-text-5" id="text-org4e1bacf">
<div class="highlight">
<pre><span></span>Scenario: the check-rep is called with bad tweets
Given a Tweet Vectorizer with bad tweets
When check-rep is called
Then it raises an AssertionError
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: the check-rep is called with bad tweets</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with bad tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_bad_tweets</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                                          <span class="n">counter</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">(</span>
                                              <span class="n">tweets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"check-rep is called"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_check_rep</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">bad_call</span><span class="p">():</span>
        <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">check_rep</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bad_call</span> <span class="o">=</span> <span class="n">bad_call</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it raises an AssertionError"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_assertion_error</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">bad_call</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">raise_error</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span>Scenario: the check-rep is called with a bad word-counter
Given a Tweet Vectorizer with the wrong counter object
When check-rep is called
Then it raises an AssertionError
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: the check-rep is called with a bad word-counter</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with the wrong counter object"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_bad_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[</span><span class="s2">"apple"</span><span class="p">],</span> <span class="n">counter</span><span class="o">=</span><span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">())</span>
    <span class="k">return</span>

<span class="c1"># When check-rep is called</span>
<span class="c1"># Then it raises an AssertionError</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org6c1d3f6">
<h4 id="org6c1d3f6">The Implementation</h4>
<div class="outline-text-4" id="text-org6c1d3f6">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">attr</span>


<span class="c1"># this package</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="n">Columns</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">bias</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">TweetClass</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># some types</span>
<span class="n">Tweets</span> <span class="o">=</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
<span class="n">Vector</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TweetVectorizer</span><span class="p">:</span>
    <span class="sd">"""A tweet vectorizer</span>

<span class="sd">    Args:</span>
<span class="sd">     tweets: the pre-processed/tokenized tweets to vectorize</span>
<span class="sd">     counter: the word counter with the tweet token counts</span>
<span class="sd">     bias: constant to use for the bias</span>
<span class="sd">    """</span>
    <span class="n">tweets</span><span class="p">:</span> <span class="n">Tweets</span>
    <span class="n">counter</span><span class="p">:</span> <span class="n">WordCounter</span>
    <span class="n">bias</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">1</span>
    <span class="n">_process</span><span class="p">:</span> <span class="n">TwitterProcessor</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TwitterProcessor</span><span class="p">:</span>
        <span class="sd">"""Processes tweet strings to tokens"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">"""The vectorized tweet counts"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span>

    <span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">as_array</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Vector</span><span class="p">:</span>
        <span class="sd">"""converts a single tweet to an array of counts</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: a string tweet to count up</span>
<span class="sd">        as_array: whether to match the assignment format or not</span>

<span class="sd">       Returns:</span>
<span class="sd">        either a list of floats or a 1 x 3 array</span>
<span class="sd">       """</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
            <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">TweetClass</span><span class="o">.</span><span class="n">positive</span><span class="p">)]</span>
                 <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)),</span>
            <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">TweetClass</span><span class="o">.</span><span class="n">negative</span><span class="p">)]</span>
                                <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vector</span><span class="p">])</span> <span class="k">if</span> <span class="n">as_array</span> <span class="k">else</span> <span class="n">vector</span>
        <span class="k">return</span> <span class="n">vector</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Removes the vectors"""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">check_rep</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Checks that the tweets and word-counter are set</span>

<span class="sd">       Raises:</span>
<span class="sd">        AssertionError if one of them isn't right</span>
<span class="sd">       """</span>
        <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span>
        <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="p">)</span> <span class="ow">is</span> <span class="n">WordCounter</span>
        <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orga26b293">
<h3 id="orga26b293">Setup the Training and Testing Sets</h3>
<div class="outline-text-3" id="text-orga26b293">
<p>This is a new step in the process. In the previous explorations we used the entire tweet sets but since we're going to train a model we need to split it into training and testing sets.</p>
<div class="highlight">
<pre><span></span><span class="n">TRAINING_SIZE</span> <span class="o">=</span> <span class="mi">4000</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">20200714</span>
<span class="n">positive_x_train</span><span class="p">,</span> <span class="n">positive_x_test</span><span class="p">,</span> <span class="n">positive_y_train</span><span class="p">,</span> <span class="n">positive_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">positive</span><span class="p">,</span> <span class="n">positive_labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">TRAINING_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">negative_x_train</span><span class="p">,</span> <span class="n">negative_x_test</span><span class="p">,</span> <span class="n">negative_y_train</span><span class="p">,</span> <span class="n">negative_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">negative</span><span class="p">,</span> <span class="n">negative_labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">TRAINING_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">positive_x_train</span> <span class="o">+</span> <span class="n">negative_x_train</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">positive_x_test</span> <span class="o">+</span> <span class="n">negative_x_test</span>

<span class="c1"># the initial code I wrote assumes that we're using lists for the tweets and labels</span>
<span class="c1"># so later on convert the y-data to arrays, but keep them al lists for now</span>
<span class="n">SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">positive_y_train</span> <span class="o">+</span> <span class="n">negative_y_train</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">positive_y_test</span> <span class="o">+</span> <span class="n">negative_y_test</span>

<span class="n">x_check</span> <span class="o">=</span> <span class="n">positive</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span> <span class="o">+</span> <span class="n">negative</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span>
<span class="n">y_check</span> <span class="o">=</span> <span class="n">positive_labels</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span> <span class="o">+</span> <span class="n">negative_labels</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">TRAIN_SIZE</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">TRAINING_SIZE</span>
<span class="n">TEST_SIZE</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">positive</span><span class="p">)</span> <span class="o">-</span> <span class="n">TRAIN_SIZE</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">))</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TEST_SIZE</span><span class="p">))</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">))</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TEST_SIZE</span><span class="p">))</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6904bc0">
<h4 id="org6904bc0">Build the Counts</h4>
<div class="outline-text-4" id="text-org6904bc0">
<p>Now we'll build the counts for the training set.</p>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span> 

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
11,443
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
<pre class="example">
[((':(', 0), 3670)]
</pre>
<p>So, as a reminder, the <code>counts</code> is a dictionary-like object that holds <code>(token, sentiment)</code> pairs as keys mapped to the number of tweets that had the token and were classified as having that sentiment. So in the sample given, the token is <code>:(</code> and it was in 3,661 negative tweets (because 0 indicates a negative tweet).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org3cf69d4">
<h4 id="org3cf69d4">Try the Vectorizer</h4>
<div class="outline-text-4" id="text-org3cf69d4">
<p><b>Note:</b> I changed the regular expression tweet cleaner to only remove URIs up to a whitespace, because it was wiping out emoticons that came after them so my numbers no longer match the Coursera numbers exactly.</p>
<div class="highlight">
<pre><span></span><span class="n">check_counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">x_check</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_check</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">x_check</span><span class="p">,</span> <span class="n">counter</span><span class="o">=</span><span class="n">check_counter</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First Tweet: </span><span class="si">{</span><span class="n">x_check</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First count vector: </span><span class="si">{</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"nunya noa agar"</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
</pre></div>
<pre class="example">
First Tweet: #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)
First count vector: [   1 3133   61]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgfe17386">
<h3 id="orgfe17386">Logistic Regression</h3>
<div class="outline-text-3" id="text-orgfe17386">
<p>Now that we have the data it's time to implement the <a href="https://www.wikiwand.com/en/Logistic_regression">Logistic Regression</a> model to classify tweets as positive or negative.</p>
</div>
<div class="outline-4" id="outline-container-org6c72dc7">
<h4 id="org6c72dc7">The Sigmoid</h4>
<div class="outline-text-4" id="text-org6c72dc7">
<p>Logistic Regression uses a version of <a href="https://www.wikiwand.com/en/Sigmoid_function">the Sigmoid Function</a> called the Standard <a href="https://www.wikiwand.com/en/Logistic_function">Logistic Function</a> to measure whether an entry has passed the threshold for classification. This is the mathematical definition:</p>
<p>\[ \sigma(z) = \frac{1}{1 + e^{-x \cdot \theta}} \]</p>
<p>The numerator (1) determines the maximum value for the function, so in this case the range is from 0 to 1 and we can interpret \(\sigma(z)\) as the probability that a tweet (<i>z</i>) is positive (<i>1</i>). The interpretation of \(\sigma(z)\) is it's the probability that <i>z</i> (a vector representation of a tweet times the weights) is classified as 1 (having a positive sentiment). So we could re-write this as:</p>
<p>\[ P(Y=1 | z) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2)}} \]</p>
<p>Where \(x_1\) is the sum of the positive tweet counts for the tokens in \(x\) and \(x_2\) is the sum of the negative tweet counts for the tokens. \(\beta_0\) is our bias and \(\beta_1\) and \(\beta_2\) are the weights that we're going to find by training our model.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">:</span> <span class="n">Tweet</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PositiveProbability</span><span class="p">:</span>
    <span class="sd">"""Calculates the logistic function value</span>

<span class="sd">    Args:</span>
<span class="sd">     z: input to the logistic function (float or array)</span>

<span class="sd">    Returns:</span>
<span class="sd">     calculated sigmoid for z</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org55a15cf"></a>A Little Test<br>
<div class="outline-text-5" id="text-org55a15cf">
<p>We have a couple of given values to test that our sigmoid is correct.</p>
<div class="highlight">
<pre><span></span><span class="n">expect</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">4.92</span><span class="p">),</span> <span class="mf">0.9927537604041685</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>

<span class="n">expected</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9927537604041685</span><span class="p">])</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">4.92</span><span class="p">]))</span>

<span class="n">expect</span><span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="orga375565"></a>Plotting It<br>
<div class="outline-text-5" id="text-orga375565">
<p>Let's see what the output looks like.</p>
<div class="highlight">
<pre><span></span><span class="n">min_x</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
<span class="n">max_x</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">halfway</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plot_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">curve</span> <span class="o">=</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">)</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Curve</span><span class="p">([(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">halfway</span><span class="p">),</span> <span class="p">(</span><span class="n">max_x</span><span class="p">,</span> <span class="n">halfway</span><span class="p">)],</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">curve</span> <span class="o">*</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Sigmoid"</span><span class="p">,</span>
    <span class="n">show_grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">embedded</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sigmoid_function"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">embedded</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/sigmoid_function.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Looking at the plot you can see that the probability that a tweet is positive is 0.5 when the input is 0, becomes more likely the more positive the input is, and is less likely the more negative an input is. Next we'll need to look at how to train our model.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org297ed42">
<h4 id="org297ed42">The Loss Function</h4>
<div class="outline-text-4" id="text-org297ed42">
<p>To train our model we need a way to measure how well (or in this case poorly) it's doing. For this we'll use the <a href="http://wiki.fast.ai/index.php/Log_Loss">Log Loss</a> function which is the negative logarithm of our probability - so for each tweet, we'll calculate \(\sigma\) (which is the probability that it's positive) and take the negative logarithm of it to get the log-loss.</p>
<p>The formula for loss:</p>
<p>\[ Loss = - \left( y\log (p) + (1-y)\log (1-p) \right) \]</p>
<p>\(y\) is the classification of the tweet (1 or 0) so when the tweet is classified 1 (positive) the right term becomes 0 and when the tweet is classified 0 (negative) the left term becomes 0 so this is the equivalent of:</p>
<div class="highlight">
<pre><span></span><span class="k">if</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
<p>Where \(p\) is the probability that the tweet is positive and \(1 - p\) is the probability that it isn't (so it's negative since that's the only alternative). We take the negative of the logarithm because \(log(p)\) is negative (all the values of \(p\) are between 0 and 1) so negating it makes the output positive.</p>
<p>We can fill it in to make it match what we're going to actually calculate - for the \(i^{th}\) item in our dataset \(p = \sigma(z^i \cdot \theta)\) and the equation becomes:</p>
<p>\[ Loss = - \left( y^{(i)}\log (\sigma(z^{(i)} \cdot \theta)) + (1-y^{(i)})\log (1-\sigma(z^{(i)} \cdot \theta)) \right) \]</p>
<div class="highlight">
<pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"p"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
    <span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span> 
<span class="p">})</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"p"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Log-Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Loss (Y=1)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"log_loss_example"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/log_loss_example.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So what is this telling us? This is for the case where a tweet is labeled positive and at the far left, near 0 (<code>log(0)</code> is undefined so you can use a really small probability but not 0) our model is saying that it probably isn't a positive tweet, so the log-loss is fairly high, then as we move along the x-axis our model is saying that it is more and more likely that the tweet is positive so our log-loss goes down, until we reach the point where our model says that it's 100% guaranteed to be a positive tweet, at which point our log-loss drops to zero. Fairly intuitive.</p>
<p>Let's look at the case where the tweet is actually negative (<i>y=0</i>). Since <i>p</i> is the probability that it's positive, when the label is 0 we need to take the log of <i>1-p</i> to see what the model thinks the probability is that it's negative.</p>
<div class="highlight">
<pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">probabilities</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"p"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
    <span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span> 
<span class="p">})</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"p"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Log-Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Loss (Y=0)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"log_loss_y_0_example"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/log_loss_y_0_example.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So now we have basically the opposite loss. In this case the tweet is not positive so when the model puts a low likelihood that the tweet is positive the log-loss is small, but as you move along the x-axis the model is giving more probability to the notion that the tweet is positive so the log-loss gets larger.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org7478e13">
<h4 id="org7478e13">Training the Model</h4>
<div class="outline-text-4" id="text-org7478e13">
<p>To train the model we're going to use <a href="https://www.wikiwand.com/en/Gradient_descent">Gradient Descent</a>. What this means is that we're going to use the <i>gradient</i> of our loss function to figure out how to update our weights. The <i>gradient</i> is just the slope of the loss-function (but generalized to multiple dimensions).</p>
<p>How do we do this? First we calculate our model's estimate of the input being positive, then we calculate the gradient of its loss. If you remember from calculus the slope of a line is the derivative of its function so instead of calculating the loss, we'll calculate the derivative of the loss-function which is given as:</p>
<p>\[ \nabla_{\theta}L_{\theta} = \left [ \sigma(x \cdot \theta) - y \right] x_j \]</p>
<p>The rightmost term \(x_j\) represents one term in the input vector, the one that matches the weight - this has to be repeated for each \(\beta\) in \(\theta\) so in our case it will be repeated three times, with \(x\) being 1 for the bias term.</p>
<p>It's called stochastic gradient descent because the inputs are chosen randomly from our training set. This turns out to not give you a smooth descent so we're going to do <b>batch training</b> which changes our gradient a little.</p>
<p>\[ \nabla_{\theta_j}L_{\theta} = \frac{1}{m} \sum_{i=1}^m(\sigma(x \cdot \theta)-y)x_j \]</p>
<p>Our gradient is now the average of the gradients for each of the inputs in our training set. We update the weights by subtracting a fraction of the difference between the current weights and the gradient. The fraction \(\eta\) is called the <i>learning rate</i> and it controls how much the weights change, representng how fast our model will learn. If it is too large we can miss the minimum and if it's too large it will take too long to train the model, so we need to choose the right value for it to reach the minima within a feasible time.</p>
<p>Here's the algorithm in the rough.</p>
<ul class="org-ul">
<li><i>L</i>: Loss Function</li>
<li>\(\sigma\): probability function parameterized by \(\theta\)</li>
<li><i>x</i>: set of training inputs</li>
<li><i>y</i>: set of training labels</li>
</ul>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<pre id="gradientdescent" style="display:hidden">
\begin{algorithm}
\caption{Stochastic Gradient Descent}
\begin{algorithmic}
\STATE $\theta \gets 0$
\WHILE{not done}

 \FOR{each $(x^{(i)},y^{(i)})$ in training data}
  \State $\hat{y} \gets \sigma(x^{(i)}; \theta)$
  \State $loss \gets L(\hat{y}^{(i)}, y^{(i)})$
  \State $g \gets \nabla_{\theta} L(\hat{y}^{(i)}, y^{(i)})$
  \State $\theta \gets \theta - \eta g$
 \ENDFOR

\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre>
<p>We can translate this a little more.</p>
<pre id="gradientdescentengrish" style="display:hidden">
\begin{algorithm}
\caption{Stochastic Gradient Descent}
\begin{algorithmic}
\STATE Initialize the weights
\WHILE{the loss is still too high}

 \FOR{each $(x^{(i)},y^{(i)})$ in training data}
  \State What is our probability that the input is positive?
  \State How far off are we?
  \State What direction would we need to head to maximize the error?
  \State Let's go in the opposite direction.
 \ENDFOR

\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescent"));
    pseudocode.renderElement(document.getElementById("gradientdescentengrish"));
</script>
<p>Note that the losses aren't needed for the algorithm to train the model, just for assessing how well the model did.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orge8e6763">
<h4 id="orge8e6763">Implement It</h4>
<div class="outline-text-4" id="text-orge8e6763"></div>
<ul class="org-ul">
<li><a id="org7d77d33"></a>The Function<br>
<div class="outline-text-5" id="text-org7d77d33">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                     <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                     <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Finds the weights for the model</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the tweet vectors</span>
<span class="sd">     y: the positive/negative labels</span>
<span class="sd">     weights: the regression weights</span>
<span class="sd">     learning_rate: (eta) how much to update the weights</span>
<span class="sd">     iterations: the number of times to repeat training</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">learning_rate</span> <span class="o">/=</span> <span class="n">rows</span>
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
        <span class="c1"># average loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)))</span> <span class="o">+</span>
                               <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">))))</span><span class="o">/</span><span class="n">rows</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
<p>If you look at the implementation you can see that there are some changes made to it from what I wrote earlier. This is because the algorithm I wrote in pseudocode came from a book while the implementation that I made came from a Coursera assignment. The main differences being that we use a set number of iterations to train the model and the learning rate is divided by the number of training examples. Of course, you could just divide the learning rate before passing it in to the function so it doesn't really change it that much. I also had to take into account the fact that you can't just take a dot product of two matrices if their shapes aren't compatible - the rows of the left hand matrix has to match the columns of the right hand matrix) so there's some transposing of matrices being done. Our actual implementation might be more like this.</p>
<pre id="gradientdescentimplementation" style="display:hidden">
\begin{algorithm}
\caption{Stochastic Gradient Descent Implemented}
\begin{algorithmic}
\STATE $\theta \gets 0$
\STATE $m \gets rows(X)$
\FOR{$iteration \in$ \{0 $\ldots iterations-1$ \}}
  \STATE $\hat{Y} \gets \sigma(X \cdot \theta)$
  \STATE $loss \gets -\frac{1}{m}(Y^T \cdot \ln \hat{Y}) + (1 - Y)^T \cdot (\ln 1 - \hat{Y})$
  \STATE $\nabla \gets \sum (\hat{Y} - Y)^T \cdot x$
  \STATE $\theta \gets \theta - \frac{\eta}{m} \nabla^T$
 \ENDFOR
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescentimplementation"));
</script></div>
</li>
<li><a id="orga31ed2d"></a>Test It<br>
<div class="outline-text-5" id="text-orga31ed2d">
<p>First we'll make a fake (random) input set.</p>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2000</span>
<span class="n">fake_tweet_vectors</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">fake</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>Now, the fake labels - we'll make around 35% of them negative and the rest positive.</p>
<div class="highlight">
<pre><span></span><span class="n">fake_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.35</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="org1ed8c98"></a>Do the Descent<br>
<div class="outline-text-5" id="text-org1ed8c98">
<p>So now we can pass our test data into the gradient descent function and see what happens.</p>
<div class="highlight">
<pre><span></span><span class="n">fake_weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">fake_loss</span><span class="p">,</span> <span class="n">fake_weights</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">fake_tweet_vectors</span><span class="p">,</span>
                                           <span class="n">y</span><span class="o">=</span><span class="n">fake_labels</span><span class="p">,</span> 
                                           <span class="n">weights</span><span class="o">=</span><span class="n">fake_weights</span><span class="p">,</span>
                                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                                           <span class="n">iterations</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">fake_loss</span><span class="p">,</span> <span class="mf">0.67094970</span><span class="p">,</span> <span class="n">rel_tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The log-loss after training is </span><span class="si">{</span><span class="n">fake_loss</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The trained weights are </span><span class="si">{</span><span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">fake_weights</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The log-loss after training is 0.67094970.
The trained weights are [4.1e-07, 0.00035658, 7.309e-05]
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgd8bb421">
<h3 id="orgd8bb421">Train the Model</h3>
<div class="outline-text-3" id="text-orgd8bb421">
<p>Now that we have our parts let's actually train the model using the real training data. At this point we need everything to be numpy arrays so I'll convert the y-sets (the vectorizer already does this for the x-sets).</p>
<div class="highlight">
<pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">train_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">counter</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">final_loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The log-loss after training is </span><span class="si">{</span><span class="n">final_loss</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The resulting vector of weights is </span><span class="si">{</span><span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weights</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The log-loss after training is 0.22361758.
The resulting vector of weights is [6e-08, 0.00053882, -0.00055969]
</pre>
<div class="highlight">
<pre><span></span><span class="n">plot_losses</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span><span class="p">})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">plot_losses</span><span class="o">.</span><span class="n">hvplot</span><span class="p">()</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Training Losses"</span><span class="p">,</span>
                            <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                            <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                            <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                            <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span>
                            <span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"training_loss"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/training_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>As you can see, the losses are still on the decline, but we'll stop here to see how it's doing.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orge7292ca">
<h3 id="orge7292ca">Test the Model</h3>
<div class="outline-text-3" id="text-orge7292ca">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TweetSentiment</span><span class="p">:</span>
    <span class="sd">"""Predicts the sentiment of a tweet</span>

<span class="sd">    Args:</span>
<span class="sd">     vectorizer: something to vectorize tweets</span>
<span class="sd">     theta: vector of weights for the logistic regression model</span>
<span class="sd">    """</span>
    <span class="n">vectorizer</span><span class="p">:</span> <span class="n">TweetVectorizer</span>
    <span class="n">theta</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>

    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">"""the logistic function</span>

<span class="sd">       Args:</span>
<span class="sd">        vectors: a matrix of bias, positive, negative counts</span>

<span class="sd">       Returns:</span>
<span class="sd">        array of probabilities that the tweets are positive</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">vectors</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">probability_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">"""Calculates the probability of the tweet being positive</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: a tweet to classify</span>

<span class="sd">       Returns:</span>
<span class="sd">        the probability that the tweet is a positive one</span>
<span class="sd">       """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">"""Decides if the tweet was positive or not</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: the tweet message to classify.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">"""Get the sentiments of the vectorized tweets</span>

<span class="sd">       Note:</span>
<span class="sd">        this assumes that the vectorizer passed in has the tweets</span>

<span class="sd">       Returns:</span>
<span class="sd">        array of predicted sentiments (1 for positive 0 for negative)</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">sentiment</span> <span class="o">=</span> <span class="n">TweetSentiment</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'I am happy'</span><span class="p">,</span> <span class="s1">'I am bad'</span><span class="p">,</span> <span class="s1">'this movie should have been great.'</span><span class="p">,</span> <span class="s1">'great'</span><span class="p">,</span> <span class="s1">'great great'</span><span class="p">,</span> <span class="s1">'great great great'</span><span class="p">,</span> <span class="s1">'great great great great'</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">tweet</span><span class="si">}</span><span class="s1"> -&gt; </span><span class="si">{</span><span class="n">sentiment</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
I am happy -&gt; 0.5194180879292754
I am bad -&gt; 0.49324236291188817
this movie should have been great. -&gt; 0.5155519549115258
great -&gt; 0.5159253614387586
great great -&gt; 0.5318184293628917
great great great -&gt; 0.5476472009859494
great great great great -&gt; 0.5633801766216647
</pre>
<p>Strangely very near the center. Probably because the words weren't that commonly used in our training set.</p>
<div class="highlight">
<pre><span></span><span class="n">totals</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Great positive percentage: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="s1">'great'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="o">/</span><span class="n">totals</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> %"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Great negative percentage: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="s1">'great'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="o">/</span><span class="n">totals</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> % "</span><span class="p">)</span>
</pre></div>
<pre class="example">
Great positive percentage: 0.25 %
Great negative percentage: 0.03 % 
</pre>
<p>Now we can see how it did overall.</p>
<div class="highlight">
<pre><span></span><span class="n">y_test</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">test_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">counter</span><span class="p">)</span>
<span class="n">sentiment</span> <span class="o">=</span> <span class="n">TweetSentiment</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">sentiment</span><span class="p">()</span>
<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.9945
</pre>
<p>That does surprisingly well. But what did we get wrong?</p>
</div>
</div>
<div class="outline-3" id="outline-container-org418194b">
<h3 id="org418194b">The Wrong Stuff</h3>
<div class="outline-text-3" id="text-org418194b">
<div class="highlight">
<pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">wrong_places</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">!=</span> <span class="n">y_test</span>
<span class="n">wrong</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">wrong_places</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wrong</span><span class="p">))</span>
</pre></div>
<pre class="example">
11
</pre>
<div class="highlight">
<pre><span></span><span class="n">wrong_ys</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">wrong_places</span><span class="p">]</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrong</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"*"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tweet: </span><span class="si">{</span><span class="n">tweet</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokens: </span><span class="si">{</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Probability Positive: </span><span class="si">{</span><span class="n">sentiment</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classification: </span><span class="si">{</span><span class="n">wrong_ys</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example">
**********
Tweet: I'm playing Brain Dots : ) #BrainDots
http://t.co/ilDzDRHf9d http://t.co/VTXNFCPFuI
Tokens: ["i'm", 'play', 'brain', 'dot', 'braindot']
Probability Positive: 0.48526803083166703
Classification: 1

**********
Tweet: @ellekagaoan @chinmarquez Catch up once in a while :( &amp;gt;:D&amp;lt; @aditriphosphate @ErinMonzon
Tokens: ['catch', ':(', '&gt;:d']
Probability Positive: 0.11389833615259448
Classification: 1

**********
Tweet: off to the park to get some sunlight : )
Tokens: ['park', 'get', 'sunlight']
Probability Positive: 0.49574440240612333
Classification: 1

**********
Tweet: Google has made @narendramodi really very sad about @ImranKhanPTI not becoming Prime Minister. :p @PTIofficial @pmln_org
Tokens: ['googl', 'made', 'realli', 'sad', 'becom', 'prime', 'minist', ':p']
Probability Positive: 0.49947331811099865
Classification: 1

**********
Tweet: @planetjedward GoodMorning ! What's coming next? =:D =:D
Tokens: ['goodmorn', "what'", 'come', 'next', '=:', '=:']
Probability Positive: 0.49786597951455913
Classification: 1

**********
Tweet: @_sarah_mae omg you can't just tell this and don't say more :p can't wait to know !!!! ❤️
Tokens: ['omg', "can't", 'tell', 'say', ':p', "can't", 'wait', 'know', '❤', '️']
Probability Positive: 0.48000079019523884
Classification: 1

**********
Tweet: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5
Tokens: ["i'm", 'play', 'brain', 'dot', 'braindot']
Probability Positive: 0.48526803083166703
Classification: 1

**********
Tweet: @samayanyan yes thank u!! Oh damn that hella sucks :-( but at least u had a really good time that's all that matters
Tokens: ['ye', 'thank', 'u', 'oh', 'damn', 'hella', 'suck', ':-(', 'least', 'u', 'realli', 'good', 'time', "that'", 'matter']
Probability Positive: 0.5145779186318544
Classification: 0

**********
Tweet: @phenomyoutube u probs had more fun with david than me : (
Tokens: ['u', 'prob', 'fun', 'david']
Probability Positive: 0.5101260021527917
Classification: 0

**********
Tweet: @wtfxmbs AMBS please it's harry's jeans :)):):):(
Tokens: ['amb', 'pleas', "harry'", 'jean', ':)', '):', '):', '):']
Probability Positive: 0.8218858541205992
Classification: 0

**********
Tweet: @hinata_shouyno fuck u Neil u ruined it &amp;gt;:-(
Tokens: ['fuck', 'u', 'neil', 'u', 'ruin', '&gt;:-(']
Probability Positive: 0.5095962377275693
Classification: 0
</pre>
<p>The first thing to notice is that there's a duplicate tweet (the one about "Brain Dots", whatever that is). Another thing to note is that sometimes there are spaces between the characters in the emoticons, which the tokenizer probably can't figure out should be togethter, along with that weird <code>:)):):):(</code> emoticon. I'm not really soure that all of the positive tweets are actually positive, nor is it always obvious what they are about - what does "AMBS please it's harry's jeans" mean?</p>
<p>In at least in one case the NLTK vectorizer seems to mangle an emoticon as well:</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">process</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s2">"=:D"</span><span class="p">))</span>
</pre></div>
<pre class="example">
['=:', 'd']
</pre>
<p>That last one looks really wrong, though, let's take a look at it.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">wrong</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">token</span><span class="si">}</span><span class="s2">: positive=</span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="si">}</span><span class="s2"> negative=</span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
fuck: positive=23 negative=47
u: positive=206 negative=148
neil: positive=2 negative=0
u: positive=206 negative=148
ruin: positive=3 negative=10
&gt;:-(: positive=0 negative=2
</pre>
<p>So the big problem seems to be that the letter "u" is there twice and it's mostly seen as a positive. Why am I allowing single letters? There should probably be a minimum length or something. Anyway, I'm not sure you could get much better.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgde4c76b">
<h3 id="orgde4c76b">Some Fresh Tweets</h3>
<div class="outline-text-3" id="text-orgde4c76b">
<p>First someone reacting to a post about the <a href="https://www.atlasobscura.com/places/clown-motel">Clown Motel</a> in Tonopah, Nevada. The previous link was to Atlas Obscura, but the tweet came from <a href="https://www.thrillist.com/travel/nation/clown-motel-nevada-hame-anand">thrillist</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">sentiments</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">"negative"</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">"positive"</span><span class="p">}</span>
<span class="n">tweet</span> <span class="o">=</span> <span class="s2">"Nah dude. I drove by that at night and it was the creepiest thing ever. The whole town gave me bad vibes. I still shudder when I think about it."</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classified as </span><span class="si">{</span><span class="n">sentiments</span><span class="p">[</span><span class="n">sentiment</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Classified as negative
</pre>
<p>Seems reasonable.</p>
<div class="highlight">
<pre><span></span><span class="n">tweet</span> <span class="o">=</span> <span class="s2">"This is just dope. Quaint! I’d love to have an ironic drive-in wedding in Las Vegas and then stay in a clown motel as newly weds for one night. I bet they have Big Clown Suits for newly weds, haha."</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classified as </span><span class="si">{</span><span class="n">sentiments</span><span class="p">[</span><span class="n">sentiment</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Classified as positive
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgc732053">
<h3 id="orgc732053">Compare to SKLearn</h3>
<div class="outline-text-3" id="text-orgc732053">
<div class="highlight">
<pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">"neg_log_loss"</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.9925
</pre>
<p>So it didn't do quite as well, but pretty much the same just using the default parameters. We could probably do a parameter search but that's okay for now.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8da45c0">
<h2 id="org8da45c0">End</h2>
<div class="outline-text-2" id="text-org8da45c0">
<p>Let's save our weights for later. I was going to just write it to a file, but you seem to lose some precision converting the values to strings. numpy has a function called <a href="https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html">savetxt</a> but it didn't behave exactly like I thought it would and I prefer pandas so I'll save it that way.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_REGRESSION_WEIGHTS"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">weights_frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">weights_frame</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>We should also save the counts because we're going to need that for later.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>

<span class="n">counts</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">counts</span><span class="p">[</span><span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_REGRESSION_DATA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">counts</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p><b>Note:</b> This is a re-working of an exercise from Coursera's Natural Language Processing specialization.</p>
<p>I also referred to this revision in progress:</p>
<ul class="org-ul">
<li>Jurafsky, D. & Martin, J. (2020). Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition. 3rd Edition draft. <a href="https://web.stanford.edu/~jurafsky/slp3/">(URL)</a></li>
</ul>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/twitter-logistic-regression/">Twitter Logistic Regression Visualization</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/twitter-logistic-regression/" rel="bookmark"><time class="published dt-published" datetime="2020-07-10T23:08:03-07:00" itemprop="datePublished" title="2020-07-10 23:08">2020-07-10 23:08</time> <span class="updated">(updated <time class="dt-updated" datetime="2020-07-23T23:08:03-07:00" itemprop="dateUpdated" title="2020-07-23 23:08">2020-07-23 23:08</time>)</span></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/twitter-logistic-regression/#orgd5cfaa6">Beginning</a>
<ul>
<li><a href="posts/nlp/twitter-logistic-regression/#org026eba7">Set Up</a></li>
<li><a href="posts/nlp/twitter-logistic-regression/#org6987b0f">The Tweet Vectors</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-logistic-regression/#org51d0308">Middle</a>
<ul>
<li><a href="posts/nlp/twitter-logistic-regression/#orgac3cb8c">Plot The Vectors</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-logistic-regression/#org6227bf3">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgd5cfaa6">
<h2 id="orgd5cfaa6">Beginning</h2>
<div class="outline-text-2" id="text-orgd5cfaa6">
<p>Having created our logistic regression model for tweet sentiment we're going to visualize what it's doing.</p>
</div>
<div class="outline-3" id="outline-container-org026eba7">
<h3 id="org026eba7">Set Up</h3>
<div class="outline-text-3" id="text-org026eba7"></div>
<div class="outline-4" id="outline-container-org0ecb1b2">
<h4 id="org0ecb1b2">Imports</h4>
<div class="outline-text-4" id="text-org0ecb1b2">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">bokeh.models.tools</span> <span class="kn">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span> 

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># Some helper code</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcbb5ec9">
<h4 id="orgcbb5ec9">Plotting</h4>
<div class="outline-text-4" id="text-orgcbb5ec9">
<p>Some constants for the plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"twitter-logistic-regression"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">990</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">780</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
    <span class="n">font_scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">color_cycle</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Cycle</span><span class="p">([</span><span class="s2">"#4687b7"</span><span class="p">,</span> <span class="s2">"#ce7b6d"</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org6987b0f">
<h3 id="org6987b0f">The Tweet Vectors</h3>
<div class="outline-text-3" id="text-org6987b0f">
<p>In the previous post we built a dictionary-like set to count the number of times each token was in a positive tweet and in a negative tweet. To represent a tweet as a vector for training the model you then sum the total counts for the tokens in the tweet when they are positive and when they are positive.</p>
<p>Come again?</p>
<p>Lets say you have a tweet <code>"a b c"</code> which tokenizes to <code>a, b, c</code>. Look up the positive and negative tweet counts for each token and then add them:</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-right" scope="col">Positive</th>
<th class="org-right" scope="col">Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">a</td>
<td class="org-right">1</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">b</td>
<td class="org-right">2</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">c</td>
<td class="org-right">3</td>
<td class="org-right">6</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">Total</td>
<td class="org-right">6</td>
<td class="org-right">15</td>
</tr>
</tbody>
</table>
<p>So to represent this tweet you would create a vector of the form:</p>
\begin{align} \hat{v} &amp;= \langle bias, positive, negative \rangle\\ &amp;= \langle 1, 6, 15\rangle\\ \end{align}
<p><b>Note:</b> The bias is always one (it just is).</p>
<p>We're skipping the step where we actually create the vectors and just loading a prepared set.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">FEATURES</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_REGRESSION_DATA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">FEATURES</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
bias            1
positive     3117
negative       67
sentiment       1
Name: 0, dtype: int64
</pre>
<p>This first row is the vector representation for a tweet that I was talking about (plus a label column). The <code>bias</code> is always one, the <code>positive</code> value is the sum of the positive tweet counts for each token in the tweet and the <code>negative</code> values is the sum of the negative tweet counts for each of the tokens.</p>
<p>Since we're using this for plotting I'm going to make the <code>sentiment</code> into a string column to make it easier to interpret.</p>
<div class="highlight">
<pre><span></span><span class="n">sentiment</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">"Negative"</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span><span class="s2">"Positive"</span>
<span class="p">}</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sentiment</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
<pre class="example">
Positive    4000
Negative    4000
Name: sentiment, dtype: int64
</pre>
<p>If you followed the previous post you can probably figure out that this is the training set.</p>
</div>
<div class="outline-4" id="outline-container-org31287d9">
<h4 id="org31287d9">The Weights</h4>
<div class="outline-text-4" id="text-org31287d9">
<p>Since I saved the weights for our Logistic Regression model we can load it now</p>
<div class="highlight">
<pre><span></span><span class="n">weights_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_REGRESSION_WEIGHTS"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">weights_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="c1"># 'weights' is just something to make it easier to remember which column is which</span>
<span class="n">Weights</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">bias</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
</pre></div>
<pre class="example">
           bias  positive  negative
0  6.369479e-08  0.000537 -0.000558
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org51d0308">
<h2 id="org51d0308">Middle</h2>
<div class="outline-text-2" id="text-org51d0308"></div>
<div class="outline-3" id="outline-container-orgac3cb8c">
<h3 id="orgac3cb8c">Plot The Vectors</h3>
<div class="outline-text-3" id="text-orgac3cb8c">
<p>We can plot the positive vs negative counts for each tweet to see how correlated they seem to be.</p>
<div class="highlight">
<pre><span></span><span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span>
    <span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">"Positive"</span><span class="p">,</span> <span class="s2">"@positive{0,0}"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Negative"</span><span class="p">,</span> <span class="s2">"@negative{0,0}"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="s2">"@sentiment"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span>
                           <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">])</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
                               <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                               <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                               <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                               <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative"</span><span class="p">,</span>
                           <span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_scatter"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-logistic-regression/positive_negative_scatter.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Looking at the plot you can see that representing the tweets this way seems to have created a fairly separable dataset (although there's some mixing when the counts are low).</p>
</div>
<div class="outline-4" id="outline-container-orgc3a432e">
<h4 id="orgc3a432e">Add the Model</h4>
<div class="outline-text-4" id="text-orgc3a432e">
<p>Since we've been given the model's weights we can plot its output when fed the vectors to see how it separates the data. To get the equation for the separation line we need to solve for the positive or negative terms when the product of the weights and the vector is 0 (\(\theta \times x = 0\), where <i>x</i> is our vector \(\langle bias, positive, negative \rangle\)).</p>
<p>Get ready for some algebra.</p>
\begin{align} \theta \times x &amp;= 0\\ \theta \times \langle bias, positive, negative \rangle &amp;= 0\\ \theta \times \langle 1, positive, negative \rangle &amp;= 0\\ \theta_0 + \theta_1 \times positive + \theta_2 \times negative &amp;= 0\\ \theta_2 \times negative &amp;= -\theta_0 - \theta_1 \times positive\\ negative &amp;= \frac{-\theta_0 - \theta_1 \times positive}{\theta_2}\\ \end{align}
<p>This is the equation for our separation line (on our plot <code>positive</code> is the <i>x-axis</i> and <code>negative</code> is the <i>y-axis</i>, which we can translate to a function to apply to our data.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">negative</span><span class="p">(</span><span class="n">theta</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">positive</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""Calculate the negative value</span>

<span class="sd">    This calculates the value for the separation line</span>

<span class="sd">    Args:</span>
<span class="sd">     theta: list of weights for the logistic regression</span>
<span class="sd">     positive: count of positive tweets matching tweet</span>

<span class="sd">    Returns:</span>
<span class="sd">     the calculated negative value for the separation line</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">theta</span><span class="o">.</span><span class="n">bias</span>
            <span class="o">-</span> <span class="n">positive</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span><span class="o">/</span><span class="n">theta</span><span class="o">.</span><span class="n">negative</span>

<span class="n">negative_</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">negative</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org30d2696">
<h4 id="org30d2696">Plot Again</h4>
<div class="outline-text-4" id="text-org30d2696">
<p>So now we can plot the separation live with our data</p>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="p">[</span><span class="s2">"regression negative"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">positive</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">positive</span><span class="p">:</span> <span class="n">negative_</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="n">positive</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">)</span>

<span class="n">most_positive</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">positive</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"regression negative"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">scatter</span> <span class="o">*</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_separated"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-logistic-regression/positive_negative_separated.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So, the model basically creates a diagonal line that separates the positive and negative tweets.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org6227bf3">
<h2 id="org6227bf3">End</h2>
<div class="outline-text-2" id="text-org6227bf3">
<p>And that's it, not a lot here, just an intuitive look at the model and a demonstration of how this representation of the tweets makes them easily separable.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/twitter-word-frequencies/">Twitter Word Frequencies</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/twitter-word-frequencies/" rel="bookmark"><time class="published dt-published" datetime="2020-07-07T18:19:19-07:00" itemprop="datePublished" title="2020-07-07 18:19">2020-07-07 18:19</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/twitter-word-frequencies/#orgd22a50b">Beginning</a>
<ul>
<li><a href="posts/nlp/twitter-word-frequencies/#org5dd0fa9">Setup</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-word-frequencies/#orge09e354">Middle</a>
<ul>
<li><a href="posts/nlp/twitter-word-frequencies/#orgca376bb">Word Frequencies</a></li>
<li><a href="posts/nlp/twitter-word-frequencies/#orgbfa0f41">Counting</a></li>
<li><a href="posts/nlp/twitter-word-frequencies/#orgb23899d">Plotting</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-word-frequencies/#orgb92dc66">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgd22a50b">
<h2 id="orgd22a50b">Beginning</h2>
<div class="outline-text-2" id="text-orgd22a50b"></div>
<div class="outline-3" id="outline-container-org5dd0fa9">
<h3 id="org5dd0fa9">Setup</h3>
<div class="outline-text-3" id="text-org5dd0fa9"></div>
<div class="outline-4" id="outline-container-orgbe9f441">
<h4 id="orgbe9f441">Imports</h4>
<div class="outline-text-4" id="text-orgbe9f441">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="kn">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="c1"># some helper stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6298a5c">
<h4 id="org6298a5c">The Data</h4>
<div class="outline-text-4" id="text-org6298a5c">
<p>First we'll download the categorized tweets and then create a single list with both of them.</p>
<div class="highlight">
<pre><span></span><span class="n">positive_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s1">'positive_tweets.json'</span><span class="p">)</span>
<span class="n">negative_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s1">'negative_tweets.json'</span><span class="p">)</span>
<span class="n">tweets</span> <span class="o">=</span> <span class="n">positive_tweets</span> <span class="o">+</span> <span class="n">negative_tweets</span>
</pre></div>
<p>Now we need to make the labels for the tweets. We're going to label positive tweets with a <code>1</code> and negative tweets with a <code>0</code>. Since we concatenated the two sets of tweets we know that the first half will be all ones and the second half will be all zeros and we can create this master labels array using lists.</p>
<div class="highlight">
<pre><span></span><span class="n">NEGATIVE</span><span class="p">,</span> <span class="n">POSITIVE</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">SENTIMENT</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">POSITIVE</span><span class="p">:</span><span class="s2">"positive"</span><span class="p">,</span>
    <span class="n">NEGATIVE</span><span class="p">:</span><span class="s2">"negative"</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">positive_tweets</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_tweets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
10,000
</pre></div>
</div>
<div class="outline-4" id="outline-container-org98a75b4">
<h4 id="org98a75b4">Plotting and Printing</h4>
<div class="outline-text-4" id="text-org98a75b4">
<p>Just some preliminary setup of the plotter and table-printer so I don't have to keep typing the same things over and over.</p>
<div class="highlight">
<pre><span></span><span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="s2">"../../files/posts/nlp/twitter-word-frequencies"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">990</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">780</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge09e354">
<h2 id="orge09e354">Middle</h2>
<div class="outline-text-2" id="text-orge09e354"></div>
<div class="outline-3" id="outline-container-orgca376bb">
<h3 id="orgca376bb">Word Frequencies</h3>
<div class="outline-text-3" id="text-orgca376bb">
<p>We're going to build up a dictionary of frequencies. The keys will be <code>(token, sentiment)</code> tuples and the values will be the counts for the token-sentiment pairs.</p>
</div>
<div class="outline-4" id="outline-container-org9d568df">
<h4 id="org9d568df">Tests</h4>
<div class="outline-text-4" id="text-org9d568df"></div>
<ul class="org-ul">
<li><a id="org160a3f9"></a>The Tangles<br>
<div class="outline-text-5" id="text-org160a3f9">
<div class="highlight">
<pre><span></span>Feature: A Word Frequency Counter

In order to get a sense of how the words correlate with sentiment
I want to be able to count word-sentiment pairs.

&lt;&lt;counter-feature&gt;&gt;

&lt;&lt;call-feature&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be</span><span class="p">,</span>
    <span class="n">equal</span><span class="p">,</span>
    <span class="n">expect</span>
    <span class="p">)</span>

<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">then</span><span class="p">,</span>
    <span class="n">when</span>
<span class="p">)</span>

<span class="c1"># testing setup</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>

<span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/word_frequencies.feature"</span><span class="p">)</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">creation</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">call</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
</li>
<li><a id="orgb77db8d"></a>Setup<br>
<div class="outline-text-5" id="text-orgb77db8d">
<div class="highlight">
<pre><span></span>Scenario: The Word Counter is created
  Given a word counter class
  When the word counter is created
  Then it has the expected attributes
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The Word Counter is created</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a word counter class"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_class</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">definition</span> <span class="o">=</span> <span class="n">WordCounter</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the word counter is created"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">create_word_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">Mock</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">Mock</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">definition</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                           <span class="n">labels</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">processor</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it has the expected attributes"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_attributes</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">processor</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org6dd8285"></a>The Call<br>
<div class="outline-text-5" id="text-org6dd8285">
<div class="highlight">
<pre><span></span>Scenario: The Word Frequency counter is called
  Given a word frequency counter
  When the counter is called
  Then the counts are the expected
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The Word Frequency counter is called</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a word frequency counter"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_word_frequency_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"a b aab a b c"</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                   <span class="n">labels</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>

    <span class="n">bad_sentiment</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"c aab aab"</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">+=</span> <span class="n">bad_sentiment</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># since the tokenizer removes and changes words</span>
    <span class="c1"># I'm going to mock it out</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">TwitterProcessor</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">{(</span><span class="s2">"a"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="s2">"b"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="s2">"aab"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                         <span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="s2">"aab"</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">2</span><span class="p">}</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the counter is called"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the counts are the expected"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org8733e5d">
<h4 id="org8733e5d">Implementation</h4>
<div class="outline-text-4" id="text-org8733e5d">
<p>This is going to be a counter class that pre-processes the tweets and then counts the frequency of word-sentiment pairs.</p>
<div class="highlight">
<pre><span></span><span class="c1"># A Word Counter</span>

<span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">typing</span>

<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>

<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">WordCounter</span><span class="p">:</span>
    <span class="sd">"""A word-sentiment counter</span>

<span class="sd">    Args:</span>
<span class="sd">     tweets: list of unprocessed tweets</span>
<span class="sd">     labels: list of 1's (positive) and 0's that identifies sentiment for each tweet</span>
<span class="sd">    """</span>
    <span class="n">tweets</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">_process</span><span class="p">:</span> <span class="n">TwitterProcessor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_processed</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_counts</span><span class="p">:</span> <span class="n">Counter</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TwitterProcessor</span><span class="p">:</span>
        <span class="sd">"""A callable to process tweets to lists of words"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">processed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">"""The processed and tokenized tweets"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_processed</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processed</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">counts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Counter</span><span class="p">:</span>
        <span class="sd">"""Processes the tweets and labels</span>

<span class="sd">       Returns:</span>
<span class="sd">        counts of word-sentiment pairs</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> \
                <span class="sa">f</span><span class="s2">"Tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span><span class="si">}</span><span class="s2">, Labels: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">tweet</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">processed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">label</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgbfa0f41">
<h3 id="orgbfa0f41">Counting</h3>
<div class="outline-text-3" id="text-orgbfa0f41">
<p>Now we can do some counting.</p>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">tweets</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total token-sentiment pairs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[nltk_data] Downloading package stopwords to /home/athena/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Total token-sentiment pairs: 13,069
</pre>
<p>What are the most common? To make the rest of the post easier I'm going to set up a pandas DataFrame.</p>
<div class="highlight">
<pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">top_counts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
    <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="o">=</span> <span class="n">key</span>
    <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="n">sentiments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentiment</span><span class="p">)</span>
    <span class="n">top_counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>

<span class="n">top_counts</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">token</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span>
    <span class="n">count</span><span class="o">=</span><span class="n">top_counts</span><span class="p">,</span>
    <span class="n">sentiment</span><span class="o">=</span><span class="n">sentiments</span><span class="p">,</span>
<span class="p">))</span>

<span class="n">top_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">SENTIMENT</span><span class="p">[</span><span class="n">row</span><span class="p">])</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">top_counts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">20</span><span class="p">]))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">token</th>
<th class="org-right" scope="col">count</th>
<th class="org-left" scope="col">sentiment</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">:(</td>
<td class="org-right">4571</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">:)</td>
<td class="org-right">3568</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">:-)</td>
<td class="org-right">692</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">:D</td>
<td class="org-right">629</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">thank</td>
<td class="org-right">620</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">:-(</td>
<td class="org-right">493</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">love</td>
<td class="org-right">400</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">follow</td>
<td class="org-right">381</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">i'm</td>
<td class="org-right">343</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">…</td>
<td class="org-right">331</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">thi</td>
<td class="org-right">318</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">thi</td>
<td class="org-right">303</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">miss</td>
<td class="org-right">301</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">…</td>
<td class="org-right">289</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">pleas</td>
<td class="org-right">275</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">follow</td>
<td class="org-right">262</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">day</td>
<td class="org-right">246</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">want</td>
<td class="org-right">246</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">wa</td>
<td class="org-right">241</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">good</td>
<td class="org-right">238</td>
<td class="org-left">positive</td>
</tr>
</tbody>
</table>
<p>It's interesting that the only repeated tokens in the top 20 are ellipses, "follow" and "thi" and that the four most common tokens were smileys, although that's not surprising, perhaps. I didn't notice this at first, but the most common token is a negative one.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgb23899d">
<h3 id="orgb23899d">Plotting</h3>
<div class="outline-text-3" id="text-orgb23899d">
<p>The counts themselves are interesting, but it might be more informative to look at their distribution as well as whether some tokens are more positive or negative.</p>
</div>
<div class="outline-4" id="outline-container-orge03e637">
<h4 id="orge03e637">Positive Vs Negative</h4>
<div class="outline-text-4" id="text-orge03e637">
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">"bar"</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"count"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span> <span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Positive and Negative"</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">embedded</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_distribution"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">embedded</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-word-frequencies/positive_negative_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So it looks like negative sentiment is more common for the tokens, even though the tweets themselves were evenly split, suggesting that the negative tweets had a greater diversity of words.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgb8fd2a8">
<h4 id="orgb8fd2a8">Distribution</h4>
<div class="outline-text-4" id="text-orgb8fd2a8">
<div class="highlight">
<pre><span></span><span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="s2">"@token"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="s2">"@sentiment"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Count"</span><span class="p">,</span> <span class="s2">"@count"</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span><span class="o">=</span><span class="n">tooltips</span><span class="p">)</span>

<span class="n">CUTOFF</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">top_counts</span><span class="p">[:</span><span class="n">CUTOFF</span><span class="p">]</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">"count"</span><span class="p">,</span> <span class="n">hover_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">"token"</span><span class="p">,</span> <span class="s2">"sentiment"</span><span class="p">],</span>
    <span class="n">loglog</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
        <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">],</span>
        <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
        <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color</span><span class="p">,</span>
        <span class="n">line_color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color</span><span class="p">,</span>
        <span class="n">xaxis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Log-Log Count Distribution (top </span><span class="si">{</span><span class="n">CUTOFF</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"count_distribution"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-word-frequencies/count_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>This shows how steep the drop is from the two most common tokens which are then followed by a long tail. Without the logarithmic axes the drop is even more pronounced.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org5971d23">
<h4 id="org5971d23">Positive Vs Negative by Tweet</h4>
<div class="outline-text-4" id="text-org5971d23">
<div class="highlight">
<pre><span></span><span class="n">CUTOFF</span> <span class="o">=</span> <span class="mi">250</span>

<span class="n">top_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"positive"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="o">.</span><span class="n">sentiment</span><span class="o">==</span><span class="s2">"positive"</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>

<span class="n">top_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"negative"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="o">.</span><span class="n">sentiment</span><span class="o">==</span><span class="s2">"negative"</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span>
<span class="p">)</span>

<span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="s2">"@token"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Positive"</span><span class="p">,</span> <span class="s2">"@positive"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Negative"</span><span class="p">,</span> <span class="s2">"@negative"</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span><span class="o">=</span><span class="n">tooltips</span><span class="p">)</span>

<span class="n">grouped</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"token"</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">"positive"</span><span class="p">:</span> <span class="s2">"sum"</span><span class="p">,</span> <span class="s2">"negative"</span><span class="p">:</span> <span class="s2">"sum"</span><span class="p">})</span>
<span class="n">to_plot</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="c1"># log plots can't have zero values</span>
<span class="n">MIN</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">"positive"</span><span class="p">,</span> <span class="s2">"negative"</span><span class="p">):</span>
    <span class="n">to_plot</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_plot</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="c1">#    to_plot.loc[:, column] = to_plot.apply(</span>
<span class="c1">#        lambda row: row[column] if row[column] else MIN, axis="columns")</span>
<span class="n">MAX</span> <span class="o">=</span> <span class="n">to_plot</span><span class="o">.</span><span class="n">negative</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Curve</span><span class="p">(([</span><span class="n">MIN</span><span class="p">,</span> <span class="n">MAX</span><span class="p">],</span> <span class="p">[</span><span class="n">MIN</span><span class="p">,</span> <span class="n">MAX</span><span class="p">]))</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">)</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">to_plot</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span>
    <span class="n">hover_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">"token"</span><span class="p">])</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">scatter</span> <span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
        <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">],</span>
        <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
        <span class="n">logx</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Positive"</span><span class="p">,</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Negative"</span><span class="p">,</span>
        <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Log Positive vs Negative"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"scatter_plot"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-word-frequencies/scatter_plot.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So, we basically end up with two types of groupings - some tokens are lopsided to be either very negative or very positive and they show up in the straight line columns or rows, while other tokens are more evenly split, and they show up in the more distributed blob along the diagonal of the plot.</p>
<p>We can also see which tokens are the most negative (the highest along the y-axis) and the most positive (furthest along the x-axis).</p>
<p>The tokens along or around the red diagonal are evenly positive and negative so they probably aren't useful indicators of sentiment in and of themselves, while those furthest from the diagonal are the most biased to one side or the other so we might expect them to be useful in guessing a tweet's sentiment.</p>
<p>There are some unexpectedly negative tokens like "love" (400, 152) and "thank" (620, 107), but at this point we haven't really started to look at the sentiment yet so I'll leave further exploration for later.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb92dc66">
<h2 id="orgb92dc66">End</h2>
<div class="outline-text-2" id="text-orgb92dc66">
<p><b>Note:</b> This is a re-working of an exercise from Coursera's Natural Language Processing specialization.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/twitter-preprocessing-with-nltk/">Twitter Preprocessing With NLTK</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/twitter-preprocessing-with-nltk/" rel="bookmark"><time class="published dt-published" datetime="2020-07-03T21:23:48-07:00" itemprop="datePublished" title="2020-07-03 21:23">2020-07-03 21:23</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#org0de506d">Beginning</a>
<ul>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#org1e6f099">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#orgfe7aa73">Middle</a>
<ul>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#org1b4720e">Explore the Data</a></li>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#orgae00570">Processing the Data</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#org5eca3b4">End</a>
<ul>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#orgd8cc33d">Tests</a></li>
<li><a href="posts/nlp/twitter-preprocessing-with-nltk/#org9a7fc1b">Implementation</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org0de506d">
<h2 id="org0de506d">Beginning</h2>
<div class="outline-text-2" id="text-org0de506d">
<p>This is a look at taking a corpus of <a href="https://twitter.com/explore">Twitter</a> data gathered as part of the <a href="https://www.nltk.org/">Natural Language Toolkit (NLTK)</a> and creating a preprocessor for a <a href="https://www.wikiwand.com/en/Sentiment_analysis">Sentiment Analysis</a> pipeline. This dataset has entries whose sentiment was categorized by hand so it's a convenient source for training models.</p>
<p>The <a href="https://www.nltk.org/howto/corpus.html">NLTK Corpus How To</a> has a brief description of the Twitter dataset and they also have <a href="https://www.nltk.org/howto/twitter.html">some documentation</a> about how to gather new data using the Twitter API yourself.</p>
</div>
<div class="outline-3" id="outline-container-org1e6f099">
<h3 id="org1e6f099">Set Up</h3>
<div class="outline-text-3" id="text-org1e6f099"></div>
<div class="outline-4" id="outline-container-org04b44c3">
<h4 id="org04b44c3">Imports</h4>
<div class="outline-text-4" id="text-org04b44c3">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">TweetTokenizer</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">CountPercentage</span><span class="p">,</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org691d328">
<h4 id="org691d328">Data</h4>
<div class="outline-text-4" id="text-org691d328">
<p>The first thing to do is download the dataset using the <a href="https://www.nltk.org/data.html">download</a> function. If you don't pass an argument to it a dialog will open and you can choose to download any or all of their datasets, but for this exercise we'll just download the Twitter samples. Note that if you run this function and the samples were already downloaded then it won't re-download them so it's safe to call it in any case.</p>
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'twitter_samples'</span><span class="p">)</span>
</pre></div>
<p>The data is contained in three files. You can see the file names using the <code>twitter_samples.fileids</code> function.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">fileids</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
- negative_tweets.json
- positive_tweets.json
- tweets.20150430-223406.json
</pre>
<p>As you can see (or maybe guess) two of the files contain tweets that have been categorized as negative or positive. The third file has another 20,000 tweets that aren't classified.</p>
<p>If you want to work with the files directly without using the NLTK interface (or move or delete them) you can use the <code>twitter_samples.abspaths</code> function to see where they are.</p>
<div class="highlight">
<pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">abspaths</span><span class="p">())</span>
</pre></div>
<pre class="example">
[FileSystemPathPointer('/home/athena/nltk_data/corpora/twitter_samples/negative_tweets.json'),
 FileSystemPathPointer('/home/athena/nltk_data/corpora/twitter_samples/positive_tweets.json'),
 FileSystemPathPointer('/home/athena/nltk_data/corpora/twitter_samples/tweets.20150430-223406.json')]
</pre>
<p>The dataset contains the JSON for each tweet, including some metadata, which you can access through the <code>twitter_samples.docs</code> function. Here's a sample.</p>
<div class="highlight">
<pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">docs</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
{'contributors': None,
 'coordinates': None,
 'created_at': 'Fri Jul 24 10:42:49 +0000 2015',
 'entities': {'hashtags': [], 'symbols': [], 'urls': [], 'user_mentions': []},
 'favorite_count': 0,
 'favorited': False,
 'geo': None,
 'id': 624530164626534400,
 'id_str': '624530164626534400',
 'in_reply_to_screen_name': None,
 'in_reply_to_status_id': None,
 'in_reply_to_status_id_str': None,
 'in_reply_to_user_id': None,
 'in_reply_to_user_id_str': None,
 'is_quote_status': False,
 'lang': 'en',
 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},
 'place': None,
 'retweet_count': 0,
 'retweeted': False,
 'source': '&lt;a href="https://mobile.twitter.com" rel="nofollow"&gt;Mobile Web '
           '(M2)&lt;/a&gt;',
 'text': 'hopeless for tmr :(',
 'truncated': False,
 'user': {'contributors_enabled': False,
          'created_at': 'Sun Mar 08 05:43:40 +0000 2015',
          'default_profile': False,
          'default_profile_image': False,
          'description': '⇨ [V] TravelGency █ 2/4 Goddest from Girls Day █ 92L '
                         '█ sucrp',
          'entities': {'description': {'urls': []}},
          'favourites_count': 196,
          'follow_request_sent': False,
          'followers_count': 1281,
          'following': False,
          'friends_count': 1264,
          'geo_enabled': True,
          'has_extended_profile': False,
          'id': 3078803375,
          'id_str': '3078803375',
          'is_translation_enabled': False,
          'is_translator': False,
          'lang': 'id',
          'listed_count': 3,
          'location': 'wearegsd;favor;pucukfams;barbx',
          'name': 'yuwra ✈ ',
          'notifications': False,
          'profile_background_color': '000000',
          'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/585476378365014016/j1mvQu3c.png',
          'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/585476378365014016/j1mvQu3c.png',
          'profile_background_tile': True,
          'profile_banner_url': 'https://pbs.twimg.com/profile_banners/3078803375/1433287528',
          'profile_image_url': 'http://pbs.twimg.com/profile_images/622631732399898624/kmYsX_k1_normal.jpg',
          'profile_image_url_https': 'https://pbs.twimg.com/profile_images/622631732399898624/kmYsX_k1_normal.jpg',
          'profile_link_color': '000000',
          'profile_sidebar_border_color': '000000',
          'profile_sidebar_fill_color': '000000',
          'profile_text_color': '000000',
          'profile_use_background_image': True,
          'protected': False,
          'screen_name': 'yuwraxkim',
          'statuses_count': 19710,
          'time_zone': 'Jakarta',
          'url': None,
          'utc_offset': 25200,
          'verified': False}}
</pre>
<p>There's some potentially useful data here - like if the tweet was re-tweeted, but for what we're doing we'll just use the tweet itself.</p>
<p>To get just the text of the tweets you use the <code>twitter_samples.strings</code> function.</p>
<div class="highlight">
<pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">)</span>
</pre></div>
<pre class="example">
Help on method strings in module nltk.corpus.reader.twitter:

strings(fileids=None) method of nltk.corpus.reader.twitter.TwitterCorpusReader instance
    Returns only the text content of Tweets in the file(s)
    
    :return: the given file(s) as a list of Tweets.
    :rtype: list(str)

</pre>
<p>Note that it says that it returns only the given file(s) as a list of tweets but it also makes the <code>fileids</code> argument optional. If you don't pass in any argument you end up with the tweets from all the files in the same list, which you probably don't want.</p>
<div class="highlight">
<pre><span></span><span class="n">positive_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s1">'positive_tweets.json'</span><span class="p">)</span>
<span class="n">negative_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s1">'negative_tweets.json'</span><span class="p">)</span>
<span class="n">all_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"tweets.20150430-223406.json"</span><span class="p">)</span>
</pre></div>
<p>Now I'll download the stopwords for our pre-processing and setup the english stopwords for use later.</p>
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'stopwords'</span><span class="p">)</span>
<span class="n">english_stopwords</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">"english"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf422d85">
<h4 id="orgf422d85">The Random Seed</h4>
<div class="outline-text-4" id="text-orgf422d85">
<p>This just sets the random seed so that we get the same values if we re-run this later on (although this is a little tricky with the notebook, since you can call the same code multiple times).</p>
<div class="highlight">
<pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">20200704</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfa9386d">
<h4 id="orgfa9386d">Plotting</h4>
<div class="outline-text-4" id="text-orgfa9386d">
<p>I won't be doing a lot of plotting here, but this is a setup for the little that I do.</p>
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"twitter-preprocessing-with-nltk"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"../../files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                <span class="n">create_folder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgfe7aa73">
<h2 id="orgfe7aa73">Middle</h2>
<div class="outline-text-2" id="text-orgfe7aa73">
<p>It can be more convenient to use a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/series.html">Pandas Series</a> for some checks of the tweets so I'll convert the all-tweets list to one.</p>
<div class="highlight">
<pre><span></span><span class="n">all_tweets</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">all_tweets</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org1b4720e">
<h3 id="org1b4720e">Explore the Data</h3>
<div class="outline-text-3" id="text-org1b4720e">
<p>Let's start by looking at the number of tweets we got and confirming that the <code>strings</code> function gave us back a list of strings like the docstring said it would.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tweets</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of positive tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">positive_tweets</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of negative tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_tweets</span><span class="p">)</span><span class="si">:</span><span class="s1">,</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">thing</span> <span class="ow">in</span> <span class="p">(</span><span class="n">positive_tweets</span><span class="p">,</span> <span class="n">negative_tweets</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">thing</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">thing</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">str</span>
</pre></div>
<pre class="example">
Number of tweets: 20,000
Number of positive tweets: 5,000
Number of negative tweets: 5,000
</pre>
<p>We can see that the data for each file is made up of strings stored in a list and there were 20,000 tweets in total but only half as much were categorized.</p>
</div>
<div class="outline-4" id="outline-container-org0083967">
<h4 id="org0083967">Looking At Some Examples</h4>
<div class="outline-text-4" id="text-org0083967">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Positive Tweet: </span><span class="si">{</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">positive_tweets</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random Negative Tweet: </span><span class="si">{</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">negative_tweets</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Random Positive Tweet: @Aaliyan_ Lucky me :))
Random Negative Tweet: @NotRedbutBlue awww :(
at least u never got called luis manzano tho
</pre>
<p>Sometimes the tweets look more like text message replies than micro-blog posts. One thing the original exercise noted is that there are <a href="https://www.wikiwand.com/en/Emoji">Emoticons</a> in the dataset that need to be handled.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org2e7caca">
<h4 id="org2e7caca">The First Token</h4>
<div class="outline-text-4" id="text-org2e7caca">
<p>Later on we're going to remove the "RT" (re-tweet) token at the start of the strings. Let's look at how significant this is.</p>
<div class="highlight">
<pre><span></span><span class="n">first_tokens</span> <span class="o">=</span> <span class="n">tweets</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">expand</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">top_ten</span> <span class="o">=</span> <span class="n">CountPercentage</span><span class="p">(</span><span class="n">first_tokens</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">value_label</span><span class="o">=</span><span class="s2">"First Token"</span><span class="p">)</span>
<span class="n">top_ten</span><span class="p">()</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">First Token</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">RT</td>
<td class="org-right">13287</td>
<td class="org-right">92.92</td>
</tr>
<tr>
<td class="org-left">I</td>
<td class="org-right">160</td>
<td class="org-right">1.12</td>
</tr>
<tr>
<td class="org-left">Farage</td>
<td class="org-right">141</td>
<td class="org-right">0.99</td>
</tr>
<tr>
<td class="org-left">The</td>
<td class="org-right">134</td>
<td class="org-right">0.94</td>
</tr>
<tr>
<td class="org-left">VIDEO:</td>
<td class="org-right">132</td>
<td class="org-right">0.92</td>
</tr>
<tr>
<td class="org-left">Nigel</td>
<td class="org-right">117</td>
<td class="org-right">0.82</td>
</tr>
<tr>
<td class="org-left">Ed</td>
<td class="org-right">116</td>
<td class="org-right">0.81</td>
</tr>
<tr>
<td class="org-left">Miliband</td>
<td class="org-right">77</td>
<td class="org-right">0.54</td>
</tr>
<tr>
<td class="org-left">SNP</td>
<td class="org-right">69</td>
<td class="org-right">0.48</td>
</tr>
<tr>
<td class="org-left">@UKIP</td>
<td class="org-right">67</td>
<td class="org-right">0.47</td>
</tr>
</tbody>
</table>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">top_ten</span><span class="o">.</span><span class="n">table</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"Percent (%)"</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">"First Token"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Top Ten Tweet First Tokens"</span><span class="p">,</span> 
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"top_ten"</span><span class="p">,</span> <span class="n">create_folder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">())</span>
</pre></div>
<object data="posts/nlp/twitter-preprocessing-with-nltk/top_ten.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So, about 93 % of the unclassified tweets start with <code>RT</code>, making it perhaps not so informative a token. Or maybe it is… what does a re-tweet tell us? Let's look at if the re-tweeted show up as duplicates and if so, how many times they show up.</p>
<div class="highlight">
<pre><span></span><span class="n">retweeted</span> <span class="o">=</span> <span class="n">tweets</span><span class="p">[</span><span class="n">tweets</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"RT"</span><span class="p">)]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">retweeted</span><span class="o">.</span><span class="n">values</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{</span><span class="n">item</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>491</li>
<li>430</li>
<li>131</li>
<li>131</li>
<li>117</li>
<li>103</li>
<li>82</li>
<li>73</li>
<li>69</li>
<li>68</li>
</ul>
<p>Some of the entries are the same tweet repeated hundreds of times. Does each one count as an additional entry? I don't show it here because the tweets are kind of long, but the top five are all about British politics, so there might have been some kind of bias in the way the tweets were gathered.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgae00570">
<h3 id="orgae00570">Processing the Data</h3>
<div class="outline-text-3" id="text-orgae00570">
<p>There are four basic steps for NLP pre-processing:</p>
<ul class="org-ul">
<li><a href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html">Tokenization</a></li>
<li>Lower-casing</li>
<li>Removing <a href="https://www.wikiwand.com/en/Stop_words">stop words</a> and punctuation</li>
<li><a href="https://www.wikiwand.com/en/Stemming">Stemming</a></li>
</ul>
<p>We're going to start by taking one tweet and seeing how it is transformed by this process.</p>
<div class="highlight">
<pre><span></span><span class="n">THE_CHOSEN</span> <span class="o">=</span> <span class="n">positive_tweets</span><span class="p">[</span><span class="mi">2277</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">THE_CHOSEN</span><span class="p">)</span>
</pre></div>
<pre class="example">
My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i
</pre></div>
<div class="outline-4" id="outline-container-orgf165fe4">
<h4 id="orgf165fe4">Cleaning Up Twitter-Specific Markup</h4>
<div class="outline-text-4" id="text-orgf165fe4">
<p>Although I listed four steps in the beginning, there's often another step where we remove things that are common or not useful but known in advance. In this case we want to remove re-tweet tags (<code>RT</code>), hyperlinks, and hashtags. We're going to do that with python's built in <a href="https://docs.python.org/3/library/re.html">regular expression</a> module. We're also going to do it one tweet at a time, although you could perhapse more efficiently do it in bulk using pandas.</p>
<div class="highlight">
<pre><span></span><span class="n">START_OF_LINE</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"^"</span>
<span class="n">OPTIONAL</span> <span class="o">=</span> <span class="s2">"?"</span>
<span class="n">ANYTHING</span> <span class="o">=</span> <span class="s2">"."</span>
<span class="n">ZERO_OR_MORE</span> <span class="o">=</span> <span class="s2">"*"</span>
<span class="n">ONE_OR_MORE</span> <span class="o">=</span> <span class="s2">"+"</span>

<span class="n">SPACE</span> <span class="o">=</span> <span class="s2">"\s"</span>
<span class="n">SPACES</span> <span class="o">=</span> <span class="n">SPACE</span> <span class="o">+</span> <span class="n">ONE_OR_MORE</span>
<span class="n">EVERYTHING_OR_NOTHING</span> <span class="o">=</span> <span class="n">ANYTHING</span> <span class="o">+</span> <span class="n">ZERO_OR_MORE</span>

<span class="n">ERASE</span> <span class="o">=</span> <span class="s2">""</span>
<span class="n">FORWARD_SLASH</span> <span class="o">=</span> <span class="s2">"\/"</span>
<span class="n">NEWLINES</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"[\r\n]"</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org0348ab1"></a>Re-Tweets<br>
<div class="outline-text-5" id="text-org0348ab1">
<p>None of the positive or negative samples have this tag so I'm going to pull an example from the complete set just to show it working.</p>
<div class="highlight">
<pre><span></span><span class="n">RE_TWEET</span> <span class="o">=</span> <span class="n">START_OF_LINE</span> <span class="o">+</span> <span class="s2">"RT"</span> <span class="o">+</span> <span class="n">SPACES</span>

<span class="n">tweet</span> <span class="o">=</span> <span class="n">all_tweets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
<span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">RE_TWEET</span><span class="p">,</span> <span class="n">ERASE</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
</pre></div>
<pre class="example">
RT @KirkKus: Indirect cost of the UK being in the EU is estimated to be costing Britain £170 billion per year! #BetterOffOut #UKIP
@KirkKus: Indirect cost of the UK being in the EU is estimated to be costing Britain £170 billion per year! #BetterOffOut #UKIP
</pre></div>
</li>
<li><a id="orgb6ab8e4"></a>Hyperlinks<br>
<div class="outline-text-5" id="text-orgb6ab8e4">
<div class="highlight">
<pre><span></span><span class="n">HYPERLINKS</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"http"</span> <span class="o">+</span> <span class="s2">"s"</span> <span class="o">+</span> <span class="n">OPTIONAL</span> <span class="o">+</span> <span class="s2">":"</span> <span class="o">+</span> <span class="n">FORWARD_SLASH</span> <span class="o">+</span> <span class="n">FORWARD_SLASH</span>
              <span class="o">+</span> <span class="n">EVERYTHING_OR_NOTHING</span> <span class="o">+</span> <span class="n">NEWLINES</span> <span class="o">+</span> <span class="n">ZERO_OR_MORE</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">THE_CHOSEN</span><span class="p">)</span>
<span class="n">re_chosen</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">HYPERLINKS</span><span class="p">,</span> <span class="n">ERASE</span><span class="p">,</span> <span class="n">THE_CHOSEN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">re_chosen</span><span class="p">)</span>
</pre></div>
<pre class="example">
My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… https://t.co/3tfYom0N1i
My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off… 
</pre>
<p>Note that the way the regular expression is written, it eats everything after the <code>http</code>.</p>
</div>
</li>
<li><a id="orgde54b3d"></a>HashTags<br>
<div class="outline-text-5" id="text-orgde54b3d">
<p>We aren't removing the actual hash-tags, just the hash-marks (<code>#</code>).</p>
<div class="highlight">
<pre><span></span><span class="n">HASH</span> <span class="o">=</span> <span class="s2">"#"</span>
<span class="n">re_chosen</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">HASH</span><span class="p">,</span> <span class="n">ERASE</span><span class="p">,</span> <span class="n">re_chosen</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">re_chosen</span><span class="p">)</span>
</pre></div>
<pre class="example">
My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off… 
</pre></div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgc5bec8e">
<h4 id="orgc5bec8e">Tokenize</h4>
<div class="outline-text-4" id="text-orgc5bec8e">
<p>NLTK has a tokenizer specially built for tweets. The <code>twitter_samples</code> module actually has a <code>tokenizer</code> function that breaks the tweets up, but since we are using regular expressions to clean up the strings a little first, it makes more sense to tokenize the strings afterwards. Also note that one of the steps in the pipeline is to lower-case the letters, which the <code>TweetTokenizer</code> will do for us if we set the <code>preserve_case</code> argument to <code>False</code>.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">TweetTokenizer</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on class TweetTokenizer in module nltk.tokenize.casual:

class TweetTokenizer(builtins.object)
 |  TweetTokenizer(preserve_case=True, reduce_len=False, strip_handles=False)
 |  
 |  Tokenizer for tweets.
 |  
 |      &gt;&gt;&gt; from nltk.tokenize import TweetTokenizer
 |      &gt;&gt;&gt; tknzr = TweetTokenizer()
 |      &gt;&gt;&gt; s0 = "This is a cooool #dummysmiley: :-) :-P &lt;3 and some arrows &lt; &gt; -&gt; &lt;--"
 |      &gt;&gt;&gt; tknzr.tokenize(s0)
 |      ['This', 'is', 'a', 'cooool', '#dummysmiley', ':', ':-)', ':-P', '&lt;3', 'and', 'some', 'arrows', '&lt;', '&gt;', '-&gt;', '&lt;--']
 |  
 |  Examples using `strip_handles` and `reduce_len parameters`:
 |  
 |      &gt;&gt;&gt; tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)
 |      &gt;&gt;&gt; s1 = '@remy: This is waaaaayyyy too much for you!!!!!!'
 |      &gt;&gt;&gt; tknzr.tokenize(s1)
 |      [':', 'This', 'is', 'waaayyy', 'too', 'much', 'for', 'you', '!', '!', '!']
 |  
 |  Methods defined here:
 |  
 |  __init__(self, preserve_case=True, reduce_len=False, strip_handles=False)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  tokenize(self, text)
 |      :param text: str
 |      :rtype: list(str)
 |      :return: a tokenized list of strings; concatenating this list returns        the original string if `preserve_case=False`
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)

None
</pre>
<div class="highlight">
<pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<p>As I mentioned, <code>preserve_case</code> lower-cases the letters. The other two arguments are <code>strip_handles</code> which removes the twitter-handles and <code>reduce_len</code> which limits the number of times a character can be repeated to three - so <code>zzzzz</code> will be changed to <code>zzz</code>. Now we can tokenize our partly cleaned token.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">re_chosen</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">re_chosen</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
<pre class="example">
My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off… 
['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '…']
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgf914908">
<h4 id="orgf914908">Remove Stop Words and Punctuation</h4>
<div class="outline-text-4" id="text-orgf914908">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">english_stopwords</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
</pre></div>
<pre class="example">
['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]
!"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\]^_`{|}~
</pre>
<div class="highlight">
<pre><span></span><span class="n">cleaned</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">english_stopwords</span> <span class="ow">and</span>
                                       <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
</pre></div>
<pre class="example">
['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '…']
</pre></div>
</div>
<div class="outline-4" id="outline-container-org5aff1f3">
<h4 id="org5aff1f3">Stemming</h4>
<div class="outline-text-4" id="text-org5aff1f3">
<p>We're going to use the <a href="https://www.nltk.org/_modules/nltk/stem/porter.html">Porter Stemmer</a> from NLTK (<a href="https://tartarus.org/martin/PorterStemmer/">this</a> is the official Porter Stemmer algorithm page) to stem the words.</p>
<div class="highlight">
<pre><span></span><span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">stemmed</span> <span class="o">=</span> <span class="p">[</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">cleaned</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stemmed</span><span class="p">)</span>
</pre></div>
<pre class="example">
['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '…']
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org5eca3b4">
<h2 id="org5eca3b4">End</h2>
<div class="outline-text-2" id="text-org5eca3b4">
<p>So now we've seen the basic steps that we're going to need to preprocess our tweets for <a href="https://www.wikiwand.com/en/Sentiment_analysis">Sentiment Analysis</a>.</p>
<p><b>Note:</b> This is a re-write of an exercise taken from Coursera's <a href="https://www.deeplearning.ai/natural-language-processing-specialization/">Natural Language Processing</a> specialization.</p>
<p>The rest of this is outside the scope of the exercise, it's just to get it all into one place.</p>
</div>
<div class="outline-3" id="outline-container-orgd8cc33d">
<h3 id="orgd8cc33d">Tests</h3>
<div class="outline-text-3" id="text-orgd8cc33d">
<p>I'm going to use <a href="https://github.com/pytest-dev/pytest-bdd">pytest-bdd</a> to run the tests for the pre-processor but I'm also going to take advantage of org-babel and keep the scenario definitions and the test functions grouped by what they do, even though they will exist in two different files (<code>tweet_preprocessing.feature</code> and <code>test_preprocessing.py</code>) when tangled out of this file.</p>
</div>
<div class="outline-4" id="outline-container-org73b8c6e">
<h4 id="org73b8c6e">The Tangles</h4>
<div class="outline-text-4" id="text-org73b8c6e">
<div class="highlight">
<pre><span></span>Feature: Tweet pre-processor

&lt;&lt;stock-processing&gt;&gt;

&lt;&lt;re-tweet-processing&gt;&gt;

&lt;&lt;hyperlink-processing&gt;&gt;

&lt;&lt;hash-processing&gt;&gt;

&lt;&lt;tokenization-preprocessing&gt;&gt;

&lt;&lt;stop-word-preprocessing&gt;&gt;

&lt;&lt;stem-preprocessing&gt;&gt;

&lt;&lt;whole-shebang-preprocessing&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">pytest</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>

<span class="k">class</span> <span class="nc">Katamari</span><span class="p">:</span>
    <span class="sd">"""Something to stick values into"""</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">katamari</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">Katamari</span><span class="p">()</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">processor</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">contain_exactly</span><span class="p">,</span>
    <span class="n">equal</span><span class="p">,</span>
    <span class="n">expect</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">then</span><span class="p">,</span>
    <span class="n">when</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">And</span> <span class="o">=</span> <span class="n">when</span>


<span class="c1"># fixtures</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span><span class="p">,</span> <span class="n">processor</span>

<span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/tweet_preprocessing.feature"</span><span class="p">)</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">stock</span><span class="o">-</span><span class="n">symbol</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">re</span><span class="o">-</span><span class="n">tweet</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">hyperlinks</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">hashtags</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">tokenization</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">unstopping</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">stem</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">call</span><span class="o">&gt;&gt;</span>
</pre></div>
<p>Now on to the sections that go into the tangles.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orge971bc4">
<h4 id="orge971bc4">Stock Symbols</h4>
<div class="outline-text-4" id="text-orge971bc4">
<p>Twitter has a special symbol for stocks which is a dollar sign followed by the stock ticker name (e.g. <code>$HOG</code> for Harley Davidson) that I'll remove. This is going to assume anything with a dollar sign immediately followed by a letter, number, or underscore is a stock symbol.</p>
<div class="highlight">
<pre><span></span>Scenario: A tweet with a stock symbol is cleaned
  Given a tweet with a stock symbol in it
  When the tweet is cleaned
  Then it has the text removed
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1">#Scenario: A tweet with a stock symbol is cleaned</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a tweet with a stock symbol in it"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_stock_symbol</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">):</span>
    <span class="n">symbol</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_uppercase</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">head</span><span class="p">,</span> <span class="n">tail</span> <span class="o">=</span> <span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">(),</span> <span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">to_clean</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">head</span><span class="si">}</span><span class="s2"> $</span><span class="si">{</span><span class="n">symbol</span><span class="si">}</span><span class="s2"> "</span>
                         <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">tail</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># the cleaner ignores spaces so there's going to be two spaces between</span>
    <span class="c1"># the head and tail after the symbol is removed</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">head</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">tail</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">return</span>

<span class="c1">#   When the tweet is cleaned</span>
<span class="c1">#   Then it has the text removed</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb16cc3c">
<h4 id="orgb16cc3c">The Re-tweets</h4>
<div class="outline-text-4" id="text-orgb16cc3c">
<p>This tests that we can remove the RT tag.</p>
<div class="highlight">
<pre><span></span>Scenario: A re-tweet is cleaned.

  Given a tweet that has been re-tweeted
  When the tweet is cleaned
  Then it has the text removed
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: A re-tweet is cleaned.</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a tweet that has been re-tweeted"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_re_tweet</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()</span>
    <span class="n">spaces</span> <span class="o">=</span> <span class="s2">" "</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">to_clean</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"RT</span><span class="si">{</span><span class="n">spaces</span><span class="si">}{</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the tweet is cleaned"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">process_tweet</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">clean</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">to_clean</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it has the text removed"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_cleaned_text</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcb65889">
<h4 id="orgcb65889">Hyperlinks</h4>
<div class="outline-text-4" id="text-orgcb65889">
<p>Now test that we can remove hyperlinks.</p>
<div class="highlight">
<pre><span></span>Scenario: The tweet has a hyperlink
  Given a tweet with a hyperlink
  When the tweet is cleaned
  Then it has the text removed
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The tweet has a hyperlink</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a tweet with a hyperlink"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_hyperlink</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">):</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="n">base</span> <span class="o">+</span> <span class="s2">" :)"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">to_clean</span> <span class="o">=</span> <span class="n">base</span> <span class="o">+</span> <span class="n">faker</span><span class="o">.</span><span class="n">uri</span><span class="p">()</span> <span class="o">+</span> <span class="s2">" :)"</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc27bf5a">
<h4 id="orgc27bf5a">Hash Symbols</h4>
<div class="outline-text-4" id="text-orgc27bf5a">
<p>Test that we can remove the pound symbol.</p>
<div class="highlight">
<pre><span></span>Scenario: A tweet has hash symbols in it.
  Given a tweet with hash symbols
  When the tweet is cleaned
  Then it has the text removed
</pre></div>
<div class="highlight">
<pre><span></span><span class="nd">@given</span><span class="p">(</span><span class="s2">"a tweet with hash symbols"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_hash_symbols</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">):</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">expected_tokens</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">faker</span><span class="o">.</span><span class="n">word</span><span class="p">()</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">index</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="sa">f</span><span class="s2">"#</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokens</span><span class="p">[</span><span class="n">index</span><span class="p">:]</span>
        <span class="n">expected_tokens</span> <span class="o">=</span> <span class="n">expected_tokens</span><span class="p">[:</span><span class="n">index</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+</span> <span class="n">expected_tokens</span><span class="p">[</span><span class="n">index</span><span class="p">:]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">to_clean</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">expected_tokens</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1ceba08">
<h4 id="org1ceba08">Tokenization</h4>
<div class="outline-text-4" id="text-org1ceba08">
<p>This is being done by NLTK, so it might not really make sense to test it, but I figured adding a test would make it more likely that I'd slow down enough to understand what it's doing.</p>
<div class="highlight">
<pre><span></span>Scenario: The text is tokenized
  Given a string of text
  When the text is tokenized
  Then it is the expected list of strings
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The text is tokenized</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a string of text"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_text</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="s2">"Time flies like an Arrow, fruit flies like a BANANAAAA!"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"time flies like an arrow , "</span>
                         <span class="s2">"fruit flies like a bananaaa !"</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the text is tokenized"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it is the expected list of strings"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_tokens</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb56d7ab">
<h4 id="orgb56d7ab">Stop Word Removal</h4>
<div class="outline-text-4" id="text-orgb56d7ab">
<p>Check that we're removing stop-words and punctuation.</p>
<div class="highlight">
<pre><span></span>Scenario: The user removes stop words and punctuation
  Given a tokenized string
  When the string is un-stopped
  Then it is the expected list of strings
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1">#Scenario: The user removes stop words and punctuation</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a tokenized string"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_tokenized_string</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"now is the winter of our discontent , "</span>
                       <span class="s2">"made glorious summer by this son of york ;"</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"winter discontent made glorious "</span>
                         <span class="s2">"summer son york"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the string is un-stopped"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">un_stop</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">remove_useless_tokens</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>
    <span class="k">return</span>
<span class="c1">#  Then it is the expected list of strings</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org948905a">
<h4 id="org948905a">Stemming</h4>
<div class="outline-text-4" id="text-org948905a">
<p>This is kind of a fake test. I guessed incorrectly what the stemming would do the first time so I had to go back and match the test values to what it output. I don't think I'll take the time to learn how the stemming is working, though, so it'll have to do.</p>
<div class="highlight">
<pre><span></span>Scenario: The user stems the tokens
  Given a tokenized string
  When the string is un-stopped
  And tokens are stemmed
  Then it is the expected list of strings
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user stems the tokens</span>
<span class="c1">#  Given a tokenized string</span>
<span class="c1">#  When the string is un-stopped</span>


<span class="nd">@And</span><span class="p">(</span><span class="s2">"tokens are stemmed"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">stem_tokens</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="s2">"winter discont made gloriou summer son york"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span>


<span class="c1">#  Then it is the expected list of strings</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0bfed34">
<h4 id="org0bfed34">The Whole Shebang</h4>
<div class="outline-text-4" id="text-org0bfed34">
<p>I made some of the steps separate just for illustration and testing, but I'll make the processor callable so they don't have to be done separately.</p>
<div class="highlight">
<pre><span></span>Scenario: The user calls the processor
  Given a tweet
  When the processor is called with the tweet
  Then it returns the cleaned, tokenized, and stemmed list
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user calls the processor</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a tweet"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_tweet</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">words</span> <span class="o">=</span> <span class="s2">"#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweet</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"RT </span><span class="si">{</span><span class="n">katamari</span><span class="o">.</span><span class="n">words</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">faker</span><span class="o">.</span><span class="n">uri</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span>  <span class="p">[</span><span class="s1">'followfriday'</span><span class="p">,</span> <span class="s1">'top'</span><span class="p">,</span> <span class="s1">'engag'</span><span class="p">,</span> <span class="s1">'member'</span><span class="p">,</span> <span class="s1">'commun'</span><span class="p">,</span> <span class="s1">'week'</span><span class="p">,</span> <span class="s1">':)'</span><span class="p">]</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the processor is called with the tweet"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">process_tweet</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it returns the cleaned, tokenized, and stemmed list"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_processed_tweet</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9a7fc1b">
<h3 id="org9a7fc1b">Implementation</h3>
<div class="outline-text-3" id="text-org9a7fc1b">
<p>I'm going to implement it as a class rather than a function just so that all this stuff that's floating around in the notebook as global variables is collected in one place.</p>
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">TweetTokenizer</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">nltk</span>

<span class="o">&lt;&lt;</span><span class="n">regular</span><span class="o">-</span><span class="n">expressions</span><span class="o">&gt;&gt;</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span>
<span class="k">class</span> <span class="nc">TwitterProcessor</span><span class="p">:</span>
    <span class="sd">"""processor for tweets"""</span>
    <span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">_stopwords</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">_stemmer</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">ib</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">clean</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">tokenizer</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">un</span><span class="o">-</span><span class="n">stop</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">stopwords</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">stemmer</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">stem</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">processor</span><span class="o">-</span><span class="n">call</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgb307289">
<h4 id="orgb307289">A Regular Expression Helper</h4>
<div class="outline-text-4" id="text-orgb307289">
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">WheatBran</span><span class="p">:</span>
    <span class="sd">"""This is a holder for the regular expressions"""</span>
    <span class="n">START_OF_LINE</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"^"</span>
    <span class="n">OPTIONAL</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{}</span><span class="s2">?"</span>
    <span class="n">ANYTHING</span> <span class="o">=</span> <span class="s2">"."</span>
    <span class="n">ZERO_OR_MORE</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{}</span><span class="s2">*"</span>
    <span class="n">ONE_OR_MORE</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{}</span><span class="s2">+"</span>
    <span class="n">ONE_OF_THESE</span> <span class="o">=</span> <span class="s2">"[</span><span class="si">{}</span><span class="s2">]"</span>

    <span class="n">NOT</span> <span class="o">=</span> <span class="s2">"^"</span>
    <span class="n">SPACE</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"\s"</span>
    <span class="n">SPACES</span> <span class="o">=</span> <span class="n">ONE_OR_MORE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">SPACE</span><span class="p">)</span>
    <span class="n">PART_OF_A_WORD</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"\w"</span>
    <span class="n">EVERYTHING_OR_NOTHING</span> <span class="o">=</span> <span class="n">ZERO_OR_MORE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ANYTHING</span><span class="p">)</span>
    <span class="n">EVERYTHING_BUT_SPACES</span> <span class="o">=</span> <span class="n">ZERO_OR_MORE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">ONE_OF_THESE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NOT</span> <span class="o">+</span> <span class="n">SPACE</span><span class="p">))</span>

    <span class="n">ERASE</span> <span class="o">=</span> <span class="s2">""</span>
    <span class="n">FORWARD_SLASHES</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"\/\/"</span>
    <span class="n">NEWLINES</span> <span class="o">=</span> <span class="n">ONE_OF_THESE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\r\n"</span><span class="p">)</span>
    <span class="c1"># a dollar is a special regular expression character meaning end of line</span>
    <span class="c1"># so escape it</span>
    <span class="n">DOLLAR_SIGN</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"\$"</span>

    <span class="c1"># to remove</span>
    <span class="n">STOCK_SYMBOL</span> <span class="o">=</span> <span class="n">DOLLAR_SIGN</span> <span class="o">+</span> <span class="n">ZERO_OR_MORE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">PART_OF_A_WORD</span><span class="p">)</span>
    <span class="n">RE_TWEET</span> <span class="o">=</span> <span class="n">START_OF_LINE</span> <span class="o">+</span> <span class="s2">"RT"</span> <span class="o">+</span> <span class="n">SPACES</span>
    <span class="n">HYPERLINKS</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"http"</span> <span class="o">+</span> <span class="n">OPTIONAL</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">"s"</span><span class="p">)</span> <span class="o">+</span> <span class="s2">":"</span> <span class="o">+</span> <span class="n">FORWARD_SLASHES</span>
                  <span class="o">+</span> <span class="n">EVERYTHING_BUT_SPACES</span> <span class="o">+</span> <span class="n">ZERO_OR_MORE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NEWLINES</span><span class="p">))</span>
    <span class="n">HASH</span> <span class="o">=</span> <span class="s2">"#"</span>

    <span class="n">remove</span> <span class="o">=</span> <span class="p">[</span><span class="n">STOCK_SYMBOL</span><span class="p">,</span> <span class="n">RE_TWEET</span><span class="p">,</span> <span class="n">HYPERLINKS</span><span class="p">,</span> <span class="n">HASH</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org314e4b7">
<h4 id="org314e4b7">The Clean Method</h4>
<div class="outline-text-4" id="text-org314e4b7">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">clean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">"""Removes sub-strings from the tweet</span>

<span class="sd">    Args:</span>
<span class="sd">     tweet: string tweet</span>

<span class="sd">    Returns:</span>
<span class="sd">     tweet with certain sub-strings removed</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">expression</span> <span class="ow">in</span> <span class="n">WheatBran</span><span class="o">.</span><span class="n">remove</span><span class="p">:</span>
        <span class="n">tweet</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">expression</span><span class="p">,</span> <span class="n">WheatBran</span><span class="o">.</span><span class="n">ERASE</span><span class="p">,</span> <span class="n">tweet</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tweet</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3dfcf94">
<h4 id="org3dfcf94">The Tokenizer</h4>
<div class="outline-text-4" id="text-org3dfcf94">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TweetTokenizer</span><span class="p">:</span>
    <span class="sd">"""The NLTK Tweet Tokenizer</span>

<span class="sd">    It will:</span>
<span class="sd">     - tokenize a string</span>
<span class="sd">     - remove twitter handles</span>
<span class="sd">     - remove repeated characters after the first three</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">preserve_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgea5fc92">
<h4 id="orgea5fc92">Stopwords</h4>
<div class="outline-text-4" id="text-orgea5fc92">
<p>This might make more sense to be done at the module level, but I'll see how it goes.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">stopwords</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""NLTK English stopwords</span>

<span class="sd">    Warning:</span>
<span class="sd">     if the stopwords haven't been downloaded this also tries too download them</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stopwords</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'stopwords'</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stopwords</span> <span class="o">=</span>  <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">"english"</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stopwords</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org301b4cb">
<h4 id="org301b4cb">Un-Stop the Tokens</h4>
<div class="outline-text-4" id="text-org301b4cb">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">remove_useless_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Remove stopwords and punctuation</span>

<span class="sd">    Args:</span>
<span class="sd">     tokens: list of strings</span>

<span class="sd">    Returns:</span>
<span class="sd">     tokens with unuseful tokens removed</span>
<span class="sd">    """</span>    
    <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="p">(</span><span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopwords</span> <span class="ow">and</span>
                                        <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge4064f7">
<h4 id="orge4064f7">Stem the Tokens</h4>
<div class="outline-text-4" id="text-orge4064f7">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">stemmer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PorterStemmer</span><span class="p">:</span>
    <span class="sd">"""Porter Stemmer for the tokens"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stemmer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stemmer</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">stem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf6e1f68">
<h4 id="orgf6e1f68">Call Me</h4>
<div class="outline-text-4" id="text-orgf6e1f68">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""does all the processing in one step</span>

<span class="sd">    Args:</span>
<span class="sd">     tweet: string to process</span>
<span class="sd">    """</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clean</span><span class="p">(</span><span class="n">tweet</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
    <span class="c1"># the stopwords are un-stemmed so this has to come before stemming</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_useless_tokens</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
    <span class="n">cleaned</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cleaned</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/keras/flask-tensorflow-and-mnist/">Flask, TensorFlow, Streamlit and the MNIST Dataset</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/keras/flask-tensorflow-and-mnist/" rel="bookmark"><time class="published dt-published" datetime="2020-06-18T15:43:56-07:00" itemprop="datePublished" title="2020-06-18 15:43">2020-06-18 15:43</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org7968487">Beginning</a>
<ul>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#orga0aff42">Set Up</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#orgf653fe6">The Environment</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org9cc4abd">Plotting</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#orgdc1ac07">The Random Seed</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org2b098cb">The Data</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org7b2277f">A Note On the Tangling</a></li>
</ul>
</li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org56cea66">Middle</a>
<ul>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#orgb023a7e">The Data</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org28752fb">The Neural Network Model</a></li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org1db0c03">The Web Page</a></li>
</ul>
</li>
<li><a href="posts/keras/flask-tensorflow-and-mnist/#org7a02e0b">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org7968487">
<h2 id="org7968487">Beginning</h2>
<div class="outline-text-2" id="text-org7968487">
<p>This is a re-working of Coursera's <a href="https://www.coursera.org/learn/neural-network-visualizer/home/welcome">Neural Network Vizualizer Web App With Python</a> course. What we'll do is use <a href="https://www.tensorflow.org/">tensorflow</a> to build a model to classify images of handwritten digits from the <a href="http://yann.lecun.com/exdb/mnist/">MNIST Database of Handwritten Digits</a> which tensoflow provides as one of their pre-built datasets. MNIST (according to <a href="https://www.wikiwand.com/en/MNIST_database">wikipedia</a>) stands for <i>Modified <a href="https://www.wikiwand.com/en/National_Institute_of_Standards_and_Technology">National Institute of Standards and Technology</a></i> (so we're using the Modified NIST Database).</p>
<p>Once we have the model we'll use <a href="https://palletsprojects.com/p/flask/">Flask</a> to serve up the model and <a href="https://www.streamlit.io/">Streamlit</a> to build a web page to view the results.</p>
</div>
<div class="outline-3" id="outline-container-orga0aff42">
<h3 id="orga0aff42">Set Up</h3>
<div class="outline-text-3" id="text-orga0aff42"></div>
<div class="outline-4" id="outline-container-org1af1513">
<h4 id="org1af1513">Parts</h4>
<div class="outline-text-4" id="text-org1af1513">
<p>These are the libraries that we will use.</p>
</div>
<ul class="org-ul">
<li><a id="orgefd3082"></a>Python<br>
<div class="outline-text-5" id="text-orgefd3082">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
</li>
<li><a id="orgfdd5e80"></a>PyPi<br>
<div class="outline-text-5" id="text-orgfdd5e80">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="kn">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</li>
<li><a id="org1edecf6"></a>My Stuff<br>
<div class="outline-text-5" id="text-org1edecf6">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgf653fe6">
<h3 id="orgf653fe6">The Environment</h3>
<div class="outline-text-3" id="text-orgf653fe6">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">".env"</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9cc4abd">
<h3 id="org9cc4abd">Plotting</h3>
<div class="outline-text-3" id="text-org9cc4abd">
<p>There won't be a lot of plotting, but we'll use matplotlib with seaborn to look at some images to see what they look like and <a href="https://hvplot.holoviz.org/">HVplot</a> to do other visualizations.</p>
<div class="highlight">
<pre><span></span><span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'inline'</span><span class="p">)</span>
<span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'config'</span><span class="p">,</span> <span class="s2">"InlineBackend.figure_format = 'retina'"</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">,</span>
            <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">"font.family"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"sans-serif"</span><span class="p">],</span>
                <span class="s2">"font.sans-serif"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"Open Sans"</span><span class="p">,</span> <span class="s2">"Latin Modern Sans"</span><span class="p">,</span> <span class="s2">"Lato"</span><span class="p">],</span>
                <span class="s2">"figure.figsize"</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)},</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>This is for the nikola posts. If you run the jupyter kernel on a remote machine there's going to be two behaviors for the plot-files. If you create the file in the code block (like I do for the HVPlot plots) then the file will show up on the remote machine. If you use the <code>:file</code> argument in the org-mode header (like I do for matplotlib) it will create the file on the machine where you're running emacs. Given this behavior it might make more sense to edit the emacs file on the remote machine so all the files are created there… next time.</p>
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"flask-tensorflow-and-mnist"</span>
<span class="n">OUTPUT</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/keras/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgdc1ac07">
<h3 id="orgdc1ac07">The Random Seed</h3>
<div class="outline-text-3" id="text-orgdc1ac07">
<p>Since I'm commenting on the outcomes I'll set the random seed to try and make things more consistent.</p>
<div class="highlight">
<pre><span></span><span class="n">tensorflow</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org2b098cb">
<h3 id="org2b098cb">The Data</h3>
<div class="outline-text-3" id="text-org2b098cb">
<p>Like I mentioned, tensorflow includes the MNIST data set that we can grab with the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data">load_data</a> function. It returns two tuples of numpy arrays.</p>
<div class="highlight">
<pre><span></span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
<p>Let's see how much data we have.</p>
<div class="highlight">
<pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training:</span><span class="se">\t</span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> images</span><span class="se">\t</span><span class="s2">image = </span><span class="si">{</span><span class="n">width</span><span class="si">}</span><span class="s2"> x </span><span class="si">{</span><span class="n">height</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing:</span><span class="se">\t</span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> images</span><span class="se">\t</span><span class="s2">image = </span><span class="si">{</span><span class="n">width</span><span class="si">}</span><span class="s2"> x </span><span class="si">{</span><span class="n">height</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Training:       60,000 images   image = 28 x 28
Testing:        10,000 images   image = 28 x 28
</pre></div>
</div>
<div class="outline-3" id="outline-container-org7b2277f">
<h3 id="org7b2277f">A Note On the Tangling</h3>
<div class="outline-text-3" id="text-org7b2277f">
<p>I'm going to do this as a <a href="https://www.wikiwand.com/en/Literate_programming">literate programming</a> document with the tangle going into a temporary folder. I was creating the temporary folder using python but I'm running the code on a different machine from where I'm editing this document so running python executes on the remote machine but tangling out the files happens on my local machine. Maybe next time it will make more sense to edit the document on the remote machine (note to future self). Although that also introduces problems because then I'd have to run the tests headless… Every solution has a problem.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org56cea66">
<h2 id="org56cea66">Middle</h2>
<div class="outline-text-2" id="text-org56cea66"></div>
<div class="outline-3" id="outline-container-orgb023a7e">
<h3 id="orgb023a7e">The Data</h3>
<div class="outline-text-3" id="text-orgb023a7e"></div>
<div class="outline-4" id="outline-container-org6dcdc70">
<h4 id="org6dcdc70">The Distribution</h4>
<div class="outline-text-4" id="text-org6dcdc70">
<p>First, we can look at the distribution of the digits to see if they are equally represented.</p>
<div class="highlight">
<pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">sort</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
          <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"index"</span><span class="p">:</span> <span class="s2">"Digit"</span><span class="p">,</span>
                           <span class="mi">0</span><span class="p">:</span> <span class="s2">"Count"</span><span class="p">}))</span>
<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span>
    <span class="n">tooltips</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">"Digit"</span><span class="p">,</span> <span class="s2">"@Digit"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Count"</span><span class="p">,</span> <span class="s2">"@Count{0,0}"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Digit"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Count"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Digit Counts"</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"digit_distribution"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">output</span><span class="p">()</span>
</pre></div>
<object data="posts/keras/flask-tensorflow-and-mnist/digit_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>If you look at the values for the counts you can see that there is a pretty significant difference between 1 and 5.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">Count</span> <span class="o">-</span> <span class="n">labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">Count</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
1,321
</pre>
<p>But we're doing this as an exercise to get a web-page up more so than build a real model so let's not worry about that for now.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgc19e984">
<h4 id="orgc19e984">Some Example Digits</h4>
<div class="outline-text-4" id="text-orgc19e984">
<p>We'll make a 4 x 4 grid of the first 16 images to see what they look like. Note that our array uses 0-based indexing but matplotlib uses 1-based indexing so we have to make sure that the reference to the cell in the subplot is one ahead of the index for the array.</p>
<div class="highlight">
<pre><span></span><span class="n">IMAGES</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">ROWS</span> <span class="o">=</span> <span class="n">COLUMNS</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">IMAGES</span><span class="p">):</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">ROWS</span><span class="p">,</span> <span class="n">COLUMNS</span><span class="p">,</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'binary'</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">index</span><span class="p">]))</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<div class="figure">
<p><img alt="sample_digits.png" src="posts/keras/flask-tensorflow-and-mnist/sample_digits.png"></p>
</div>
<p>So the digits (at least the first 16) seem to be pretty clear.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orga8da8c8">
<h4 id="orga8da8c8">Normalizing the Data</h4>
<div class="outline-text-4" id="text-orga8da8c8">
<p>One problem we have, though, is that images use values from 0 to 255 to indicate the brightness of a pixel, but neural networks tend to work better with values from 0 to 1, so we'l have to scale the data back. The images are also 28 x 28 squares, but we need to transform them to flat vectors. We can change the shape of the input data using the <a href="https://numpy.org/doc/1.18/reference/generated/numpy.reshape.html">numpy.reshape</a> function, which takes the original data and the shape you want to change it to. In our case we want the same number of rows that there were originally and we want to reduce the images from 2-dimensional images to 1-dimensional images which we can do by passing in the number of total number of pixels in each image as a single number instead of width and height.</p>
<p>Since we have to do this for both the training and testing data I'll make a helper function.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">:</span>
    <span class="sd">"""reshapes the data and scales the values"""</span>
    <span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">pixels</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">height</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">pixels</span><span class="p">))</span>

    <span class="k">assert</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">pixels</span><span class="p">)</span>

    <span class="n">MAX_BRIGHTNESS</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">/</span> <span class="n">MAX_BRIGHTNESS</span>

    <span class="k">assert</span> <span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">data</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org28752fb">
<h3 id="org28752fb">The Neural Network Model</h3>
<div class="outline-text-3" id="text-org28752fb"></div>
<div class="outline-4" id="outline-container-orgf18e5bb">
<h4 id="orgf18e5bb">Build and Train It</h4>
<div class="outline-text-4" id="text-orgf18e5bb">
<p>Now we'll build the model. It's going to be a simple fully-connected network with three layers (input, hidden, output). To make the visualization simpler we'll use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid">sigmoid activation</a> function.</p>
<p>Besides the shallowness of the model it's also going to be relatively simple, with only 32 nodes in the hidden layer.</p>
<p>First we'll build it as a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential">Sequential</a> (linear stack) model.</p>
<div class="highlight">
<pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">pixels</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span>
<span class="n">HIDDEN_NODES</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">CATEGORIES</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">ACTIVATION</span> <span class="o">=</span> <span class="s2">"sigmoid"</span>
<span class="n">OUTPUT_ACTIVATION</span> <span class="o">=</span> <span class="s2">"softmax"</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">HIDDEN_NODES</span><span class="p">,</span>
                                  <span class="n">activation</span><span class="o">=</span><span class="n">ACTIVATION</span><span class="p">,</span>
                                  <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">pixels</span><span class="p">,)),</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">HIDDEN_NODES</span><span class="p">,</span>
                                  <span class="n">activation</span><span class="o">=</span><span class="n">ACTIVATION</span><span class="p">),</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">CATEGORIES</span><span class="p">,</span>
                                  <span class="n">activation</span><span class="o">=</span><span class="n">OUTPUT_ACTIVATION</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
<p>Now we can <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile">compile</a> the model using a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy">sparse categorical cross-entropy loss function</a>, which is for the case where you have more than one category (non-binary) and the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam">Adam</a> optimizer.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre></div>
<p>And next we'll train the model by calling its <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit">fit</a> method.</p>
<div class="highlight">
<pre><span></span><span class="n">NO_OUTPUT</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">2048</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="n">NO_OUTPUT</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4649585">
<h4 id="org4649585">Plot the Training History</h4>
<div class="outline-text-4" id="text-org4649585">
<div class="highlight">
<pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"loss"</span><span class="p">:</span> <span class="s2">"Training Loss"</span><span class="p">,</span>
        <span class="s2">"accuracy"</span><span class="p">:</span> <span class="s2">"Training Accuracy"</span><span class="p">,</span>
        <span class="s2">"val_loss"</span><span class="p">:</span> <span class="s2">"Validation Loss"</span><span class="p">,</span>
        <span class="s2">"val_accuracy"</span><span class="p">:</span> <span class="s2">"Validation Accuracy"</span><span class="p">,</span>
    <span class="p">})</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span>
    <span class="n">tooltips</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">"Metric"</span><span class="p">,</span> <span class="s2">"$name"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Epoch"</span><span class="p">,</span> <span class="s2">"$x"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Value"</span><span class="p">,</span> <span class="s2">"$y"</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">hvplot</span><span class="p">()</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Training History"</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"training_history"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">output</span><span class="p">()</span>
</pre></div>
<object data="posts/keras/flask-tensorflow-and-mnist/training_history.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">history</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">lowest</span> <span class="o">=</span> <span class="n">history</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">highest</span> <span class="o">=</span> <span class="n">history</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"(</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">) Min=</span><span class="si">{</span><span class="n">lowest</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> Max=</span><span class="si">{</span><span class="n">highest</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(Training Loss) Min=0.20 Max= 2.26
(Training Accuracy) Min=0.22 Max= 0.95
(Validation Loss) Min=0.21 Max= 2.14
(Validation Accuracy) Min=0.38 Max= 0.94
</pre>
<p>So our validation accuracy goes from 38 % to 94%, which isn't bad, especially when you consider what a simple model we have.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org6dcafc9">
<h4 id="org6dcafc9">Save It</h4>
<div class="outline-text-4" id="text-org6dcafc9">
<p>Now we can save the model to use in our flask application.</p>
<p><b>Note To Self:</b> Since this is being run on a remote machine, both the <code>.env</code> file and the directory to save the models refers to the remote machine, not the local machine where this file is being edited so you have to copy it to the local machine later on to use it with flask.</p>
<p>Also note that the you can't see the name since I put it in a <code>.env</code> file but it has <code>.h5</code> as the extension. According to the TensorFlow page on <a href="https://www.tensorflow.org/guide/keras/save_and_serialize">saving and loading a model</a>, H5 is the older format, they've switched to the <a href="https://www.tensorflow.org/guide/saved_model">SavedModel</a> format, you lose some information that would help you resume training, but we're not going to do that anyway, and the H5 format should be a little smaller.</p>
<p>Most of the next blob is to make sure the folder for the model exists. I put it in the environment variable mostly because I keep changing my mind as to where to put it and what to call it.</p>
<div class="highlight">
<pre><span></span><span class="n">base</span> <span class="o">=</span> <span class="s2">"flask_tensorflow_mnist"</span>
<span class="n">MODELS</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">base</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">base</span><span class="si">}</span><span class="s2">_model"</span><span class="p">]</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">MODELS</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="n">MODELS</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">MODELS</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>
<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">MODELS</span><span class="o">/</span><span class="n">MODEL_NAME</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">MODEL_PATH</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org1db0c03">
<h3 id="org1db0c03">The Web Page</h3>
<div class="outline-text-3" id="text-org1db0c03"></div>
<ul class="org-ul">
<li><a id="orgdddd595"></a>Back-End (The Model Server)<br>
<ul class="org-ul">
<li><a id="org1595ec4"></a>Tests<br>
<ul class="org-ul">
<li><a id="orge6790a7"></a>Fixtures<br>
<div class="outline-text-7" id="text-orge6790a7">
<p>These are the pytest fixtures to make it easier to create objects.</p>
<div class="highlight">
<pre><span></span> <span class="c1"># python</span>
 <span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>

 <span class="c1"># from pypi</span>

 <span class="kn">import</span> <span class="nn">pytest</span>
 <span class="kn">import</span> <span class="nn">tensorflow</span>

 <span class="c1"># software under test</span>
 <span class="kn">from</span> <span class="nn">ml_server</span> <span class="kn">import</span> <span class="n">app</span>


 <span class="k">class</span> <span class="nc">Katamari</span><span class="p">:</span>
     <span class="sd">"""Something to stick things into"""</span>


 <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
 <span class="k">def</span> <span class="nf">katamari</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Katamari</span><span class="p">:</span>
     <span class="k">return</span> <span class="n">Katamari</span><span class="p">()</span>


 <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
 <span class="k">def</span> <span class="nf">client</span><span class="p">():</span>
     <span class="sd">"""generates the flask client for testing"""</span>
     <span class="n">app</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"TESTING"</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
     <span class="k">with</span> <span class="n">app</span><span class="o">.</span><span class="n">test_client</span><span class="p">()</span> <span class="k">as</span> <span class="n">client</span><span class="p">:</span>
         <span class="k">yield</span> <span class="n">client</span>
     <span class="k">return</span>


 <span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
 <span class="k">def</span> <span class="nf">mnist</span><span class="p">():</span>
     <span class="sd">"""Gets the test labels"""</span>
     <span class="n">MAX_BRIGHTNESS</span> <span class="o">=</span> <span class="mi">255</span>
     <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
     <span class="k">return</span> <span class="n">Namespace</span><span class="p">(</span>
         <span class="n">x_test</span><span class="o">=</span><span class="n">x_test</span><span class="o">/</span><span class="n">MAX_BRIGHTNESS</span><span class="p">,</span>
         <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
     <span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="org4df9676"></a>Features<br>
<div class="outline-text-7" id="text-org4df9676">
<p>These are the feature files.</p>
<div class="highlight">
<pre><span></span> Feature: A Prediction Getter

 Scenario: The root page is retrieved
   Given a connection to the flask client
   When the root page is retrieved
   Then it has the expected text

 Scenario: A prediction is retrieved
   Given the get_prediction function
   When a prediction is retrieved
   Then it has the correct tuple

 Scenario: The API end-point is retrieved
   Given a connection to the flask client
   When the API end-point is retrieved
   Then the response has the expected JSON
</pre></div>
</div>
</li>
<li><a id="orgd34628c"></a>The Tests<br>
<div class="outline-text-7" id="text-orgd34628c">
<p>These are the actual test functions.</p>
<div class="highlight">
<pre><span></span> <span class="c1"># python</span>
 <span class="kn">from</span> <span class="nn">http</span> <span class="kn">import</span> <span class="n">HTTPStatus</span>

 <span class="kn">import</span> <span class="nn">random</span>

 <span class="c1"># pypi</span>
 <span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
     <span class="n">be</span><span class="p">,</span>
     <span class="n">be_true</span><span class="p">,</span>
     <span class="n">contain</span><span class="p">,</span>
     <span class="n">equal</span><span class="p">,</span>
     <span class="n">expect</span><span class="p">,</span>
 <span class="p">)</span>

 <span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
     <span class="n">given</span><span class="p">,</span>
     <span class="n">when</span><span class="p">,</span>
     <span class="n">then</span><span class="p">,</span>
     <span class="n">scenario</span><span class="p">,</span>
     <span class="n">scenarios</span><span class="p">,</span>
 <span class="p">)</span>

 <span class="kn">import</span> <span class="nn">numpy</span>

 <span class="c1"># for testing</span>
 <span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">client</span><span class="p">,</span> <span class="n">katamari</span><span class="p">,</span> <span class="n">mnist</span>

 <span class="c1"># software under test</span>
 <span class="kn">from</span> <span class="nn">ml_server</span> <span class="kn">import</span> <span class="n">get_prediction</span><span class="p">,</span> <span class="n">PATHS</span>

 <span class="n">scenarios</span><span class="p">(</span><span class="s2">"get_predictions.feature"</span><span class="p">)</span>

 <span class="c1"># ***** Get Root Page ***** #</span>
 <span class="c1"># Scenario: The root page is retrieved</span>


 <span class="nd">@given</span><span class="p">(</span><span class="s2">"a connection to the flask client"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">setup_client</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">client</span><span class="p">):</span>
     <span class="c1"># this is a no-op since I made a fixture to build the client instead</span>
     <span class="k">return</span>


 <span class="nd">@when</span><span class="p">(</span><span class="s2">"the root page is retrieved"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">get_root_page</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">client</span><span class="p">):</span>
     <span class="n">katamari</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">PATHS</span><span class="o">.</span><span class="n">root</span><span class="p">)</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">HTTPStatus</span><span class="o">.</span><span class="n">OK</span><span class="p">))</span>
     <span class="k">return</span>

 <span class="nd">@then</span><span class="p">(</span><span class="s2">"it has the expected text"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">check_root_text</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
         <span class="n">contain</span><span class="p">(</span><span class="sa">b</span><span class="s2">"This is the Neural Network Visualizer"</span><span class="p">))</span>
     <span class="k">return</span>

 <span class="c1"># ***** get predictions ***** #</span>
 <span class="c1"># *** Call the function *** #</span>
 <span class="c1"># Scenario: A prediction is retrieved</span>

 <span class="nd">@given</span><span class="p">(</span><span class="s2">"the get_prediction function"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">check_get_prediction</span><span class="p">():</span>
     <span class="sd">"""Another no-op"""</span>
     <span class="k">return</span>

 <span class="nd">@when</span><span class="p">(</span><span class="s2">"a prediction is retrieved"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">call_get_prediction</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
     <span class="n">choice_mock</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
     <span class="n">katamari</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="mi">6</span>
     <span class="n">choice_mock</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">index</span>
     <span class="n">mocker</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">"ml_server.numpy.random.choice"</span><span class="p">,</span> <span class="n">choice_mock</span><span class="p">)</span>
     <span class="n">katamari</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">get_prediction</span><span class="p">()</span>
     <span class="k">return</span>


 <span class="nd">@then</span><span class="p">(</span><span class="s2">"it has the correct tuple"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">check_predictions</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mnist</span><span class="p">):</span>
     <span class="c1"># Our model emits a list with one array for each layer of the model</span>
     <span class="n">expect</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="nb">list</span><span class="p">))</span>
     <span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>

     <span class="c1"># the last layer is the prediction layer</span>
     <span class="n">predictions</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

     <span class="n">predicted</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
     <span class="n">expected</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">y_test</span><span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">expected</span><span class="p">))</span>

     <span class="c1"># now check the image</span>
     <span class="n">expected</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">x_test</span><span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
     <span class="c1"># expect(katamari.output[1].shape).to(equal((28, 28)))</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
     <span class="k">return</span>

 <span class="c1"># *** API Call *** #</span>
 <span class="c1">#Scenario: the API end-point is retrieved</span>
 <span class="c1">#  Given a connection to the flask client</span>


 <span class="nd">@when</span><span class="p">(</span><span class="s2">"the API end-point is retrieved"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">get_predictions</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">client</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
     <span class="c1"># set up the mock so we can control which of the images it tries to predict</span>
     <span class="n">choice_mock</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>

     <span class="n">mocker</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">"ml_server.numpy.random.choice"</span><span class="p">,</span> <span class="n">choice_mock</span><span class="p">)</span>

     <span class="n">katamari</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
     <span class="n">choice_mock</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">index</span>

     <span class="n">katamari</span><span class="o">.</span><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">PATHS</span><span class="o">.</span><span class="n">api</span><span class="p">)</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">HTTPStatus</span><span class="o">.</span><span class="n">OK</span><span class="p">))</span>
     <span class="k">return</span>


 <span class="nd">@then</span><span class="p">(</span><span class="s2">"the response has the expected JSON"</span><span class="p">)</span>
 <span class="k">def</span> <span class="nf">check_response</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mnist</span><span class="p">):</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">is_json</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
     <span class="n">data</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">json</span>
     <span class="n">layers</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">"prediction"</span><span class="p">]</span>

     <span class="c1"># the prediction should be the three outputs of our model</span>
     <span class="c1"># except with lists instead of numpy arrays</span>
     <span class="n">expect</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">layers</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="nb">list</span><span class="p">))</span>
     <span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
     <span class="n">prediction</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

     <span class="c1"># now check that it made the expected prediction</span>
     <span class="n">predicted</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
     <span class="n">expected</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">y_test</span><span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">expected</span><span class="p">))</span>

     <span class="c1"># and that it gave us the right image</span>
     <span class="n">expected</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">x_test</span><span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
     <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">"image"</span><span class="p">]),</span> <span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
     <span class="k">return</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><a id="org065bbb9"></a>The Implementation<br>
<div class="outline-text-6" id="text-org065bbb9">
<p>This is where we tangle out a file to run a flask server that will serve up our model's predictions.</p>
<div class="highlight">
<pre><span></span> <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">flask</span><span class="o">-</span><span class="n">app</span><span class="o">&gt;&gt;</span>


 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">load</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">feature</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">load</span><span class="o">-</span><span class="n">data</span><span class="o">&gt;&gt;</span>


 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">get</span><span class="o">-</span><span class="n">prediction</span><span class="o">&gt;&gt;</span>


 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">index</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">api</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">ml</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">main</span><span class="o">&gt;&gt;</span>
</pre></div>
<p>First up is our imports. Other than Flask there really isn't anything new here.</p>
<div class="highlight">
<pre><span></span> <span class="c1"># python</span>
 <span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
 <span class="kn">import</span> <span class="nn">json</span>
 <span class="kn">import</span> <span class="nn">os</span>
 <span class="kn">import</span> <span class="nn">random</span>
 <span class="kn">import</span> <span class="nn">string</span>

 <span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

 <span class="c1"># pypi</span>
 <span class="kn">import</span> <span class="nn">numpy</span>
 <span class="kn">import</span> <span class="nn">tensorflow</span>

 <span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
 <span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span>
</pre></div>
<p>Now we create the flask app and something to hold the paths.</p>
<div class="highlight">
<pre><span></span> <span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

 <span class="n">PATHS</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
     <span class="n">root</span> <span class="o">=</span> <span class="s2">"/"</span><span class="p">,</span>
     <span class="n">api</span> <span class="o">=</span> <span class="s2">"/api"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
<p>Next we'll load the saved model. I'm going to break this up a little bit just because I wasn't clear about what was going on originally.</p>
<div class="highlight">
<pre><span></span> <span class="n">load_dotenv</span><span class="p">(</span><span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

 <span class="n">base</span> <span class="o">=</span> <span class="s2">"flask_tensorflow_mnist"</span>
 <span class="n">MODELS</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">base</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
 <span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">base</span><span class="si">}</span><span class="s2">_model"</span><span class="p">]</span>
 <span class="k">assert</span> <span class="n">MODELS</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>
 <span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="n">MODELS</span><span class="o">/</span><span class="n">MODEL_NAME</span>
 <span class="k">assert</span> <span class="n">MODEL_PATH</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>

 <span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">MODEL_PATH</span><span class="p">)</span>
</pre></div>
<p>At this point we should have a re-loaded version of our trained model (minus some information as noted above because it was saved using the <code>H5</code> format). Our model has one output layer - the softmax prediction layer - which gives the probabilities that an input image is one of the ten digits, but since we want to see what each layer is doing, we'll create a new model with the output from each layer added to the outputs - so since we have three layers in the model we'll now have three outputs.</p>
<div class="highlight">
<pre><span></span> <span class="n">feature_model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
     <span class="n">inputs</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
     <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">])</span>
</pre></div>
<p>Next let's load and normalize the data. We don't use the training data or the labels here.</p>
<div class="highlight">
<pre><span></span> <span class="n">MAX_BRIGHTNESS</span> <span class="o">=</span> <span class="mi">255</span>

 <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
 <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">/</span><span class="n">MAX_BRIGHTNESS</span>
</pre></div>
<p>Now we create the function to get the prediction for an image. It also returns the image so that we can see what it was.</p>
<div class="highlight">
<pre><span></span> <span class="n">ROWS</span><span class="p">,</span> <span class="n">HEIGHT</span><span class="p">,</span> <span class="n">WIDTH</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span>
 <span class="n">PIXELS</span> <span class="o">=</span> <span class="n">HEIGHT</span> <span class="o">*</span> <span class="n">WIDTH</span>

 <span class="k">def</span> <span class="nf">get_prediction</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">):</span>
     <span class="sd">"""Gets a random image and prediction</span>

<span class="sd">     The 'prediction' isn't so much the value (e.g. it's a 5) but rather the</span>
<span class="sd">     outputs of each layer so that they can be visualised. So the first value</span>
<span class="sd">     of the tuple will be a list of arrays whose length will be the number of </span>
<span class="sd">     layers in the model. Each array will be the outputs for that layer.</span>

<span class="sd">     This always pulls the image from =x_test=.</span>

<span class="sd">     Returns:</span>
<span class="sd">      What our model predicts for a random image and the image</span>
<span class="sd">     """</span>
     <span class="n">index</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">ROWS</span><span class="p">)</span>
     <span class="n">image</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">index</span><span class="p">,:,:]</span>
     <span class="n">image_array</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">PIXELS</span><span class="p">))</span>
     <span class="k">return</span> <span class="n">feature_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image_array</span><span class="p">),</span> <span class="n">image</span>
</pre></div>
<p>Next we create the handler for the REST calls. If you make a GET request from the root you'll get an HTML page back.</p>
<div class="highlight">
<pre><span></span> <span class="nd">@app</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="n">PATHS</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s1">'GET'</span><span class="p">])</span>
 <span class="k">def</span> <span class="nf">index</span><span class="p">():</span>
     <span class="sd">"""The home page view"""</span>
     <span class="k">return</span> <span class="s2">"This is the Neural Network Visualizer (use /api for the API)"</span>
</pre></div>
<p>If you return a dict flask will automatically identify it as JSON.</p>
<div class="highlight">
<pre><span></span> <span class="nd">@app</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="n">PATHS</span><span class="o">.</span><span class="n">api</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s2">"GET"</span><span class="p">])</span>
 <span class="k">def</span> <span class="nf">api</span><span class="p">():</span>
     <span class="sd">"""the JSON view</span>

<span class="sd">     Returns:</span>
<span class="sd">       JSON with prediction layers and image</span>
<span class="sd">     """</span>
     <span class="n">predictions</span><span class="p">,</span> <span class="n">image</span> <span class="o">=</span> <span class="n">get_prediction</span><span class="p">()</span>

     <span class="c1"># JSON needs lists, not numpy arrays</span>
     <span class="n">final_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">prediction</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
     <span class="k">return</span> <span class="p">{</span><span class="s2">"prediction"</span><span class="p">:</span> <span class="n">final_predictions</span><span class="p">,</span>
             <span class="s1">'image'</span><span class="p">:</span> <span class="n">image</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}</span>
</pre></div>
<p>And now we make the "main" entry point.</p>
<div class="highlight">
<pre><span></span> <span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
     <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
<p>To run this you would enter the same directory as the <code>ml_server.py</code> file and execute:</p>
<div class="highlight">
<pre><span></span> python ml_server.py
</pre></div>
<p>Or better, use the <a href="https://flask.palletsprojects.com/en/1.1.x/server/">development server</a>.</p>
<div class="highlight">
<pre><span></span>set -X FLASK_APP ml_server
set -X FLASK_ENV development

flask run
</pre></div>
<p>This will automatically re-load if you make changes to the code. The first two lines in the code block above tell flask which one of the modules has the flask-app and also that it should run in development mode. I'm using the <a href="https://fishshell.com/">Fish Shell</a>, so if you are using bash or a similar shell instead the lines would be this instead.</p>
<div class="highlight">
<pre><span></span>export FLASK_APP=ml_server
export FLASK_ENV=development

flask run
</pre></div>
</div>
</li>
</ul>
</li>
<li><a id="org44e429f"></a>Front-End<br>
<ul class="org-ul">
<li><a id="orgfd33584"></a>Tests<br>
<div class="outline-text-6" id="text-orgfd33584">
<div class="highlight">
<pre><span></span>&lt;&lt;front-end-feature-title&gt;&gt;

&lt;&lt;front-end-click&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>

<span class="kn">import</span> <span class="nn">pytest</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">browser</span><span class="p">():</span>
    <span class="sd">"""Creates the selenium webdriver session"""</span>
    <span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Firefox</span><span class="p">()</span>
    <span class="k">yield</span> <span class="n">browser</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span>


<span class="n">CSSSelectors</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">main_title</span> <span class="o">=</span> <span class="s2">".main h1"</span><span class="p">,</span>
    <span class="n">main_button</span> <span class="o">=</span> <span class="s2">".main button"</span><span class="p">,</span>
    <span class="n">sidebar_title</span> <span class="o">=</span> <span class="s2">".sidebar h1"</span><span class="p">,</span>
    <span class="n">sidebar_image</span> <span class="o">=</span> <span class="s2">".sidebar-content img"</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">class</span> <span class="nc">HomePage</span><span class="p">:</span>
    <span class="sd">"""A page-class for testing</span>

<span class="sd">    Args:</span>
<span class="sd">     address: the address of the streamlit server</span>
<span class="sd">     wait: seconds to implicitly wait for page-objects</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">address</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"http://localhost:8501"</span><span class="p">,</span>
                 <span class="n">wait</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">address</span> <span class="o">=</span> <span class="n">address</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="n">wait</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">browser</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Firefox</span><span class="p">:</span>
        <span class="sd">"""The browser opened to the home page"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Firefox</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span><span class="o">.</span><span class="n">implicitly_wait</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wait</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">address</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">main_title</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">firefox</span><span class="o">.</span><span class="n">webelement</span><span class="o">.</span><span class="n">FirefoxWebElement</span><span class="p">:</span>
        <span class="sd">"""The object with the main title"""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_css_selector</span><span class="p">(</span>
                <span class="n">CSSSelectors</span><span class="o">.</span><span class="n">main_title</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">main_button</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">firefox</span><span class="o">.</span><span class="n">webelement</span><span class="o">.</span><span class="n">FirefoxWebElement</span><span class="p">:</span>
        <span class="sd">"""The man button"""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_css_selector</span><span class="p">(</span>
                <span class="n">CSSSelectors</span><span class="o">.</span><span class="n">main_button</span>
            <span class="p">)</span>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sidebar_title</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">firefox</span><span class="o">.</span><span class="n">webelement</span><span class="o">.</span><span class="n">FirefoxWebElement</span><span class="p">:</span>
        <span class="sd">"""The sidebar title element"""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_css_selector</span><span class="p">(</span>
                <span class="n">CSSSelectors</span><span class="o">.</span><span class="n">sidebar_title</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sidebar_image</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">firefox</span><span class="o">.</span><span class="n">webelement</span><span class="o">.</span><span class="n">FirefoxWebElement</span><span class="p">:</span>
        <span class="sd">"""This tries to get the sidebar image element</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_css_selector</span><span class="p">(</span>
            <span class="n">CSSSelectors</span><span class="o">.</span><span class="n">sidebar_image</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Finalizer that closes the browser"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_browser</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">browser</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span> <span class="nf">home_page</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">HomePage</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span> <span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">front</span><span class="o">-</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">front</span><span class="o">-</span><span class="n">text</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">front</span><span class="o">-</span><span class="n">click</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
</li>
<li><a id="org0bc43aa"></a>The Features<br>
<div class="outline-text-6" id="text-org0bc43aa">
<p>We can start with the imports and basic set up.</p>
<div class="highlight">
<pre><span></span> <span class="c1"># pypi</span>
 <span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
     <span class="n">be_true</span><span class="p">,</span>
     <span class="n">equal</span><span class="p">,</span>
     <span class="n">expect</span>
 <span class="p">)</span>

 <span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
     <span class="n">given</span><span class="p">,</span>
     <span class="n">scenarios</span><span class="p">,</span>
     <span class="n">then</span><span class="p">,</span>
     <span class="n">when</span><span class="p">,</span>
 <span class="p">)</span>

 <span class="c1"># fixtures</span>
 <span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

 <span class="kn">from</span> <span class="nn">front_end_fixtures</span> <span class="kn">import</span> <span class="n">home_page</span>

 <span class="n">and_also</span> <span class="o">=</span> <span class="n">then</span>
 <span class="n">scenarios</span><span class="p">(</span><span class="s2">"front_end.feature"</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org48d1db5"></a>The Initial Text<br>
<div class="outline-text-7" id="text-org48d1db5">
<div class="highlight">
<pre><span></span> Feature: The GUI web page to view the model

 Scenario: The user goes to the home page and checks it out
   Given a browser on the home page
   When the user checks out the titles and button
   Then they have the expected text
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># ***** The Text ***** #</span>
<span class="c1"># Scenario: The user goes to the home page and checks it out</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a browser on the home page"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_browser</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">home_page</span><span class="p">):</span>
    <span class="c1"># katamari.home_page = home_page</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks out the titles and button"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_text</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">home_page</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">main_title</span> <span class="o">=</span> <span class="n">home_page</span><span class="o">.</span><span class="n">main_title</span><span class="o">.</span><span class="n">text</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">button_text</span> <span class="o">=</span> <span class="n">home_page</span><span class="o">.</span><span class="n">main_button</span><span class="o">.</span><span class="n">text</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">sidebar_title</span> <span class="o">=</span> <span class="n">home_page</span><span class="o">.</span><span class="n">sidebar_title</span><span class="o">.</span><span class="n">text</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"they have the expected text"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_text</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">main_title</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="s2">"Neural Network Visualizer"</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">button_text</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="s2">"Get Random Prediction"</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">sidebar_title</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="s2">"Input Image"</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="orge49b42a"></a>Click the Button<br>
<div class="outline-text-7" id="text-orge49b42a">
<div class="highlight">
<pre><span></span>Scenario: The user gets a random prediction
  Given a browser on the home page
  When the user clicks on the button
  Then the sidebar displays the input image
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># ***** The button click ****** #</span>
<span class="c1"># Scenario: The user gets a random prediction</span>
<span class="c1">#  Given a browser on the home page</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user clicks on the button"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">click_get_image_button</span><span class="p">(</span><span class="n">home_page</span><span class="p">):</span>
    <span class="n">home_page</span><span class="o">.</span><span class="n">main_button</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the sidebar displays the input image"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_sidebar_sections</span><span class="p">(</span><span class="n">home_page</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">home_page</span><span class="o">.</span><span class="n">sidebar_image</span><span class="o">.</span><span class="n">is_displayed</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><a id="org838d3a9"></a>Streamlit<br>
<div class="outline-text-6" id="text-org838d3a9">
<p>For the front-end we'll use Streamlit, a python library to make creating web-pages for certain types of applications more easily (I think, I'll need to check it out more later).</p>
<div class="highlight">
<pre><span></span> <span class="o">&lt;&lt;</span><span class="n">streamlit</span><span class="o">-</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">streamlit</span><span class="o">-</span><span class="n">url</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">streamlit</span><span class="o">-</span><span class="n">title</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">streamlit</span><span class="o">-</span><span class="n">sidebar</span><span class="o">&gt;&gt;</span>

 <span class="o">&lt;&lt;</span><span class="n">streamlit</span><span class="o">-</span><span class="n">control</span><span class="o">&gt;&gt;</span>
</pre></div>
<p>First the imports.</p>
<div class="highlight">
<pre><span></span> <span class="c1"># python</span>
 <span class="kn">import</span> <span class="nn">json</span>
 <span class="kn">import</span> <span class="nn">os</span>
 <span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urljoin</span>

 <span class="c1"># pypi</span>
 <span class="kn">import</span> <span class="nn">requests</span>
 <span class="kn">import</span> <span class="nn">numpy</span>
 <span class="kn">import</span> <span class="nn">streamlit</span>
 <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>

 <span class="c1"># this code</span>
 <span class="kn">from</span> <span class="nn">ml_server</span> <span class="kn">import</span> <span class="n">PATHS</span>
</pre></div>
<p>Now we'll setup the URL for our flask backend - as you can see we're expecting to run this on the <code>localhost</code> address, you'd have to change this for make it available outside the host PC.</p>
<div class="highlight">
<pre><span></span> <span class="n">URI</span> <span class="o">=</span> <span class="n">urljoin</span><span class="p">(</span><span class="s2">"http://127.0.0.1:5000/"</span><span class="p">,</span> <span class="n">PATHS</span><span class="o">.</span><span class="n">api</span><span class="p">)</span>
</pre></div>
<p>Next we'll set the title for the page - this can be a little confusing, although it's called the title, it isn't the HTML title but rather the main heading for the page.</p>
<div class="highlight">
<pre><span></span> <span class="n">streamlit</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Neural Network Visualizer'</span><span class="p">)</span>
</pre></div>
<p>Now we'll add a collapsible sidebar where we'll eventually put our image output and add a headline for it (<code>Input Image</code>).</p>
<div class="highlight">
<pre><span></span> <span class="n">streamlit</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">markdown</span><span class="p">(</span><span class="s1">'# Input Image'</span><span class="p">)</span>
</pre></div>
<p>Now we'll add some logic. I think this would be the <code>control</code> portion of a more traditional web-server. It's basically where we react to a button press by getting a random image and visualizing how it makes a prediction.</p>
<div class="highlight">
<pre><span></span> <span class="c1"># create a button and wait for someone to press it</span>
 <span class="k">if</span> <span class="n">streamlit</span><span class="o">.</span><span class="n">button</span><span class="p">(</span><span class="s2">"Get Random Prediction"</span><span class="p">):</span>
     <span class="c1"># Someone pressed the button, make an API call to our flask server</span>
     <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">URI</span><span class="p">)</span>

     <span class="c1"># convert the response to a dict</span>
     <span class="n">response</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

     <span class="c1"># get the prediction array</span>
     <span class="n">predictions</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'prediction'</span><span class="p">)</span>

     <span class="c1"># get the image we were making the prediction for</span>
     <span class="n">image</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'image'</span><span class="p">)</span>

     <span class="c1"># the image </span>
     <span class="c1"># streamlit expects a numpy array or string-like object, not lists</span>
     <span class="n">image</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

     <span class="c1"># show the image in the sidebar</span>
     <span class="n">streamlit</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

     <span class="c1"># iterate over the prediction for each layer in the model</span>
     <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
         <span class="c1"># convert the prediction list to an array</span>
         <span class="c1"># and flatten it to a vector</span>
         <span class="n">numbers</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">prediction</span><span class="p">))</span>
         <span class="n">pyplot</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
         <span class="n">rows</span> <span class="o">=</span> <span class="mi">1</span>
         <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
             <span class="c1"># this is the output layer so we only want one row</span>
             <span class="c1"># and we want 10 columns (one for each digit)</span>
             <span class="n">columns</span> <span class="o">=</span> <span class="mi">10</span>
         <span class="k">else</span><span class="p">:</span>
             <span class="c1"># this is the input or hidden layer</span>
             <span class="c1"># since our model had 32 hidden nodes it has 32 columns</span>
             <span class="c1"># the original version had 2 rows and 16 columns, but</span>
             <span class="c1"># while that looked nicer, I think it makes more sense for </span>
             <span class="c1"># there to be one layer</span>
             <span class="n">columns</span> <span class="o">=</span> <span class="mi">32</span>
         <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">number</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">numbers</span><span class="p">):</span>
             <span class="c1"># add a subplot to the figure</span>
             <span class="n">pyplot</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
             <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">number</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
                           <span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'binary'</span><span class="p">)</span>
             <span class="n">pyplot</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
             <span class="n">pyplot</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
             <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                 <span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
             <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
             <span class="n">pyplot</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
         <span class="n">streamlit</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s1">'Layer </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="p">)</span>
         <span class="n">streamlit</span><span class="o">.</span><span class="n">pyplot</span><span class="p">()</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org7a02e0b">
<h2 id="org7a02e0b">End</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/fastai/hand-rolling-a-countvectorizer/">Hand-rolling a CountVectorizer</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/fastai/hand-rolling-a-countvectorizer/" rel="bookmark"><time class="published dt-published" datetime="2020-01-03T17:21:23-08:00" itemprop="datePublished" title="2020-01-03 17:21">2020-01-03 17:21</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#orgdf835eb">Beginning</a>
<ul>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#orgf50eb45">Imports</a>
<ul>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org9f07c2a">Python</a></li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org2b2e3e9">PyPi</a></li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org60a4781">Others</a></li>
</ul>
</li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org28cc130">Setup</a>
<ul>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#orgbe1aac1">Plotting</a></li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org5e54ed1">The Data Set</a></li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org5e3c7a2">The Text List</a></li>
</ul>
</li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#orgb1d41c7">Creating a Term-Document Matrix</a></li>
</ul>
</li>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#orga0a53d0">End</a>
<ul>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#orgb33814d">Reference</a>
<ul>
<li><a href="posts/fastai/hand-rolling-a-countvectorizer/#org2f8da6e">The Dataset</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgdf835eb">
<h2 id="orgdf835eb">Beginning</h2>
<div class="outline-text-2" id="text-orgdf835eb">
<p>This is part of lesson 3 from the <a href="https://github.com/fastai/course-nlp">fastai NLP course</a>.</p>
</div>
<div class="outline-3" id="outline-container-orgf50eb45">
<h3 id="orgf50eb45">Imports</h3>
<div class="outline-text-3" id="text-orgf50eb45"></div>
<div class="outline-4" id="outline-container-org9f07c2a">
<h4 id="org9f07c2a">Python</h4>
<div class="outline-text-4" id="text-org9f07c2a">
<div class="highlight">
<pre><span></span>from collections import Counter
from functools import partial
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2b2e3e9">
<h4 id="org2b2e3e9">PyPi</h4>
<div class="outline-text-4" id="text-org2b2e3e9">
<div class="highlight">
<pre><span></span>from fastai.text import (
    URLs,
    untar_data,
    TextList,
    )
import hvplot.pandas
import pandas
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org60a4781">
<h4 id="org60a4781">Others</h4>
<div class="outline-text-4" id="text-org60a4781">
<div class="highlight">
<pre><span></span>from graeae import CountPercentage, EmbedHoloviews
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org28cc130">
<h3 id="org28cc130">Setup</h3>
<div class="outline-text-3" id="text-org28cc130"></div>
<div class="outline-4" id="outline-container-orgbe1aac1">
<h4 id="orgbe1aac1">Plotting</h4>
<div class="outline-text-4" id="text-orgbe1aac1">
<div class="highlight">
<pre><span></span>Embed = partial(
    EmbedHoloviews,
    folder_path="../../files/posts/fastai/hand-rolling-a-countvectorizer/")
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5e54ed1">
<h4 id="org5e54ed1">The Data Set</h4>
<div class="outline-text-4" id="text-org5e54ed1">
<p>The data-set is a collection of 50,000 IMDB reviews <a href="https://course.fast.ai/datasets.html">hosted on AWS Open Datasets</a> as part of the fastai datasets collection. We're going to try and create a classifier that can predict the "sentiment" of reviews. The <a href="http://ai.stanford.edu/~amaas/data/sentiment/">original dataset</a> comes from Stanford University.</p>
<p>To make it easier to experiment, we'll initially load a sub-set of the dataset that fastai prepared. The <a href="https://docs.fast.ai/datasets.html#URLs">URLs</a> class contains the URLs for the datasets that fastai has uploaded and the <a href="https://docs.fast.ai/datasets.html#untar_data"><code>untar_data</code></a> function downloads data from the URL given to a given (or in this case default) location.</p>
<div class="highlight">
<pre><span></span>path = untar_data(URLs.IMDB_SAMPLE)
print(path)
</pre></div>
<pre class="example">
/home/athena/.fastai/data/imdb_sample
</pre>
<p>The <code>untar_data</code> function doesn't actually load the data for us, so we'll use pandas to do that.</p>
<div class="highlight">
<pre><span></span>sample_frame = pandas.read_csv(path/"texts.csv")
print(sample_frame.head())
</pre></div>
<pre class="example">
      label                                               text  is_valid
0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False
1  positive  This is a extremely well-made film. The acting...     False
2  negative  Every once in a long while a movie will come a...     False
3  positive  Name just says it all. I watched this movie wi...     False
4  negative  This movie succeeds at being one of the most u...     False
</pre>
<p>The <code>is_valid</code> column is kind of interesting here especially since the first examples are all false… but I couldn't find an explanation for it on the data-download page.</p>
<div class="highlight">
<pre><span></span>CountPercentage(sample.label)()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Value</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">negative</td>
<td class="org-right">524</td>
<td class="org-right">52.40</td>
</tr>
<tr>
<td class="org-left">positive</td>
<td class="org-right">476</td>
<td class="org-right">47.60</td>
</tr>
</tbody>
</table>
<p>So it is nearly balanced but with a slight bias toward negative comments.</p>
<div class="highlight">
<pre><span></span>CountPercentage(sample.is_valid)()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Value</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">False</td>
<td class="org-right">800</td>
<td class="org-right">80.00</td>
</tr>
<tr>
<td class="org-left">True</td>
<td class="org-right">200</td>
<td class="org-right">20.00</td>
</tr>
</tbody>
</table>
<p>Well, so exactly 20% are invalid? Curious.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org5e3c7a2">
<h4 id="org5e3c7a2">The Text List</h4>
<div class="outline-text-4" id="text-org5e3c7a2">
<p>To actually work with the dataset we'll use fastai's <a href="https://docs.fast.ai/text.data.html#The-TextList-input-classes">TextList</a> instead of pandas' dataframe.</p>
<div class="highlight">
<pre><span></span>sample_list = TextList.from_csv(path, "texts.csv", cols="text")
sample_split = sample_list.split_from_df(col=2)
sample = (sample_split
          .label_from_df(cols=0))
</pre></div>
<p>The original notebook builds the <code>TextList</code> in a single train-wreck, but if you try and find out what those methods do from the fastai documentation… well, good luck to you, it's easier (although still obscure) to inspect the intermediate objects to try and muddle through what's going on. The ultimate outcome seems to be that <code>sample</code> is an object with the somewhat pre-processed. It looks like the text is lower-cased and somewhat tokenized. There's also a lot of strange tokens inserted (<code>xxmaj</code>, <code>xxunk</code>) which, according to the <a href="https://docs.fast.ai/text.transform.html#Introduction">tokenization documentation</a> indicate special tokens - although there's more unknown tokens than I would have expected.</p>
<div class="highlight">
<pre><span></span>print(sample.train.x[0])
</pre></div>
<pre class="example">
xxbos xxmaj un - xxunk - believable ! xxmaj meg xxmaj ryan does n't even look her usual xxunk lovable self in this , which normally makes me forgive her shallow xxunk acting xxunk . xxmaj hard to believe she was the producer on this dog . xxmaj plus xxmaj kevin xxmaj kline : what kind of suicide trip has his career been on ? xxmaj xxunk ... xxmaj xxunk ! ! ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . xxmaj xxunk !
</pre>
<div class="highlight">
<pre><span></span>print(sample_frame.text.iloc[0])
</pre></div>
<pre class="example">
Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!
</pre>
<p>Here's the category fo that review.</p>
<div class="highlight">
<pre><span></span>print(sample.train.y[0])
</pre></div>
<pre class="example">
negative
</pre>
<p>Note that the output looks like a string, but it's actually a fastai "type".</p>
<div class="highlight">
<pre><span></span>print(type(sample.train.y[0]))
</pre></div>
<pre class="example">
&lt;class 'fastai.core.Category'&gt;
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb1d41c7">
<h3 id="orgb1d41c7">Creating a Term-Document Matrix</h3>
<div class="outline-text-3" id="text-orgb1d41c7">
<p>Here we'll create a matrix that counts the number of times each token appears in each document.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orga0a53d0">
<h2 id="orga0a53d0">End</h2>
<div class="outline-text-2" id="text-orga0a53d0"></div>
<div class="outline-3" id="outline-container-orgb33814d">
<h3 id="orgb33814d">Reference</h3>
<div class="outline-text-3" id="text-orgb33814d"></div>
<div class="outline-4" id="outline-container-org2f8da6e">
<h4 id="org2f8da6e">The Dataset</h4>
<div class="outline-text-4" id="text-org2f8da6e">
<ul class="org-ul">
<li>Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1 (HLT ’11). Association for Computational Linguistics, USA, 142–150</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/fastai/topic-modeling-with-matrix-decomposition/">Topic Modeling With Matrix Decomposition</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/fastai/topic-modeling-with-matrix-decomposition/" rel="bookmark"><time class="published dt-published" datetime="2019-12-28T17:11:58-08:00" itemprop="datePublished" title="2019-12-28 17:11">2019-12-28 17:11</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org4eae663">Beginning</a>
<ul>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org2c99cac">Related Tutorials</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org64d4eb3">Imports</a>
<ul>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org437d1ae">Python</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org060f90d">PyPi</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org7a1b93d">Others</a></li>
</ul>
</li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org786443f">Set Up</a>
<ul>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org5f1a436">The Timer</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#orge6cd78d">Plotting</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org2a4fb1b">Middle</a>
<ul>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#orgb5ca70e">The Dataset</a>
<ul>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#orgdeeb260">Vectorizing</a></li>
</ul>
</li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org190be82">Singular Value Decomposition (SVD)</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org244b2ae">Looking At Some Topics</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org7b703d1">Non-negative Matrix Factorization (NMF)</a></li>
<li><a href="posts/fastai/topic-modeling-with-matrix-decomposition/#org4c95ca1">Term-Frequency/Inverse Document Frequency</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4eae663">
<h2 id="org4eae663">Beginning</h2>
<div class="outline-text-2" id="text-org4eae663">
<p>This is part of a walk-through of the <a href="https://github.com/fastai/course-nlp">fastai Code-First Introduction to NLP</a>. In this post I'll be using <a href="https://www.wikiwand.com/en/Singular_value_decomposition">Singular Value Decomposition (SVD)</a> and <a href="https://www.wikiwand.com/en/Non-negative_matrix_factorization">Non-Negative Matrix Factorization (NMF)</a> to group <a href="https://scikit-learn.org/stable/datasets/index.html#newsgroups-dataset">newsgroup posts</a>. Both of these methods are statistical approaches that use the word-counts within documents to decide how similar they are (while ignoring things like word order).</p>
</div>
<div class="outline-3" id="outline-container-org2c99cac">
<h3 id="org2c99cac">Related Tutorials</h3>
<div class="outline-text-3" id="text-org2c99cac">
<ul class="org-ul">
<li><a href="http://scikit-learn.org/stable/auto_examples/applications/plot_out_of_core_classification.html">Out-Of-Core Text Classification with sklearn</a></li>
<li><a href="https://de.dariah.eu/tatom/index.html)">Text Analysis with Topic Models for the Humanities and Social Sciences</a></li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org64d4eb3">
<h3 id="org64d4eb3">Imports</h3>
<div class="outline-text-3" id="text-org64d4eb3"></div>
<div class="outline-4" id="outline-container-org437d1ae">
<h4 id="org437d1ae">Python</h4>
<div class="outline-text-4" id="text-org437d1ae">
<div class="highlight">
<pre><span></span>from functools import partial
import random
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org060f90d">
<h4 id="org060f90d">PyPi</h4>
<div class="outline-text-4" id="text-org060f90d">
<div class="highlight">
<pre><span></span>from scipy import linalg
from sklearn import decomposition
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import hvplot.pandas
import matplotlib.pyplot as pyplot
import numpy
import pandas
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7a1b93d">
<h4 id="org7a1b93d">Others</h4>
<div class="outline-text-4" id="text-org7a1b93d">
<div class="highlight">
<pre><span></span>from graeae import EmbedHoloviews, Timer
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org786443f">
<h3 id="org786443f">Set Up</h3>
<div class="outline-text-3" id="text-org786443f"></div>
<div class="outline-4" id="outline-container-org5f1a436">
<h4 id="org5f1a436">The Timer</h4>
<div class="outline-text-4" id="text-org5f1a436">
<div class="highlight">
<pre><span></span>TIMER = Timer()
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge6cd78d">
<h4 id="orge6cd78d">Plotting</h4>
<div class="outline-text-4" id="text-orge6cd78d">
<div class="highlight">
<pre><span></span>Embed = partial(
    EmbedHoloviews,
    folder_path="../../files/posts/fastai/topic-modeling-with-matrix-decomposition")
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org2a4fb1b">
<h2 id="org2a4fb1b">Middle</h2>
<div class="outline-text-2" id="text-org2a4fb1b"></div>
<div class="outline-3" id="outline-container-orgb5ca70e">
<h3 id="orgb5ca70e">The Dataset</h3>
<div class="outline-text-3" id="text-orgb5ca70e">
<p>The dataset consists of ~18,000 newsgroup posts with 20 topics. To keep the computation down I'll only use a subset of the categories. I'm also going to only use the body of the posts.</p>
<div class="highlight">
<pre><span></span>keep = ("alt.atheism", "comp.graphics", "misc.forsale", "sci.crypt", "talk.politics.guns")
remove = ("headers", "footers", "quotes")
training = fetch_20newsgroups(subset="train", categories=keep, remove=remove)
testing = fetch_20newsgroups(subset="test", categories=keep, remove=remove)
</pre></div>
<p>I've run this more than once so there's no output, but the first time you run the <code>fetch_20newsgroups</code> function it downloads the dataset and you'll see some output mentioning this fact.</p>
<div class="highlight">
<pre><span></span>print(f"{training.filenames.shape[0]:,}")
print(f"{training.target.shape[0]:,}")
</pre></div>
<pre class="example">
2,790
2,790
</pre>
<p>So, although the entire dataset has over 18,000 entries, our sub-set has fewer than 3,000.</p>
<div class="highlight">
<pre><span></span>print(numpy.unique(training.target))
</pre></div>
<pre class="example">
[0 1 2 3 4]
</pre>
<p>So the categories don't seem to be preserved (I'm assuming that the five I kept weren't the first five in the original set) so you have to check anytime you pull a subset out of the data.</p>
<p>Lets see what one of the posts looks like.</p>
<div class="highlight">
<pre><span></span>print(random.choice(training.data))
</pre></div>
<pre class="example">
      Just a question. 
      As a provider of a public BBS service - aren't you bound by law to gurantee
      intelligble access to the data of the users on the BBS, if police comes
      with sufficent authorisation ? I guessed this would be  a basic condition
      for such systems. (I did run a bbs some time ago, but that was in Switzerland)

The US doesn't yet have many laws covering BBSs - they're not common carriers,
they're not phone companies, they're just private machines or services
operated by businesses.  There's no obligation to keep records.
As Perry Metzger points out, if the police come with a search warrant,
you have to let them see what the warrant demands, if it exists,
and they generally can confiscate the equipment as "evidence"
(which is not Constitutionally valid, but we're only beginning to
develop court cases supporting us).  A court MAY be able to compel
you to tell them information you know, such as the encryption password
for the disk - there aren't any definitive cases yet, since it's a new
situation, and there probably aren't laws specifically covering it.
But the court can't force you to *know* the keys, and there are no
laws preventing you from allowing your users to have their own keys
for their own files without giving them to you.

Even in areas that do have established law, there is uncertainty.
There was a guy in Idaho a few years ago who had his business records
subpoenaed as evidence for taxes or some other business-restriction law,
so he gave the court the records.  Which were in Hebrew.
The US doesn't have laws forcing you to keep your records in English,
and these were the originals of the records.  HE didn't speak Hebrew,
and neither did anybody in the court organization.  Don't think they
were able to do much about it.

It might be illegal for your BBS to deny access to potential customers
based on race, religion, national origin, gender, or sexual preference;
it probably hasn't been tested in court, but it seems like a plausible
extension of anti-discrimination laws affecting other businesses.
</pre></div>
<div class="outline-4" id="outline-container-orgdeeb260">
<h4 id="orgdeeb260">Vectorizing</h4>
<div class="outline-text-4" id="text-orgdeeb260">
<p>Here we'll convert the text to a matrix using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">sklearn's CountVectorizer</a>. Interestingly, the <a href="https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html">Introduction to Information Retrieval</a> book says the the trend has been towards not removing the most common words (<i>stop word</i>) but we'll be dropping them. There's a paper called <a href="https://www.aclweb.org/anthology/W18-2502/">Stop Word Lists in Free Open-source Software Packages</a> which points out some problems with stop-word lists in general, but sklearn's list in particular. I don't know if sklearn has done anything to address their concerns since the paper came out, but the sklearn documentation includes a link to the paper so I would assume the problems are still there. Nonetheless, the fastai examples uses them so I will too.</p>
<div class="highlight">
<pre><span></span>vectorizer = CountVectorizer(stop_words="english")
</pre></div>
<p>The function we'le going to use doesn't accept the sparse matrices that are output by default so we'll make it a dense matrix after it's fit.</p>
<div class="highlight">
<pre><span></span>with TIMER:
    vectors = vectorizer.fit_transform(training.data).todense()
</pre></div>
<pre class="example">
2020-01-01 16:26:48,048 graeae.timers.timer start: Started: 2020-01-01 16:26:48.047927
2020-01-01 16:26:48,466 graeae.timers.timer end: Ended: 2020-01-01 16:26:48.466285
2020-01-01 16:26:48,466 graeae.timers.timer end: Elapsed: 0:00:00.418358
</pre>
<p>That was much quicker than I thought it would be, probably because our dataset is so small.</p>
<div class="highlight">
<pre><span></span>vocabulary = vectorizer.get_feature_names()
print(f"{len(vocabulary):,}")
</pre></div>
<pre class="example">
34,632
</pre>
<p>So our "vocabulary" is around 35,000 tokens.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org190be82">
<h3 id="org190be82">Singular Value Decomposition (SVD)</h3>
<div class="outline-text-3" id="text-org190be82">
<p>Singular Value Decomposition is a linear algebra method to factor a matrix. The math is beyond me at this point, so I'll just try using it as a black box.</p>
<div class="highlight">
<pre><span></span>with TIMER:
    U, s, V = linalg.svd(vectors, full_matrices=False)
</pre></div>
<pre class="example">
2020-01-01 16:26:50,508 graeae.timers.timer start: Started: 2020-01-01 16:26:50.508003
2020-01-01 16:27:23,979 graeae.timers.timer end: Ended: 2020-01-01 16:27:23.978988
2020-01-01 16:27:23,980 graeae.timers.timer end: Elapsed: 0:00:33.470985
</pre>
<div class="highlight">
<pre><span></span>s_frame = pandas.Series(s)
plot = s_frame.hvplot().opts(title="Diagonal Matrix S", width=1000, height=800)
Embed(plot=plot, file_name="s_values")()
</pre></div>
<object data="posts/fastai/topic-modeling-with-matrix-decomposition/s_values.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
<div class="outline-3" id="outline-container-org244b2ae">
<h3 id="org244b2ae">Looking At Some Topics</h3>
<div class="outline-text-3" id="text-org244b2ae">
<div class="highlight">
<pre><span></span>top_words_count = 8

def top_words(token):
    return [vocabulary[index] for index in numpy.argsort(token)[: -top_words_count - 1: -1]]

def show_topics(array):
    topic_words = ([top_words(topic) for topic in array])
    return [' '.join(topic) for topic in topic_words]
</pre></div>
<div class="highlight">
<pre><span></span>topics = show_topics(V[:10])
for index, topic in enumerate(topics):
    print(f"{index}: {topic}")
</pre></div>
<pre class="example">
0: propagandist heliocentric galacticentric surname sandvik 400included wovy imaginative
1: file jpeg image edu pub ftp use graphics
2: file gun congress firearms control mr states rkba
3: privacy internet anonymous pub email information eff mail
4: graphics edu 128 3d ray pub data ftp
5: 00 50 40 appears dos 10 art 25
6: privacy internet 00 jpeg eff pub email electronic
7: key data image encryption des chip available law
8: pub key jesus jpeg eff graphics encryption ripem
9: key encryption edu des anonymous posting chip graphics
</pre>
<p>So what we're showing is the most significant words for the top-ten most strongly grouped "topics". It takes a little bit of interpretation to figure out how to map them to the newsgroups we used, and there probably could have been some clean-up of the texts (entry 5 looks suspect) but it's interesting that this linear algebra decomposition method could find these similar groups without any kind of prompting as to what groups might even exist in the first place (this is an unsupervised method, not a supervised method).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org7b703d1">
<h3 id="org7b703d1">Non-negative Matrix Factorization (NMF)</h3>
<div class="outline-text-3" id="text-org7b703d1">
<div class="highlight">
<pre><span></span>number_of_topics = 5
classifier = decomposition.NMF(n_components=number_of_topics, random_state=1)
weights = classifier.fit_transform(vectors)
classified = classifier.components_
for index, topic in enumerate(show_topics(classified)):
    print(f"{index}: {topic}")
</pre></div>
<pre class="example">
0: db mov bh si cs byte al bl
1: privacy internet anonymous information email eff use pub
2: file gun congress control firearms states mr united
3: jpeg image gif file color images format quality
4: edu graphics pub image data ftp mail available
</pre></div>
</div>
<div class="outline-3" id="outline-container-org4c95ca1">
<h3 id="org4c95ca1">Term-Frequency/Inverse Document Frequency</h3>
<div class="outline-text-3" id="text-org4c95ca1">
<div class="highlight">
<pre><span></span>tfidf_vectorizer = TfidfVectorizer(stop_words="english")
tfidf_vectors = tfidf_vectorizer.fit_transform(training.data)
weights = classifier.fit_transform(tfidf_vectors)
classified = classifier.components_

for index, topic in enumerate(show_topics(classified)):
    print(f"{index}: {topic}")
</pre></div>
<pre class="example">
0: people gun don think just guns right government
1: 00 sale offer shipping new drive price condition
2: key chip encryption clipper keys escrow government algorithm
3: graphics thanks file files image program know windows
4: god atheism believe does atheists belief said exist
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/link-collection/">Link-Collection</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/link-collection/" rel="bookmark"><time class="published dt-published" datetime="2019-12-28T16:12:17-08:00" itemprop="datePublished" title="2019-12-28 16:12">2019-12-28 16:12</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/link-collection/#orge90814c">Machine Learning</a>
<ul>
<li><a href="posts/link-collection/#org4e2129c">Blogs</a></li>
</ul>
</li>
<li><a href="posts/link-collection/#org0c25a6f">Visualization</a></li>
<li><a href="posts/link-collection/#org2785be9">Natural Language Processing</a>
<ul>
<li><a href="posts/link-collection/#org4e0c66d">Books</a></li>
<li><a href="posts/link-collection/#orge92d5c5">Blogs</a></li>
<li><a href="posts/link-collection/#org9f00629">Code</a>
<ul>
<li><a href="posts/link-collection/#org51a01b0">FaceBook</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orge90814c">
<h2 id="orge90814c">Machine Learning</h2>
<div class="outline-text-2" id="text-orge90814c"></div>
<div class="outline-3" id="outline-container-org4e2129c">
<h3 id="org4e2129c">Blogs</h3>
<div class="outline-text-3" id="text-org4e2129c">
<ul class="org-ul">
<li><a href="https://smerity.com/">Smerity</a></li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org0c25a6f">
<h2 id="org0c25a6f">Visualization</h2>
<div class="outline-text-2" id="text-org0c25a6f">
<ul class="org-ul">
<li><a href="https://jalammar.github.io/">Jay Alamar</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org2785be9">
<h2 id="org2785be9">Natural Language Processing</h2>
<div class="outline-text-2" id="text-org2785be9"></div>
<div class="outline-3" id="outline-container-org4e0c66d">
<h3 id="org4e0c66d">Books</h3>
<div class="outline-text-3" id="text-org4e0c66d">
<ul class="org-ul">
<li><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a> by <a href="https://web.stanford.edu/~jurafsky/">Dan Jurafsky</a> and <a href="https://www.cs.colorado.edu/~martin/">James H. Martin</a></li>
<li><a href="https://nlp.stanford.edu/IR-book/">Introduction to Information Retrieval</a> by Christopher D. Manning, Prabhakar Raghavan & Hinrich Schutze</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orge92d5c5">
<h3 id="orge92d5c5">Blogs</h3>
<div class="outline-text-3" id="text-orge92d5c5">
<ul class="org-ul">
<li><a href="https://ruder.io/">Sebastian Ruder</a></li>
<li><a href="http://www.abigailsee.com/">Abigail See</a></li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org9f00629">
<h3 id="org9f00629">Code</h3>
<div class="outline-text-3" id="text-org9f00629"></div>
<div class="outline-4" id="outline-container-org51a01b0">
<h4 id="org51a01b0">FaceBook</h4>
<div class="outline-text-4" id="text-org51a01b0">
<ul class="org-ul">
<li><a href="https://github.com/facebookresearch/pytext">pytext</a></li>
<li><a href="https://fasttext.cc/">fastText</a></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/keras/nlp-classification-exercise/">NLP Classification Exercise</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/keras/nlp-classification-exercise/" rel="bookmark"><time class="published dt-published" datetime="2019-09-29T11:28:06-07:00" itemprop="datePublished" title="2019-09-29 11:28">2019-09-29 11:28</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#orgc3ce70f">Beginning</a>
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#org11fd0b7">Imports</a>
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#org6e86360">Python</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org9455706">PyPi</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org3d04dc9">Others</a></li>
</ul>
</li>
<li><a href="posts/keras/nlp-classification-exercise/#orgee71724">Set Up</a>
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#orgaff3cd1">The Timer</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org0cb73eb">The Plotting</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org99a7815">The Dataset</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org48e0a19">Some Constants</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/keras/nlp-classification-exercise/#org7267bf9">Middle</a>
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#orgea3447c">The Data</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org18320b5">The Tokenizer</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#orgec3a1fa">GloVe</a></li>
<li><a href="posts/keras/nlp-classification-exercise/#org5ffcd85">The Models</a>
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#org07a7596">A CNN</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/keras/nlp-classification-exercise/#org893acc6">End</a>
<ul>
<li><a href="posts/keras/nlp-classification-exercise/#org55e9163">Citations</a></li>
</ul>
</li>
<li><a href="posts/keras/nlp-classification-exercise/#orge209131">Raw</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgc3ce70f">
<h2 id="orgc3ce70f">Beginning</h2>
<div class="outline-text-2" id="text-orgc3ce70f"></div>
<div class="outline-3" id="outline-container-org11fd0b7">
<h3 id="org11fd0b7">Imports</h3>
<div class="outline-text-3" id="text-org11fd0b7"></div>
<div class="outline-4" id="outline-container-org6e86360">
<h4 id="org6e86360">Python</h4>
<div class="outline-text-4" id="text-org6e86360">
<div class="highlight">
<pre><span></span>from argparse import Namespace
from functools import partial
from pathlib import Path
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9455706">
<h4 id="org9455706">PyPi</h4>
<div class="outline-text-4" id="text-org9455706">
<div class="highlight">
<pre><span></span>from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
import hvplot.pandas
import numpy
import pandas
import tensorflow
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3d04dc9">
<h4 id="org3d04dc9">Others</h4>
<div class="outline-text-4" id="text-org3d04dc9">
<div class="highlight">
<pre><span></span>from graeae import (CountPercentage,
                    EmbedHoloviews,
                    SubPathLoader,
                    Timer,
                    ZipDownloader)
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgee71724">
<h3 id="orgee71724">Set Up</h3>
<div class="outline-text-3" id="text-orgee71724"></div>
<div class="outline-4" id="outline-container-orgaff3cd1">
<h4 id="orgaff3cd1">The Timer</h4>
<div class="outline-text-4" id="text-orgaff3cd1">
<div class="highlight">
<pre><span></span>TIMER = Timer()
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0cb73eb">
<h4 id="org0cb73eb">The Plotting</h4>
<div class="outline-text-4" id="text-org0cb73eb">
<div class="highlight">
<pre><span></span>slug = "nlp-classification-exercise"
Embed = partial(EmbedHoloviews, folder_path=f"../../files/posts/keras/{slug}")
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org99a7815">
<h4 id="org99a7815">The Dataset</h4>
<div class="outline-text-4" id="text-org99a7815">
<p>It isn't mentioned in the notebook where the data originally came from, but it looks like it's the <a href="http://help.sentiment140.com/home">Sentiment140</a> dataset, which consists of tweets whose sentiment was inferred by emoticons in each tweet.</p>
<div class="highlight">
<pre><span></span>url = "http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
path = Path("~/data/datasets/texts/sentiment140/").expanduser()
download = ZipDownloader(url, path)
download()
</pre></div>
<pre class="example">
Files exist, not downloading

</pre>
<div class="highlight">
<pre><span></span>columns = ["polarity", "tweet_id", "datetime", "query", "user", "text"]
training = pandas.read_csv(path/"training.1600000.processed.noemoticon.csv", 
                           encoding="latin-1", names=columns, header=None)
testing = pandas.read_csv(path/"testdata.manual.2009.06.14.csv", 
                           encoding="latin-1", names=columns, header=None)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org48e0a19">
<h4 id="org48e0a19">Some Constants</h4>
<div class="outline-text-4" id="text-org48e0a19">
<div class="highlight">
<pre><span></span>Text = Namespace(
    embedding_dim = 100,
    max_length = 16,
    trunc_type='post',
    padding_type='post',
    oov_tok = "&lt;OOV&gt;",
    training_size=16000,
)
</pre></div>
<div class="highlight">
<pre><span></span>Data = Namespace(
    batch_size = 64,
    shuffle_buffer_size=100,
)
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7267bf9">
<h2 id="org7267bf9">Middle</h2>
<div class="outline-text-2" id="text-org7267bf9"></div>
<div class="outline-3" id="outline-container-orgea3447c">
<h3 id="orgea3447c">The Data</h3>
<div class="outline-text-3" id="text-orgea3447c">
<div class="highlight">
<pre><span></span>print(training.sample().iloc[0])
</pre></div>
<pre class="example">
polarity                                                    4
tweet_id                                           1468852290
datetime                         Tue Apr 07 04:04:10 PDT 2009
query                                                NO_QUERY
user                                              leawoodward
text        Def off now...unexpected day out tomorrow so s...
Name: 806643, dtype: object

</pre>
<div class="highlight">
<pre><span></span>CountPercentage(training.polarity)()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Value</th>
<th class="org-left" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">4</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
</tbody>
</table>
<p>The <code>polarity</code> is what might also be called the "sentiment" of the tweet - <i>0</i> means a negative tweet and <i>4</i> means a positive tweet.</p>
<p>But, for our purposes, we would be better off if the positive polarity was <code>1</code>, not <code>4</code>, so let's convert it.</p>
<div class="highlight">
<pre><span></span>training.loc[training.polarity==4, "polarity"] = 1
counts = CountPercentage(training.polarity)()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Value</th>
<th class="org-left" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="outline-3" id="outline-container-org18320b5">
<h3 id="org18320b5">The Tokenizer</h3>
<div class="outline-text-3" id="text-org18320b5">
<p>As you can see from the sample, the data is still in text form so we need to convert it to a numeric form with a Tokenizer.</p>
<p>First I'll Lower-case it.</p>
<div class="highlight">
<pre><span></span>training.loc[:, "text"] = training.text.str.lower()
</pre></div>
<p>Next we'll fit it to our text.</p>
<div class="highlight">
<pre><span></span>tokenizer = Tokenizer()
with TIMER:
    tokenizer.fit_on_texts(training.text.values)
</pre></div>
<pre class="example">
2019-10-10 07:25:09,065 graeae.timers.timer start: Started: 2019-10-10 07:25:09.065039
WARNING: Logging before flag parsing goes to stderr.
I1010 07:25:09.065394 140436771002176 timer.py:70] Started: 2019-10-10 07:25:09.065039
2019-10-10 07:25:45,389 graeae.timers.timer end: Ended: 2019-10-10 07:25:45.389540
I1010 07:25:45.389598 140436771002176 timer.py:77] Ended: 2019-10-10 07:25:45.389540
2019-10-10 07:25:45,391 graeae.timers.timer end: Elapsed: 0:00:36.324501
I1010 07:25:45.391984 140436771002176 timer.py:78] Elapsed: 0:00:36.324501

</pre>
<p>Now, we can store some of it's values in variables for convenience.</p>
<div class="highlight">
<pre><span></span>word_index = tokenizer.word_index
vocabulary_size = len(tokenizer.word_index)
</pre></div>
<p>Now, we'll convert the texts to sequences and pad them so they are all the same length.</p>
<div class="highlight">
<pre><span></span>with TIMER:
    sequences = tokenizer.texts_to_sequences(training.text.values)
    padded = pad_sequences(sequences, maxlen=Text.max_length,
                           truncating=Text.trunc_type)

    splits = train_test_split(
        padded, training.polarity, test_size=.2)

    training_sequences, test_sequences, training_labels, test_labels = splits
</pre></div>
<pre class="example">
2019-10-10 07:25:51,057 graeae.timers.timer start: Started: 2019-10-10 07:25:51.057684
I1010 07:25:51.057712 140436771002176 timer.py:70] Started: 2019-10-10 07:25:51.057684
2019-10-10 07:26:33,530 graeae.timers.timer end: Ended: 2019-10-10 07:26:33.530338
I1010 07:26:33.530381 140436771002176 timer.py:77] Ended: 2019-10-10 07:26:33.530338
2019-10-10 07:26:33,531 graeae.timers.timer end: Elapsed: 0:00:42.472654
I1010 07:26:33.531477 140436771002176 timer.py:78] Elapsed: 0:00:42.472654

</pre>
<p>Now convert them to <a href="https://www.tensorflow.org/tutorials/load_data/numpy">datasets</a>.</p>
<div class="highlight">
<pre><span></span>training_dataset = tensorflow.data.Dataset.from_tensor_slices(
    (training_sequences, training_labels)
)

testing_dataset = tensorflow.data.Dataset.from_tensor_slices(
    (test_sequences, test_labels)
)

training_dataset = training_dataset.shuffle(Data.shuffle_buffer_size).batch(Data.batch_size)
testing_dataset = testing_dataset.shuffle(Data.shuffle_buffer_size).batch(Data.batch_size)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgec3a1fa">
<h3 id="orgec3a1fa">GloVe</h3>
<div class="outline-text-3" id="text-orgec3a1fa">
<p>GloVe is short for <i>Global Vectors for Word Representation</i>. It is an <i>unsupervised</i> algorithm that creates vector representations for words. They have a <a href="https://nlp.stanford.edu/projects/glove/">site</a> where you can download pre-trained models or get the code and train one yourself. We're going to use one of their pre-trained models.</p>
<div class="highlight">
<pre><span></span>path = Path("~/models/glove/").expanduser()
url = "http://nlp.stanford.edu/data/glove.6B.zip"
ZipDownloader(url, path)()
</pre></div>
<pre class="example">
Files exist, not downloading

</pre>
<p>The GloVe data is stored as a series of space separated lines with the first column being the word that's encoded and the rest of the columns being the values for the vector. To make this work we're going to split the word off from the vector and put each into a dictionary.</p>
<div class="highlight">
<pre><span></span>embeddings = {}
with TIMER:
    with open(path/"glove.6B.100d.txt") as lines:
        for line in lines:
            tokens = line.split()
            embeddings[tokens[0]] = numpy.array(tokens[1:])
</pre></div>
<pre class="example">
2019-10-06 18:55:11,592 graeae.timers.timer start: Started: 2019-10-06 18:55:11.592880
I1006 18:55:11.592908 140055379531584 timer.py:70] Started: 2019-10-06 18:55:11.592880
2019-10-06 18:55:21,542 graeae.timers.timer end: Ended: 2019-10-06 18:55:21.542689
I1006 18:55:21.542738 140055379531584 timer.py:77] Ended: 2019-10-06 18:55:21.542689
2019-10-06 18:55:21,544 graeae.timers.timer end: Elapsed: 0:00:09.949809
I1006 18:55:21.544939 140055379531584 timer.py:78] Elapsed: 0:00:09.949809

</pre>
<div class="highlight">
<pre><span></span>print(f"{len(embeddings):,}")
</pre></div>
<pre class="example">
400,000

</pre>
<p>So, our vocabulary consists of 400,000 "words" (tokens is more accurate, since they also include punctuation). The problem we have to deal with next is that our data set wasn't part of the dataset used to train the embeddings, so there will probably be some tokens in our data set that aren't in the embeddings. To handle this we need to add zeroed embeddings for the extra tokens.</p>
<p>Rather than adding to the dict, we'll create a matrix of zeros with rows for each word in our datasets vocabulary, then we'll iterate over the words in our dataset and if there's a match in the GloVE embeddings we'll insert it into the matrix.</p>
<div class="highlight">
<pre><span></span>with TIMER:
    embeddings_matrix = numpy.zeros((vocabulary_size+1, Text.embedding_dim));
    for word, index in word_index.items():
        embedding_vector = embeddings.get(word);
        if embedding_vector is not None:
            embeddings_matrix[index] = embedding_vector;
</pre></div>
<pre class="example">
2019-10-06 18:55:46,577 graeae.timers.timer start: Started: 2019-10-06 18:55:46.577855
I1006 18:55:46.577886 140055379531584 timer.py:70] Started: 2019-10-06 18:55:46.577855
2019-10-06 18:55:51,374 graeae.timers.timer end: Ended: 2019-10-06 18:55:51.374706
I1006 18:55:51.374763 140055379531584 timer.py:77] Ended: 2019-10-06 18:55:51.374706
2019-10-06 18:55:51,377 graeae.timers.timer end: Elapsed: 0:00:04.796851
I1006 18:55:51.377207 140055379531584 timer.py:78] Elapsed: 0:00:04.796851

</pre>
<div class="highlight">
<pre><span></span>print(f"{len(embeddings_matrix):,}")
</pre></div>
<pre class="example">
690,961

</pre></div>
</div>
<div class="outline-3" id="outline-container-org5ffcd85">
<h3 id="org5ffcd85">The Models</h3>
<div class="outline-text-3" id="text-org5ffcd85"></div>
<div class="outline-4" id="outline-container-org07a7596">
<h4 id="org07a7596">A CNN</h4>
<div class="outline-text-4" id="text-org07a7596"></div>
<ul class="org-ul">
<li><a id="orgd9ee93c"></a>Build<br>
<div class="outline-text-5" id="text-orgd9ee93c">
<div class="highlight">
<pre><span></span>convoluted_model = tensorflow.keras.Sequential([
    tensorflow.keras.layers.Embedding(
        vocabulary_size + 1,
        Text.embedding_dim,
        input_length=Text.max_length,
        weights=[embeddings_matrix],
        trainable=False),
    tensorflow.keras.layers.Conv1D(filters=128,
                                   kernel_size=5,
    activation='relu'),
    tensorflow.keras.layers.GlobalMaxPooling1D(),
    tensorflow.keras.layers.Dense(24, activation='relu'),
    tensorflow.keras.layers.Dense(1, activation='sigmoid')
])
convoluted_model.compile(loss="binary_crossentropy", optimizer="rmsprop",
                         metrics=["accuracy"])
</pre></div>
<div class="highlight">
<pre><span></span>print(convoluted_model.summary())
</pre></div>
<pre class="example">
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 16, 100)           69096100  
_________________________________________________________________
conv1d (Conv1D)              (None, 12, 128)           64128     
_________________________________________________________________
global_max_pooling1d (Global (None, 128)               0         
_________________________________________________________________
dense (Dense)                (None, 24)                3096      
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 25        
=================================================================
Total params: 69,163,349
Trainable params: 67,249
Non-trainable params: 69,096,100
_________________________________________________________________
None
</pre></div>
</li>
<li><a id="org57f12aa"></a>Train<br>
<div class="outline-text-5" id="text-org57f12aa">
<div class="highlight">
<pre><span></span>Training = Namespace(
    size = 0.75,
    epochs = 2,
    verbosity = 2,
    batch_size=128,
    )
</pre></div>
<div class="highlight">
<pre><span></span>with TIMER:
    cnn_history = convoluted_model.fit(training_dataset,
                                       epochs=Training.epochs,
                                       validation_data=testing_dataset,
                                       verbose=Training.verbosity)
</pre></div>
<pre class="example">
2019-10-10 07:27:04,921 graeae.timers.timer start: Started: 2019-10-10 07:27:04.921617
I1010 07:27:04.921657 140436771002176 timer.py:70] Started: 2019-10-10 07:27:04.921617
Epoch 1/2
W1010 07:27:05.154920 140436771002176 deprecation.py:323] From /home/hades/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
20000/20000 - 4964s - loss: 0.5091 - accuracy: 0.7454 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/2
20000/20000 - 4935s - loss: 0.4790 - accuracy: 0.7671 - val_loss: 0.4782 - val_accuracy: 0.7677
2019-10-10 10:12:04,382 graeae.timers.timer end: Ended: 2019-10-10 10:12:04.382359
I1010 10:12:04.382491 140436771002176 timer.py:77] Ended: 2019-10-10 10:12:04.382359
2019-10-10 10:12:04,384 graeae.timers.timer end: Elapsed: 2:44:59.460742
I1010 10:12:04.384716 140436771002176 timer.py:78] Elapsed: 2:44:59.460742
</pre></div>
</li>
<li><a id="org6f7dbb3"></a>Some Plotting<br>
<div class="outline-text-5" id="text-org6f7dbb3">
<div class="highlight">
<pre><span></span>performance = pandas.DataFrame(cnn_history.history)
plot = performance.hvplot().opts(title="CNN Twitter Sentiment Training Performance",
                                 width=1000,
                                 height=800)
Embed(plot=plot, file_name="cnn_training")()
</pre></div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org893acc6">
<h2 id="org893acc6">End</h2>
<div class="outline-text-2" id="text-org893acc6"></div>
<div class="outline-3" id="outline-container-org55e9163">
<h3 id="org55e9163">Citations</h3>
<div class="outline-text-3" id="text-org55e9163">
<ul class="org-ul">
<li>Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge209131">
<h2 id="orge209131">Raw</h2>
<div class="outline-text-2" id="text-orge209131"></div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/keras/embeddings-from-scratch/">Embeddings from Scratch</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/keras/embeddings-from-scratch/" rel="bookmark"><time class="published dt-published" datetime="2019-09-25T13:30:12-07:00" itemprop="datePublished" title="2019-09-25 13:30">2019-09-25 13:30</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/keras/embeddings-from-scratch/#org4a41309">Beginning</a>
<ul>
<li><a href="posts/keras/embeddings-from-scratch/#org3ff541b">Imports</a>
<ul>
<li><a href="posts/keras/embeddings-from-scratch/#org093f061">Python</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#orgaf6f43a">PyPi</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#org36b47f9">Others</a></li>
</ul>
</li>
<li><a href="posts/keras/embeddings-from-scratch/#orgce4084e">Set Up</a>
<ul>
<li><a href="posts/keras/embeddings-from-scratch/#org5b4728e">Plotting</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#org7b49415">The Timer</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/keras/embeddings-from-scratch/#org4e302e0">Middle</a>
<ul>
<li><a href="posts/keras/embeddings-from-scratch/#orgd45e3e4">Some Constants</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#org1614462">The Embeddings Layer</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#org74c2e38">The Dataset</a>
<ul>
<li><a href="posts/keras/embeddings-from-scratch/#org5010690">Add Padding</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#orgc7b8673">Checkout a Sample</a></li>
</ul>
</li>
<li><a href="posts/keras/embeddings-from-scratch/#org954b9de">Build a Model</a></li>
<li><a href="posts/keras/embeddings-from-scratch/#org04d5dbc">Compile and Train</a></li>
</ul>
</li>
<li><a href="posts/keras/embeddings-from-scratch/#orgda18e8a">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4a41309">
<h2 id="org4a41309">Beginning</h2>
<div class="outline-text-2" id="text-org4a41309">
<p>This is a walk-through of the tensorflow <a href="https://www.tensorflow.org/beta/tutorials/text/word_embeddings">Word Embeddings</a> tutorial, just to make sure I can do it.</p>
</div>
<div class="outline-3" id="outline-container-org3ff541b">
<h3 id="org3ff541b">Imports</h3>
<div class="outline-text-3" id="text-org3ff541b"></div>
<div class="outline-4" id="outline-container-org093f061">
<h4 id="org093f061">Python</h4>
<div class="outline-text-4" id="text-org093f061">
<div class="highlight">
<pre><span></span>from argparse import Namespace
from functools import partial
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgaf6f43a">
<h4 id="orgaf6f43a">PyPi</h4>
<div class="outline-text-4" id="text-orgaf6f43a">
<div class="highlight">
<pre><span></span>from tensorflow import keras
from tensorflow.keras import layers
import hvplot.pandas
import pandas
import tensorflow
import tensorflow_datasets
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org36b47f9">
<h4 id="org36b47f9">Others</h4>
<div class="outline-text-4" id="text-org36b47f9">
<div class="highlight">
<pre><span></span>from graeae import EmbedHoloviews, Timer
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgce4084e">
<h3 id="orgce4084e">Set Up</h3>
<div class="outline-text-3" id="text-orgce4084e"></div>
<div class="outline-4" id="outline-container-org5b4728e">
<h4 id="org5b4728e">Plotting</h4>
<div class="outline-text-4" id="text-org5b4728e">
<div class="highlight">
<pre><span></span>prefix = "../../files/posts/keras/"
slug = "embeddings-from-scratch"

Embed = partial(EmbedHoloviews, folder_path=f"{prefix}{slug}")
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7b49415">
<h4 id="org7b49415">The Timer</h4>
<div class="outline-text-4" id="text-org7b49415">
<div class="highlight">
<pre><span></span>TIMER = Timer()
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org4e302e0">
<h2 id="org4e302e0">Middle</h2>
<div class="outline-text-2" id="text-org4e302e0"></div>
<div class="outline-3" id="outline-container-orgd45e3e4">
<h3 id="orgd45e3e4">Some Constants</h3>
<div class="outline-text-3" id="text-orgd45e3e4">
<div class="highlight">
<pre><span></span>Text = Namespace(
    vocabulary_size=1000,
    embeddings_size=16,
    max_length=500,
    padding="post",
)

Tokens = Namespace(
    padding = "&lt;PAD&gt;",
    start = "&lt;START&gt;",
    unknown = "&lt;UNKNOWN&gt;",
    unused = "&lt;UNUSED&gt;",
)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1614462">
<h3 id="org1614462">The Embeddings Layer</h3>
<div class="outline-text-3" id="text-org1614462">
<div class="highlight">
<pre><span></span>print(layers.Embedding.__doc__)
</pre></div>
<pre class="example">
Turns positive integers (indexes) into dense vectors of fixed size.

  e.g. `[[4], [20]] -&gt; [[0.25, 0.1], [0.6, -0.2]]`

  This layer can only be used as the first layer in a model.

  Example:

  ```python
  model = Sequential()
  model.add(Embedding(1000, 64, input_length=10))
  # the model will take as input an integer matrix of size (batch,
  # input_length).
  # the largest integer (i.e. word index) in the input should be no larger
  # than 999 (vocabulary size).
  # now model.output_shape == (None, 10, 64), where None is the batch
  # dimension.

  input_array = np.random.randint(1000, size=(32, 10))

  model.compile('rmsprop', 'mse')
  output_array = model.predict(input_array)
  assert output_array.shape == (32, 10, 64)
  ```

  Arguments:
    input_dim: int &gt; 0. Size of the vocabulary,
      i.e. maximum integer index + 1.
    output_dim: int &gt;= 0. Dimension of the dense embedding.
    embeddings_initializer: Initializer for the `embeddings` matrix.
    embeddings_regularizer: Regularizer function applied to
      the `embeddings` matrix.
    embeddings_constraint: Constraint function applied to
      the `embeddings` matrix.
    mask_zero: Whether or not the input value 0 is a special "padding"
      value that should be masked out.
      This is useful when using recurrent layers
      which may take variable length input.
      If this is `True` then all subsequent layers
      in the model need to support masking or an exception will be raised.
      If mask_zero is set to True, as a consequence, index 0 cannot be
      used in the vocabulary (input_dim should equal size of
      vocabulary + 1).
    input_length: Length of input sequences, when it is constant.
      This argument is required if you are going to connect
      `Flatten` then `Dense` layers upstream
      (without it, the shape of the dense outputs cannot be computed).

  Input shape:
    2D tensor with shape: `(batch_size, input_length)`.

  Output shape:
    3D tensor with shape: `(batch_size, input_length, output_dim)`.
  
</pre>
<div class="highlight">
<pre><span></span>embedding_layer = layers.Embedding(Text.vocabulary_size, Text.embeddings_size)
</pre></div>
<p>The first argument is the number of possible words in the vocabulary and the second is the number of dimensions. The Emebdding is a sort of lookup table that maps an integer that represents a word to a vector. In this case we're going to build a vocabulary of 1,000 words represented by vectors with a length of 32. The weights in the vectors are learned when we train the model and will encode the distance between words.</p>
<p>The input to the embeddings layer is a 2D tensor of integers with the shape (<code>number of samples</code>, <code>sequence_length</code>). The sequences are integer-encoded sentences of the same length - so you have to pad the shorter sentences to match the longest one (the <code>sequence_length</code>).</p>
<p>The ouput of the embeddings layer is a 3D tensor with the shape (<code>number of samples</code>, <code>sequence_length</code>, <code>embedding_dimensionality</code>).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org74c2e38">
<h3 id="org74c2e38">The Dataset</h3>
<div class="outline-text-3" id="text-org74c2e38">
<div class="highlight">
<pre><span></span>(train_data, test_data), info = tensorflow_datasets.load(
    "imdb_reviews/subwords8k",
    split=(tensorflow_datasets.Split.TRAIN,
           tensorflow_datasets.Split.TEST),
    with_info=True, as_supervised=True)
</pre></div>
<div class="highlight">
<pre><span></span>encoder = info.features["text"].encoder
print(encoder.subwords[:10])
</pre></div>
<pre class="example">
['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br']

</pre></div>
<div class="outline-4" id="outline-container-org5010690">
<h4 id="org5010690">Add Padding</h4>
<div class="outline-text-4" id="text-org5010690">
<div class="highlight">
<pre><span></span>padded_shapes = ([None], ())
train_batches = train_data.shuffle(Text.vocabulary_size).padded_batch(
    10, padded_shapes=padded_shapes)
test_batches = test_data.shuffle(Text.vocabulary_size).padded_batch(
    10, padded_shapes=padded_shapes
)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc7b8673">
<h4 id="orgc7b8673">Checkout a Sample</h4>
<div class="outline-text-4" id="text-orgc7b8673">
<div class="highlight">
<pre><span></span>batch, labels = next(iter(train_batches))
print(batch.numpy())
</pre></div>
<pre class="example">
[[  62    9    4 ...    0    0    0]
 [  19 2428    6 ...    0    0    0]
 [ 691    2  594 ... 7961 1457 7975]
 ...
 [6072 5644 8043 ...    0    0    0]
 [ 977   15   57 ...    0    0    0]
 [5646    2    1 ...    0    0    0]]

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org954b9de">
<h3 id="org954b9de">Build a Model</h3>
<div class="outline-text-3" id="text-org954b9de">
<div class="highlight">
<pre><span></span>model = keras.Sequential([
    layers.Embedding(encoder.vocab_size, Text.embeddings_size),
    layers.GlobalAveragePooling1D(),
    layers.Dense(1, activation="sigmoid")
])
</pre></div>
<div class="highlight">
<pre><span></span>print(model.summary())
</pre></div>
<pre class="example">
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, None, 16)          130960    
_________________________________________________________________
global_average_pooling1d (Gl (None, 16)                0         
_________________________________________________________________
dense (Dense)                (None, 1)                 17        
=================================================================
Total params: 130,977
Trainable params: 130,977
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="outline-3" id="outline-container-org04d5dbc">
<h3 id="org04d5dbc">Compile and Train</h3>
<div class="outline-text-3" id="text-org04d5dbc">
<div class="highlight">
<pre><span></span>model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
ONCE_PER_EPOCH = 2
with TIMER:
    history = model.fit(train_batches, epochs=10,
                        validation_data=test_batches,
                        verbose=ONCE_PER_EPOCH,
                        validation_steps=20)
</pre></div>
<pre class="example">
2019-09-28 17:14:52,764 graeae.timers.timer start: Started: 2019-09-28 17:14:52.764725
I0928 17:14:52.764965 140515023214400 timer.py:70] Started: 2019-09-28 17:14:52.764725
W0928 17:14:52.806057 140515023214400 deprecation.py:323] From /home/hades/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Epoch 1/10
 val_loss: 0.3015 - val_accuracy: 0.8900
2019-09-28 17:17:36,036 graeae.timers.timer end: Ended: 2019-09-28 17:17:36.036090
I0928 17:17:36.036139 140515023214400 timer.py:77] Ended: 2019-09-28 17:17:36.036090
2019-09-28 17:17:36,037 graeae.timers.timer end: Elapsed: 0:02:43.271365
I0928 17:17:36.037808 140515023214400 timer.py:78] Elapsed: 0:02:43.271365
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgda18e8a">
<h2 id="orgda18e8a">End</h2>
<div class="outline-text-2" id="text-orgda18e8a">
<div class="highlight">
<pre><span></span>data = pandas.DataFrame(history.history)
plot = data.hvplot().opts(title="Training/Validation Performance",
                          width=1000,
                          height=800)
Embed(plot=plot, file_name="training")()
</pre></div>
<object data="posts/keras/embeddings-from-scratch/training.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Amazingly, even with such a simple model, it managed a 92 % validation accuracy.</p>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="next"><a href="index-10.html" rel="next">Older posts</a></li>
</ul>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
