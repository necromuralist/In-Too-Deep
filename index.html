<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/" rel="canonical">
<link href="index-20.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
<link href="posts/gans/cnn-gan/" rel="prefetch" type="text/html">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="."><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item active"><a class="nav-link" href=".">Cloistered Monkey <span class="sr-only">(active)</span></a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/gans/cnn-gan/">CNN GAN</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/gans/cnn-gan/" rel="bookmark"><time class="published dt-published" datetime="2021-04-14T19:52:11-07:00" itemprop="datePublished" title="2021-04-14 19:52">2021-04-14 19:52</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/gans/cnn-gan/#org2eb810b">Deep Convolutional GAN (DCGAN)</a>
<ul>
<li><a href="posts/gans/cnn-gan/#orgadb4ce5">Imports</a></li>
<li><a href="posts/gans/cnn-gan/#org76abedc">Set Up</a>
<ul>
<li><a href="posts/gans/cnn-gan/#org5ef907b">The Random Seed</a></li>
<li><a href="posts/gans/cnn-gan/#orgf519141">Plotting and Timing</a></li>
</ul>
</li>
<li><a href="posts/gans/cnn-gan/#org4bed3ac">Helper Functions</a>
<ul>
<li><a href="posts/gans/cnn-gan/#orgc65eccf">A Plotter</a></li>
<li><a href="posts/gans/cnn-gan/#org3818178">A Noise Maker</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/gans/cnn-gan/#org9c2ae14">Middle</a>
<ul>
<li><a href="posts/gans/cnn-gan/#org9afd59d">The Generator</a>
<ul>
<li><a href="posts/gans/cnn-gan/#org0e8c98f">The Generator Class</a></li>
<li><a href="posts/gans/cnn-gan/#orgdd26498">Setup Testing</a></li>
<li><a href="posts/gans/cnn-gan/#org6b1aee0">Unit Tests</a></li>
</ul>
</li>
<li><a href="posts/gans/cnn-gan/#org17172a2">The Discriminator</a>
<ul>
<li><a href="posts/gans/cnn-gan/#org8e3369f">The Discriminator Class</a></li>
<li><a href="posts/gans/cnn-gan/#orgd04e936">Set Up Testing</a></li>
<li><a href="posts/gans/cnn-gan/#org6d98ddd">Unit Testing</a></li>
</ul>
</li>
<li><a href="posts/gans/cnn-gan/#orge636bc2">Training The Model</a>
<ul>
<li><a href="posts/gans/cnn-gan/#orgf665903">Set Up The Data</a></li>
<li><a href="posts/gans/cnn-gan/#org3b45d33">Set Up the GAN</a></li>
<li><a href="posts/gans/cnn-gan/#org7466db9">A Weight Initializer</a></li>
<li><a href="posts/gans/cnn-gan/#orgfdd058a">Train it</a></li>
</ul>
</li>
<li><a href="posts/gans/cnn-gan/#orgc5381fe">Looking at the Final model.</a></li>
</ul>
</li>
<li><a href="posts/gans/cnn-gan/#orga727767">End</a>
<ul>
<li><a href="posts/gans/cnn-gan/#org37eb952">Sources</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org2eb810b">
<h2 id="org2eb810b">Deep Convolutional GAN (DCGAN)</h2>
<div class="outline-text-2" id="text-org2eb810b">
<p>We're going to build a Generative Adversarial Network to generate handwritten digits. Instead of using fully-connected layers we'll use Convolutional layers.</p>
<p>Here are the main features of a DCGAN.</p>
<ul class="org-ul">
<li>Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).</li>
<li>Use BatchNorm in both the generator and the discriminator.</li>
<li>Remove fully connected hidden layers for deeper architectures.</li>
<li>ReLU activation in generator for all layers except for the output, which uses Tanh.</li>
<li>Use LeakyReLU activation in the discriminator for all layers.</li>
</ul>
</div>
<div class="outline-3" id="outline-container-orgadb4ce5">
<h3 id="orgadb4ce5">Imports</h3>
<div class="outline-text-3" id="text-orgadb4ce5">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># conda</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org76abedc">
<h3 id="org76abedc">Set Up</h3>
<div class="outline-text-3" id="text-org76abedc"></div>
<div class="outline-4" id="outline-container-org5ef907b">
<h4 id="org5ef907b">The Random Seed</h4>
<div class="outline-text-4" id="text-org5ef907b">
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf519141">
<h4 id="orgf519141">Plotting and Timing</h4>
<div class="outline-text-4" id="text-orgf519141">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
<span class="n">slug</span> <span class="o">=</span> <span class="s2">"cnn-gan"</span>

<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/gans/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org4bed3ac">
<h3 id="org4bed3ac">Helper Functions</h3>
<div class="outline-text-3" id="text-org4bed3ac"></div>
<div class="outline-4" id="outline-container-orgc65eccf">
<h4 id="orgc65eccf">A Plotter</h4>
<div class="outline-text-4" id="text-orgc65eccf">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">plot_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
                <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/gans/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">/"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Plot the image and save it</span>

<span class="sd">    Args:</span>
<span class="sd">     image: the tensor with the image to plot</span>
<span class="sd">     filename: name for the final image file</span>
<span class="sd">     title: title to put on top of the image</span>
<span class="sd">     num_images: how many images to put in the composite image</span>
<span class="sd">     size: the size for the image</span>
<span class="sd">     folder: sub-folder to save the file in</span>
<span class="sd">    """</span>
    <span class="n">unflattened_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">)</span>
    <span class="n">image_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">unflattened_image</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

    <span class="n">pyplot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[[file:</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">]]"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3818178">
<h4 id="org3818178">A Noise Maker</h4>
<div class="outline-text-4" id="text-org3818178">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">make_some_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">"""create noise vectors</span>

<span class="sd">    creates </span>
<span class="sd">    Args:</span>
<span class="sd">       n_samples: the number of samples to generate, a scalar</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       device: the device type (cpu or cuda)</span>

<span class="sd">    Returns:</span>
<span class="sd">     tensor with random numbers from the normal distribution.</span>
<span class="sd">    """</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org9c2ae14">
<h2 id="org9c2ae14">Middle</h2>
<div class="outline-text-2" id="text-org9c2ae14"></div>
<div class="outline-3" id="outline-container-org9afd59d">
<h3 id="org9afd59d">The Generator</h3>
<div class="outline-text-3" id="text-org9afd59d">
<p>The first component you will make is the generator. You may notice that instead of passing in the image dimension, you will pass the number of image channels to the generator. This is because with DCGAN, you use convolutions which don’t depend on the number of pixels on an image. However, the number of channels is important to determine the size of the filters.</p>
<p>You will build a generator using 4 layers (3 hidden layers + 1 output layer). As before, you will need to write a function to create a single block for the generator's neural network. From the paper:</p>
<ul class="org-ul">
<li>[u]se batchnorm in both the generator and the discriminator"</li>
<li>[u]se ReLU activation in generator for all layers except for the output, which uses Tanh.</li>
</ul>
<p>Since in DCGAN the activation function will be different for the output layer, you will need to check what layer is being created.</p>
<p>At the end of the generator class, you are given a forward pass function that takes in a noise vector and generates an image of the output dimension using your neural network. You are also given a function to create a noise vector. These functions are the same as the ones from the last assignment.</p>
<p>See also:</p>
<ul class="org-ul">
<li><a href="https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html">nn.ConvTranspose2d</a></li>
<li><a href="https://pytorch.org/docs/master/generated/torch.nn.BatchNorm2d.html">nn.BatchNorm2d</a></li>
</ul>
</div>
<div class="outline-4" id="outline-container-org0e8c98f">
<h4 id="org0e8c98f">The Generator Class</h4>
<div class="outline-text-4" id="text-org0e8c98f">
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""The DCGAN Generator</span>

<span class="sd">    Args:</span>
<span class="sd">       z_dim: the dimension of the noise vector</span>
<span class="sd">       im_chan: the number of channels in the images, fitted for the dataset used</span>
<span class="sd">             (MNIST is black-and-white, so 1 channel is your default)</span>
<span class="sd">       hidden_dim: the inner dimension,</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span> <span class="o">=</span> <span class="n">z_dim</span>
        <span class="c1"># Build the neural network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_gen_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                       <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                       <span class="n">final_layer</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
        <span class="sd">"""Creates a block for the generator (sub sequence)</span>

<span class="sd">       The parts</span>
<span class="sd">        - a transposed convolution</span>
<span class="sd">        - a batchnorm (except for in the last layer)</span>
<span class="sd">        - an activation.</span>

<span class="sd">       Args:</span>
<span class="sd">           input_channels: how many channels the input feature representation has</span>
<span class="sd">           output_channels: how many channels the output feature representation should have</span>
<span class="sd">           kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span>
<span class="sd">           stride: the stride of the convolution</span>
<span class="sd">           final_layer: a boolean, true if it is the final layer and false otherwise </span>
<span class="sd">                     (affects activation and batchnorm)</span>

<span class="sd">       Returns:</span>
<span class="sd">        the sub-sequence of layers</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">final_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Final Layer</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">unsqueeze_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""transforms the noize tensor</span>

<span class="sd">       Args:</span>
<span class="sd">           noise: a noise tensor with dimensions (n_samples, z_dim)</span>

<span class="sd">       Returns:</span>
<span class="sd">        copy of noise with width and height = 1 and channels = z_dim.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="n">noise</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">noise</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">z_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""complete a forward pass of the generator: Given a noise tensor, </span>

<span class="sd">       Args:</span>
<span class="sd">        noise: a noise tensor with dimensions (n_samples, z_dim)</span>

<span class="sd">       Returns:</span>
<span class="sd">        generated images.</span>
<span class="sd">       """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze_noise</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdd26498">
<h4 id="orgdd26498">Setup Testing</h4>
<div class="outline-text-4" id="text-orgdd26498">
<div class="highlight">
<pre><span></span><span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
<span class="n">num_test</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Test the hidden block</span>
<span class="n">test_hidden_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">gen</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)</span>
<span class="n">test_hidden_block</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_uns_noise</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">unsqueeze_noise</span><span class="p">(</span><span class="n">test_hidden_noise</span><span class="p">)</span>
<span class="n">hidden_output</span> <span class="o">=</span> <span class="n">test_hidden_block</span><span class="p">(</span><span class="n">test_uns_noise</span><span class="p">)</span>

<span class="c1"># Check that it works with other strides</span>
<span class="n">test_hidden_block_stride</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">test_final_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">gen</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)</span> <span class="o">*</span> <span class="mi">20</span>
<span class="n">test_final_block</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">make_gen_block</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_final_uns_noise</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">unsqueeze_noise</span><span class="p">(</span><span class="n">test_final_noise</span><span class="p">)</span>
<span class="n">final_output</span> <span class="o">=</span> <span class="n">test_final_block</span><span class="p">(</span><span class="n">test_final_uns_noise</span><span class="p">)</span>

<span class="c1"># Test the whole thing:</span>
<span class="n">test_gen_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">gen</span><span class="o">.</span><span class="n">z_dim</span><span class="p">)</span>
<span class="n">test_uns_gen_noise</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">unsqueeze_noise</span><span class="p">(</span><span class="n">test_gen_noise</span><span class="p">)</span>
<span class="n">gen_output</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">test_uns_gen_noise</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6b1aee0">
<h4 id="org6b1aee0">Unit Tests</h4>
<div class="outline-text-4" id="text-org6b1aee0">
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">hidden_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.2</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span>

<span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_hidden_block_stride</span><span class="p">(</span><span class="n">hidden_output</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">final_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>
<span class="k">assert</span> <span class="n">final_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span>

<span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">gen_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">gen_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
<span class="k">assert</span> <span class="n">gen_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.8</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Success!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org17172a2">
<h3 id="org17172a2">The Discriminator</h3>
<div class="outline-text-3" id="text-org17172a2">
<p>The second component you need to create is the discriminator.</p>
<p>You will use 3 layers in your discriminator's neural network. Like with the generator, you will need to create the method to create a single neural network block for the discriminator.</p>
<p>From the paper:</p>
<ul class="org-ul">
<li>[u]se LeakyReLU activation in the discriminator for all layers.</li>
<li>For the LeakyReLUs, "the slope of the leak was set to 0.2" in DCGAN.</li>
</ul>
<p>See Also:</p>
<ul class="org-ul">
<li><a href="https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html">nn.Conv2d</a></li>
<li><a href="https://pytorch.org/docs/master/generated/torch.nn.BatchNorm2d.html">nn.BatchNorm2d</a></li>
<li><a href="https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html">nn.LeakyReLU</a></li>
</ul>
</div>
<div class="outline-4" id="outline-container-org8e3369f">
<h4 id="org8e3369f">The Discriminator Class</h4>
<div class="outline-text-4" id="text-org8e3369f">
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""The DCGAN Discriminator</span>

<span class="sd">    Args:</span>
<span class="sd">     im_chan: the number of channels in the images, fitted for the dataset used</span>
<span class="sd">             (MNIST is black-and-white, so 1 channel is the default)</span>
<span class="sd">     hidden_dim: the inner dimension,</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im_chan</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="n">im_chan</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">make_disc_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">final_layer</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
        <span class="sd">"""Make a sub-block of layers for the discriminator</span>

<span class="sd">        - a convolution</span>
<span class="sd">        - a batchnorm (except for in the last layer)</span>
<span class="sd">        - an activation.</span>

<span class="sd">       Args:</span>
<span class="sd">         input_channels: how many channels the input feature representation has</span>
<span class="sd">         output_channels: how many channels the output feature representation should have</span>
<span class="sd">         kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)</span>
<span class="sd">         stride: the stride of the convolution</span>
<span class="sd">         final_layer: if true it is the final layer and otherwise not</span>
<span class="sd">                     (affects activation and batchnorm)</span>
<span class="sd">       """</span>        
        <span class="c1"># Build the neural block</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">final_layer</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">output_channels</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Final Layer</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="c1">#### START CODE HERE #### #</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="c1">#### END CODE HERE ####</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""Complete a forward pass of the discriminator</span>

<span class="sd">       Args:</span>
<span class="sd">         image: a flattened image tensor with dimension (im_dim)</span>

<span class="sd">       Returns:</span>
<span class="sd">        a 1-dimension tensor representing fake/real.</span>
<span class="sd">       """</span>
        <span class="n">disc_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">disc_pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">disc_pred</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd04e936">
<h4 id="orgd04e936">Set Up Testing</h4>
<div class="outline-text-4" id="text-orgd04e936">
<div class="highlight">
<pre><span></span><span class="n">num_test</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">make_some_noise</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">gen</span><span class="o">.</span><span class="n">z_dim</span><span class="p">))</span>

<span class="c1"># Test the hidden block</span>
<span class="n">test_hidden_block</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">hidden_output</span> <span class="o">=</span> <span class="n">test_hidden_block</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span>

<span class="c1"># Test the final block</span>
<span class="n">test_final_block</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">make_disc_block</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">final_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">final_output</span> <span class="o">=</span> <span class="n">test_final_block</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span>

<span class="c1"># Test the whole thing:</span>
<span class="n">disc_output</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6d98ddd">
<h4 id="org6d98ddd">Unit Testing</h4>
<div class="outline-text-4" id="text-org6d98ddd"></div>
<ul class="org-ul">
<li><a id="orgd25c066"></a>The Hidden Block<br>
<div class="outline-text-5" id="text-orgd25c066">
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">hidden_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="c1"># Because of the LeakyReLU slope</span>
<span class="k">assert</span> <span class="o">-</span><span class="n">hidden_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.15</span>
<span class="k">assert</span> <span class="o">-</span><span class="n">hidden_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.25</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
<span class="k">assert</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span>
</pre></div>
</div>
</li>
<li><a id="org0763c49"></a>The Final Block<br>
<div class="outline-text-5" id="text-org0763c49">
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">final_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">final_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
<span class="k">assert</span> <span class="n">final_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="k">assert</span> <span class="n">final_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
<span class="k">assert</span> <span class="n">final_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.6</span>
</pre></div>
</div>
</li>
<li><a id="org08c4b60"></a>The Whole Thing<br>
<div class="outline-text-5" id="text-org08c4b60">
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">disc_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">disc_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.25</span>
<span class="k">assert</span> <span class="n">disc_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Success!"</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orge636bc2">
<h3 id="orge636bc2">Training The Model</h3>
<div class="outline-text-3" id="text-orge636bc2">
<p>Remember that these are your parameters:</p>
<ul class="org-ul">
<li>criterion: the loss function</li>
<li>n_epochs: the number of times you iterate through the entire dataset when training</li>
<li>z_dim: the dimension of the noise vector</li>
<li>display_step: how often to display/visualize the images</li>
<li>batch_size: the number of images per forward/backward pass</li>
<li>lr: the learning rate</li>
<li>beta_1, beta_2: the momentum term</li>
<li>device: the device type</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgf665903">
<h4 id="orgf665903">Set Up The Data</h4>
<div class="outline-text-4" id="text-orgf665903">
<div class="highlight">
<pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># A learning rate of 0.0002 works well on DCGAN</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0002</span>

<span class="c1"># These parameters control the optimizer's momentum, which you can read more about here:</span>
<span class="c1"># https://distill.pub/2017/momentum/ but you don’t need to worry about it for this course!</span>
<span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.5</span> 
<span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.999</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span>

<span class="c1"># You can tranform the image values to be between -1 and 1 (the range of the tanh activation)</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,)),</span>
<span class="p">])</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/pytorch-data/MNIST"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">MNIST</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3b45d33">
<h4 id="org3b45d33">Set Up the GAN</h4>
<div class="outline-text-4" id="text-org3b45d33">
<div class="highlight">
<pre><span></span><span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">beta_1</span><span class="p">,</span> <span class="n">beta_2</span><span class="p">))</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
<span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">beta_1</span><span class="p">,</span> <span class="n">beta_2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7466db9">
<h4 id="org7466db9">A Weight Initializer</h4>
<div class="outline-text-4" id="text-org7466db9">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">initial_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">"""Initialize the weights to the normal distribution</span>

<span class="sd">     - mean 0</span>
<span class="sd">     - standard deviation 0.02</span>

<span class="sd">    Args:</span>
<span class="sd">     m: layer whose weights to initialize</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">gen</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">initial_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfdd058a">
<h4 id="orgfdd058a">Train it</h4>
<div class="outline-text-4" id="text-orgfdd058a">
<p>For each epoch, you will process the entire dataset in batches. For every batch, you will update the discriminator and generator. Then, you can see DCGAN's results!</p>
<p>Here's roughly the progression you should be expecting. On GPU this takes about 30 seconds per thousand steps. On CPU, this can take about 8 hours per thousand steps. You might notice that in the image of Step 5000, the generator is disproprotionately producing things that look like ones. If the discriminator didn't learn to detect this imbalance quickly enough, then the generator could just produce more ones. As a result, it may have ended up tricking the discriminator so well that there would be no more improvement, known as mode collapse.</p>
<div class="highlight">
<pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">cur_step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">mean_generator_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mean_discriminator_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">generator_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">discriminator_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
<span class="n">best_step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/gans/mnist-dcgan/best_model.pth"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># Dataloader returns the batches</span>
        <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
            <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1">## Update discriminator ##</span>
            <span class="n">disc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">fake_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">fake_noise</span><span class="p">)</span>
            <span class="n">disc_fake_pred</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
            <span class="n">disc_fake_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">))</span>
            <span class="n">disc_real_pred</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
            <span class="n">disc_real_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_real_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc_real_pred</span><span class="p">))</span>
            <span class="n">disc_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">disc_fake_loss</span> <span class="o">+</span> <span class="n">disc_real_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

            <span class="c1"># Keep track of the average discriminator loss</span>
            <span class="n">mean_discriminator_loss</span> <span class="o">+=</span> <span class="n">disc_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">display_step</span>
            <span class="c1"># Update gradients</span>
            <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># Update optimizer</span>
            <span class="n">disc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1">## Update generator ##</span>
            <span class="n">gen_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">fake_noise_2</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">fake_2</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">fake_noise_2</span><span class="p">)</span>
            <span class="n">disc_fake_pred</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fake_2</span><span class="p">)</span>
            <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc_fake_pred</span><span class="p">))</span>
            <span class="n">gen_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">gen_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Keep track of the average generator loss</span>
            <span class="n">mean_generator_loss</span> <span class="o">+=</span> <span class="n">gen_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">display_step</span>
            <span class="k">if</span> <span class="n">mean_generator_loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span><span class="p">,</span> <span class="n">best_step</span> <span class="o">=</span> <span class="n">mean_generator_loss</span><span class="p">,</span> <span class="n">cur_step</span>
                <span class="k">with</span> <span class="n">best_path</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
            <span class="c1">## Visualization code ##</span>
            <span class="k">if</span> <span class="n">cur_step</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cur_step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, step </span><span class="si">{</span><span class="n">cur_step</span><span class="si">}</span><span class="s2">: Generator loss:"</span>
                        <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">mean_generator_loss</span><span class="si">}</span><span class="s2">, discriminator loss:"</span>
                        <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">mean_discriminator_loss</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

                <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_step</span><span class="p">)</span>
                <span class="n">generator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_generator_loss</span><span class="p">)</span>
                <span class="n">discriminator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_discriminator_loss</span><span class="p">)</span>

                <span class="n">mean_generator_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">mean_discriminator_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cur_step</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
<pre class="example">
Started: 2021-04-21 12:45:12.452739
Epoch 2, step 1000: Generator loss: 1.2671969079673289, discriminator loss: 0.43014343224465823
Epoch 4, step 2000: Generator loss: 1.1353899730443968, discriminator loss: 0.5306872705817226
Epoch 6, step 3000: Generator loss: 0.8764803466945883, discriminator loss: 0.611450107574464
Epoch 8, step 4000: Generator loss: 0.7747784045338618, discriminator loss: 0.6631499938964849
Epoch 10, step 5000: Generator loss: 0.7640163034200661, discriminator loss: 0.6734729865789411
Epoch 12, step 6000: Generator loss: 0.7452541967928404, discriminator loss: 0.6805261079072958
Epoch 14, step 7000: Generator loss: 0.7337032879889016, discriminator loss: 0.6874966211915009
Epoch 17, step 8000: Generator loss: 0.7245009585618979, discriminator loss: 0.6908933531045917
Epoch 19, step 9000: Generator loss: 0.7180560626983646, discriminator loss: 0.6936621717810626
Epoch 21, step 10000: Generator loss: 0.7115822317004211, discriminator loss: 0.695760274052621
Epoch 23, step 11000: Generator loss: 0.7090291924774644, discriminator loss: 0.6962701203227039
Epoch 25, step 12000: Generator loss: 0.7059894913136957, discriminator loss: 0.6973492541313167
Epoch 27, step 13000: Generator loss: 0.7030480077862743, discriminator loss: 0.6978999735713001
Epoch 29, step 14000: Generator loss: 0.7028095332086096, discriminator loss: 0.6974007876515396
Epoch 31, step 15000: Generator loss: 0.7027116653919212, discriminator loss: 0.6965595571994787
Epoch 34, step 16000: Generator loss: 0.7005282629728309, discriminator loss: 0.6962912415862079
Epoch 36, step 17000: Generator loss: 0.7007142878770828, discriminator loss: 0.6961965024471283
Epoch 38, step 18000: Generator loss: 0.699474583208561, discriminator loss: 0.6952810400128371
Epoch 40, step 19000: Generator loss: 0.6989677719473828, discriminator loss: 0.6954642050266268
Epoch 42, step 20000: Generator loss: 0.6977452509403238, discriminator loss: 0.695180906951427
Epoch 44, step 21000: Generator loss: 0.6973587237596515, discriminator loss: 0.6950308464765543
Epoch 46, step 22000: Generator loss: 0.6960379970669743, discriminator loss: 0.6949119175076485
Epoch 49, step 23000: Generator loss: 0.6957966268062581, discriminator loss: 0.6948324624896048
Epoch 51, step 24000: Generator loss: 0.6958502059578898, discriminator loss: 0.6945331234931943
Epoch 53, step 25000: Generator loss: 0.6954856168627734, discriminator loss: 0.6943869084119801
Epoch 55, step 26000: Generator loss: 0.6957543395757682, discriminator loss: 0.694317172288894
Epoch 57, step 27000: Generator loss: 0.6947923063635825, discriminator loss: 0.694082073867321
Epoch 59, step 28000: Generator loss: 0.6945026598572728, discriminator loss: 0.6939926172494871
Epoch 61, step 29000: Generator loss: 0.6947789136767392, discriminator loss: 0.6938506522774704
Epoch 63, step 30000: Generator loss: 0.6946699734926227, discriminator loss: 0.6937169924378406
Epoch 66, step 31000: Generator loss: 0.6944284628629694, discriminator loss: 0.6936815274357805
Epoch 68, step 32000: Generator loss: 0.6940396347641948, discriminator loss: 0.6935891906023032
Epoch 70, step 33000: Generator loss: 0.6946771386265761, discriminator loss: 0.6937210547327995
Epoch 72, step 34000: Generator loss: 0.693429798424244, discriminator loss: 0.6937174627780922
Epoch 74, step 35000: Generator loss: 0.6937471128702157, discriminator loss: 0.6935204346776015
Epoch 76, step 36000: Generator loss: 0.6938841561675072, discriminator loss: 0.6934832554459566
Epoch 78, step 37000: Generator loss: 0.6934520475268362, discriminator loss: 0.6934578058719627
Epoch 81, step 38000: Generator loss: 0.6936635475754732, discriminator loss: 0.6934186050295835
Epoch 83, step 39000: Generator loss: 0.6936795052289972, discriminator loss: 0.6935187472105031
Epoch 85, step 40000: Generator loss: 0.6933113215565679, discriminator loss: 0.6933534587025645
Epoch 87, step 41000: Generator loss: 0.6934976277351385, discriminator loss: 0.6933284662365923
Epoch 89, step 42000: Generator loss: 0.6933313971757892, discriminator loss: 0.693348657488824
Epoch 91, step 43000: Generator loss: 0.6937436528205883, discriminator loss: 0.6933502901792529
Epoch 93, step 44000: Generator loss: 0.6943431540131578, discriminator loss: 0.6933887023925772
Epoch 95, step 45000: Generator loss: 0.6938722513914105, discriminator loss: 0.6932663491368296
Epoch 98, step 46000: Generator loss: 0.6933276618123067, discriminator loss: 0.6934270900487906
Ended: 2021-04-21 13:06:00.256725
Elapsed: 0:20:47.803986
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc5381fe">
<h3 id="orgc5381fe">Looking at the Final model.</h3>
<div class="outline-text-3" id="text-orgc5381fe">
<div class="highlight">
<pre><span></span><span class="n">fake_noise</span> <span class="o">=</span> <span class="n">make_some_noise</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">best_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">best_path</span><span class="p">)</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">(</span><span class="n">fake_noise</span><span class="p">)</span>
<span class="n">plot_image</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"fake_digits.png"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Fake Digits"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="fake_digits.png" src="posts/gans/cnn-gan/fake_digits.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="n">plot_image</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"real_digits.png"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Real Digits"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="real_digits.png" src="posts/gans/cnn-gan/real_digits.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="n">plotting</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"Step"</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
    <span class="s2">"Generator Loss"</span><span class="p">:</span> <span class="n">generator_losses</span><span class="p">,</span>
    <span class="s2">"Discriminator Loss"</span><span class="p">:</span> <span class="n">discriminator_losses</span>
<span class="p">})</span>

<span class="n">best</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">plotting</span><span class="p">[</span><span class="s2">"Generator Loss"</span><span class="p">]</span><span class="o">.</span><span class="n">argmin</span><span class="p">()]</span>
<span class="n">best_line</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">best</span><span class="o">.</span><span class="n">Step</span><span class="p">)</span>
<span class="n">gen_plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Generator Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>
<span class="n">disc_plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Discriminator Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">gen_plot</span> <span class="o">*</span> <span class="n">disc_plot</span> <span class="o">*</span> <span class="n">best_line</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Training Losses"</span><span class="p">,</span>
                                               <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                                               <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                               <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span>
                                               <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"losses"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/gans/cnn-gan/losses.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
</div>
<div class="outline-2" id="outline-container-orga727767">
<h2 id="orga727767">End</h2>
<div class="outline-text-2" id="text-orga727767"></div>
<div class="outline-3" id="outline-container-org37eb952">
<h3 id="org37eb952">Sources</h3>
<div class="outline-text-3" id="text-org37eb952">
<ul class="org-ul">
<li>Radford A, Metz L, Chintala S. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434. 2015 Nov 19. (<a href="https://arxiv.org/pdf/1511.06434v1.pdf">PDF</a>)</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/pytorch/pytorch-linear-regression/">PyTorch Linear Regression</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/pytorch/pytorch-linear-regression/" rel="bookmark"><time class="published dt-published" datetime="2021-04-10T16:05:44-07:00" itemprop="datePublished" title="2021-04-10 16:05">2021-04-10 16:05</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/pytorch/pytorch-linear-regression/#orgc722e77">Beginning</a>
<ul>
<li><a href="posts/pytorch/pytorch-linear-regression/#org1cad777">Imports</a></li>
<li><a href="posts/pytorch/pytorch-linear-regression/#org440af51">Set Up</a></li>
</ul>
</li>
<li><a href="posts/pytorch/pytorch-linear-regression/#org00d8e3d">Middle</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgc722e77">
<h2 id="orgc722e77">Beginning</h2>
<div class="outline-text-2" id="text-orgc722e77"></div>
<div class="outline-3" id="outline-container-org1cad777">
<h3 id="org1cad777">Imports</h3>
<div class="outline-text-3" id="text-org1cad777">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># local stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org440af51">
<h3 id="org440af51">Set Up</h3>
<div class="outline-text-3" id="text-org440af51">
<div class="highlight">
<pre><span></span><span class="n">random_generator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">2021</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"pytorch-linear-regression"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/pytorch/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">start</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">stop</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">uniform</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Create a random sample</span>

<span class="sd">    Args:</span>
<span class="sd">     start: lowest allowed value</span>
<span class="sd">     stop: highest allowed value</span>
<span class="sd">     shape: shape for the final array (just an int for single values)</span>
<span class="sd">     uniform: use the uniform distribution instead of the standard normal</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">uniform</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">*</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">*</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org00d8e3d">
<h2 id="org00d8e3d">Middle</h2>
<div class="outline-text-2" id="text-org00d8e3d">
<div class="highlight">
<pre><span></span><span class="n">SAMPLES</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">X_RANGE</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x_values</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="o">-</span><span class="n">X_RANGE</span><span class="p">,</span> <span class="n">X_RANGE</span><span class="p">,</span> <span class="n">SAMPLES</span><span class="p">)</span>
<span class="n">SLOPE</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">INTERCEPT</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">SAMPLES</span><span class="p">,</span> <span class="n">uniform</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">y_values</span> <span class="o">=</span> <span class="n">SLOPE</span> <span class="o">*</span> <span class="n">x_values</span> <span class="o">+</span> <span class="n">INTERCEPT</span> <span class="o">+</span> <span class="n">noise</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">data_frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">x_values</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">y_values</span><span class="p">))</span>
<span class="n">first</span><span class="p">,</span> <span class="n">last</span> <span class="o">=</span> <span class="n">x_values</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x_values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">line_frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
    <span class="nb">dict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">],</span>
         <span class="n">Y</span><span class="o">=</span><span class="p">[</span><span class="n">SLOPE</span> <span class="o">*</span> <span class="n">first</span> <span class="o">+</span> <span class="n">INTERCEPT</span><span class="p">,</span>
            <span class="n">SLOPE</span> <span class="o">*</span> <span class="n">last</span> <span class="o">+</span> <span class="n">INTERCEPT</span><span class="p">]))</span>
<span class="n">line_plot</span> <span class="o">=</span> <span class="n">line_frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"X"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Y"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>
<span class="n">data_plot</span> <span class="o">=</span> <span class="n">data_frame</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"X"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Y"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Sample Data"</span><span class="p">,</span>
                                      <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_plot</span> <span class="o">*</span> <span class="n">line_plot</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span>
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sample_data"</span><span class="p">)()</span>
</pre></div>
<object data="posts/pytorch/pytorch-linear-regression/sample_data.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">XY</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">index</span><span class="p">):</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">"x"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s2">"y"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">]}</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">XY</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">y_values</span><span class="p">)</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/gans/mnist-gan/">MNIST GAN</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/gans/mnist-gan/" rel="bookmark"><time class="published dt-published" datetime="2021-04-06T17:48:17-07:00" itemprop="datePublished" title="2021-04-06 17:48">2021-04-06 17:48</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/gans/mnist-gan/#orge58ad4c">Beginning</a>
<ul>
<li><a href="posts/gans/mnist-gan/#org50d2e3c">Imports</a></li>
<li><a href="posts/gans/mnist-gan/#org1b79290">Some Setup</a></li>
</ul>
</li>
<li><a href="posts/gans/mnist-gan/#org4808868">Middle</a>
<ul>
<li><a href="posts/gans/mnist-gan/#org9dfa75f">The MNIST Dataset</a></li>
<li><a href="posts/gans/mnist-gan/#org7c0a730">The Generator</a>
<ul>
<li><a href="posts/gans/mnist-gan/#orgfd5a335">Verify the generator block function</a></li>
<li><a href="posts/gans/mnist-gan/#orga594c2f">Building the Generator Class</a></li>
<li><a href="posts/gans/mnist-gan/#org3af7714">Verify the Generator Class</a></li>
</ul>
</li>
<li><a href="posts/gans/mnist-gan/#orgb5d06dc">Noise</a>
<ul>
<li><a href="posts/gans/mnist-gan/#org023693c">Verify the noise vector function</a></li>
</ul>
</li>
<li><a href="posts/gans/mnist-gan/#org34b9d22">The Discriminator</a>
<ul>
<li><a href="posts/gans/mnist-gan/#org3bc5fef">Verify the discriminator block function</a></li>
<li><a href="posts/gans/mnist-gan/#orgbde27f8">The Discriminator Class</a></li>
</ul>
</li>
<li><a href="posts/gans/mnist-gan/#orgbfa618a">Training</a>
<ul>
<li><a href="posts/gans/mnist-gan/#org97ca33d">Set your parameters</a></li>
<li><a href="posts/gans/mnist-gan/#org97df2ca">Load MNIST dataset as tensors</a></li>
<li><a href="posts/gans/mnist-gan/#org1afd0b9">Generator Loss</a></li>
<li><a href="posts/gans/mnist-gan/#orgd818a82">All Together</a></li>
</ul>
</li>
<li><a href="posts/gans/mnist-gan/#org15705bd">Looking at the Final model.</a></li>
</ul>
</li>
<li><a href="posts/gans/mnist-gan/#org52abb44">End</a></li>
</ul>
</div>
</div>
<p><b>Note:</b> The current version of pytorch (1.8.1) causes a Segmentation Fault in my nvidia-docker container (running CUDA 11, python 3.9, and Ubuntu 20.04). The fault comes at different points in the code depending on what I do - sometimes it's the backward's propagation, sometimes it's the pytorch binary that causes it, sometimes it's the libcuda binary… trying to debug it is probably beyond me so to get this working I had to go to the previous version of pytorch (1.7.1).</p>
<p><b>Update:</b> The previous error happened when I was using pip. I switched to using conda and that seems to have fixed it. One of the downsides to using conda is that it seems to download all the binary dependencies and it takes much longer to install everything than it does with pip, maybe because I don't have a really fat internet pipe. Oh, well.</p>
<div class="outline-2" id="outline-container-orge58ad4c">
<h2 id="orge58ad4c">Beginning</h2>
<div class="outline-text-2" id="text-orge58ad4c"></div>
<div class="outline-3" id="outline-container-org50d2e3c">
<h3 id="org50d2e3c">Imports</h3>
<div class="outline-text-3" id="text-org50d2e3c">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># local code</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1b79290">
<h3 id="org1b79290">Some Setup</h3>
<div class="outline-text-3" id="text-org1b79290">
<p>First we'll set the manual seed to make this reproducible.</p>
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<p>This is a convenience object to time the training.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
<p>This is for plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"mnist-gan"</span>

<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/gans/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org4808868">
<h2 id="org4808868">Middle</h2>
<div class="outline-text-2" id="text-org4808868"></div>
<div class="outline-3" id="outline-container-org9dfa75f">
<h3 id="org9dfa75f">The MNIST Dataset</h3>
<div class="outline-text-3" id="text-org9dfa75f">
<p>The training images we will be using are from a dataset called <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>. The dataset contains 60,000 images of handwritten digits, from 0 to 9.</p>
<p>The images are 28 pixels x 28 pixels in size. The small size of its images makes MNIST ideal for simple training. Additionally, these images are also in black-and-white so only one dimension, or "color channel", is needed to represent them. Pytorch has a <a href="https://pytorch.org/vision/0.8/datasets.html#mnist">version of it</a> ready-made for their system so we'll use theirs.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org7c0a730">
<h3 id="org7c0a730">The Generator</h3>
<div class="outline-text-3" id="text-org7c0a730">
<p>The first step is to build the generator component.</p>
<p>We'll start by creating a function to make a single layer/block for the generator's neural network. Each block should include a <a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">linear transformation</a> (\(y=xA^T + b\)) to the input to another shape, <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">batch normalization</a> for stabilization, and finally a non-linear activation function (<a href="https://pytorch.org/docs/master/generated/torch.nn.ReLU.html">ReLU</a> in this case).</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">generator_block</span><span class="p">(</span><span class="n">input_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Creates a block of the generator's neural network</span>

<span class="sd">    Args:</span>
<span class="sd">      input_features: the dimension of the input vector</span>
<span class="sd">      output_features: the dimension of the output vector</span>

<span class="sd">    Returns:</span>
<span class="sd">       a generator neural network layer, with a linear transformation </span>
<span class="sd">         followed by a batch normalization and then a relu activation</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_features</span><span class="p">,</span> <span class="n">output_features</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">output_features</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgfd5a335">
<h4 id="orgfd5a335">Verify the generator block function</h4>
<div class="outline-text-4" id="text-orgfd5a335">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_gen_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                   <span class="n">test_rows</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Test the generator block creator</span>

<span class="sd">    Args:</span>
<span class="sd">     in_features: number of features for the block input</span>
<span class="sd">     out_features: the final number of features for it to output</span>
<span class="sd">     test_rows: how many rows to put in the test Tensor</span>

<span class="sd">    Raises:</span>
<span class="sd">     AssertionError: something isn't right</span>
<span class="sd">    """</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">generator_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># Check the three parts</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">block</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">block</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">block</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span>

    <span class="c1"># Check the output shape</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">test_rows</span><span class="p">,</span> <span class="n">in_features</span><span class="p">))</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">test_rows</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># check the normalization</span>
    <span class="k">assert</span> <span class="mf">0.65</span> <span class="o">&gt;</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.55</span>
    <span class="k">return</span>

<span class="n">test_gen_block</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">test_gen_block</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga594c2f">
<h4 id="orga594c2f">Building the Generator Class</h4>
<div class="outline-text-4" id="text-orga594c2f">
<p>Now that we have the block-builder we can define our Generator network. It's going to contain a sequence of blocks output by our block-building function and a final two layers that use the linear transformation again, but don't apply normalization and use a <a href="https://pytorch.org/docs/master/generated/torch.nn.Sigmoid.html">Sigmoid Function</a> instead of the ReLU. Each block will have an output double that of the previous one.</p>
<div class="figure">
<p><img alt="generator.png" src="posts/gans/mnist-gan/generator.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""Generator Class</span>

<span class="sd">    Args:</span>
<span class="sd">      input_dimension: the dimension of the noise vector</span>
<span class="sd">      image_dimension: the dimension of the images, fitted for the dataset used</span>
<span class="sd">        (MNIST images are 28 x 28 = 784 so that is the default)</span>
<span class="sd">      hidden_dimension: the initial hidden-layer dimension</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">image_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span>
                 <span class="n">hidden_dimension</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">get_generator_block</span><span class="p">(</span><span class="n">input_dimension</span><span class="p">,</span> <span class="n">hidden_dimension</span><span class="p">),</span>
            <span class="n">get_generator_block</span><span class="p">(</span><span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">get_generator_block</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">get_generator_block</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">8</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dimension</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">image_dimension</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">       Method for a forward pass of the generator</span>

<span class="sd">       Args:</span>
<span class="sd">        noise: a noise tensor with dimensions (n_samples, z_dim)</span>

<span class="sd">       Returns: </span>
<span class="sd">        generated images.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3af7714">
<h4 id="org3af7714">Verify the Generator Class</h4>
<div class="outline-text-4" id="text-org3af7714">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                   <span class="n">num_test</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Test the Generator Class</span>

<span class="sd">    Args:</span>
<span class="sd">     z_dim: the size of the input</span>
<span class="sd">     im_dim: the size of the image</span>
<span class="sd">     hidden_dim: the size of the initial hidden layer</span>

<span class="sd">    Raises:</span>
<span class="sd">     AssertionError: something is wrong</span>
<span class="sd">    """</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">generator</span>

    <span class="c1"># Check there are six modules in the sequential part</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">gen</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>

    <span class="c1"># Check that the output shape is correct</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">)</span>

    <span class="c1"># Chechk the output</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">test_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">"Make sure to use a sigmoid"</span>
    <span class="k">assert</span> <span class="n">test_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">"Don't use a block in your solution"</span>
    <span class="k">assert</span> <span class="mf">0.15</span> <span class="o">&gt;</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s2">"Don't use batchnorm here"</span>
    <span class="k">return</span>

<span class="n">test_generator</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">test_generator</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb5d06dc">
<h3 id="orgb5d06dc">Noise</h3>
<div class="outline-text-3" id="text-orgb5d06dc">
<p>To be able to use the generator, we will need to be able to create noise vectors. The noise vector <code>z</code> has the important role of making sure the images generated from the same class don't all look the same – think of it as a random seed. You will generate it randomly using PyTorch by sampling random numbers from the normal distribution. Since multiple images will be processed per pass, you will generate all the noise vectors at once.</p>
<p>Note that whenever you create a new tensor using torch.ones, torch.zeros, or <a href="https://pytorch.org/docs/master/generated/torch.randn.html">torch.randn</a>, you either need to create it on the target device, e.g. <code>torch.ones(3, 3, device=device)</code>, or move it onto the target device using <code>torch.ones(3, 3).to(device)</code>. You do not need to do this if you're creating a tensor by manipulating another tensor or by using a variation that defaults the device to the input, such as <code>torch.ones_like</code>. In general, use <code>torch.ones_like</code> and <code>torch.zeros_like</code> instead of <code>torch.ones</code> or <code>torch.zeros</code> where possible.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda'</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">"""create noise vectors</span>

<span class="sd">    Args:</span>
<span class="sd">       n_samples: the number of samples to generate, a scalar</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       device: the device type</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org023693c">
<h4 id="org023693c">Verify the noise vector function</h4>
<div class="outline-text-4" id="text-org023693c">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_get_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># Make sure a normal distribution was used</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
    <span class="k">assert</span> <span class="nb">str</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">test_get_noise</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org34b9d22">
<h3 id="org34b9d22">The Discriminator</h3>
<div class="outline-text-3" id="text-org34b9d22">
<p>The second component that you need to construct is the discriminator. As with the generator component, you will start by creating a function that builds a neural network block for the discriminator.</p>
<p><b>Note: You use <a href="https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html">leaky ReLUs</a> to prevent the "dying ReLU" problem, which refers to the phenomenon where the parameters stop changing due to consistently negative values passed to a ReLU, which result in a zero gradient.</b></p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_discriminator_block</span><span class="p">(</span><span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                            <span class="n">negative_slope</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="sd">"""Create the Discriminator block</span>

<span class="sd">    Args:</span>
<span class="sd">      input_dim: the dimension of the input vector, a scalar</span>
<span class="sd">      output_dim: the dimension of the output vector, a scalar</span>
<span class="sd">      negative_slope: angle for the negative slope</span>

<span class="sd">    Returns:</span>
<span class="sd">       a discriminator neural network layer, with a linear transformation </span>
<span class="sd">         followed by an nn.LeakyReLU activation with negative slope of 0.2 </span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3bc5fef">
<h4 id="org3bc5fef">Verify the discriminator block function</h4>
<div class="outline-text-4" id="text-org3bc5fef">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_disc_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">num_test</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># Check there are two parts</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">in_features</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>

    <span class="c1"># Check that the shape is right</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="c1"># Check that the LeakyReLU slope is about 0.2</span>
    <span class="k">assert</span> <span class="o">-</span><span class="n">test_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">test_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.1</span>
    <span class="k">assert</span> <span class="o">-</span><span class="n">test_output</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">test_output</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.3</span>
    <span class="k">assert</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.3</span>
    <span class="k">assert</span> <span class="n">test_output</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span>

<span class="n">test_disc_block</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">test_disc_block</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbde27f8">
<h4 id="orgbde27f8">The Discriminator Class</h4>
<div class="outline-text-4" id="text-orgbde27f8">
<p>The discriminator class holds 2 values:</p>
<ul class="org-ul">
<li>The image dimension</li>
<li>The hidden dimension</li>
</ul>
<p>The discriminator will build a neural network with 4 layers. It will start with the image tensor and transform it until it returns a single number (1-dimension tensor) output. This output classifies whether an image is fake or real. Note that you do not need a sigmoid after the output layer since it is included in the loss function. Finally, to use your discrimator's neural network you are given a forward pass function that takes in an image tensor to be classified.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""The Discriminator Class</span>

<span class="sd">    Args:</span>
<span class="sd">       im_dim: the dimension of the images, fitted for the dataset used, a scalar</span>
<span class="sd">           (MNIST images are 28x28 = 784 so that is your default)</span>
<span class="sd">       hidden_dim: the inner dimension, a scalar</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">im_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">),</span>
            <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">get_discriminator_block</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""forward pass of the discriminator</span>

<span class="sd">       Args:</span>
<span class="sd">           image: a flattened image tensor with dimension (im_dim)</span>

<span class="sd">       Returns a 1-dimension tensor representing fake/real.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">disc</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org4aec163"></a>Verify the discriminator class<br>
<div class="outline-text-5" id="text-org4aec163">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_discriminator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_test</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span><span class="o">.</span><span class="n">disc</span>

    <span class="c1"># Check there are three parts</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">disc</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>

    <span class="c1"># Check the linear layer is correct</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="n">test_output</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">test_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Don't use a block</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">disc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">)</span>

<span class="n">test_discriminator</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">test_discriminator</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgbfa618a">
<h3 id="orgbfa618a">Training</h3>
<div class="outline-text-3" id="text-orgbfa618a">
<p>First, you will set your parameters:</p>
<ul class="org-ul">
<li>criterion: the loss function (<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html?highlight=bcewithlogitsloss">BCEWithLogitsLoss</a></li>
<li>n_epochs: the number of times you iterate through the entire dataset when training</li>
<li>z_dim: the dimension of the noise vector</li>
<li>display_step: how often to display/visualize the images</li>
<li>batch_size: the number of images per forward/backward pass</li>
<li>lr: the learning rate</li>
<li>device: the device type, here using a GPU (which runs CUDA), not CPU</li>
</ul>
<p>Next, you will load the MNIST dataset as tensors using a dataloader.</p>
</div>
<div class="outline-4" id="outline-container-org97ca33d">
<h4 id="org97ca33d">Set your parameters</h4>
<div class="outline-text-4" id="text-org97ca33d">
<div class="highlight">
<pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.00001</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org97df2ca">
<h4 id="org97df2ca">Load MNIST dataset as tensors</h4>
<div class="outline-text-4" id="text-org97df2ca">
<div class="highlight">
<pre><span></span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">MNIST</span><span class="p">(</span><span class="s1">'.'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<p>Now, you can initialize your generator, discriminator, and optimizers. Note that each optimizer only takes the parameters of one particular model, since we want each optimizer to optimize only one of the models.</p>
<div class="highlight">
<pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span>
<span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
<span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
<p>Before you train your GAN, you will need to create functions to calculate the discriminator's loss and the generator's loss. This is how the discriminator and generator will know how they are doing and improve themselves. Since the generator is needed when calculating the discriminator's loss, you will need to call .detach() on the generator result to ensure that only the discriminator is updated!</p>
<p>Remember that you have already defined a loss function earlier (<code>criterion</code>) and you are encouraged to use <a href="https://pytorch.org/docs/master/generated/torch.ones_like.html?highlight=ones_like#torch.ones_like"><code>torch.ones_like</code></a> and <a href="https://pytorch.org/docs/master/generated/torch.zeros_like.html?highlight=zeros_like#torch.zeros_like"><code>torch.zeros_like</code></a> instead of <code>torch.ones</code> or <code>torch.zeros</code>. If you use <code>torch.ones</code> or <code>torch.zeros</code>, you'll need to pass <code>device=device</code> to them.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">:</span> <span class="n">Generator</span><span class="p">,</span> <span class="n">disc</span><span class="p">:</span> <span class="n">Discriminator</span><span class="p">,</span>
                  <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">,</span>
                  <span class="n">real</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                  <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
                  <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Get the loss of the discriminator given inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">       gen: the generator model, which returns an image given z-dimensional noise</span>
<span class="sd">       disc: the discriminator model, which returns a single-dimensional prediction of real/fake</span>
<span class="sd">       criterion: the loss function, which should be used to compare </span>
<span class="sd">              the discriminator's predictions to the ground truth reality of the images </span>
<span class="sd">              (e.g. fake = 0, real = 1)</span>
<span class="sd">       real: a batch of real images</span>
<span class="sd">       num_images: the number of images the generator should produce, </span>
<span class="sd">               which is also the length of the real images</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       device: the device type</span>

<span class="sd">    Returns:</span>
<span class="sd">       disc_loss: a torch scalar loss value for the current batch</span>
<span class="sd">    """</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">fakes</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="n">fake_prediction</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fakes</span><span class="p">)</span>
    <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">))</span>

    <span class="n">real_prediction</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
    <span class="n">real_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">real_prediction</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_prediction</span><span class="p">))</span>
    <span class="n">disc_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">fake_loss</span> <span class="o">+</span> <span class="n">real_loss</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">disc_loss</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_disc_reasonable</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Don't use explicit casts to cuda - use the device argument</span>
    <span class="kn">import</span> <span class="nn">inspect</span><span class="o">,</span> <span class="nn">re</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">get_disc_loss</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"to\(.cuda.\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\.cuda\(\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">disc_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="mi">10</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="n">disc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mf">11.25</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.75</span><span class="p">))</span>
    <span class="k">return</span>

<span class="n">test_disc_reasonable</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_disc_loss</span><span class="p">(</span><span class="n">max_tests</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
    <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>
        <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1">### Update discriminator ###</span>
        <span class="c1"># Zero out the gradient before backpropagation</span>
        <span class="n">disc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Calculate discriminator loss</span>
        <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">disc_loss</span> <span class="o">-</span> <span class="mf">0.68</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">disc_loss</span>

        <span class="c1"># Update gradients</span>
        <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Check that they detached correctly</span>
        <span class="k">assert</span> <span class="n">gen</span><span class="o">.</span><span class="n">gen</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="c1"># Update optimizer</span>
        <span class="n">old_weight</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">disc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">disc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">new_weight</span> <span class="o">=</span> <span class="n">disc</span><span class="o">.</span><span class="n">disc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>

        <span class="c1"># Check that some discriminator weights changed</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">old_weight</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">))</span>
        <span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">num_steps</span> <span class="o">&gt;=</span> <span class="n">max_tests</span><span class="p">:</span>
            <span class="k">break</span>

<span class="n">test_disc_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1afd0b9">
<h4 id="org1afd0b9">Generator Loss</h4>
<div class="outline-text-4" id="text-org1afd0b9">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">:</span> <span class="n">Generator</span><span class="p">,</span>
                 <span class="n">disc</span><span class="p">:</span> <span class="n">Discriminator</span><span class="p">,</span>
                 <span class="n">criterion</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">,</span>
                 <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">z_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">"""Calculates the loss for the generator</span>

<span class="sd">    Args:</span>
<span class="sd">       gen: the generator model, which returns an image given z-dimensional noise</span>
<span class="sd">       disc: the discriminator model, which returns a single-dimensional prediction of real/fake</span>
<span class="sd">       criterion: the loss function, which should be used to compare </span>
<span class="sd">              the discriminator's predictions to the ground truth reality of the images </span>
<span class="sd">              (e.g. fake = 0, real = 1)</span>
<span class="sd">       num_images: the number of images the generator should produce, </span>
<span class="sd">               which is also the length of the real images</span>
<span class="sd">       z_dim: the dimension of the noise vector, a scalar</span>
<span class="sd">       device: the device type</span>
<span class="sd">    Returns:</span>
<span class="sd">       gen_loss: a torch scalar loss value for the current batch</span>
<span class="sd">    """</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">fakes</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">fake_prediction</span> <span class="o">=</span> <span class="n">disc</span><span class="p">(</span><span class="n">fakes</span><span class="p">)</span>
    <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_prediction</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">gen_loss</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_gen_reasonable</span><span class="p">(</span><span class="n">num_images</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Don't use explicit casts to cuda - use the device argument</span>
    <span class="kn">import</span> <span class="nn">inspect</span><span class="o">,</span> <span class="nn">re</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getsource</span><span class="p">(</span><span class="n">get_gen_loss</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"to\(.cuda.\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\.cuda\(\)"</span><span class="p">,</span> <span class="n">lines</span><span class="p">))</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">gen_loss_tensor</span> <span class="o">=</span> <span class="n">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">gen_loss_tensor</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="c1">#Verify shape. Related to gen_noise parametrization</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">gen_loss_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>

    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span> <span class="c1"># Multiply</span>
    <span class="n">real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">gen_loss_tensor</span> <span class="o">=</span> <span class="n">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">gen_loss_tensor</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="c1">#Verify shape. Related to gen_noise parametrization</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">gen_loss_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">)</span>
    <span class="k">return</span>
<span class="n">test_gen_reasonable</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_gen_loss</span><span class="p">(</span><span class="n">num_images</span><span class="p">):</span>
    <span class="n">z_dim</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">z_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">gen_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">disc</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
    <span class="n">disc_opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">disc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># Check that the loss is reasonable</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">gen_loss</span> <span class="o">-</span> <span class="mf">0.7</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
    <span class="n">gen_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">old_weight</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">gen</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">gen_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">new_weight</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">gen</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">old_weight</span><span class="p">,</span> <span class="n">new_weight</span><span class="p">))</span>
<span class="n">test_gen_loss</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd818a82">
<h4 id="orgd818a82">All Together</h4>
<div class="outline-text-4" id="text-orgd818a82">
<p>For each epoch, you will process the entire dataset in batches. For every batch, you will need to update the discriminator and generator using their loss. Batches are sets of images that will be predicted on before the loss functions are calculated (instead of calculating the loss function after each image). Note that you may see a loss to be greater than 1, this is okay since binary cross entropy loss can be any positive number for a sufficiently confident wrong guess.</p>
<p>It’s also often the case that the discriminator will outperform the generator, especially at the start, because its job is easier. It's important that neither one gets too good (that is, near-perfect accuracy), which would cause the entire model to stop learning. Balancing the two models is actually remarkably hard to do in a standard GAN and something you will see more of in later lectures and assignments.</p>
<p>After you've submitted a working version with the original architecture, feel free to play around with the architecture if you want to see how different architectural choices can lead to better or worse GANs. For example, consider changing the size of the hidden dimension, or making the networks shallower or deeper by changing the number of layers.</p>
<div class="highlight">
<pre><span></span><span class="n">cur_step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mean_generator_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mean_discriminator_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">test_generator</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Whether the generator should be tested</span>
<span class="n">gen_loss</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">error</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">4100</span>
<span class="n">generator_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">discriminator_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>

        <span class="c1"># Dataloader returns the batches</span>
        <span class="k">for</span> <span class="n">real</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">real</span><span class="p">)</span>

            <span class="c1"># Flatten the batch of real images from the dataset</span>
            <span class="n">real</span> <span class="o">=</span> <span class="n">real</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1">### Update discriminator ###</span>
            <span class="c1"># Zero out the gradients before backpropagation</span>
            <span class="n">disc_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Calculate discriminator loss</span>
            <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">get_disc_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

            <span class="c1"># Update gradients</span>
            <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Update optimizer</span>
            <span class="n">disc_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># For testing purposes, to keep track of the generator weights</span>
            <span class="k">if</span> <span class="n">test_generator</span><span class="p">:</span>
                <span class="n">old_generator_weights</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">gen</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

            <span class="c1">### Update generator ###</span>
            <span class="n">gen_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">get_gen_loss</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">disc</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="n">gen_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">gen_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># For testing purposes, to check that your code changes the generator weights</span>
            <span class="k">if</span> <span class="n">test_generator</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="n">lr</span> <span class="o">&gt;</span> <span class="mf">0.0000002</span> <span class="ow">or</span> <span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">gen</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.0005</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">gen</span><span class="o">.</span><span class="n">gen</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">!=</span> <span class="n">old_generator_weights</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">error</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">"Runtime tests have failed"</span><span class="p">)</span>

            <span class="c1"># Keep track of the average discriminator loss</span>
            <span class="n">mean_discriminator_loss</span> <span class="o">+=</span> <span class="n">disc_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">display_step</span>

            <span class="c1"># Keep track of the average generator loss</span>
            <span class="n">mean_generator_loss</span> <span class="o">+=</span> <span class="n">gen_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">display_step</span>

            <span class="k">if</span> <span class="n">cur_step</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">cur_step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, step </span><span class="si">{</span><span class="n">cur_step</span><span class="si">}</span><span class="s2">: Generator loss:"</span>
                        <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">mean_generator_loss</span><span class="si">}</span><span class="s2">, discriminator loss:"</span>
                        <span class="sa">f</span><span class="s2">" </span><span class="si">{</span><span class="n">mean_discriminator_loss</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_step</span><span class="p">)</span>
                <span class="n">generator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_generator_loss</span><span class="p">)</span>
                <span class="n">discriminator_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_discriminator_loss</span><span class="p">)</span>

                <span class="n">mean_generator_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">mean_discriminator_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">cur_step</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
<pre class="example">
Started: 2021-04-08 19:11:09.461117
Epoch 5, step 2500: Generator loss: 1.706548154211052, discriminator loss: 0.2566282903790473
Epoch 10, step 5000: Generator loss: 4.417493268251426, discriminator loss: 0.37590573319792847
Epoch 15, step 7500: Generator loss: 8.217398338270204, discriminator loss: 0.4420946755893531
Epoch 21, step 10000: Generator loss: 12.379702310991277, discriminator loss: 0.49946175085604244
Epoch 26, step 12500: Generator loss: 16.363392679834355, discriminator loss: 0.577481897354875
Epoch 31, step 15000: Generator loss: 20.321313246965392, discriminator loss: 0.6705450104258994
Epoch 37, step 17500: Generator loss: 23.881395485830232, discriminator loss: 0.7909670361138917
Epoch 42, step 20000: Generator loss: 27.36178849205961, discriminator loss: 0.9245524749659035
Epoch 47, step 22500: Generator loss: 30.756254529428357, discriminator loss: 1.0683966985411961
Epoch 53, step 25000: Generator loss: 33.873566954183424, discriminator loss: 1.2374154507704083
Epoch 58, step 27500: Generator loss: 36.76653855376236, discriminator loss: 1.4335610504932743
Epoch 63, step 30000: Generator loss: 39.610195555067065, discriminator loss: 1.6299822613395802
Epoch 69, step 32500: Generator loss: 42.27110341444029, discriminator loss: 1.8545818868704136
Epoch 74, step 35000: Generator loss: 44.86730858569149, discriminator loss: 2.081926002264768
Epoch 79, step 37500: Generator loss: 47.34035383772865, discriminator loss: 2.3272732418782995
Epoch 85, step 40000: Generator loss: 49.69807465667742, discriminator loss: 2.5900223485894514
Epoch 90, step 42500: Generator loss: 51.95912191028614, discriminator loss: 2.856632189888516
Epoch 95, step 45000: Generator loss: 54.13774062051793, discriminator loss: 3.1388706683166423
Epoch 101, step 47500: Generator loss: 56.25892917881031, discriminator loss: 3.435482066709555
Epoch 106, step 50000: Generator loss: 58.2940666561604, discriminator loss: 3.742299897164866
Epoch 111, step 52500: Generator loss: 60.34588112130169, discriminator loss: 4.039923962772651
Epoch 117, step 55000: Generator loss: 62.3250578921796, discriminator loss: 4.3601536815710755
Epoch 122, step 57500: Generator loss: 64.21707550911917, discriminator loss: 4.693669865030843
Epoch 127, step 60000: Generator loss: 66.14931350994115, discriminator loss: 5.012754998887372
Epoch 133, step 62500: Generator loss: 68.01088003492343, discriminator loss: 5.350926510263262
Epoch 138, step 65000: Generator loss: 69.7833545449736, discriminator loss: 5.705678011608883
Epoch 143, step 67500: Generator loss: 71.56750503945366, discriminator loss: 6.058190715546184
Epoch 149, step 70000: Generator loss: 73.28055478563336, discriminator loss: 6.422111075831223
Epoch 154, step 72500: Generator loss: 74.93712217669513, discriminator loss: 6.801459926683468
Epoch 159, step 75000: Generator loss: 76.57140328321462, discriminator loss: 7.186894027460396
Epoch 165, step 77500: Generator loss: 78.11976942777646, discriminator loss: 7.59347033443528
Epoch 170, step 80000: Generator loss: 79.70259762425445, discriminator loss: 7.990671021056967
Epoch 175, step 82500: Generator loss: 81.29402320809406, discriminator loss: 8.38323437005357
Epoch 181, step 85000: Generator loss: 82.81459570746449, discriminator loss: 8.79464628630952
Epoch 186, step 87500: Generator loss: 84.37445686025625, discriminator loss: 9.187008984566525
Epoch 191, step 90000: Generator loss: 85.85529090266233, discriminator loss: 9.62971806451164
Epoch 197, step 92500: Generator loss: 87.28264569795147, discriminator loss: 10.0601266036578
Epoch 202, step 95000: Generator loss: 88.77136517236256, discriminator loss: 10.470760706252658
Epoch 207, step 97500: Generator loss: 90.20359932258185, discriminator loss: 10.896903645534154
Epoch 213, step 100000: Generator loss: 91.64949153683249, discriminator loss: 11.314317919439938
Epoch 218, step 102500: Generator loss: 93.04353729379224, discriminator loss: 11.754701970989366
Epoch 223, step 105000: Generator loss: 94.48434179880661, discriminator loss: 12.17579472559178
Epoch 229, step 107500: Generator loss: 95.90043624894685, discriminator loss: 12.609691903144922
Epoch 234, step 110000: Generator loss: 97.22790038921927, discriminator loss: 13.06728125928124
Epoch 239, step 112500: Generator loss: 98.54396488256565, discriminator loss: 13.530596924526252
Epoch 245, step 115000: Generator loss: 99.77238301303473, discriminator loss: 14.021221584183708
Epoch 250, step 117500: Generator loss: 100.95588274421799, discriminator loss: 14.52276291984987
Epoch 255, step 120000: Generator loss: 102.16950242385977, discriminator loss: 15.009217036432748
Epoch 261, step 122500: Generator loss: 103.34768993141779, discriminator loss: 15.510240219909676
Epoch 266, step 125000: Generator loss: 104.49850498325966, discriminator loss: 16.02100355718803
Epoch 271, step 127500: Generator loss: 105.63248440983429, discriminator loss: 16.529967280096464
Epoch 277, step 130000: Generator loss: 106.77215565025928, discriminator loss: 17.040578575879902
Epoch 282, step 132500: Generator loss: 107.84948109347918, discriminator loss: 17.577629218131907
Epoch 287, step 135000: Generator loss: 108.89120032596693, discriminator loss: 18.1230313348835
Epoch 293, step 137500: Generator loss: 109.94543989174456, discriminator loss: 18.66669545603442
Epoch 298, step 140000: Generator loss: 111.05784844493985, discriminator loss: 19.186080698353518
Epoch 303, step 142500: Generator loss: 112.11954127087729, discriminator loss: 19.72143556161576
Epoch 309, step 145000: Generator loss: 113.1505551135316, discriminator loss: 20.266378742129064
Epoch 314, step 147500: Generator loss: 114.14504244511286, discriminator loss: 20.82540130450163
Epoch 319, step 150000: Generator loss: 115.14619642219694, discriminator loss: 21.377254920214682
Epoch 325, step 152500: Generator loss: 116.18683508672831, discriminator loss: 21.91325990107692
Epoch 330, step 155000: Generator loss: 117.20365596852427, discriminator loss: 22.464628956920198
Epoch 335, step 157500: Generator loss: 118.18476380837096, discriminator loss: 23.02610586987158
Epoch 341, step 160000: Generator loss: 119.1733443738712, discriminator loss: 23.57863494028462
Epoch 346, step 162500: Generator loss: 120.0683158794178, discriminator loss: 24.17668376757525
Epoch 351, step 165000: Generator loss: 121.00822785911677, discriminator loss: 24.759683359057014
Epoch 357, step 167500: Generator loss: 122.01716691696792, discriminator loss: 25.306333132869433
Epoch 362, step 170000: Generator loss: 122.95615759954634, discriminator loss: 25.882448339409144
Epoch 367, step 172500: Generator loss: 123.8601865704076, discriminator loss: 26.472507165831818
Epoch 373, step 175000: Generator loss: 124.77679342136544, discriminator loss: 27.06009588730988
Epoch 378, step 177500: Generator loss: 125.68742787552021, discriminator loss: 27.650220775634565
Epoch 383, step 180000: Generator loss: 126.58067360401337, discriminator loss: 28.24680029824429
Epoch 389, step 182500: Generator loss: 127.47687033252896, discriminator loss: 28.841687268430586
Epoch 394, step 185000: Generator loss: 128.33945010419103, discriminator loss: 29.470305139536162
Epoch 399, step 187500: Generator loss: 129.2645899116776, discriminator loss: 30.056467109007148
Epoch 405, step 190000: Generator loss: 130.17483343897044, discriminator loss: 30.65010625776692
Epoch 410, step 192500: Generator loss: 131.07306051247323, discriminator loss: 31.24635483381194
Epoch 415, step 195000: Generator loss: 131.98270811326725, discriminator loss: 31.83840948063775
Epoch 421, step 197500: Generator loss: 132.89332210309777, discriminator loss: 32.427245197707826
Epoch 426, step 200000: Generator loss: 133.85536700406317, discriminator loss: 32.99699493227643
Epoch 431, step 202500: Generator loss: 134.78184310503255, discriminator loss: 33.582932585127054
Epoch 437, step 205000: Generator loss: 135.67147595069721, discriminator loss: 34.18765857823589
Epoch 442, step 207500: Generator loss: 136.59887173002065, discriminator loss: 34.770955285043314
Epoch 447, step 210000: Generator loss: 137.53319753001017, discriminator loss: 35.35211720700919
Epoch 453, step 212500: Generator loss: 138.4486942873986, discriminator loss: 35.94530614820166
Epoch 458, step 215000: Generator loss: 139.33902888264944, discriminator loss: 36.54999590321232
Epoch 463, step 217500: Generator loss: 140.27206793022475, discriminator loss: 37.13930196701909
Epoch 469, step 220000: Generator loss: 140.99687212999171, discriminator loss: 37.93871315395262
Epoch 474, step 222500: Generator loss: 141.7673044035706, discriminator loss: 38.59500126797581
Epoch 479, step 225000: Generator loss: 142.5946069137365, discriminator loss: 39.21644382466705
Epoch 485, step 227500: Generator loss: 143.47817903824173, discriminator loss: 39.82380570806908
Epoch 490, step 230000: Generator loss: 144.42988614442692, discriminator loss: 40.41459694806965
Epoch 495, step 232500: Generator loss: 145.41308410630532, discriminator loss: 40.99819621782919
Epoch 501, step 235000: Generator loss: 146.35154331310105, discriminator loss: 41.60116203337314
Epoch 506, step 237500: Generator loss: 147.3414293385067, discriminator loss: 42.182913084965904
Epoch 511, step 240000: Generator loss: 148.16208219452346, discriminator loss: 42.84799684844597
Epoch 517, step 242500: Generator loss: 149.01690332217666, discriminator loss: 43.4645494998036
Epoch 522, step 245000: Generator loss: 149.90361780090743, discriminator loss: 44.07395624421216
Epoch 527, step 247500: Generator loss: 150.81761934249764, discriminator loss: 44.67337528136382
Epoch 533, step 250000: Generator loss: 151.760788434009, discriminator loss: 45.27149211621905
Epoch 538, step 252500: Generator loss: 152.72171067755622, discriminator loss: 45.862570312196205
Epoch 543, step 255000: Generator loss: 153.70058994908774, discriminator loss: 46.446673588067306
Epoch 549, step 257500: Generator loss: 154.6540338594482, discriminator loss: 47.04409442761572
Epoch 554, step 260000: Generator loss: 155.61953176954265, discriminator loss: 47.64129806395185
Epoch 559, step 262500: Generator loss: 156.57851000073427, discriminator loss: 48.23621501955407
Epoch 565, step 265000: Generator loss: 157.57013796937912, discriminator loss: 48.81841204716583
Epoch 570, step 267500: Generator loss: 158.58745419824487, discriminator loss: 49.39728153505935
Epoch 575, step 270000: Generator loss: 159.61897925506034, discriminator loss: 49.97088020893944
Epoch 581, step 272500: Generator loss: 160.62414082653933, discriminator loss: 50.55845826935191
Epoch 586, step 275000: Generator loss: 161.6360176999136, discriminator loss: 51.13836716422452
Epoch 591, step 277500: Generator loss: 162.6937001745749, discriminator loss: 51.703352506631745
Epoch 597, step 280000: Generator loss: 163.713712522297, discriminator loss: 52.28744219620823
Epoch 602, step 282500: Generator loss: 164.74417761338188, discriminator loss: 52.86771041123264
Epoch 607, step 285000: Generator loss: 165.76970245681252, discriminator loss: 53.44563473485114
Epoch 613, step 287500: Generator loss: 166.811878925066, discriminator loss: 54.01528675569889
Epoch 618, step 290000: Generator loss: 167.8307581976232, discriminator loss: 54.590264578408025
Epoch 623, step 292500: Generator loss: 168.891059790879, discriminator loss: 55.156935418433086
Epoch 628, step 295000: Generator loss: 169.9474142856893, discriminator loss: 55.71990455088043
Epoch 634, step 297500: Generator loss: 171.0481772922807, discriminator loss: 56.27077199867391
Epoch 639, step 300000: Generator loss: 172.11923127556335, discriminator loss: 56.83505055757194
Epoch 644, step 302500: Generator loss: 173.16847663276675, discriminator loss: 57.40616466661116
Epoch 650, step 305000: Generator loss: 174.07904141102364, discriminator loss: 58.13510520734215
Epoch 655, step 307500: Generator loss: 174.9117115099017, discriminator loss: 58.74583771123328
Epoch 660, step 310000: Generator loss: 175.81728609905886, discriminator loss: 59.34154992217456
Epoch 666, step 312500: Generator loss: 176.7578212393589, discriminator loss: 59.92914648076939
Epoch 671, step 315000: Generator loss: 177.6959055232357, discriminator loss: 60.52539835767199
Epoch 676, step 317500: Generator loss: 178.65148061598035, discriminator loss: 61.114570335239605
Epoch 682, step 320000: Generator loss: 179.61467326215066, discriminator loss: 61.701995908111826
Epoch 687, step 322500: Generator loss: 180.57620892596987, discriminator loss: 62.314891455287345
Epoch 692, step 325000: Generator loss: 181.45410679765476, discriminator loss: 62.936326666588116
Epoch 698, step 327500: Generator loss: 182.3509983194426, discriminator loss: 63.536605342692496
Epoch 703, step 330000: Generator loss: 183.2767872462343, discriminator loss: 64.13359040188224
Epoch 708, step 332500: Generator loss: 184.24614562447758, discriminator loss: 64.71242399436842
Epoch 714, step 335000: Generator loss: 185.2339295223548, discriminator loss: 65.29031219341155
Epoch 719, step 337500: Generator loss: 186.22102292967574, discriminator loss: 65.87176483958355
Epoch 724, step 340000: Generator loss: 187.16576725860415, discriminator loss: 66.46805416325945
Epoch 730, step 342500: Generator loss: 188.17708793676715, discriminator loss: 67.02993150789138
Epoch 735, step 345000: Generator loss: 189.2133280149301, discriminator loss: 67.59322807443746
Epoch 740, step 347500: Generator loss: 190.23208963008815, discriminator loss: 68.16751613625887
Epoch 746, step 350000: Generator loss: 191.25920752848035, discriminator loss: 68.7402887957158
Epoch 751, step 352500: Generator loss: 192.28080943237188, discriminator loss: 69.31388918965479
Epoch 756, step 355000: Generator loss: 193.3113937983357, discriminator loss: 69.88720360422755
Epoch 762, step 357500: Generator loss: 194.36098039241693, discriminator loss: 70.46414442196532
Epoch 767, step 360000: Generator loss: 195.2757543816169, discriminator loss: 71.13062453675919
Epoch 772, step 362500: Generator loss: 196.20393474234035, discriminator loss: 71.72337642310346
Epoch 778, step 365000: Generator loss: 197.17895898321507, discriminator loss: 72.2954984176345
Epoch 783, step 367500: Generator loss: 198.16447116800182, discriminator loss: 72.87443887000731
Epoch 788, step 370000: Generator loss: 199.0904656322084, discriminator loss: 73.4706785914252
Epoch 794, step 372500: Generator loss: 200.0776066501466, discriminator loss: 74.04545851565092
Epoch 799, step 375000: Generator loss: 201.02695143798252, discriminator loss: 74.6362730719872
Epoch 804, step 377500: Generator loss: 201.990468873819, discriminator loss: 75.22039345236489
Epoch 810, step 380000: Generator loss: 203.01058207302907, discriminator loss: 75.78494052414334
Epoch 815, step 382500: Generator loss: 204.05225880001382, discriminator loss: 76.35463489610616
Epoch 820, step 385000: Generator loss: 205.01460667336755, discriminator loss: 76.94180617091138
Epoch 826, step 387500: Generator loss: 206.05344676898304, discriminator loss: 77.51117122195475
Epoch 831, step 390000: Generator loss: 207.07375686963422, discriminator loss: 78.09562644241576
Epoch 836, step 392500: Generator loss: 208.0923817031217, discriminator loss: 78.6823844633292
Epoch 842, step 395000: Generator loss: 209.13077087057394, discriminator loss: 79.25322038175547
Epoch 847, step 397500: Generator loss: 210.17313802006993, discriminator loss: 79.82443133078309
Epoch 852, step 400000: Generator loss: 211.24034579869058, discriminator loss: 80.39010535690288
Epoch 858, step 402500: Generator loss: 212.29597073660645, discriminator loss: 80.95657187560273
Epoch 863, step 405000: Generator loss: 213.36997850652477, discriminator loss: 81.5198167693678
Epoch 868, step 407500: Generator loss: 214.34861638153268, discriminator loss: 82.11812956745074
Epoch 874, step 410000: Generator loss: 215.34710292697525, discriminator loss: 82.68937682878448
Epoch 879, step 412500: Generator loss: 216.41345989072963, discriminator loss: 83.24355317315504
Epoch 884, step 415000: Generator loss: 217.28458412296192, discriminator loss: 83.92686493608393
Epoch 890, step 417500: Generator loss: 218.29466441413823, discriminator loss: 84.48695280879178
Epoch 895, step 420000: Generator loss: 219.3093764458604, discriminator loss: 85.05175313127683
Epoch 900, step 422500: Generator loss: 220.34153808440644, discriminator loss: 85.61656451819609
Epoch 906, step 425000: Generator loss: 221.36335393692892, discriminator loss: 86.20032007145346
Epoch 911, step 427500: Generator loss: 222.4004497556632, discriminator loss: 86.77878700938892
Epoch 916, step 430000: Generator loss: 223.45292786750198, discriminator loss: 87.35415507568788
Epoch 922, step 432500: Generator loss: 224.49835159925806, discriminator loss: 87.92856502636128
Epoch 927, step 435000: Generator loss: 225.5315329488691, discriminator loss: 88.51101210754575
Epoch 932, step 437500: Generator loss: 226.5669734054742, discriminator loss: 89.09301339096481
Epoch 938, step 440000: Generator loss: 227.48296755303724, discriminator loss: 89.70019514662671
Epoch 943, step 442500: Generator loss: 228.48196144422903, discriminator loss: 90.27654089993891
Epoch 948, step 445000: Generator loss: 229.51780844437448, discriminator loss: 90.83335400045588
Epoch 954, step 447500: Generator loss: 230.60036065892555, discriminator loss: 91.38414017357304
Epoch 959, step 450000: Generator loss: 231.67713544449177, discriminator loss: 91.94271953728851
Epoch 964, step 452500: Generator loss: 232.64530618559718, discriminator loss: 92.56010472605873
Epoch 970, step 455000: Generator loss: 233.68903298704024, discriminator loss: 93.11562871940767
Epoch 975, step 457500: Generator loss: 234.72853977193282, discriminator loss: 93.68664950763602
Epoch 980, step 460000: Generator loss: 235.69478953835426, discriminator loss: 94.26967884075088
Epoch 986, step 462500: Generator loss: 236.70701852056465, discriminator loss: 94.835702462167
Epoch 991, step 465000: Generator loss: 237.76209552497326, discriminator loss: 95.39685135828884
Epoch 996, step 467500: Generator loss: 238.79892911128448, discriminator loss: 95.97513031529836
Ended: 2021-04-08 20:55:49.865623
Elapsed: 1:44:40.404506
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org15705bd">
<h3 id="org15705bd">Looking at the Final model.</h3>
<div class="outline-text-3" id="text-org15705bd">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">plot_image</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
                <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">num_images</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                <span class="n">size</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
                <span class="n">folder</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"files/posts/gans/mnist-gan/"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Plot the image and save it</span>

<span class="sd">    Args:</span>
<span class="sd">     image: the tensor with the image to plot</span>
<span class="sd">     filename: name for the final image file</span>
<span class="sd">     title: title to put on top of the image</span>
<span class="sd">     num_images: how many images to put in the composite image</span>
<span class="sd">     size: the size for the image</span>
<span class="sd">     folder: sub-folder to save the file in</span>
<span class="sd">    """</span>
    <span class="n">unflattened_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">)</span>
    <span class="n">image_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">unflattened_image</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

    <span class="n">pyplot</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">labelleft</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[[file:</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">]]"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">fake_noise</span> <span class="o">=</span> <span class="n">get_noise</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">gen</span><span class="p">(</span><span class="n">fake_noise</span><span class="p">)</span>
<span class="n">plot_image</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">fake</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"fake_digits.png"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Fake Digits"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="fake_digits.png" src="posts/gans/mnist-gan/fake_digits.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="n">plot_image</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">"real_digits.png"</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Real Digits"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="real_digits.png" src="posts/gans/mnist-gan/real_digits.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="n">plotting</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"Step"</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
    <span class="s2">"Generator Loss"</span><span class="p">:</span> <span class="n">generator_losses</span><span class="p">,</span>
    <span class="s2">"Discriminator Loss"</span><span class="p">:</span> <span class="n">discriminator_losses</span>
<span class="p">})</span>

<span class="n">gen_plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Generator Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>
<span class="n">disc_plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Step"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Discriminator Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">gen_plot</span> <span class="o">*</span> <span class="n">disc_plot</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Training Losses"</span><span class="p">,</span>
                                   <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                                   <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                   <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span>
                                   <span class="n">fontscale</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">fontscale</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"losses"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/gans/mnist-gan/losses.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>I thought something was wrong with the losses, at first, since they seem to go up over time, but the loss is based on the Generator and the Discriminator being able to do their job, so as they get better, the loss goes up. The main one for us to note is the Discriminator loss, since this is how much it gets fooled by the Generator. Since it's still going up this likely means that the Generator can still improve.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org52abb44">
<h2 id="org52abb44">End</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation-helper-functions/">Neural Machine Translation: Helper Functions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation-helper-functions/" rel="bookmark"><time class="published dt-published" datetime="2021-02-27T14:41:04-08:00" itemprop="datePublished" title="2021-02-27 14:41">2021-02-27 14:41</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/#org2ce8fd3">Helper Functions</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/#orgf8c2944">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/#orge2beddf">Helper functions</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/#orgac66161">Input encoder</a></li>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/#orgb4fa34f">Pre-attention decoder</a></li>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/#org77ca447">Preparing the attention input</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org2ce8fd3">
<h2 id="org2ce8fd3">Helper Functions</h2>
<div class="outline-text-2" id="text-org2ce8fd3">
<p>We will first implement a few functions that we will use later on. These will be for:</p>
<ul class="org-ul">
<li>the input encoder</li>
<li>the pre-attention decoder</li>
<li>preparation of the queries, keys, values, and mask.</li>
</ul>
</div>
<div class="outline-3" id="outline-container-orgf8c2944">
<h3 id="orgf8c2944">Imports</h3>
<div class="outline-text-3" id="text-orgf8c2944">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastmath_numpy</span>

<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge2beddf">
<h2 id="orge2beddf">Helper functions</h2>
<div class="outline-text-2" id="text-orge2beddf"></div>
<div class="outline-3" id="outline-container-orgac66161">
<h3 id="orgac66161">Input encoder</h3>
<div class="outline-text-3" id="text-orgac66161">
<p>The input encoder runs on the input tokens, creates its embeddings, and feeds it to an LSTM network. This outputs the activations that will be the keys and values for attention. It is a <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial">Serial</a> network which uses:</p>
<ul class="org-ul">
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">tl.Embedding</a>: Converts each token to its vector representation. In this case, it is the the size of the vocabulary by the dimension of the model: <code>tl.Embedding(vocab_size, d_model)</code>. <code>vocab_size</code> is the number of entries in the given vocabulary. <code>d_model</code> is the number of elements in the word embedding.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">tl.LSTM</a>: LSTM layer of size <code>d_model</code>. We want to be able to configure how many encoder layers we have so remember to create LSTM layers equal to the number of the <code>n_encoder_layers</code> parameter.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">input_encoder</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                     <span class="n">n_encoder_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
    <span class="sd">""" Input encoder runs on the input sentence and creates</span>
<span class="sd">    activations that will be the keys and values for attention.</span>

<span class="sd">    Args:</span>
<span class="sd">       input_vocab_size: vocab size of the input</span>
<span class="sd">       d_model:  depth of embedding (n_units in the LSTM cell)</span>
<span class="sd">       n_encoder_layers: number of LSTM layers in the encoder</span>

<span class="sd">    Returns:</span>
<span class="sd">       tl.Serial: The input encoder</span>
<span class="sd">    """</span>
    <span class="n">input_encoder</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span> 
        <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span>
        <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_encoder_layers</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">input_encoder</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_input_encoder_fn</span><span class="p">(</span><span class="n">input_encoder_fn</span><span class="p">):</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">input_encoder_fn</span>
    <span class="n">success</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fails</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">input_vocab_size</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">n_encoder_layers</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="n">encoder</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_encoder_layers</span><span class="p">)</span>

    <span class="n">lstms</span> <span class="o">=</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s1">'  LSTM_</span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="s1">'</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_encoder_layers</span><span class="p">)</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Serial[</span><span class="se">\n</span><span class="s2">  Embedding_</span><span class="si">{</span><span class="n">input_vocab_size</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">lstms</span><span class="si">}</span><span class="se">\n</span><span class="s2">]"</span>

    <span class="n">proposed</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">encoder</span><span class="p">)</span>

    <span class="c1"># Test all layers are in the expected sequence</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">proposed</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">""</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong model. </span><span class="se">\n</span><span class="s2">Proposed:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="n">proposed</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">Expected:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="n">expected</span><span class="p">)</span>

    <span class="c1"># Test the output type</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Test the number of layers</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Test </span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_encoder_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'The number of sublayers does not match </span><span class="si">%s</span><span class="s1"> &lt;&gt;'</span> <span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">sublayers</span><span class="p">),</span> <span class="s2">" </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="p">(</span><span class="n">n_encoder_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"The enconder is not an object of "</span><span class="p">,</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="p">)</span>


    <span class="k">if</span> <span class="n">fails</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\033</span><span class="s2">[92m All tests passed"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[92m'</span><span class="p">,</span> <span class="n">success</span><span class="p">,</span><span class="s2">" Tests passed"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[91m'</span><span class="p">,</span> <span class="n">fails</span><span class="p">,</span> <span class="s2">" Tests failed"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">test_input_encoder_fn</span><span class="p">(</span><span class="n">input_encoder</span><span class="p">)</span>
</pre></div>
<pre class="example">
[92m All tests passed
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgb4fa34f">
<h3 id="orgb4fa34f">Pre-attention decoder</h3>
<div class="outline-text-3" id="text-orgb4fa34f">
<p>The pre-attention decoder runs on the targets and creates activations that are used as queries in attention. This is a Serial network which is composed of the following:</p>
<ul class="org-ul">
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight">tl.ShiftRight</a>: This pads a token to the beginning of your target tokens (e.g. <code>[8, 34, 12]</code> shifted right is <code>[0, 8, 34, 12]</code>). This will act like a start-of-sentence token that will be the first input to the decoder. During training, this shift also allows the target tokens to be passed as input to do teacher forcing.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">tl.Embedding</a>: Like in the previous function, this converts each token to its vector representation. In this case, it is the the size of the vocabulary by the dimension of the model: <code>tl.Embedding(vocab_size, d_model)</code>. <code>vocab_size</code> is the number of entries in the given vocabulary. <code>d_model</code> is the number of elements in the word embedding.</li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">tl.LSTM</a>: LSTM layer of size <code>d_model</code>.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">pre_attention_decoder</span><span class="p">(</span><span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
    <span class="sd">""" Pre-attention decoder runs on the targets and creates</span>
<span class="sd">    activations that are used as queries in attention.</span>

<span class="sd">    Args:</span>
<span class="sd">       mode: 'train' or 'eval'</span>
<span class="sd">       target_vocab_size: vocab size of the target</span>
<span class="sd">       d_model:  depth of embedding (n_units in the LSTM cell)</span>
<span class="sd">    Returns:</span>
<span class="sd">       tl.Serial: The pre-attention decoder</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">ShiftRight</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_pre_attention_decoder_fn</span><span class="p">(</span><span class="n">pre_attention_decoder_fn</span><span class="p">):</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">pre_attention_decoder_fn</span>
    <span class="n">success</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fails</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">mode</span> <span class="o">=</span> <span class="s1">'train'</span>
    <span class="n">target_vocab_size</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">decoder</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Serial[</span><span class="se">\n</span><span class="s2">  ShiftRight(1)</span><span class="se">\n</span><span class="s2">  Embedding_</span><span class="si">{</span><span class="n">target_vocab_size</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="se">\n</span><span class="s2">  LSTM_</span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="se">\n</span><span class="s2">]"</span>

    <span class="n">proposed</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">decoder</span><span class="p">)</span>

    <span class="c1"># Test all layers are in the expected sequence</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">proposed</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span> <span class="o">==</span> <span class="n">expected</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">" "</span><span class="p">,</span> <span class="s2">""</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong model. </span><span class="se">\n</span><span class="s2">Proposed:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="n">proposed</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">Expected:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="n">expected</span><span class="p">)</span>

    <span class="c1"># Test the output type</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Test the number of layers</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Test </span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
            <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'The number of sublayers does not match </span><span class="si">%s</span><span class="s1"> &lt;&gt;'</span> <span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">sublayers</span><span class="p">),</span> <span class="s2">" </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"The enconder is not an object of "</span><span class="p">,</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="p">)</span>


    <span class="k">if</span> <span class="n">fails</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\033</span><span class="s2">[92m All tests passed"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[92m'</span><span class="p">,</span> <span class="n">success</span><span class="p">,</span><span class="s2">" Tests passed"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[91m'</span><span class="p">,</span> <span class="n">fails</span><span class="p">,</span> <span class="s2">" Tests failed"</span><span class="p">)</span>
</pre></div>
<p>They changed the behavior of the <code>Fn</code> (or something in there) so that it always wraps the ShiftRight in a Serial layer, so it doesn't match the test anymore. Testing strings is kind of gimpy anyway…</p>
<p>It looks like they're using a decorator to check the shape which then wraps it in a Serial layer. See trax.layers.assert_shape.AssertFunction</p>
<div class="highlight">
<pre><span></span><span class="n">test_pre_attention_decoder_fn</span><span class="p">(</span><span class="n">pre_attention_decoder</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org6a83aa5">
Wrong model. 
Proposed:
Serial[
  Serial[
    ShiftRight(1)
  ]
  Embedding_10_2
  LSTM_2
] 
Expected:
Serial[
  ShiftRight(1)
  Embedding_10_2
  LSTM_2
]
[92m 2  Tests passed
[91m 1  Tests failed
</pre></div>
</div>
<div class="outline-3" id="outline-container-org77ca447">
<h3 id="org77ca447">Preparing the attention input</h3>
<div class="outline-text-3" id="text-org77ca447">
<p>This function will prepare the inputs to the attention layer. We want to take in the encoder and pre-attention decoder activations and assign it to the queries, keys, and values. In addition, another output here will be the mask to distinguish real tokens from padding tokens. This mask will be used internally by Trax when computing the softmax so padding tokens will not have an effect on the computated probabilities. From the data preparation steps in Section 1 of this assignment, you should know which tokens in the input correspond to padding.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">prepare_attention_input</span><span class="p">(</span><span class="n">encoder_activations</span><span class="p">:</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
                            <span class="n">decoder_activations</span><span class="p">:</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
                            <span class="n">inputs</span><span class="p">:</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""Prepare queries, keys, values and mask for attention.</span>

<span class="sd">    Args:</span>
<span class="sd">       encoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the input encoder</span>
<span class="sd">       decoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the pre-attention decoder</span>
<span class="sd">       inputs fastnp.array(batch_size, padded_input_length): padded input tokens</span>

<span class="sd">    Returns:</span>
<span class="sd">       queries, keys, values and mask for attention.</span>
<span class="sd">    """</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">encoder_activations</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">encoder_activations</span>
    <span class="n">queries</span> <span class="o">=</span> <span class="n">decoder_activations</span>    
    <span class="n">mask</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">!=</span> <span class="mi">0</span>

    <span class="n">mask</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">mask</span> <span class="o">+=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">decoder_activations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">mask</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_prepare_attention_input</span><span class="p">(</span><span class="n">prepare_attention_input</span><span class="p">):</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">prepare_attention_input</span>
    <span class="n">success</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fails</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1">#This unit test consider a batch size = 2, number_of_tokens = 3 and embedding_size = 4</span>

    <span class="n">enc_act</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
               <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]])</span>
    <span class="n">dec_act</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> 
               <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]])</span>
    <span class="n">inputs</span> <span class="o">=</span>  <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    <span class="n">exp_mask</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]],</span> 
                             <span class="p">[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]]])</span>

    <span class="n">exp_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">enc_act</span><span class="p">)</span>

    <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">enc_act</span><span class="p">,</span> <span class="n">dec_act</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">dec_act</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Queries does not match the decoder activations"</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">enc_act</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Keys does not match the encoder activations"</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">enc_act</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Values does not match the encoder activations"</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">exp_mask</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Mask does not match expected tensor. </span><span class="se">\n</span><span class="s2">Expected:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="n">exp_mask</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">Output:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span><span class="n">mask</span><span class="p">)</span>

    <span class="c1"># Test the output type</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">exp_type</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">exp_type</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">exp_type</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">exp_type</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"One of the output object are not of type "</span><span class="p">,</span> <span class="n">jax</span><span class="o">.</span><span class="n">interpreters</span><span class="o">.</span><span class="n">xla</span><span class="o">.</span><span class="n">DeviceArray</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fails</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\033</span><span class="s2">[92m All tests passed"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[92m'</span><span class="p">,</span> <span class="n">success</span><span class="p">,</span><span class="s2">" Tests passed"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[91m'</span><span class="p">,</span> <span class="n">fails</span><span class="p">,</span> <span class="s2">" Tests failed"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">test_prepare_attention_input</span><span class="p">(</span><span class="n">prepare_attention_input</span><span class="p">)</span>
</pre></div>
<pre class="example">
[92m All tests passed
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation-testing-the-model/">Neural Machine Translation: Testing the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation-testing-the-model/" rel="bookmark"><time class="published dt-published" datetime="2021-02-14T14:54:56-08:00" itemprop="datePublished" title="2021-02-14 14:54">2021-02-14 14:54</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/neural-machine-translation-testing-the-model/#org1aaeea6">Testing the Model</a></li>
<li><a href="posts/nlp/neural-machine-translation-testing-the-model/#orgbaf1cf6">End</a></li>
<li><a href="posts/nlp/neural-machine-translation-testing-the-model/#org1ebb3f8">Raw</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org1aaeea6">
<h2 id="org1aaeea6">Testing the Model</h2>
<div class="outline-text-2" id="text-org1aaeea6">
<p>In the <a href="posts/nlp/neural-machine-translation-training-the-model/">previous post</a> we trained our machine translation model so now it's time to test it and see how well it does.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgbaf1cf6">
<h2 id="orgbaf1cf6">End</h2>
<div class="outline-text-2" id="text-orgbaf1cf6">
<p>The overview post with links to all the posts in this series is <a href="posts/nlp/neural-machine-translation/">here</a>.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org1ebb3f8">
<h2 id="org1ebb3f8">Raw</h2>
<div class="outline-text-2" id="text-org1ebb3f8">
<pre class="example">
# # Part 4:  Testing
# 
# We will now be using the model you just trained to translate English sentences to German. We will implement this with two functions: The first allows you to identify the next symbol (i.e. output token). The second one takes care of combining the entire translated string.
# 
# We will start by first loading in a pre-trained copy of the model you just coded. Please run the cell below to do just that.

# In[ ]:


# instantiate the model we built in eval mode
model = NMTAttn(mode='eval')

# initialize weights from a pre-trained model
model.init_from_file("model.pkl.gz", weights_only=True)
model = tl.Accelerate(model)


# &lt;a name="4.1"&gt;&lt;/a&gt;
# ## 4.1  Decoding
# 
# As discussed in the lectures, there are several ways to get the next token when translating a sentence. For instance, we can just get the most probable token at each step (i.e. greedy decoding) or get a sample from a distribution. We can generalize the implementation of these two approaches by using the `tl.logsoftmax_sample()` method. Let's briefly look at its implementation:
# 
# ```python
# def logsoftmax_sample(log_probs, temperature=1.0):  # pylint: disable=invalid-name
#   """Returns a sample from a log-softmax output, with temperature.
# 
#   Args:
#     log_probs: Logarithms of probabilities (often coming from LogSofmax)
#     temperature: For scaling before sampling (1.0 = default, 0.0 = pick argmax)
#   """
#   # This is equivalent to sampling from a softmax with temperature.
#   u = np.random.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)
#   g = -np.log(-np.log(u))
#   return np.argmax(log_probs + g * temperature, axis=-1)
# ```
# 
# The key things to take away here are: 1. it gets random samples with the same shape as your input (i.e. `log_probs`), and 2. the amount of "noise" added to the input by these random samples is scaled by a `temperature` setting. You'll notice that setting it to `0` will just make the return statement equal to getting the argmax of `log_probs`. This will come in handy later. 
# 
# &lt;a name="ex06"&gt;&lt;/a&gt;
# ### Exercise 06
# 
# **Instructions:** Implement the `next_symbol()` function that takes in the `input_tokens` and the `cur_output_tokens`, then return the index of the next word. You can click below for hints in completing this exercise.
# 
# &lt;details&gt;    
# &lt;summary&gt;
#     &lt;font size="3" color="darkgreen"&gt;&lt;b&gt;Click Here for Hints&lt;/b&gt;&lt;/font&gt;
# &lt;/summary&gt;
# &lt;p&gt;
# &lt;ul&gt;
#     &lt;li&gt;To get the next power of two, you can compute &lt;i&gt;2^log_2(token_length + 1)&lt;/i&gt; . We add 1 to avoid &lt;i&gt;log(0).&lt;/i&gt;&lt;/li&gt;
#     &lt;li&gt;You can use &lt;i&gt;np.ceil()&lt;/i&gt; to get the ceiling of a float.&lt;/li&gt;
#     &lt;li&gt;&lt;i&gt;np.log2()&lt;/i&gt; will get the logarithm base 2 of a value&lt;/li&gt;
#     &lt;li&gt;&lt;i&gt;int()&lt;/i&gt; will cast a value into an integer type&lt;/li&gt;
#     &lt;li&gt;From the model diagram in part 2, you know that it takes two inputs. You can feed these with this syntax to get the model outputs: &lt;i&gt;model((input1, input2))&lt;/i&gt;. It's up to you to determine which variables below to substitute for input1 and input2. Remember also from the diagram that the output has two elements: [log probabilities, target tokens]. You won't need the target tokens so we assigned it to _ below for you. &lt;/li&gt;
#     &lt;li&gt; The log probabilities output will have the shape: (batch size, decoder length, vocab size). It will contain log probabilities for each token in the &lt;i&gt;cur_output_tokens&lt;/i&gt; plus 1 for the start symbol introduced by the ShiftRight in the preattention decoder. For example, if cur_output_tokens is [1, 2, 5], the model will output an array of log probabilities each for tokens 0 (start symbol), 1, 2, and 5. To generate the next symbol, you just want to get the log probabilities associated with the last token (i.e. token 5 at index 3). You can slice the model output at [0, 3, :] to get this. It will be up to you to generalize this for any length of cur_output_tokens &lt;/li&gt;
# &lt;/ul&gt;
# 

# In[ ]:


# UNQ_C6
# GRADED FUNCTION
def next_symbol(NMTAttn, input_tokens, cur_output_tokens, temperature):
    """Returns the index of the next token.

    Args:
        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.
        input_tokens (np.ndarray 1 x n_tokens): tokenized representation of the input sentence
        cur_output_tokens (list): tokenized representation of previously translated words
        temperature (float): parameter for sampling ranging from 0.0 to 1.0.
            0.0: same as argmax, always pick the most probable token
            1.0: sampling from the distribution (can sometimes say random things)

    Returns:
        int: index of the next token in the translated sentence
        float: log probability of the next symbol
    """

    ### START CODE HERE (REPLACE INSTANCES OF `None` WITH YOUR CODE) ###

    # set the length of the current output tokens
    token_length = None

    # calculate next power of 2 for padding length 
    padded_length = None

    # pad cur_output_tokens up to the padded_length
    padded = cur_output_tokens + None
    
    # model expects the output to have an axis for the batch size in front so
    # convert `padded` list to a numpy array with shape (x, &lt;padded_length&gt;) where the
    # x position is the batch axis. (hint: you can use np.expand_dims() with axis=0 to insert a new axis)
    padded_with_batch = None

    # get the model prediction. remember to use the `NMTAttn` argument defined above.
    # hint: the model accepts a tuple as input (e.g. `my_model((input1, input2))`)
    output, _ = None
    
    # get log probabilities from the last token output
    log_probs = output[None]

    # get the next symbol by getting a logsoftmax sample (*hint: cast to an int)
    symbol = None
    
    ### END CODE HERE ###

    return symbol, float(log_probs[symbol])


# In[ ]:


# BEGIN UNIT TEST
w1_unittest.test_next_symbol(next_symbol, model)
# END UNIT TEST


# Now you will implement the `sampling_decode()` function. This will call the `next_symbol()` function above several times until the next output is the end-of-sentence token (i.e. `EOS`). It takes in an input string and returns the translated version of that string.
# 
# &lt;a name="ex07"&gt;&lt;/a&gt;
# ### Exercise 07
# 
# **Instructions**: Implement the `sampling_decode()` function.

# In[ ]:


# UNQ_C7
# GRADED FUNCTION
def sampling_decode(input_sentence, NMTAttn = None, temperature=0.0, vocab_file=None, vocab_dir=None):
    """Returns the translated sentence.

    Args:
        input_sentence (str): sentence to translate.
        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.
        temperature (float): parameter for sampling ranging from 0.0 to 1.0.
            0.0: same as argmax, always pick the most probable token
            1.0: sampling from the distribution (can sometimes say random things)
        vocab_file (str): filename of the vocabulary
        vocab_dir (str): path to the vocabulary file

    Returns:
        tuple: (list, str, float)
            list of int: tokenized version of the translated sentence
            float: log probability of the translated sentence
            str: the translated sentence
    """
    
    ### START CODE HERE (REPLACE INSTANCES OF `None` WITH YOUR CODE) ###
    
    # encode the input sentence
    input_tokens = None
    
    # initialize the list of output tokens
    cur_output_tokens = None
    
    # initialize an integer that represents the current output index
    cur_output = None
    
    # Set the encoding of the "end of sentence" as 1
    EOS = None
    
    # check that the current output is not the end of sentence token
    while cur_output != EOS:
        
        # update the current output token by getting the index of the next word (hint: use next_symbol)
        cur_output, log_prob = None
        
        # append the current output token to the list of output tokens
        cur_output_tokens.append(cur_output)
    
    # detokenize the output tokens
    sentence = None
    
    ### END CODE HERE ###
    
    return cur_output_tokens, log_prob, sentence


# In[ ]:


# Test the function above. Try varying the temperature setting with values from 0 to 1.
# Run it several times with each setting and see how often the output changes.
sampling_decode("I love languages.", model, temperature=0.0, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)


# In[ ]:


# BEGIN UNIT TEST
w1_unittest.test_sampling_decode(sampling_decode, model)
# END UNIT TEST


# We have set a default value of `0` to the temperature setting in our implementation of `sampling_decode()` above. As you may have noticed in the `logsoftmax_sample()` method, this setting will ultimately result in greedy decoding. As mentioned in the lectures, this algorithm generates the translation by getting the most probable word at each step. It gets the argmax of the output array of your model and then returns that index. See the testing function and sample inputs below. You'll notice that the output will remain the same each time you run it.

# In[ ]:


def greedy_decode_test(sentence, NMTAttn=None, vocab_file=None, vocab_dir=None):
    """Prints the input and output of our NMTAttn model using greedy decode

    Args:
        sentence (str): a custom string.
        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.
        vocab_file (str): filename of the vocabulary
        vocab_dir (str): path to the vocabulary file

    Returns:
        str: the translated sentence
    """
    
    _,_, translated_sentence = sampling_decode(sentence, NMTAttn, vocab_file=vocab_file, vocab_dir=vocab_dir)
    
    print("English: ", sentence)
    print("German: ", translated_sentence)
    
    return translated_sentence


# In[ ]:


# put a custom string here
your_sentence = 'I love languages.'

greedy_decode_test(your_sentence, model, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR);


# In[ ]:


greedy_decode_test('You are almost done with the assignment!', model, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR);


# &lt;a name="4.2"&gt;&lt;/a&gt;
# ## 4.2  Minimum Bayes-Risk Decoding
# 
# As mentioned in the lectures, getting the most probable token at each step may not necessarily produce the best results. Another approach is to do Minimum Bayes Risk Decoding or MBR. The general steps to implement this are:
# 
# 1. take several random samples
# 2. score each sample against all other samples
# 3. select the one with the highest score
# 
# You will be building helper functions for these steps in the following sections.

# &lt;a name='4.2.1'&gt;&lt;/a&gt;
# ### 4.2.1 Generating samples
# 
# First, let's build a function to generate several samples. You can use the `sampling_decode()` function you developed earlier to do this easily. We want to record the token list and log probability for each sample as these will be needed in the next step.

# In[ ]:


def generate_samples(sentence, n_samples, NMTAttn=None, temperature=0.6, vocab_file=None, vocab_dir=None):
    """Generates samples using sampling_decode()

    Args:
        sentence (str): sentence to translate.
        n_samples (int): number of samples to generate
        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.
        temperature (float): parameter for sampling ranging from 0.0 to 1.0.
            0.0: same as argmax, always pick the most probable token
            1.0: sampling from the distribution (can sometimes say random things)
        vocab_file (str): filename of the vocabulary
        vocab_dir (str): path to the vocabulary file
        
    Returns:
        tuple: (list, list)
            list of lists: token list per sample
            list of floats: log probability per sample
    """
    # define lists to contain samples and probabilities
    samples, log_probs = [], []

    # run a for loop to generate n samples
    for _ in range(n_samples):
        
        # get a sample using the sampling_decode() function
        sample, logp, _ = sampling_decode(sentence, NMTAttn, temperature, vocab_file=vocab_file, vocab_dir=vocab_dir)
        
        # append the token list to the samples list
        samples.append(sample)
        
        # append the log probability to the log_probs list
        log_probs.append(logp)
                
    return samples, log_probs


# In[ ]:


# generate 4 samples with the default temperature (0.6)
generate_samples('I love languages.', 4, model, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)


# ### 4.2.2 Comparing overlaps
# 
# Let us now build our functions to compare a sample against another. There are several metrics available as shown in the lectures and you can try experimenting with any one of these. For this assignment, we will be calculating scores for unigram overlaps. One of the more simple metrics is the [Jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index) which gets the intersection over union of two sets. We've already implemented it below for your perusal.

# In[ ]:


def jaccard_similarity(candidate, reference):
    """Returns the Jaccard similarity between two token lists

    Args:
        candidate (list of int): tokenized version of the candidate translation
        reference (list of int): tokenized version of the reference translation

    Returns:
        float: overlap between the two token lists
    """
    
    # convert the lists to a set to get the unique tokens
    can_unigram_set, ref_unigram_set = set(candidate), set(reference)  
    
    # get the set of tokens common to both candidate and reference
    joint_elems = can_unigram_set.intersection(ref_unigram_set)
    
    # get the set of all tokens found in either candidate or reference
    all_elems = can_unigram_set.union(ref_unigram_set)
    
    # divide the number of joint elements by the number of all elements
    overlap = len(joint_elems) / len(all_elems)
    
    return overlap


# In[ ]:


# let's try using the function. remember the result here and compare with the next function below.
jaccard_similarity([1, 2, 3], [1, 2, 3, 4])


# One of the more commonly used metrics in machine translation is the ROUGE score. For unigrams, this is called ROUGE-1 and as shown in class, you can output the scores for both precision and recall when comparing two samples. To get the final score, you will want to compute the F1-score as given by:
# 
# $$score = 2* \frac{(precision * recall)}{(precision + recall)}$$
# 
# &lt;a name="ex08"&gt;&lt;/a&gt;
# ### Exercise 08
# 
# **Instructions**: Implement the `rouge1_similarity()` function.

# In[ ]:


# UNQ_C8
# GRADED FUNCTION

# for making a frequency table easily
from collections import Counter

def rouge1_similarity(system, reference):
    """Returns the ROUGE-1 score between two token lists

    Args:
        system (list of int): tokenized version of the system translation
        reference (list of int): tokenized version of the reference translation

    Returns:
        float: overlap between the two token lists
    """    
    
    ### START CODE HERE (REPLACE INSTANCES OF `None` WITH YOUR CODE) ###
    
    # make a frequency table of the system tokens (hint: use the Counter class)
    sys_counter = None
    
    # make a frequency table of the reference tokens (hint: use the Counter class)
    ref_counter = None
    
    # initialize overlap to 0
    overlap = None
    
    # run a for loop over the sys_counter object (can be treated as a dictionary)
    for token in sys_counter:
        
        # lookup the value of the token in the sys_counter dictionary (hint: use the get() method)
        token_count_sys = None
        
        # lookup the value of the token in the ref_counter dictionary (hint: use the get() method)
        token_count_ref = None
        
        # update the overlap by getting the smaller number between the two token counts above
        overlap += None
    
    # get the precision (i.e. number of overlapping tokens / number of system tokens)
    precision = None
    
    # get the recall (i.e. number of overlapping tokens / number of reference tokens)
    recall = None
    
    if precision + recall != 0:
        # compute the f1-score
        rouge1_score = None
    else:
        rouge1_score = 0 
    ### END CODE HERE ###
    
    return rouge1_score
    


# In[ ]:


# notice that this produces a different value from the jaccard similarity earlier
rouge1_similarity([1, 2, 3], [1, 2, 3, 4])


# In[ ]:


# BEGIN UNIT TEST
w1_unittest.test_rouge1_similarity(rouge1_similarity)
# END UNIT TEST


# ### 4.2.3 Overall score
# 
# We will now build a function to generate the overall score for a particular sample. As mentioned earlier, we need to compare each sample with all other samples. For instance, if we generated 30 sentences, we will need to compare sentence 1 to sentences 2 to 30. Then, we compare sentence 2 to sentences 1 and 3 to 30, and so forth. At each step, we get the average score of all comparisons to get the overall score for a particular sample. To illustrate, these will be the steps to generate the scores of a 4-sample list.
# 
# 1. Get similarity score between sample 1 and sample 2
# 2. Get similarity score between sample 1 and sample 3
# 3. Get similarity score between sample 1 and sample 4
# 4. Get average score of the first 3 steps. This will be the overall score of sample 1.
# 5. Iterate and repeat until samples 1 to 4 have overall scores.
# 
# We will be storing the results in a dictionary for easy lookups.
# 
# &lt;a name="ex09"&gt;&lt;/a&gt;
# ### Exercise 09
# 
# **Instructions**: Implement the `average_overlap()` function.

# In[ ]:


# UNQ_C9
# GRADED FUNCTION
def average_overlap(similarity_fn, samples, *ignore_params):
    """Returns the arithmetic mean of each candidate sentence in the samples

    Args:
        similarity_fn (function): similarity function used to compute the overlap
        samples (list of lists): tokenized version of the translated sentences
        *ignore_params: additional parameters will be ignored

    Returns:
        dict: scores of each sample
            key: index of the sample
            value: score of the sample
    """  
    
    # initialize dictionary
    scores = {}
    
    # run a for loop for each sample
    for index_candidate, candidate in enumerate(samples):    
        
        ### START CODE HERE (REPLACE INSTANCES OF `None` WITH YOUR CODE) ###
        
        # initialize overlap to 0.0
        overlap = None
        
        # run a for loop for each sample
        for index_sample, sample in enumerate(samples): 

            # skip if the candidate index is the same as the sample index
            if index_candidate == index_sample:
                continue
                
            # get the overlap between candidate and sample using the similarity function
            sample_overlap = None
            
            # add the sample overlap to the total overlap
            overlap += None
            
        # get the score for the candidate by computing the average
        score = None
        
        # save the score in the dictionary. use index as the key.
        scores[index_candidate] = None
        
        ### END CODE HERE ###
    return scores


# In[ ]:


average_overlap(jaccard_similarity, [[1, 2, 3], [1, 2, 4], [1, 2, 4, 5]], [0.4, 0.2, 0.5])


# In[ ]:


# BEGIN UNIT TEST
w1_unittest.test_average_overlap(average_overlap)
# END UNIT TEST


# In practice, it is also common to see the weighted mean being used to calculate the overall score instead of just the arithmetic mean. We have implemented it below and you can use it in your experiements to see which one will give better results.

# In[ ]:


def weighted_avg_overlap(similarity_fn, samples, log_probs):
    """Returns the weighted mean of each candidate sentence in the samples

    Args:
        samples (list of lists): tokenized version of the translated sentences
        log_probs (list of float): log probability of the translated sentences

    Returns:
        dict: scores of each sample
            key: index of the sample
            value: score of the sample
    """
    
    # initialize dictionary
    scores = {}
    
    # run a for loop for each sample
    for index_candidate, candidate in enumerate(samples):    
        
        # initialize overlap and weighted sum
        overlap, weight_sum = 0.0, 0.0
        
        # run a for loop for each sample
        for index_sample, (sample, logp) in enumerate(zip(samples, log_probs)):

            # skip if the candidate index is the same as the sample index            
            if index_candidate == index_sample:
                continue
                
            # convert log probability to linear scale
            sample_p = float(np.exp(logp))

            # update the weighted sum
            weight_sum += sample_p

            # get the unigram overlap between candidate and sample
            sample_overlap = similarity_fn(candidate, sample)
            
            # update the overlap
            overlap += sample_p * sample_overlap
            
        # get the score for the candidate
        score = overlap / weight_sum
        
        # save the score in the dictionary. use index as the key.
        scores[index_candidate] = score
    
    return scores


# In[ ]:


weighted_avg_overlap(jaccard_similarity, [[1, 2, 3], [1, 2, 4], [1, 2, 4, 5]], [0.4, 0.2, 0.5])


# ### 4.2.4 Putting it all together
# 
# We will now put everything together and develop the `mbr_decode()` function. Please use the helper functions you just developed to complete this. You will want to generate samples, get the score for each sample, get the highest score among all samples, then detokenize this sample to get the translated sentence.
# 
# &lt;a name="ex10"&gt;&lt;/a&gt;
# ### Exercise 10
# 
# **Instructions**: Implement the `mbr_overlap()` function.

# In[ ]:


# UNQ_C10
# GRADED FUNCTION
def mbr_decode(sentence, n_samples, score_fn, similarity_fn, NMTAttn=None, temperature=0.6, vocab_file=None, vocab_dir=None):
    """Returns the translated sentence using Minimum Bayes Risk decoding

    Args:
        sentence (str): sentence to translate.
        n_samples (int): number of samples to generate
        score_fn (function): function that generates the score for each sample
        similarity_fn (function): function used to compute the overlap between a pair of samples
        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.
        temperature (float): parameter for sampling ranging from 0.0 to 1.0.
            0.0: same as argmax, always pick the most probable token
            1.0: sampling from the distribution (can sometimes say random things)
        vocab_file (str): filename of the vocabulary
        vocab_dir (str): path to the vocabulary file

    Returns:
        str: the translated sentence
    """
    
    ### START CODE HERE (REPLACE INSTANCES OF `None` WITH YOUR CODE) ###
    # generate samples
    samples, log_probs = None
    
    # use the scoring function to get a dictionary of scores
    # pass in the relevant parameters as shown in the function definition of 
    # the mean methods you developed earlier
    scores = None
    
    # find the key with the highest score
    max_index = None
    
    # detokenize the token list associated with the max_index
    translated_sentence = None
    
    ### END CODE HERE ###
    return (translated_sentence, max_index, scores)


# In[ ]:


TEMPERATURE = 1.0

# put a custom string here
your_sentence = 'She speaks English and German.'


# In[ ]:


mbr_decode(your_sentence, 4, weighted_avg_overlap, jaccard_similarity, model, TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)[0]


# In[ ]:


mbr_decode('Congratulations!', 4, average_overlap, rouge1_similarity, model, TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)[0]


# In[ ]:


mbr_decode('You have completed the assignment!', 4, average_overlap, rouge1_similarity, model, TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)[0]


# **This unit test take a while to run. Please be patient**

# In[ ]:


# BEGIN UNIT TEST
w1_unittest.test_mbr_decode(mbr_decode, model)
# END UNIT TEST


# #### Congratulations! Next week, you'll dive deeper into attention models and study the Transformer architecture. You will build another network but without the recurrent part. It will show that attention is all you need! It should be fun!


</pre></div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation-training-the-model/">Neural Machine Translation: Training the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation-training-the-model/" rel="bookmark"><time class="published dt-published" datetime="2021-02-14T14:54:34-08:00" itemprop="datePublished" title="2021-02-14 14:54">2021-02-14 14:54</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#orgdf1e30f">Training Our Model</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#orgae816bb">Imports</a></li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#org1814160">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#org3ca749d">Training</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#orgf34687d">TrainTask</a></li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#orgf0f61bf">EvalTask</a></li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#org718bcf8">Loop</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#orge4fedd5">End</a></li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/#org828e9f4">Raw</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgdf1e30f">
<h2 id="orgdf1e30f">Training Our Model</h2>
<div class="outline-text-2" id="text-orgdf1e30f">
<p>In the <a href="posts/nlp/neural-machine-translation-the-attention-model/">previous post</a> we defined our model for machine translation. In this post we'll train the model on our data.</p>
<p>Doing supervised training in Trax is pretty straightforward (short example <a href="https://trax-ml.readthedocs.io/en/latest/notebooks/trax_intro.html#Supervised-training">here</a>). We will be instantiating three classes for this: <code>TrainTask</code>, <code>EvalTask</code>, and <code>Loop</code>. Let's take a closer look at each of these in the sections below.</p>
</div>
<div class="outline-3" id="outline-container-orgae816bb">
<h3 id="orgae816bb">Imports</h3>
<div class="outline-text-3" id="text-orgae816bb">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">redirect_stdout</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">holoviews</span> <span class="kn">import</span> <span class="n">opts</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">optimizers</span>
<span class="kn">from</span> <span class="nn">trax.supervised</span> <span class="kn">import</span> <span class="n">lr_schedules</span><span class="p">,</span> <span class="n">training</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.machine_translation</span> <span class="kn">import</span> <span class="n">DataGenerator</span><span class="p">,</span> <span class="n">NMTAttn</span>

<span class="c1"># related</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1814160">
<h3 id="org1814160">Set Up</h3>
<div class="outline-text-3" id="text-org1814160">
<div class="highlight">
<pre><span></span><span class="n">train_batch_stream</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">()</span><span class="o">.</span><span class="n">batch_generator</span>
<span class="n">eval_batch_stream</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">batch_generator</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"neural-machine-translation-training-the-model"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org3ca749d">
<h2 id="org3ca749d">Training</h2>
<div class="outline-text-2" id="text-org3ca749d"></div>
<div class="outline-3" id="outline-container-orgf34687d">
<h3 id="orgf34687d">TrainTask</h3>
<div class="outline-text-3" id="text-orgf34687d">
<p>The <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask">TrainTask</a> class allows us to define the labeled data to use for training and the feedback mechanisms to compute the loss and update the weights.</p>
<div class="highlight">
<pre><span></span><span class="n">train_task</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">TrainTask</span><span class="p">(</span>

    <span class="c1"># use the train batch stream as labeled data</span>
    <span class="n">labeled_data</span> <span class="o">=</span> <span class="n">train_batch_stream</span><span class="p">,</span>

    <span class="c1"># use the cross entropy loss</span>
    <span class="n">loss_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">WeightedCategoryCrossEntropy</span><span class="p">(),</span>

    <span class="c1"># use the Adam optimizer with learning rate of 0.01</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>

    <span class="c1"># use the `trax.lr.warmup_and_rsqrt_decay` as the learning rate schedule</span>
    <span class="c1"># have 1000 warmup steps with a max value of 0.01</span>
    <span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">lr_schedules</span><span class="o">.</span><span class="n">warmup_and_rsqrt_decay</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>

    <span class="c1"># have a checkpoint every 10 steps</span>
    <span class="n">n_steps_per_checkpoint</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_train_task</span><span class="p">(</span><span class="n">train_task</span><span class="p">):</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">train_task</span>
    <span class="n">success</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fails</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Test the labeled data parameter</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">strlabel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">_labeled_data</span><span class="p">)</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">strlabel</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">"generator"</span><span class="p">)</span> <span class="ow">and</span> <span class="n">strlabel</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'add_loss_weights'</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong labeled data parameter"</span><span class="p">)</span>

    <span class="c1"># Test the cross entropy loss data parameter</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">strlabel</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">_loss_layer</span><span class="p">)</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">strlabel</span> <span class="o">==</span> <span class="s2">"CrossEntropyLoss_in3"</span><span class="p">)</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong loss functions. CrossEntropyLoss_in3 was expected"</span><span class="p">)</span>

     <span class="c1"># Test the optimizer parameter</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">trax</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">adam</span><span class="o">.</span><span class="n">Adam</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong optimizer"</span><span class="p">)</span>

    <span class="c1"># Test the schedule parameter</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">_lr_schedule</span><span class="p">,</span><span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">lr_schedules</span><span class="o">.</span><span class="n">_BodyAndTail</span><span class="p">))</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong learning rate schedule type"</span><span class="p">)</span>

    <span class="c1"># Test the _n_steps_per_checkpoint parameter</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">_n_steps_per_checkpoint</span><span class="o">==</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Wrong checkpoint step frequency"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fails</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\033</span><span class="s2">[92m All tests passed"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[92m'</span><span class="p">,</span> <span class="n">success</span><span class="p">,</span><span class="s2">" Tests passed"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[91m'</span><span class="p">,</span> <span class="n">fails</span><span class="p">,</span> <span class="s2">" Tests failed"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">test_train_task</span><span class="p">(</span><span class="n">train_task</span><span class="p">)</span>
</pre></div>
<pre class="example">
Wrong loss functions. CrossEntropyLoss_in3 was expected
Wrong optimizer
Wrong learning rate schedule type
[92m 2  Tests passed
[91m 3  Tests failed
</pre>
<p>The code has changed a bit since the test was written so it won't pass without updates.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgf0f61bf">
<h3 id="orgf0f61bf">EvalTask</h3>
<div class="outline-text-3" id="text-orgf0f61bf">
<p>The <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask">EvalTask</a> on the other hand allows us to see how the model is doing while training. For our application, we want it to report the cross entropy loss and accuracy.</p>
<div class="highlight">
<pre><span></span><span class="n">eval_task</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">EvalTask</span><span class="p">(</span>

    <span class="c1">## use the eval batch stream as labeled data</span>
    <span class="n">labeled_data</span><span class="o">=</span><span class="n">eval_batch_stream</span><span class="p">,</span>

    <span class="c1">## use the cross entropy loss and accuracy as metrics</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">WeightedCategoryCrossEntropy</span><span class="p">(),</span> <span class="n">layers</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org718bcf8">
<h3 id="org718bcf8">Loop</h3>
<div class="outline-text-3" id="text-org718bcf8">
<p>The <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop">Loop</a> class defines the model we will train as well as the train and eval tasks to execute. Its <code>run()</code> method allows us to execute the training for a specified number of steps.</p>
<div class="highlight">
<pre><span></span><span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/machine_translation/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
</pre></div>
<p>Define the training loop.</p>
<div class="highlight">
<pre><span></span><span class="n">training_loop</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">Loop</span><span class="p">(</span><span class="n">NMTAttn</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">'train'</span><span class="p">),</span>
                              <span class="n">train_task</span><span class="p">,</span>
                              <span class="n">eval_tasks</span><span class="o">=</span><span class="p">[</span><span class="n">eval_task</span><span class="p">],</span>
                              <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">train_steps</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">,</span> \
     <span class="nb">open</span><span class="p">(</span><span class="s2">"/tmp/machine_translation_training.log"</span><span class="p">,</span> <span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">,</span> \
     <span class="n">redirect_stdout</span><span class="p">(</span><span class="n">temp_file</span><span class="p">):</span>
            <span class="n">training_loop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_steps</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2021-03-09 18:31:58.844878
Ended: 2021-03-09 20:14:43.090358
Elapsed: 1:42:44.245480
</pre>
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/WeightedCategoryCrossEntropy"</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch CrossEntropy"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">CrossEntropy</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">CrossEntropy</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"CrossEntropy"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Cross Entropy Loss"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_cross_entropy"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/neural-machine-translation-training-the-model/evaluation_cross_entropy.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/Accuracy"</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch Accuracy"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">Accuracy</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Accuracy"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Accuracy"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_accuracy"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/neural-machine-translation-training-the-model/evaluation_accuracy.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It seems to be stuck…</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge4fedd5">
<h2 id="orge4fedd5">End</h2>
<div class="outline-text-2" id="text-orge4fedd5">
<p>Now that we've trained the model in the <a href="posts/nlp/neural-machine-translation-testing-the-model/">next post</a> we'll test our model to see how well it does. The overview post with links to all the posts in this series is <a href="posts/nlp/neural-machine-translation/">here</a>.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org828e9f4">
<h2 id="org828e9f4">Raw</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation-the-attention-model/">Neural Machine Translation: The Attention Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation-the-attention-model/" rel="bookmark"><time class="published dt-published" datetime="2021-02-14T14:54:08-08:00" itemprop="datePublished" title="2021-02-14 14:54">2021-02-14 14:54</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#org7734357">Defining the Model</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#org3ac4558">Attention Overview</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#org82df267">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#orgcd79f24">Implementation</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#org0897f0c">Overview</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#org0428639">The Implementation</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/#orga4ea059">End</a></li>
</ul>
</div>
</div>
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">attention</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;&gt;</span>
</pre></div>
<div class="outline-2" id="outline-container-org7734357">
<h2 id="org7734357">Defining the Model</h2>
<div class="outline-text-2" id="text-org7734357">
<p>In the <a href="posts/nlp/neural-machine-translation-helper-functions/">previous post</a> we made some helper functions to prepare inputs for some of the layers in the model. In this post we'll define the model itself.</p>
</div>
<div class="outline-3" id="outline-container-org3ac4558">
<h3 id="org3ac4558">Attention Overview</h3>
<div class="outline-text-3" id="text-org3ac4558">
<p>The model we will be building uses an encoder-decoder architecture. This Recurrent Neural Network (RNN) will take in a tokenized version of a sentence in its encoder, then passes it on to the decoder for translation. Just using a a regular sequence-to-sequence model with LSTMs will work effectively for short to medium sentences but will start to degrade for longer ones. You can picture it like the figure below where all of the context of the input sentence is compressed into one vector that is passed into the decoder block. You can see how this will be an issue for very long sentences (e.g. 100 tokens or more) because the context of the first parts of the input will have very little effect on the final vector passed to the decoder.</p>
<p>Adding an attention layer to this model avoids this problem by giving the decoder access to all parts of the input sentence. To illustrate, let's just use a 4-word input sentence as shown below. Remember that a hidden state is produced at each timestep of the encoder (represented by the orange rectangles). These are all passed to the attention layer and each are given a score given the current activation (i.e. hidden state) of the decoder. For instance, let's consider the figure below where the first prediction "Wie" is already made. To produce the next prediction, the attention layer will first receive all the encoder hidden states (i.e. orange rectangles) as well as the decoder hidden state when producing the word "Wie" (i.e. first green rectangle). Given this information, it will score each of the encoder hidden states to know which one the decoder should focus on to produce the next word. The result of the model training might have learned that it should align to the second encoder hidden state and subsequently assigns a high probability to the word "geht". If we are using greedy decoding, we will output the said word as the next symbol, then restart the process to produce the next word until we reach an end-of-sentence prediction.</p>
<p>There are different ways to implement attention and the one we'll use is the Scaled Dot Product Attention which has the form:</p>
<p>\[ Attention(Q, K, V) = softmax \left(\frac{QK^T}{\sqrt{d_k}} \right)V \]</p>
<p>You can think of it as computing scores using queries (Q) and keys (K), followed by a multiplication of values (V) to get a context vector at a particular timestep of the decoder. This context vector is fed to the decoder RNN to get a set of probabilities for the next predicted word. The division by square root of the keys dimensionality (\(\sqrt{d_k}\)) is for improving model performance and you'll also learn more about it next week. For our machine translation application, the encoder activations (i.e. encoder hidden states) will be the keys and values, while the decoder activations (i.e. decoder hidden states) will be the queries.</p>
<p>You will see in the upcoming sections that this complex architecture and mechanism can be implemented with just a few lines of code.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org82df267">
<h3 id="org82df267">Imports</h3>
<div class="outline-text-3" id="text-org82df267">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.machine_translation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">NMTAttn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgcd79f24">
<h2 id="orgcd79f24">Implementation</h2>
<div class="outline-text-2" id="text-orgcd79f24"></div>
<div class="outline-3" id="outline-container-org0897f0c">
<h3 id="org0897f0c">Overview</h3>
<div class="outline-text-3" id="text-org0897f0c">
<p>We are now ready to implement our sequence-to-sequence model with attention. This will be a Serial network and is illustrated in the diagram below. It shows the layers you'll be using in Trax and you'll see that each step can be implemented quite easily with one line commands. We've placed several links to the documentation for each relevant layer in the discussion after the figure below.</p>
<ul class="org-ul">
<li><b>Step 0:</b> Prepare the input encoder and pre-attention decoder branches. We've already defined this earlier as helper functions so it's just a matter of calling those functions and assigning it to variables.</li>
<li><b>Step 1:</b> Create a Serial network. This will stack the layers in the next steps one after the other. As before, we'll use <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial">tl.Serial</a>.</li>
<li><b>Step 2:</b> Make a copy of the input and target tokens. As you see in the diagram above, the input and target tokens will be fed into different layers of the model. We'll use <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Select">tl.Select</a> layer to create copies of these tokens, arranging them as <code>[input tokens, target tokens, input tokens, target tokens]</code>.</li>
<li><b>Step 3:</b> Create a parallel branch to feed the input tokens to the <code>input_encoder</code> and the target tokens to the <code>pre_attention_decoder</code>. We'll use <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Parallel">tl.Parallel</a> to create these sublayers in parallel, remembering to pass the variables defined in Step 0 as parameters to this layer.</li>
<li><b>Step 4:</b> Next, call the `prepare_attention_input` function to convert the encoder and pre-attention decoder activations to a format that the attention layer will accept. You can use <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn">tl.Fn</a> to call this function. Note: Pass the <code>prepare_attention_input</code> function as the <code>f</code> parameter in <code>tl.Fn</code> without any arguments or parenthesis.</li>
<li><b>Step 5:</b> We will now feed the (queries, keys, values, and mask) to the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.AttentionQKV">tl.AttentionQKV</a> layer. This computes the scaled dot product attention and outputs the attention weights and mask. Take note that although it is a one liner, this layer is actually composed of a deep network made up of several branches. We'll show the implementation show <a href="https://github.com/google/trax/blob/master/trax/layers/attention.py#L61">here</a> (on github) to see the different layers used.</li>
</ul>
<pre class="example" id="org5edb6df">
def AttentionQKV(d_feature, n_heads=1, dropout=0.0, mode='train'):
  """Returns a layer that maps (q, k, v, mask) to (activations, mask).

  See `Attention` above for further context/details.

  Args:
    d_feature: Depth/dimensionality of feature embedding.
    n_heads: Number of attention heads.
    dropout: Probababilistic rate for internal dropout applied to attention
        activations (based on query-key pairs) before dotting them with values.
    mode: Either 'train' or 'eval'.
  """
  return cb.Serial(
      cb.Parallel(
          core.Dense(d_feature),
          core.Dense(d_feature),
          core.Dense(d_feature),
      ),
      PureAttention(  # pylint: disable=no-value-for-parameter
          n_heads=n_heads, dropout=dropout, mode=mode),
      core.Dense(d_feature),
  )
</pre>
<p>Having deep layers poses the risk of vanishing gradients during training and we would want to mitigate that. To improve the ability of the network to learn, we can insert a <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual">tl.Residual</a> layer to add the output of AttentionQKV with the <code>queries</code> input. You can do this in trax by simply nesting the <code>AttentionQKV</code> layer inside the <code>Residual</code> layer. The library will take care of branching and adding for you.</p>
<ul class="org-ul">
<li><b>Step 6:</b> We will not need the mask for the model we're building so we can safely drop it. At this point in the network, the signal stack currently has <code>[attention activations, mask, target tokens]</code> and you can use <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Select">tl.Select</a> to output just <code>[attention activations, target tokens]</code>.</li>
<li><b>Step 7:</b> We can now feed the attention weighted output to the LSTM decoder. We can stack multiple <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">tl.LSTM</a> layers to improve the output so remember to append LSTMs equal to the number defined by <code>n_decoder_layers</code> parameter to the model.</li>
<li><b>Step 8:</b> We want to determine the probabilities of each subword in the vocabulary and you can set this up easily with a <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a> layer by making its size equal to the size of our vocabulary.</li>
<li><b>Step 9:</b> Normalize the output to log probabilities by passing the activations in Step 8 to a <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax">tl.LogSoftmax</a> layer.</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org0428639">
<h3 id="org0428639">The Implementation</h3>
<div class="outline-text-3" id="text-org0428639">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.help_me</span> <span class="kn">import</span> <span class="n">input_encoder</span> <span class="k">as</span> <span class="n">input_encoder_fn</span>
<span class="kn">from</span> <span class="nn">.help_me</span> <span class="kn">import</span> <span class="n">pre_attention_decoder</span> <span class="k">as</span> <span class="n">pre_attention_decoder_fn</span>
<span class="kn">from</span> <span class="nn">.help_me</span> <span class="kn">import</span> <span class="n">prepare_attention_input</span> <span class="k">as</span> <span class="n">prepare_attention_input_fn</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">NMTAttn</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">33300</span><span class="p">,</span>
            <span class="n">target_vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">33300</span><span class="p">,</span>
            <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">n_encoder_layers</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_decoder_layers</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_attention_heads</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">attention_dropout</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s1">'train'</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
    <span class="sd">"""Returns an LSTM sequence-to-sequence model with attention.</span>

<span class="sd">    The input to the model is a pair (input tokens, target tokens), e.g.,</span>
<span class="sd">    an English sentence (tokenized) and its translation into German (tokenized).</span>

<span class="sd">    Args:</span>
<span class="sd">    input_vocab_size: int: vocab size of the input</span>
<span class="sd">    target_vocab_size: int: vocab size of the target</span>
<span class="sd">    d_model: int:  depth of embedding (n_units in the LSTM cell)</span>
<span class="sd">    n_encoder_layers: int: number of LSTM layers in the encoder</span>
<span class="sd">    n_decoder_layers: int: number of LSTM layers in the decoder after attention</span>
<span class="sd">    n_attention_heads: int: number of attention heads</span>
<span class="sd">    attention_dropout: float, dropout for the attention layer</span>
<span class="sd">    mode: str: 'train', 'eval' or 'predict', predict mode is for fast inference</span>

<span class="sd">    Returns:</span>
<span class="sd">    A LSTM sequence-to-sequence model with attention.</span>
<span class="sd">    """</span>
    <span class="c1"># Step 0: call the helper function to create layers for the input encoder</span>
    <span class="n">input_encoder</span> <span class="o">=</span> <span class="n">input_encoder_fn</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_encoder_layers</span><span class="p">)</span>

    <span class="c1"># Step 0: call the helper function to create layers for the pre-attention decoder</span>
    <span class="n">pre_attention_decoder</span> <span class="o">=</span> <span class="n">pre_attention_decoder_fn</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="c1"># Step 1: create a serial network</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span> 

      <span class="c1"># Step 2: copy input tokens and target tokens as they will be needed later.</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>

      <span class="c1"># Step 3: run input encoder on the input and pre-attention decoder on the target.</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">input_encoder</span><span class="p">,</span> <span class="n">pre_attention_decoder</span><span class="p">),</span>

      <span class="c1"># Step 4: prepare queries, keys, values and mask for attention.</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s1">'PrepareAttentionInput'</span><span class="p">,</span> <span class="n">prepare_attention_input_fn</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>

      <span class="c1"># Step 5: run the AttentionQKV layer</span>
      <span class="c1"># nest it inside a Residual layer to add to the pre-attention decoder activations(i.e. queries)</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">Residual</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">AttentionQKV</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span>
                                          <span class="n">n_heads</span><span class="o">=</span><span class="n">n_attention_heads</span><span class="p">,</span>
                                          <span class="n">dropout</span><span class="o">=</span><span class="n">attention_dropout</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)),</span>

      <span class="c1"># Step 6: drop attention mask (i.e. index = None</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>

      <span class="c1"># Step 7: run the rest of the RNN decoder</span>
      <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_decoder_layers</span><span class="p">)],</span>

      <span class="c1"># Step 8: prepare output by making it the right size</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">),</span>

      <span class="c1"># Step 9: Log-softmax for output</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_NMTAttn</span><span class="p">(</span><span class="n">NMTAttn</span><span class="p">):</span>
    <span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">"name"</span><span class="p">:</span><span class="s2">"simple_test_check"</span><span class="p">,</span>
                    <span class="s2">"expected"</span><span class="p">:</span><span class="s2">"Serial_in2_out2[</span><span class="se">\n</span><span class="s2">  Select[0,1,0,1]_in2_out4</span><span class="se">\n</span><span class="s2">  Parallel_in2_out2[</span><span class="se">\n</span><span class="s2">    Serial[</span><span class="se">\n</span><span class="s2">      Embedding_33300_1024</span><span class="se">\n</span><span class="s2">      LSTM_1024</span><span class="se">\n</span><span class="s2">      LSTM_1024</span><span class="se">\n</span><span class="s2">    ]</span><span class="se">\n</span><span class="s2">    Serial[</span><span class="se">\n</span><span class="s2">      ShiftRight(1)</span><span class="se">\n</span><span class="s2">      Embedding_33300_1024</span><span class="se">\n</span><span class="s2">      LSTM_1024</span><span class="se">\n</span><span class="s2">    ]</span><span class="se">\n</span><span class="s2">  ]</span><span class="se">\n</span><span class="s2">  PrepareAttentionInput_in3_out4</span><span class="se">\n</span><span class="s2">  Serial_in4_out2[</span><span class="se">\n</span><span class="s2">    Branch_in4_out3[</span><span class="se">\n</span><span class="s2">      None</span><span class="se">\n</span><span class="s2">      Serial_in4_out2[</span><span class="se">\n</span><span class="s2">        Parallel_in3_out3[</span><span class="se">\n</span><span class="s2">          Dense_1024</span><span class="se">\n</span><span class="s2">          Dense_1024</span><span class="se">\n</span><span class="s2">          Dense_1024</span><span class="se">\n</span><span class="s2">        ]</span><span class="se">\n</span><span class="s2">        PureAttention_in4_out2</span><span class="se">\n</span><span class="s2">        Dense_1024</span><span class="se">\n</span><span class="s2">      ]</span><span class="se">\n</span><span class="s2">    ]</span><span class="se">\n</span><span class="s2">    Add_in2</span><span class="se">\n</span><span class="s2">  ]</span><span class="se">\n</span><span class="s2">  Select[0,2]_in3_out2</span><span class="se">\n</span><span class="s2">  LSTM_1024</span><span class="se">\n</span><span class="s2">  LSTM_1024</span><span class="se">\n</span><span class="s2">  Dense_33300</span><span class="se">\n</span><span class="s2">  LogSoftmax</span><span class="se">\n</span><span class="s2">]"</span><span class="p">,</span>
                    <span class="s2">"error"</span><span class="p">:</span><span class="s2">"The NMTAttn is not defined properly."</span>
                <span class="p">},</span>
                <span class="p">{</span>
                    <span class="s2">"name"</span><span class="p">:</span><span class="s2">"layer_len_check"</span><span class="p">,</span>
                    <span class="s2">"expected"</span><span class="p">:</span><span class="mi">9</span><span class="p">,</span>
                    <span class="s2">"error"</span><span class="p">:</span><span class="s2">"We found </span><span class="si">{}</span><span class="s2"> layers in your model. It should be 9.</span><span class="se">\n</span><span class="s2">Check the LSTM stack before the dense layer"</span>
                <span class="p">},</span>
                <span class="p">{</span>
                    <span class="s2">"name"</span><span class="p">:</span><span class="s2">"selection_layer_check"</span><span class="p">,</span>
                    <span class="s2">"expected"</span><span class="p">:[</span><span class="s2">"Select[0,1,0,1]_in2_out4"</span><span class="p">,</span> <span class="s2">"Select[0,2]_in3_out2"</span><span class="p">],</span>
                    <span class="s2">"error"</span><span class="p">:</span><span class="s2">"Look at your selection layers."</span>
                <span class="p">}</span>
            <span class="p">]</span>

    <span class="n">success</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">fails</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">test_case</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">test_case</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"simple_test_check"</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">test_case</span><span class="p">[</span><span class="s2">"expected"</span><span class="p">]</span> <span class="o">==</span> <span class="nb">str</span><span class="p">(</span><span class="n">NMTAttn</span><span class="p">())</span>
                <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">test_case</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"layer_len_check"</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">test_case</span><span class="p">[</span><span class="s2">"expected"</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">NMTAttn</span><span class="p">()</span><span class="o">.</span><span class="n">sublayers</span><span class="p">):</span>
                    <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">test_case</span><span class="p">[</span><span class="s2">"error"</span><span class="p">]</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">NMTAttn</span><span class="p">()</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)))</span> 
                    <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">test_case</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"selection_layer_check"</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">NMTAttn</span><span class="p">()</span>
                <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">sublayers</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">sublayers</span><span class="p">[</span><span class="mi">4</span><span class="p">])]</span>
                <span class="n">check_count</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">test_case</span><span class="p">[</span><span class="s2">"expected"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="n">test_case</span><span class="p">[</span><span class="s2">"error"</span><span class="p">])</span>
                        <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">break</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">check_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">check_count</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">success</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">test_case</span><span class="p">[</span><span class="s1">'error'</span><span class="p">])</span>
            <span class="n">fails</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">fails</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\033</span><span class="s2">[92m All tests passed"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[92m'</span><span class="p">,</span> <span class="n">success</span><span class="p">,</span><span class="s2">" Tests passed"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\033</span><span class="s1">[91m'</span><span class="p">,</span> <span class="n">fails</span><span class="p">,</span> <span class="s2">" Tests failed"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">test_cases</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">test_cases</span> <span class="o">=</span> <span class="n">test_NMTAttn</span><span class="p">(</span><span class="n">NMTAttn</span><span class="p">)</span>
</pre></div>
<pre class="example">
The NMTAttn is not defined properly.
[92m 2  Tests passed
[91m 1  Tests failed
</pre>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NMTAttn</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org2f7b849">
Serial_in2_out2[
  Select[0,1,0,1]_in2_out4
  Parallel_in2_out2[
    Serial[
      Embedding_33300_1024
      LSTM_1024
      LSTM_1024
    ]
    Serial[
      Serial[
        ShiftRight(1)
      ]
      Embedding_33300_1024
      LSTM_1024
    ]
  ]
  PrepareAttentionInput_in3_out4
  Serial_in4_out2[
    Branch_in4_out3[
      None
      Serial_in4_out2[
        _in4_out4
        Serial_in4_out2[
          Parallel_in3_out3[
            Dense_1024
            Dense_1024
            Dense_1024
          ]
          PureAttention_in4_out2
          Dense_1024
        ]
        _in2_out2
      ]
    ]
    Add_in2
  ]
  Select[0,2]_in3_out2
  LSTM_1024
  LSTM_1024
  Dense_33300
  LogSoftmax
]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orga4ea059">
<h2 id="orga4ea059">End</h2>
<div class="outline-text-2" id="text-orga4ea059">
<p>Now that we have the model defined, in the <a href="posts/nlp/neural-machine-translation-training-the-model/">next post</a> we'll train the model. The overview post with links to all the posts in this series is <a href="posts/nlp/neural-machine-translation/">here</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation-the-data/">Neural Machine Translation: The Data</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation-the-data/" rel="bookmark"><time class="published dt-published" datetime="2021-02-14T14:53:32-08:00" itemprop="datePublished" title="2021-02-14 14:53">2021-02-14 14:53</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orge2c24f4">The Data</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org5fac1cc">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org15ff595">Middle</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org94c1ae2">Loading the Data</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org97a21dd">The Training Data</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orgcee823a">The Evaluation Data</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org801a11d">Tokenization and Formatting</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org535fb56">Integer assigned as end-of-sentence (EOS)</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org118083f">Filter long sentences</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org1764a38">tokenize & detokenize helper functions</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org895f730">Bucketing</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orge1fbae7">Bucketing to create streams of batches.</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org73fda4f">Exploring the data</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org7516a44">Bundle it Up</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orgcb57f09">Imports</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orgfce077b">Constants</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org88bc5e5">Tokenizer/Detokenizer</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org6e0071c">Tokenizer</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org85ca6e9">Detokenizer</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org2f4c821">Data Generator</a>
<ul>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org4edeed6">Append End of Sentence</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orgf640abd">Generator Function</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orga634fb3">Batch Stream</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#org7092d91">Try It Out</a></li>
</ul>
</li>
<li><a href="posts/nlp/neural-machine-translation-the-data/#orga61fbcf">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orge2c24f4">
<h2 id="orge2c24f4">The Data</h2>
<div class="outline-text-2" id="text-orge2c24f4">
<p>This is the first post in a series that will look at creating a Long-Short-Term-Memory (LSTM) model with attention for Machine Learning. The <a href="posts/nlp/neural-machine-translation/">previous post</a> was an overview that holds the links to all the posts in the series.</p>
</div>
<div class="outline-3" id="outline-container-org5fac1cc">
<h3 id="org5fac1cc">Imports</h3>
<div class="outline-text-3" id="text-org5fac1cc">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">termcolor</span> <span class="kn">import</span> <span class="n">colored</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org15ff595">
<h2 id="org15ff595">Middle</h2>
<div class="outline-text-2" id="text-org15ff595"></div>
<div class="outline-3" id="outline-container-org94c1ae2">
<h3 id="org94c1ae2">Loading the Data</h3>
<div class="outline-text-3" id="text-org94c1ae2">
<p>Next, we will import the dataset we will use to train the model. If you are running out of space, you can just use a small dataset from <a href="http://opus.nlpl.eu/">Opus</a>, a growing collection of translated texts from the web. Particularly, we will get an English to German translation subset specified as <code>opus/medical</code> which has medical related texts. If storage is not an issue, you can opt to get a larger corpus such as the English to German translation dataset from <a href="https://paracrawl.eu/">ParaCrawl</a>, a large multi-lingual translation dataset created by the European Union. Both of these datasets are available via <a href="https://www.tensorflow.org/datasets">Tensorflow Datasets (TFDS)</a> and you can browse through the other available datasets <a href="https://www.tensorflow.org/datasets/catalog/overview">here</a>. As you'll see below, you can easily access this dataset from TFDS with <code>trax.data.TFDS</code>. The result is a python generator function yielding tuples. Use the <code>keys</code> argument to select what appears at which position in the tuple. For example, <code>keys=('en', 'de')</code> below will return pairs as (English sentence, German sentence).</p>
<p>The <a href="https://www.tensorflow.org/datasets/catalog/para_crawl#para_crawlende"><code>para_crawl/ende</code></a> dataset is 4.04 GiB while the <a href="https://www.tensorflow.org/datasets/catalog/opus#opusmedical_default_config"><code>opus/medical</code></a> dataset is 188.85 MiB.</p>
<p><b>Note:</b> Trying to download the ParaCrawl dataset using trax creates an out of resource error. You can try downloading the source from:</p>
<p><a href="https://s3.amazonaws.com/web-language-models/paracrawl/release4/en-de.bicleaner07.txt.gz">https://s3.amazonaws.com/web-language-models/paracrawl/release4/en-de.bicleaner07.txt.gz</a></p>
<p>Although I haven't figured out how to get it into the trax data yet so I'm sticking with the smaller data set.</p>
</div>
<div class="outline-4" id="outline-container-org97a21dd">
<h4 id="org97a21dd">The Training Data</h4>
<div class="outline-text-4" id="text-org97a21dd">
<p>The first time you run this it will download the dataset, after that it will just load it from the file.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/data/tensorflow/translation/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>

<span class="n">data_set</span> <span class="o">=</span> <span class="s2">"opus/medical"</span>
<span class="c1"># data_set = "para_crawl/ende"</span>

<span class="n">train_stream_fn</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFDS</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span>
                                 <span class="n">data_dir</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                                 <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s1">'en'</span><span class="p">,</span> <span class="s1">'de'</span><span class="p">),</span>
                                 <span class="n">eval_holdout_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                                 <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org1f44cfc">
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-fb62d04026f5&gt; in &lt;module&gt;
      4 # data_set = "para_crawl/ende"
      5 
----&gt; 6 train_stream_fn = trax.data.TFDS(data_set,
      7                                  data_dir=path,
      8                                  keys=('en', 'de'),

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1067       scope_info = " in scope '{}'".format(scope_str) if scope_str else ''
   1068       err_str = err_str.format(name, fn_or_cls, scope_info)
-&gt; 1069       utils.augment_exception_message_and_reraise(e, err_str)
   1070 
   1071   return gin_wrapper

/usr/local/lib/python3.8/dist-packages/gin/utils.py in augment_exception_message_and_reraise(exception, message)
     39   proxy = ExceptionProxy()
     40   ExceptionProxy.__qualname__ = type(exception).__qualname__
---&gt; 41   raise proxy.with_traceback(exception.__traceback__) from None
     42 
     43 

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1044 
   1045     try:
-&gt; 1046       return fn(*new_args, **new_kwargs)
   1047     except Exception as e:  # pylint: disable=broad-except
   1048       err_str = ''

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1067       scope_info = " in scope '{}'".format(scope_str) if scope_str else ''
   1068       err_str = err_str.format(name, fn_or_cls, scope_info)
-&gt; 1069       utils.augment_exception_message_and_reraise(e, err_str)
   1070 
   1071   return gin_wrapper

/usr/local/lib/python3.8/dist-packages/gin/utils.py in augment_exception_message_and_reraise(exception, message)
     39   proxy = ExceptionProxy()
     40   ExceptionProxy.__qualname__ = type(exception).__qualname__
---&gt; 41   raise proxy.with_traceback(exception.__traceback__) from None
     42 
     43 

/usr/local/lib/python3.8/dist-packages/gin/config.py in gin_wrapper(*args, **kwargs)
   1044 
   1045     try:
-&gt; 1046       return fn(*new_args, **new_kwargs)
   1047     except Exception as e:  # pylint: disable=broad-except
   1048       err_str = ''

~/trax/trax/data/tf_inputs.py in TFDS(dataset_name, data_dir, tfds_preprocess_fn, keys, train, shuffle_train, host_id, n_hosts, eval_holdout_size)
    279   else:
    280     subsplit = None
--&gt; 281   (train_data, eval_data, _) = _train_and_eval_dataset(
    282       dataset_name, data_dir, eval_holdout_size,
    283       train_shuffle_files=shuffle_train, subsplit=subsplit)

~/trax/trax/data/tf_inputs.py in _train_and_eval_dataset(dataset_name, data_dir, eval_holdout_size, train_shuffle_files, eval_shuffle_files, subsplit)
    224   if eval_holdout_examples &gt; 0 or subsplit is not None:
    225     n_train = train_examples - eval_holdout_examples
--&gt; 226     train_start = int(n_train * subsplit[0])
    227     train_end = int(n_train * subsplit[1])
    228     if train_end - train_start &lt; 1:

TypeError: 'NoneType' object is not subscriptable
  In call to configurable 'TFDS' (&lt;function TFDS at 0x7f960c527280&gt;)
  In call to configurable 'TFDS' (&lt;function TFDS at 0x7f960c526f70&gt;)
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgcee823a">
<h4 id="orgcee823a">The Evaluation Data</h4>
<div class="outline-text-4" id="text-orgcee823a">
<p>Since we already downloaded the data in the previous code-block, this will just load the evaluation set from the downloaded data.</p>
<div class="highlight">
<pre><span></span><span class="n">eval_stream_fn</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFDS</span><span class="p">(</span><span class="s1">'opus/medical'</span><span class="p">,</span>
                                <span class="n">data_dir</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
                                <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s1">'en'</span><span class="p">,</span> <span class="s1">'de'</span><span class="p">),</span>
                                <span class="n">eval_holdout_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                                <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>Notice that TFDS returns a generator <b>function</b>, not a generator. This is because in Python, you cannot reset generators so you cannot go back to a previously yielded value. During deep learning training, you use Stochastic Gradient Descent and don't actually need to go back – but it is sometimes good to be able to do that, and that's where the functions come in. Let's print a a sample pair from our train and eval data. Notice that the raw output is represented in bytes (denoted by the <code>b'</code> prefix) and these will be converted to strings internally in the next steps.</p>
<div class="highlight">
<pre><span></span><span class="n">train_stream</span> <span class="o">=</span> <span class="n">train_stream_fn</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'train data (en, de) tuple:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_stream</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example">
[31mtrain data (en, de) tuple:[0m (b'Tel: +421 2 57 103 777\n', b'Tel: +421 2 57 103 777\n')

</pre>
<div class="highlight">
<pre><span></span><span class="n">eval_stream</span> <span class="o">=</span> <span class="n">eval_stream_fn</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'eval data (en, de) tuple:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="nb">next</span><span class="p">(</span><span class="n">eval_stream</span><span class="p">))</span>
</pre></div>
<pre class="example">
[31meval data (en, de) tuple:[0m (b'Lutropin alfa Subcutaneous use.\n', b'Pulver zur Injektion Lutropin alfa Subkutane Anwendung\n')
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org801a11d">
<h3 id="org801a11d">Tokenization and Formatting</h3>
<div class="outline-text-3" id="text-org801a11d">
<p>Now that we have imported our corpus, we will be preprocessing the sentences into a format that our model can accept. This will be composed of several steps:</p>
<p><b>Tokenizing the sentences using subword representations:</b> We want to represent each sentence as an array of integers instead of strings. For our application, we will use <b>subword</b> representations to tokenize our sentences. This is a common technique to avoid out-of-vocabulary words by allowing parts of words to be represented separately. For example, instead of having separate entries in your vocabulary for –"fear", "fearless", "fearsome", "some", and "less"–, you can simply store –"fear", "some", and "less"– then allow your tokenizer to combine these subwords when needed. This allows it to be more flexible so you won't have to save uncommon words explicitly in your vocabulary (e.g. <b>stylebender</b>, <b>nonce</b>, etc). Tokenizing is done with the `trax.data.Tokenize()` command and we have provided you the combined subword vocabulary for English and German (i.e. `ende_32k.subword`) retrieved from <a href="https://storage.googleapis.com/trax-ml/vocabs/ende_32k.subword">https://storage.googleapis.com/trax-ml/vocabs/ende_32k.subword</a> (I'm using the web-interface, but you could also just download it and put it in a directory).</p>
<div class="highlight">
<pre><span></span><span class="n">VOCAB_FILE</span> <span class="o">=</span> <span class="s1">'ende_32k.subword'</span>
<span class="n">VOCAB_DIR</span> <span class="o">=</span> <span class="s2">"gs://trax-ml/vocabs/"</span> <span class="c1"># google storage</span>

<span class="c1"># Tokenize the dataset.</span>
<span class="n">tokenized_train_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Tokenize</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">)(</span><span class="n">train_stream</span><span class="p">)</span>
<span class="n">tokenized_eval_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Tokenize</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">)(</span><span class="n">eval_stream</span><span class="p">)</span>
</pre></div>
<p><b>Append an end-of-sentence token to each sentence:</b> We will assign a token (i.e. in this case <code>1</code>) to mark the end of a sentence. This will be useful in inference/prediction so we'll know that the model has completed the translation.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org535fb56">
<h3 id="org535fb56">Integer assigned as end-of-sentence (EOS)</h3>
<div class="outline-text-3" id="text-org535fb56">
<div class="highlight">
<pre><span></span><span class="n">EOS</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">append_eos</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span>
    <span class="sd">"""helper to add end of sentence token to sentences in the stream</span>

<span class="sd">    Yields:</span>
<span class="sd">     next tuple of numpy arrays with EOS token added (inputs, targets)</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="n">inputs_with_eos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
        <span class="n">targets_with_eos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs_with_eos</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets_with_eos</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">tokenized_train_stream</span> <span class="o">=</span> <span class="n">append_eos</span><span class="p">(</span><span class="n">tokenized_train_stream</span><span class="p">)</span>
<span class="n">tokenized_eval_stream</span> <span class="o">=</span> <span class="n">append_eos</span><span class="p">(</span><span class="n">tokenized_eval_stream</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org118083f">
<h4 id="org118083f">Filter long sentences</h4>
<div class="outline-text-4" id="text-org118083f">
<p>We will place a limit on the number of tokens per sentence to ensure we won't run out of memory. This is done with the <code>trax.data.FilterByLength()</code> method and you can see its syntax below.</p>
<p>Filter too long sentences to not run out of memory. length_keys=[0, 1] means we filter both English and German sentences, so both must not be longer that 256 tokens for training and 512 tokens for evaluation.</p>
<div class="highlight">
<pre><span></span><span class="n">filtered_train_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FilterByLength</span><span class="p">(</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])(</span><span class="n">tokenized_train_stream</span><span class="p">)</span>
<span class="n">filtered_eval_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FilterByLength</span><span class="p">(</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])(</span><span class="n">tokenized_eval_stream</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">filtered_train_stream</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single tokenized example input:'</span><span class="p">,</span> <span class="s1">'red'</span> <span class="p">),</span> <span class="n">train_input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single tokenized example target:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">train_target</span><span class="p">)</span>
</pre></div>
<pre class="example">
[31mSingle tokenized example input:[0m [ 2538  2248    30 12114 23184 16889     5     2 20852  6456 20592  5812
  3932    96  5178  3851    30  7891  3550 30650  4729   992     1]
[31mSingle tokenized example target:[0m [ 1872    11  3544    39  7019 17877 30432    23  6845    10 14222    47
  4004    18 21674     5 27467  9513   920   188 10630    18  3550 30650
  4729   992     1]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1764a38">
<h3 id="org1764a38">tokenize & detokenize helper functions</h3>
<div class="outline-text-3" id="text-org1764a38">
<p>Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your trax models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following:</p>
<ul class="org-ul">
<li>word2Ind: a dictionary mapping the word to its index.</li>
<li>ind2Word: a dictionary mapping the index to its word.</li>
<li>word2Count: a dictionary mapping the word to the number of times it appears.</li>
<li>num_words: total number of words that have appeared.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">input_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
             <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">EOS</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">EOS</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Encodes a string to an array of integers</span>

<span class="sd">    Args:</span>
<span class="sd">       input_str: human-readable string to encode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>

<span class="sd">    Returns:</span>
<span class="sd">       tokenized version of the input string</span>
<span class="sd">    """</span>
    <span class="c1"># Use the trax.data.tokenize method. It takes streams and returns streams,</span>
    <span class="c1"># we get around it by making a 1-element stream with `iter`.</span>
    <span class="n">inputs</span> <span class="o">=</span>  <span class="nb">next</span><span class="p">(</span><span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">iter</span><span class="p">([</span><span class="n">input_str</span><span class="p">]),</span>
                                      <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span>
                                      <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">))</span>

    <span class="c1"># Mark the end of the sentence with EOS</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS</span><span class="p">]</span>

    <span class="c1"># Adding the batch dimension to the front of the shape</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">batch_inputs</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
               <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">EOS</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">EOS</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">"""Decodes an array of integers to a human readable string</span>

<span class="sd">    Args:</span>
<span class="sd">       integers: array of integers to decode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>

<span class="sd">    Returns:</span>
<span class="sd">       str: the decoded sentence.</span>
<span class="sd">    """</span>
    <span class="c1"># Remove the dimensions of size 1</span>
    <span class="n">integers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">integers</span><span class="p">))</span>

    <span class="c1"># Remove the EOS to decode only the original tokens</span>
    <span class="k">if</span> <span class="n">EOS</span> <span class="ow">in</span> <span class="n">integers</span><span class="p">:</span>
        <span class="n">integers</span> <span class="o">=</span> <span class="n">integers</span><span class="p">[:</span><span class="n">integers</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">EOS</span><span class="p">)]</span> 

    <span class="k">return</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">)</span>
</pre></div>
<p>Let's see how we might use these functions:</p>
<p>Detokenize an input-target pair of tokenized sentences</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single detokenized example input:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Single detokenized example target:'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">train_target</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example">
[31mSingle detokenized example input:[0m During treatment with olanzapine, adolescents gained significantly more weight compared with adults.

[31mSingle detokenized example target:[0m Während der Behandlung mit Olanzapin nahmen die Jugendlichen im Vergleich zu Erwachsenen signifikant mehr Gewicht zu.

</pre>
<p>Tokenize and detokenize a word that is not explicitly saved in the vocabulary file. See how it combines the subwords – 'hell' and 'o'– to form the word 'hello'.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s2">"tokenize('hello'): "</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">),</span> <span class="n">tokenize</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s2">"detokenize([17332, 140, 1]): "</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">([</span><span class="mi">17332</span><span class="p">,</span> <span class="mi">140</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">))</span>
</pre></div>
<pre class="example">
[32mtokenize('hello'): [0m [[17332   140     1]]
[32mdetokenize([17332, 140, 1]): [0m hello
</pre></div>
</div>
<div class="outline-3" id="outline-container-org895f730">
<h3 id="org895f730">Bucketing</h3>
<div class="outline-text-3" id="text-org895f730">
<p>Bucketing the tokenized sentences is an important technique used to speed up training in NLP. Here is a <a href="https://medium.com/@rashmi.margani/how-to-speed-up-the-training-of-the-sequence-model-using-bucketing-techniques-9e302b0fd976">nice article describing it in detail</a> but the gist is very simple. Our inputs have variable lengths and you want to make these the same when batching groups of sentences together. One way to do that is to pad each sentence to the length of the longest sentence in the dataset. This might lead to some wasted computation though. For example, if there are multiple short sentences with just two tokens, do we want to pad these when the longest sentence is composed of a 100 tokens? Instead of padding with 0s to the maximum length of a sentence each time, we can group our tokenized sentences by length and bucket.</p>
<p>We batch the sentences with similar length together and only add minimal padding to make them have equal length (usually up to the nearest power of two). This allows us to waste less computation when processing padded sequences.</p>
<p>In Trax, it is implemented in the <a href="https://github.com/google/trax/blob/5fb8aa8c5cb86dabb2338938c745996d5d87d996/trax/supervised/inputs.py#L378">bucket_by_length</a> function.</p>
</div>
<div class="outline-4" id="outline-container-orge1fbae7">
<h4 id="orge1fbae7">Bucketing to create streams of batches.</h4>
<div class="outline-text-4" id="text-orge1fbae7">
<p>Buckets are defined in terms of boundaries and batch sizes. Batch_sizes[i] determines the batch size for items with length &lt; boundaries[i]. So below, we'll take a batch of 256 sentences of length &lt; 8, 128 if length is between 8 and 16, and so on – and only 2 if length is over 512. We'll do the bucketing using <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html?highlight=bucket_by_length#trax.data.inputs.bucket_by_length">bucket_by_length</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
<p>Create the generators.</p>
<div class="highlight">
<pre><span></span><span class="n">train_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BucketByLength</span><span class="p">(</span>
    <span class="n">boundaries</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span>
    <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># As before: count inputs and targets to length.</span>
<span class="p">)(</span><span class="n">filtered_train_stream</span><span class="p">)</span>

<span class="n">eval_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BucketByLength</span><span class="p">(</span>
    <span class="n">boundaries</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span>
    <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)(</span><span class="n">filtered_eval_stream</span><span class="p">)</span>
</pre></div>
<p>Add masking for the padding (0s) using <a href="https://trax-ml.readthedocs.io/en/latest/trax.data.html">add_loss_weights</a> (we're using <code>AddLossWeights</code> but the documentation for that just says "see add_loss_weights"). I can't find any documentation for it, but I think the 0's are what BucketByLength uses for padding.</p>
<div class="highlight">
<pre><span></span><span class="n">train_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AddLossWeights</span><span class="p">(</span><span class="n">id_to_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">train_batch_stream</span><span class="p">)</span>
<span class="n">eval_batch_stream</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AddLossWeights</span><span class="p">(</span><span class="n">id_to_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">eval_batch_stream</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org73fda4f">
<h3 id="org73fda4f">Exploring the data</h3>
<div class="outline-text-3" id="text-org73fda4f">
<p>We will now be displaying some of our data. You will see that the functions defined above (i.e. <code>tokenize()</code> and <code>detokenize()</code>) do the same things you have been doing again and again throughout the specialization. We gave these so you can focus more on building the model from scratch. Let us first get the data generator and get one batch of the data.</p>
<div class="highlight">
<pre><span></span><span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">mask_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">train_batch_stream</span><span class="p">)</span>
</pre></div>
<p>Let's see the data type of a batch.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"input_batch data type: "</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">input_batch</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"target_batch data type: "</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">target_batch</span><span class="p">))</span>
</pre></div>
<pre class="example">
input_batch data type:  &lt;class 'numpy.ndarray'&gt;
target_batch data type:  &lt;class 'numpy.ndarray'&gt;
</pre>
<p>Let's see the shape of this particular batch (batch length, sentence length).</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"input_batch shape: "</span><span class="p">,</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"target_batch shape: "</span><span class="p">,</span> <span class="n">target_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
<pre class="example">
input_batch shape:  (32, 64)
target_batch shape:  (32, 64)
</pre>
<p>The <code>input_batch</code> and <code>target_batch</code> are Numpy arrays consisting of tokenized English sentences and German sentences respectively. These tokens will later be used to produce embedding vectors for each word in the sentence (so the embedding for a sentence will be a matrix). The number of sentences in each batch is usually a power of 2 for optimal computer memory usage.</p>
<p>We can now visually inspect some of the data. You can run the cell below several times to shuffle through the sentences. Just to note, while this is a standard data set that is used widely, it does have some known wrong translations. With that, let's pick a random sentence and print its tokenized representation.</p>
<p>Pick a random index less than the batch size.</p>
<div class="highlight">
<pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batch</span><span class="p">))</span>
</pre></div>
<p>Use the index to grab an entry from the input and target batch.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1"> '</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgc8a8f7b">
[31mTHIS IS THE ENGLISH SENTENCE: 
[0m Kidneys and urinary tract (no effects were found to be common); uncommon: blood in the urine, proteins in the urine, sugar in the urine; rare: urge to pass urine, kidney pain, passing urine frequently.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: 
 [0m [ 5381 17607  3093     8  8670  6086   105 19166     5    50   154  1743
   152  1103     9    32   568  8076 19124  6847    64  6196     6     4
  8670   510     2 13355   823     6     4  8670   510     2  4968     6
     4  8670   510   115  7227    64  7628     9  2685  8670   510     2
 12220  5509 12095     2 19632  8670   510  7326  3550 30650  4729   992
     1     0     0     0] 

[31mTHIS IS THE GERMAN TRANSLATION: 
[0m Harndrang, Nierenschmerzen, häufiges Wasserlassen.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: 
[0m [ 5135 14970  2920     2  6262  4594 27552    28     2 20052    33  3736
   530  3550 30650  4729   992     1     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0] 
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org7516a44">
<h2 id="org7516a44">Bundle it Up</h2>
<div class="outline-text-2" id="text-org7516a44"></div>
<div class="outline-3" id="outline-container-orgcb57f09">
<h3 id="orgcb57f09">Imports</h3>
<div class="outline-text-3" id="text-orgcb57f09">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgfce077b">
<h3 id="orgfce077b">Constants</h3>
<div class="outline-text-3" id="text-orgfce077b">
<div class="highlight">
<pre><span></span><span class="n">DataDefaults</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"DataDefaults"</span><span class="p">,</span>
                          <span class="p">[</span><span class="s2">"path"</span><span class="p">,</span>
                           <span class="s2">"dataset"</span><span class="p">,</span>
                           <span class="s2">"keys"</span><span class="p">,</span>
                           <span class="s2">"evaluation_size"</span><span class="p">,</span>
                           <span class="s2">"end_of_sentence"</span><span class="p">,</span>
                           <span class="s2">"vocabulary_file"</span><span class="p">,</span>
                           <span class="s2">"vocabulary_path"</span><span class="p">,</span>
                           <span class="s2">"length_keys"</span><span class="p">,</span>
                           <span class="s2">"boundaries"</span><span class="p">,</span>
                           <span class="s2">"batch_sizes"</span><span class="p">,</span>
                           <span class="s2">"padding_token"</span><span class="p">])</span>

<span class="n">DEFAULTS</span> <span class="o">=</span> <span class="n">DataDefaults</span><span class="p">(</span>
    <span class="n">path</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s2">"~/data/tensorflow/translation/"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(),</span>
    <span class="n">dataset</span><span class="o">=</span><span class="s2">"opus/medical"</span><span class="p">,</span>
    <span class="n">keys</span><span class="o">=</span><span class="p">(</span><span class="s2">"en"</span><span class="p">,</span> <span class="s2">"de"</span><span class="p">),</span>
    <span class="n">evaluation_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">end_of_sentence</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocabulary_file</span><span class="o">=</span><span class="s2">"ende_32k.subword"</span><span class="p">,</span>
    <span class="n">vocabulary_path</span><span class="o">=</span><span class="s2">"gs://trax-ml/vocabs/"</span><span class="p">,</span>
    <span class="n">length_keys</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">boundaries</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)],</span>
    <span class="n">batch_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">power_of_two</span> <span class="k">for</span> <span class="n">power_of_two</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)],</span>
    <span class="n">padding_token</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">MaxLength</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"MaxLength"</span><span class="p">,</span> <span class="s2">"train evaluate"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="n">MaxLength</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">END_OF_SENTENCE</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org88bc5e5">
<h3 id="org88bc5e5">Tokenizer/Detokenizer</h3>
<div class="outline-text-3" id="text-org88bc5e5"></div>
<div class="outline-4" id="outline-container-org6e0071c">
<h4 id="org6e0071c">Tokenizer</h4>
<div class="outline-text-4" id="text-org6e0071c">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">input_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
             <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">end_of_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Encodes a string to an array of integers</span>

<span class="sd">    Args:</span>
<span class="sd">       input_str: human-readable string to encode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>
<span class="sd">       end_of_sentence: token for the end of sentence</span>
<span class="sd">    Returns:</span>
<span class="sd">       tokenized version of the input string</span>
<span class="sd">    """</span>
    <span class="c1"># The trax.data.tokenize method takes streams and returns streams,</span>
    <span class="c1"># we get around it by making a 1-element stream with `iter`.</span>
    <span class="n">inputs</span> <span class="o">=</span>  <span class="nb">next</span><span class="p">(</span><span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="nb">iter</span><span class="p">([</span><span class="n">input_str</span><span class="p">]),</span>
                                      <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span>
                                      <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">))</span>

    <span class="c1"># Mark the end of the sentence with EOS</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">end_of_sentence</span><span class="p">]</span>

    <span class="c1"># Adding the batch dimension to the front of the shape</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch_inputs</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org85ca6e9">
<h4 id="org85ca6e9">Detokenizer</h4>
<div class="outline-text-4" id="text-org85ca6e9">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
               <span class="n">vocab_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">vocab_dir</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">end_of_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">"""Decodes an array of integers to a human readable string</span>

<span class="sd">    Args:</span>
<span class="sd">       integers: array of integers to decode</span>
<span class="sd">       vocab_file: filename of the vocabulary text file</span>
<span class="sd">       vocab_dir: path to the vocabulary file</span>
<span class="sd">       end_of_sentence: token to mark the end of a sentence</span>
<span class="sd">    Returns:</span>
<span class="sd">       str: the decoded sentence.</span>
<span class="sd">    """</span>
    <span class="c1"># Remove the dimensions of size 1</span>
    <span class="n">integers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">integers</span><span class="p">))</span>

    <span class="c1"># Remove the EOS to decode only the original tokens</span>
    <span class="k">if</span> <span class="n">end_of_sentence</span> <span class="ow">in</span> <span class="n">integers</span><span class="p">:</span>
        <span class="n">integers</span> <span class="o">=</span> <span class="n">integers</span><span class="p">[:</span><span class="n">integers</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">end_of_sentence</span><span class="p">)]</span> 

    <span class="k">return</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detokenize</span><span class="p">(</span><span class="n">integers</span><span class="p">,</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">vocab_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2f4c821">
<h3 id="org2f4c821">Data Generator</h3>
<div class="outline-text-3" id="text-org2f4c821">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">:</span>
    <span class="sd">"""Generates the streams of data</span>

<span class="sd">    Args:</span>
<span class="sd">     training: whether this generates training data or not</span>
<span class="sd">     path: path to the data set</span>
<span class="sd">     data_set: name of the data set (from tensorflow datasets)</span>
<span class="sd">     keys: the names of the data</span>
<span class="sd">     max_length: longest allowed set of tokens</span>
<span class="sd">     evaluation_fraction: how much of the data is saved for evaluation</span>
<span class="sd">     length_keys: keys (indexes) to use when setting length</span>
<span class="sd">     boundaries: upper limits for batch sizes</span>
<span class="sd">     batch_sizes: batch_size for each boundary</span>
<span class="sd">     padding_token: which token is used for padding</span>
<span class="sd">     vocabulary_file: name of the sub-words vocabulary file</span>
<span class="sd">     vocabulary_path: where to find the vocabulary file</span>
<span class="sd">     end_of_sentence: token to indicate the end of a sentence</span>
<span class="sd">    """</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Path</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">path</span>
    <span class="n">data_set</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">dataset</span>
    <span class="n">keys</span><span class="p">:</span> <span class="nb">tuple</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">keys</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="o">.</span><span class="n">train</span>
    <span class="n">length_keys</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">length_keys</span>
    <span class="n">boundaries</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">boundaries</span>
    <span class="n">batch_sizes</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">batch_sizes</span>
    <span class="n">evaluation_fraction</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">evaluation_size</span>
    <span class="n">vocabulary_file</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">vocabulary_file</span>
    <span class="n">vocabulary_path</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">vocabulary_path</span>
    <span class="n">padding_token</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">padding_token</span>
    <span class="n">end_of_sentence</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">DEFAULTS</span><span class="o">.</span><span class="n">end_of_sentence</span>
    <span class="n">_generator_function</span><span class="p">:</span> <span class="nb">type</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_batch_generator</span><span class="p">:</span> <span class="nb">type</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org4edeed6">
<h4 id="org4edeed6">Append End of Sentence</h4>
<div class="outline-text-4" id="text-org4edeed6">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">end_of_sentence_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">):</span>
    <span class="sd">"""Generator that adds end of sentence tokens</span>

<span class="sd">    Args:</span>
<span class="sd">     original: generator to add the end of sentence tokens to</span>

<span class="sd">    Yields:</span>
<span class="sd">     next tuple of arrays with EOS token added</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">original</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">]</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">end_of_sentence</span><span class="p">]</span>
        <span class="k">yield</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> 
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf640abd">
<h4 id="orgf640abd">Generator Function</h4>
<div class="outline-text-4" id="text-orgf640abd">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">generator_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Function to create the data generator"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generator_function</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFDS</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_set</span><span class="p">,</span>
                                                  <span class="n">data_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span>
                                                  <span class="n">keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span>
                                                  <span class="n">eval_holdout_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_fraction</span><span class="p">,</span>
                                                  <span class="n">train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generator_function</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga634fb3">
<h4 id="orga634fb3">Batch Stream</h4>
<div class="outline-text-4" id="text-orga634fb3">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">batch_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""batch data generator"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_generator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_function</span><span class="p">()</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Tokenize</span><span class="p">(</span>
            <span class="n">vocab_file</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_file</span><span class="p">,</span>
            <span class="n">vocab_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_path</span><span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_of_sentence_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FilterByLength</span><span class="p">(</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">length_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">length_keys</span><span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
        <span class="n">generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BucketByLength</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">boundaries</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_sizes</span><span class="p">,</span>
            <span class="n">length_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">length_keys</span>
        <span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_generator</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AddLossWeights</span><span class="p">(</span>
            <span class="n">id_to_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_token</span><span class="p">)(</span><span class="n">generator</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_generator</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7092d91">
<h3 id="org7092d91">Try It Out</h3>
<div class="outline-text-3" id="text-org7092d91">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.machine_translation</span> <span class="kn">import</span> <span class="n">DataGenerator</span><span class="p">,</span> <span class="n">detokenize</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">()</span><span class="o">.</span><span class="n">batch_generator</span>
<span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">mask_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>


<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: </span><span class="se">\n</span><span class="s1"> '</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">input_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">detokenize</span><span class="p">(</span><span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">vocab_file</span><span class="o">=</span><span class="n">VOCAB_FILE</span><span class="p">,</span> <span class="n">vocab_dir</span><span class="o">=</span><span class="n">VOCAB_DIR</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">colored</span><span class="p">(</span><span class="s1">'THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">),</span> <span class="n">target_batch</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgf57d507">
[31mTHIS IS THE ENGLISH SENTENCE: 
[0m Signs of hypersensitivity reactions include hives, generalised urticaria, tightness of the chest, wheezing, hypotension and anaphylaxis.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: 
 [0m [10495    14     7 10224 19366 10991  1020  3481  2486     2  9547  7417
   103  4572 11927  9371     2 13197  1496     7     4 24489    62     2
 16402 24010   211     2  4814 23010 12122    22     8  4867 19606  6457
  5175    14  3550 30650  4729   992     1     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0] 

[31mTHIS IS THE GERMAN TRANSLATION: 
[0m Überempfindlichkeitsreaktionen können sich durch Anzeichen wie Nesselausschlag, generalisierte Urtikaria, Engegefühl im Brustkorb, Pfeifatmung, Blutdruckabfall und Anaphylaxie äußern.
 

[31mTHIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: 
[0m [ 3916 29551 13504  5020  4094 13522   119    51   121  8602    93 31508
  6050 30327  6978     2  9547  7417  2446  5618  4581  5530  1384     2
 26006  7831 13651     5    47  8584  4076  5262   868     2 25389  8898
 28268     2  9208 29697 17944    83    12  9925 19606  6457 16384     5
 11790  3550 30650  4729   992     1     0     0     0     0     0     0
     0     0     0     0] 
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orga61fbcf">
<h2 id="orga61fbcf">End</h2>
<div class="outline-text-2" id="text-orga61fbcf">
<p>Now that we have our data prepared it's time to move on to <a href="posts/nlp/neural-machine-translation-the-attention-model/">defining the Attention Model</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/neural-machine-translation/">Neural Machine Translation</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/neural-machine-translation/" rel="bookmark"><time class="published dt-published" datetime="2021-02-11T19:56:46-08:00" itemprop="datePublished" title="2021-02-11 19:56">2021-02-11 19:56</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/neural-machine-translation/#orgb26d0a8">Neural Machine Translations</a></li>
<li><a href="posts/nlp/neural-machine-translation/#org36d2587">The Posts</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgb26d0a8">
<h2 id="orgb26d0a8">Neural Machine Translations</h2>
<div class="outline-text-2" id="text-orgb26d0a8">
<p>Here, we will build an English-to-German neural machine translation (NMT) model using Long Short-Term Memory (LSTM) networks with attention. Machine translation is an important task in natural language processing and could be useful not only for translating one language to another but also for word sense disambiguation (e.g. determining whether the word "bank" refers to the financial bank, or the land alongside a river). Implementing this using just a Recurrent Neural Network (RNN) with LSTMs can work for short to medium length sentences but can result in vanishing gradients for very long sequences. To solve this, we will be adding an attention mechanism to allow the decoder to access all relevant parts of the input sentence regardless of its length. By completing this assignment, we will:</p>
<ul class="org-ul">
<li>learn how to preprocess your training and evaluation data</li>
<li>implement an encoder-decoder system with attention</li>
<li>understand how attention works</li>
<li>build the NMT model from scratch using Trax</li>
<li>generate translations using greedy and Minimum Bayes Risk (MBR) decoding</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org36d2587">
<h2 id="org36d2587">The Posts</h2>
<div class="outline-text-2" id="text-org36d2587">
<p>This will be broken up into the following posts.</p>
<ul class="org-ul">
<li><a href="posts/nlp/neural-machine-translation-the-data/">The Data</a></li>
<li><a href="posts/nlp/neural-machine-translation-helper-functions/">Helper Functions</a></li>
<li><a href="posts/nlp/neural-machine-translation-the-attention-model/">The Attention Model</a></li>
<li><a href="posts/nlp/neural-machine-translation-training-the-model/">Training the Model</a></li>
<li><a href="posts/nlp/neural-machine-translation-testing-the-model/">Testing the Model</a></li>
</ul>
<p>First - a <a href="posts/nlp/neural-machine-translation-the-data/">look at the data</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/stack-semantics/">Stack Semantics</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/stack-semantics/" rel="bookmark"><time class="published dt-published" datetime="2021-02-11T19:53:36-08:00" itemprop="datePublished" title="2021-02-11 19:53">2021-02-11 19:53</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/stack-semantics/#org02a0ea4">Stack Semantics in Trax</a>
<ul>
<li><a href="posts/nlp/stack-semantics/#orgc69595a">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/stack-semantics/#orgd17a421">Middle</a>
<ul>
<li><a href="posts/nlp/stack-semantics/#org885d93a">The Serial Combinator is Stack Oriented.</a>
<ul>
<li><a href="posts/nlp/stack-semantics/#orga09181a">Defining addition</a></li>
<li><a href="posts/nlp/stack-semantics/#orge4b8c63">Defining multiplication</a></li>
<li><a href="posts/nlp/stack-semantics/#org84deea6">Implementing the computations using the Serial combinator</a></li>
</ul>
</li>
<li><a href="posts/nlp/stack-semantics/#orgccc4c51">The tl.Select combinator in the context of the Serial combinator</a>
<ul>
<li><a href="posts/nlp/stack-semantics/#org68a8471">First example of tl.Select</a></li>
<li><a href="posts/nlp/stack-semantics/#org7f94067">Select Makes It More Like a Collection</a></li>
</ul>
</li>
<li><a href="posts/nlp/stack-semantics/#org214ed63">Another example of tl.Select</a></li>
<li><a href="posts/nlp/stack-semantics/#orgc86fae9">The tl.Residual combinator in the context of the Serial combinator</a>
<ul>
<li><a href="posts/nlp/stack-semantics/#orge6f8a01">tl.Residual</a></li>
<li><a href="posts/nlp/stack-semantics/#org4bba641">Modifying the network</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org02a0ea4">
<h2 id="org02a0ea4">Stack Semantics in Trax</h2>
<div class="outline-text-2" id="text-org02a0ea4">
<p>This will help in understanding how to use layers like <code>Select</code> and <code>Residual</code> which operate on elements in the stack. If you've taken a computer science class before, you will recall that a stack is a data structure that follows the Last In, First Out (LIFO) principle. That is, whatever is the latest element that is pushed into the stack will also be the first one to be popped out. If you're not yet familiar with stacks, then you may find this <a href="https://www.tutorialspoint.com/python_data_structure/python_stack.htm">short tutorial</a> useful. In a nutshell, all you really need to remember is it puts elements one on top of the other. You should be aware of what is on top of the stack to know which element you will be popping.</p>
</div>
<div class="outline-3" id="outline-container-orgc69595a">
<h3 id="orgc69595a">Imports</h3>
<div class="outline-text-3" id="text-orgc69595a">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">fastmath</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">shapes</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd17a421">
<h2 id="orgd17a421">Middle</h2>
<div class="outline-text-2" id="text-orgd17a421"></div>
<div class="outline-3" id="outline-container-org885d93a">
<h3 id="org885d93a">The Serial Combinator is Stack Oriented.</h3>
<div class="outline-text-3" id="text-org885d93a">
<p>To understand how stack-orientation works in <a href="https://trax-ml.readthedocs.io/en/latest/">Trax</a>, most times one will be using the <code>Serial</code> layer. We will define two simple <a href="https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html?highlight=fn#With-the-Fn-layer-creating-function.">Function layers</a>:</p>
<ol class="org-ol">
<li>Addition</li>
<li>Multiplication</li>
</ol>
<p>Suppose we want to make the simple calculation \((3 + 4) \times 15 + 3\). We'll use <code>Serial</code> to perform the calculations in the following order <code>3</code> <code>4</code> <code>add</code> <code>15</code> <code>mul</code> <code>3</code> <code>add</code>. The steps of the calculation are shown in the table below.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Stack Operations</th>
<th class="org-right" scope="col">Stack</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Push(4)</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-right">4 3</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-right">7</td>
</tr>
<tr>
<td class="org-left">Push(15)</td>
<td class="org-right">7 15</td>
</tr>
<tr>
<td class="org-left">Push(Mul Pop() Pop())</td>
<td class="org-right">105</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-right">105 3</td>
</tr>
<tr>
<td class="org-left">Push(Add() Pop() Pop())</td>
<td class="org-right">108</td>
</tr>
</tbody>
</table>
<p>The first column shows the operations made on the stack and the second column is what's on the stack. Moreover, the rightmost element in the second column represents the top of the stack (e.g. in the second row, <code>Push(3)</code> pushes <code>3 = on top of the stack and =4</code> is now under it).</p>
<p>After finishing the steps the stack contains 108 which is the answer to our simple computation.</p>
<p>From this, the following can be concluded: a stack-based layer has only one way to handle data, by taking one piece of data from atop the stack, called <i>popping</i>, and putting data back atop the stack, called <i>pushing</i>. Any expression that can be written conventionally, can be written this way and thus will be amenable to being interpreted by a stack-oriented layer like <code>Serial</code>.</p>
</div>
<div class="outline-4" id="outline-container-orga09181a">
<h4 id="orga09181a">Defining addition</h4>
<div class="outline-text-4" id="text-orga09181a">
<p>We're going to define a trax <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=Fn#trax.layers.base.Fn">function (FN)</a> for addition.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Addition</span><span class="p">():</span>
    <span class="n">layer_name</span> <span class="o">=</span> <span class="s2">"Addition"</span> 

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
</pre></div>
<p>Test it out.</p>
<div class="highlight">
<pre><span></span><span class="n">add</span> <span class="o">=</span> <span class="n">Addition</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">add</span><span class="p">))</span>
</pre></div>
<pre class="example">
&lt;class 'trax.layers.base.PureLayer'&gt;
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">add</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">add</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">add</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example">
name : Addition
expected inputs : 2
promised outputs : 1
</pre>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">add</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[3] + [4] = [7]
</pre></div>
</div>
<div class="outline-4" id="outline-container-orge4b8c63">
<h4 id="orge4b8c63">Defining multiplication</h4>
<div class="outline-text-4" id="text-orge4b8c63">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Multiplication</span><span class="p">():</span>
    <span class="n">layer_name</span> <span class="o">=</span> <span class="s2">"Multiplication"</span>

    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>

    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
</pre></div>
<p>Test it out.</p>
<div class="highlight">
<pre><span></span><span class="n">mul</span> <span class="o">=</span> <span class="n">Multiplication</span><span class="p">()</span>
</pre></div>
<p>The properties.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">mul</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">mul</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">mul</span><span class="o">.</span><span class="n">n_out</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
name : Multiplication
expected inputs : 2
promised outputs : 1 

</pre>
<p>Some Inputs.</p>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">15</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"x :"</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"y :"</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
<pre class="example">
x : [7]
y : [15]
</pre>
<p>The Output</p>
<div class="highlight">
<pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">mul</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">mul</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[7] * [15] = [105]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org84deea6">
<h4 id="org84deea6">Implementing the computations using the Serial combinator</h4>
<div class="outline-text-4" id="text-org84deea6">
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">Addition</span><span class="p">(),</span> <span class="n">Multiplication</span><span class="p">(),</span> <span class="n">Addition</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">15</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sublayers :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org67036b8">
Serial_in4[
  Addition_in2
  Multiplication_in2
  Addition_in2
] 

name : Serial
sublayers : [Addition_in2, Multiplication_in2, Addition_in2]
expected inputs : 4
promised outputs : 1 
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">inputs</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4]), array([15]), array([3])) -&gt; [108]
</pre>
<p>The example with the two simple adition and multiplication functions that where coded together with the serial combinator show how stack semantics work in <code>Trax</code>.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgccc4c51">
<h3 id="orgccc4c51">The tl.Select combinator in the context of the Serial combinator</h3>
<div class="outline-text-3" id="text-orgccc4c51">
<p>Having understood how stack semantics work in <code>Trax</code>, we will demonstrate how the <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=select#trax.layers.combinators.Select">tl.Select</a> combinator works.</p>
</div>
<div class="outline-4" id="outline-container-org68a8471">
<h4 id="org68a8471">First example of tl.Select</h4>
<div class="outline-text-4" id="text-org68a8471">
<p>Suppose we want to make the simple calculation \((3 + 4) \times 3 + 4\). We can use <code>Select</code> to perform the calculations in the following manner:</p>
<ol class="org-ol">
<li>input <code>3</code> <code>4</code></li>
<li><code>tl.Select([0, 1, 0, 1])</code></li>
<li><code>add</code></li>
<li><code>mul</code></li>
<li><code>add</code>.</li>
</ol>
<p>The <code>tl.Select</code> requires a list or tuple of 0-based indices to select elements relative to the top of the stack. For our example, the top of the stack is <code>3</code> (which is at index 0) then <code>4</code> (index 1) and we us Select to copy the top two elements of the stack and then push all four elements back onto the stack which after the command executes will now contain <code>3</code> <code>4</code> <code>3</code> <code>4</code>. The steps of the calculation for our example are shown in the table below. As in the previous table each column shows the contents of the stack and the outputs after the operations are carried out.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Stack Operations</th>
<th class="org-left" scope="col">Stack</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Push(4)</td>
<td class="org-left">4</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-left">4 3</td>
</tr>
<tr>
<td class="org-left">Push(Select([0, 1, 0, 1]))</td>
<td class="org-left">4 3 4 3</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-left">4 3 7</td>
</tr>
<tr>
<td class="org-left">Push(Mul Pop() Pop())</td>
<td class="org-left">4 21</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-left">25</td>
</tr>
</tbody>
</table>
<p>After processing all the inputs the stack contains 25 which is the result of the calculations.</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">Addition</span><span class="p">(),</span>
    <span class="n">Multiplication</span><span class="p">(),</span>
    <span class="n">Addition</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
<p>Now we'll create the input.</p>
<div class="highlight">
<pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]))</span>
<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sublayers :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org39720ba">
Serial_in2[
  Select[0,1,0,1]_in2_out4
  Addition_in2
  Multiplication_in2
  Addition_in2
] 

name : Serial
sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Multiplication_in2, Addition_in2]
expected inputs : 2
promised outputs : 1 
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4])) -&gt; [25]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org7f94067">
<h4 id="org7f94067">Select Makes It More Like a Collection</h4>
<div class="outline-text-4" id="text-org7f94067">
<p>Note that since you are passing in indices to Select, you aren't really using it like a stack, even if behind the scenes it's using push and pop.</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
    <span class="n">Addition</span><span class="p">(),</span>
    <span class="n">Multiplication</span><span class="p">(),</span>
    <span class="n">Addition</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">]))</span>
<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4]), array([5])) -&gt; [41]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">((</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
<pre class="example">
41
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org214ed63">
<h3 id="org214ed63">Another example of tl.Select</h3>
<div class="outline-text-3" id="text-org214ed63">
<p>Suppose we want to make the simple calculation \((3 + 4) \times 4\). We can use <code>Select</code> to perform the calculations in the following manner:</p>
<ol class="org-ol">
<li><code>4</code></li>
<li><code>3</code></li>
<li><code>tl.Select([0,1,0,1])</code></li>
<li><code>add</code></li>
<li><code>tl.Select([0], n_in=2)</code></li>
<li><code>mul</code></li>
</ol>
<p>The example is a bit contrived but it demonstrates the flexibility of the command. The second <code>tl.Select</code> pops two elements (specified in n_in) from the stack starting from index 0 (i.e. top of the stack). This means that <code>7</code> and <code>3 = will be popped out because ~n_in = 2~) but only =7</code> is placed back on top because it only selects <code>[0]</code>. As in the previous table each column shows the contents of the stack and the outputs after the operations are carried out.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Stack Operations</th>
<th class="org-left" scope="col">Outputs</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Push(4)</td>
<td class="org-left">4</td>
</tr>
<tr>
<td class="org-left">Push(3)</td>
<td class="org-left">4 3</td>
</tr>
<tr>
<td class="org-left">Push(select([0, 1, 0, 1]))</td>
<td class="org-left">4 3 4 3</td>
</tr>
<tr>
<td class="org-left">Push(Add Pop() Pop())</td>
<td class="org-left">4 3 7</td>
</tr>
<tr>
<td class="org-left">Push(select([0], n_in=2))</td>
<td class="org-left">7</td>
</tr>
<tr>
<td class="org-left">Push(Mul Pop() Pop())</td>
<td class="org-left">28</td>
</tr>
</tbody>
</table>
<p>After processing all the inputs the stack contains 28 which is the answer we get above.</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">Addition</span><span class="p">(),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_in</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">Multiplication</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">]))</span>
<span class="n">serial</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">shapes</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"sublayers :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">sublayers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org89e6e27">
Serial_in2[
  Select[0,1,0,1]_in2_out4
  Addition_in2
  Select[0]_in2
  Multiplication_in2
] 

name : Serial
sublayers : [Select[0,1,0,1]_in2_out4, Addition_in2, Select[0]_in2, Multiplication_in2]
expected inputs : 2
promised outputs : 1
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">inputs</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
(array([3]), array([4])) -&gt; [28]
</pre>
<p>In summary, what Select does in this example is make a copy of the inputs in order to be used further along in the stack of operations.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgc86fae9">
<h3 id="orgc86fae9">The tl.Residual combinator in the context of the Serial combinator</h3>
<div class="outline-text-3" id="text-orgc86fae9"></div>
<div class="outline-4" id="outline-container-orge6f8a01">
<h4 id="orge6f8a01">tl.Residual</h4>
<div class="outline-text-4" id="text-orge6f8a01">
<p><a href="https://arxiv.org/pdf/1512.03385.pdf">Residual networks</a> (that link is to a research paper, this is <a href="https://en.wikipedia.org/wiki/Residual_neural_network">wikipedia</a>)are frequently used to make deep models easier to train. Trax already has a built in layer for this. The <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html?highlight=residual#trax.layers.combinators.Residual">Residual layer</a> computes the element-wise <b>sum</b> of the <b>stack-top</b> input with the output of the layer series. Let's first see how it is used in the code below:</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Residual</span><span class="p">(</span><span class="n">Addition</span><span class="p">())</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org10fb53d">
Serial_in2_out3[
  Select[0,1,0,1]_in2_out4
  Serial_in2[
    Branch_in2_out2[
      None
      Addition_in2
    ]
    Add_in2
  ]
] 

name : Serial
expected inputs : 2
promised outputs : 3
</pre>
<p>Here, we use the Serial combinator to define our model. The inputs first goes through a <code>Select</code> layer, followed by a <code>Residual</code> layer which passes the <code>Fn: Addition()</code> layer as an argument. What this means is the <code>Residual</code> layer will take the stack top input at that point and add it to the output of the <code>Fn: Addition()</code> layer. You can picture it like the diagram the below, where <code>x1</code> and <code>x2</code> are the inputs to the model:</p>
<p>Now, let's try running our model with some sample inputs and see the result:</p>
<div class="highlight">
<pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x1</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">x2</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[3] + [4] -&gt; (array([10]), array([3]), array([4]))
</pre>
<p>As you can see, the <code>Residual</code> layer remembers the stack top input (i.e. <code>3</code>) and adds it to the result of the <code>Fn: Addition()</code> layer (i.e. <code>3 + 4 = 7</code>). The output of <code>Residual(Addition()</code> is then <code>3 + 7 = 10</code> and is pushed onto the stack.</p>
<p>On a different note, you'll notice that the <code>Select</code> layer has 4 outputs but the <code>Fn: Addition()</code> layer only pops 2 inputs from the stack. This means the duplicate inputs (i.e. the 2 rightmost arrows of the <code>Select</code> outputs in the figure above) remain in the stack. This is why you still see it in the output of our simple serial network (i.e. <code>array([3]), array([4])</code>). This is useful if you want to use these duplicate inputs in another layer further down the network.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org4bba641">
<h4 id="org4bba641">Modifying the network</h4>
<div class="outline-text-4" id="text-org4bba641">
<p>To strengthen your understanding, you can modify the network above and examine the outputs you get. For example, you can pass the <code>Fn: Multiplication()</code> layer instead in the <code>Residual</code> block:</p>
<div class="highlight">
<pre><span></span><span class="n">serial</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Select</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> 
    <span class="n">layers</span><span class="o">.</span><span class="n">Residual</span><span class="p">(</span><span class="n">Multiplication</span><span class="p">())</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">serial</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"name :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"expected inputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_in</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"promised outputs :"</span><span class="p">,</span> <span class="n">serial</span><span class="o">.</span><span class="n">n_out</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orge993ccd">
Serial_in2_out3[
  Select[0,1,0,1]_in2_out4
  Serial_in2[
    Branch_in2_out2[
      None
      Multiplication_in2
    ]
    Add_in2
  ]
] 

name : Serial
expected inputs : 2
promised outputs : 3
</pre>
<p>This means you'll have a different output that will be added to the stack top input saved by the Residual block. The diagram becomes like this:</p>
<p>And you'll get <code>3 + (3 * 4) = 15</code> as output of the <code>Residual</code> block:</p>
<div class="highlight">
<pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">serial</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">x1</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="n">x2</span><span class="si">}</span><span class="s2"> -&gt; </span><span class="si">{</span><span class="n">serial</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[3] * [4] -&gt; (array([15]), array([3]), array([4]))
</pre></div>
</div>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="next"><a href="index-20.html" rel="next">Older posts</a></li>
</ul>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script><!--End of body content-->
<footer id="footer"><a href="https://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://licensebuttons.net/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
