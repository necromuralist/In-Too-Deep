<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/" rel="canonical">
<link href="index-19.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
<link href="posts/nlp/siamese-networks-new-questions/" rel="prefetch" type="text/html">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="."><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item active"><a class="nav-link" href=".">Cloistered Monkey <span class="sr-only">(active)</span></a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-new-questions/">Siamese Networks: New Questions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-new-questions/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:40:55-08:00" itemprop="datePublished" title="2021-01-25 19:40">2021-01-25 19:40</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/#org0f80269">Trying New Questions</a>
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/#org63448e4">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-new-questions/#org43fca6b">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/#orge57e0a6">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-new-questions/#org8440e56">The Model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-new-questions/#org18ad63b">Implementing It</a>
<ul>
<li><a href="posts/nlp/siamese-networks-new-questions/#orgccbdeec">Some Trials</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org0f80269">
<h2 id="org0f80269">Trying New Questions</h2>
<div class="outline-text-2" id="text-org0f80269"></div>
<div class="outline-3" id="outline-container-org63448e4">
<h3 id="org63448e4">Imports</h3>
<div class="outline-text-3" id="text-org63448e4">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DataGenerator</span><span class="p">,</span>
    <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">SiameseModel</span><span class="p">,</span>
    <span class="n">TOKENS</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org43fca6b">
<h3 id="org43fca6b">Set Up</h3>
<div class="outline-text-3" id="text-org43fca6b"></div>
<div class="outline-4" id="outline-container-orge57e0a6">
<h4 id="orge57e0a6">The Data</h4>
<div class="outline-text-4" id="text-orge57e0a6">
<div class="highlight">
<pre><span></span><span class="n">data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8440e56">
<h4 id="org8440e56">The Model</h4>
<div class="outline-text-4" id="text-org8440e56">
<div class="highlight">
<pre><span></span><span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/siamese_networks/model.pkl.gz"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">siamese</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org18ad63b">
<h2 id="org18ad63b">Implementing It</h2>
<div class="outline-text-2" id="text-org18ad63b">
<p>Write a function =predict=that takes in two questions, the model, and the vocabulary and returns whether the questions are duplicates (<i>1</i>) or not duplicates (<i>0</i>) given a similarity threshold.</p>
<p><b>Instructions:</b></p>
<ul class="org-ul">
<li>Tokenize your question using `nltk.word_tokenize`</li>
<li>Create Q1,Q2 by encoding your questions as a list of numbers using vocab</li>
<li>pad Q1,Q2 with next(data_generator([Q1], [Q2],1,vocab['&lt;PAD&gt;']))</li>
<li>use model() to create v1, v2</li>
<li>compute the cosine similarity (dot product) of v1, v2</li>
<li>compute res by comparing d to the threshold</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">question1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">question2</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">vocab</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="n">vocabulary</span><span class="p">,</span> <span class="n">data_generator</span><span class="p">:</span> <span class="nb">type</span><span class="o">=</span><span class="n">data_generator</span><span class="p">,</span>
            <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="sd">"""Function for predicting if two questions are duplicates.</span>

<span class="sd">    Args:</span>
<span class="sd">       question1 (str): First question.</span>
<span class="sd">       question2 (str): Second question.</span>
<span class="sd">       threshold (float): Desired threshold.</span>
<span class="sd">       model (trax.layers.combinators.Parallel): The Siamese model.</span>
<span class="sd">       vocab (collections.defaultdict): The vocabulary used.</span>
<span class="sd">       data_generator (function): Data generator function. Defaults to data_generator.</span>
<span class="sd">       verbose (bool, optional): If the results should be printed out. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">       bool: True if the questions are duplicates, False otherwise.</span>
<span class="sd">    """</span>
    <span class="n">question_one</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">question1</span><span class="p">)]]</span>
    <span class="n">question_two</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">question2</span><span class="p">)]]</span>

    <span class="n">questions</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_generator</span><span class="p">(</span><span class="n">question_one</span><span class="p">,</span>
                                    <span class="n">question_two</span><span class="p">,</span>
                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">vector_1</span><span class="p">,</span> <span class="n">vector_2</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vector_1</span><span class="p">,</span> <span class="n">vector_2</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">same_question</span> <span class="o">=</span> <span class="n">similarity</span> <span class="o">&gt;</span> <span class="n">threshold</span>

    <span class="k">if</span><span class="p">(</span><span class="n">verbose</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q1  = </span><span class="si">{</span><span class="n">questions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Q2 = </span><span class="si">{</span><span class="n">questions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Similarity : </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">similarity</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"They are the same question: </span><span class="si">{</span><span class="n">same_question</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">same_question</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgccbdeec">
<h3 id="orgccbdeec">Some Trials</h3>
<div class="outline-text-3" id="text-orgccbdeec">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">TOKENS</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tokens(unknown=0, padding=1, padding_token='&lt;PAD&gt;')
</pre>
<p>So if we see a 0 in the tokens then we know the word wasn't in the vocabulary.</p>
<div class="highlight">
<pre><span></span><span class="n">question1</span> <span class="o">=</span> <span class="s2">"When will I see you?"</span>
<span class="n">question2</span> <span class="o">=</span> <span class="s2">"When can I see you again?"</span>
<span class="c1"># 1 means it is duplicated, 0 otherwise</span>
<span class="n">predict</span><span class="p">(</span><span class="n">question1</span> <span class="p">,</span> <span class="n">question2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[581  64  20  44  49  16   1   1]]
Q2 = [[ 581   39   20   44   49 7280   16    1]]
Similarity : 0.95
They are the same question: True
</pre>
<div class="highlight">
<pre><span></span><span class="n">question1</span> <span class="o">=</span> <span class="s2">"Do they enjoy eating the dessert?"</span>
<span class="n">question2</span> <span class="o">=</span> <span class="s2">"Do they like hiking in the desert?"</span>

<span class="n">predict</span><span class="p">(</span><span class="n">question1</span> <span class="p">,</span> <span class="n">question2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  446  1138  3159  1169    70 29016    16     1]]
Q2 = [[  446  1138    57 15302    24    70  7430    16]]
Similarity : 0.60
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Do cows have butts?"</span><span class="p">,</span> <span class="s2">"Do dogs have bones?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  446  5757   216 25442    16     1     1     1]]
Q2 = [[  446   788   216 11192    16     1     1     1]]
Similarity : 0.25
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Do cows from Lancashire have butts?"</span><span class="p">,</span> <span class="s2">"Do dogs have bones as big as whales?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  446  5757   125     0   216 25442    16     1     1     1     1     1
      1     1     1     1]]
Q2 = [[  446   788   216 11192   249  1124   249 30836    16     1     1     1
      1     1     1     1]]
Similarity : 0.13
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Can pigs fly?"</span><span class="p">,</span> <span class="s2">"Are you my mother?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  221 14137  5750    16     1     1     1     1]]
Q2 = [[ 517   49   41 1585   16    1    1    1]]
Similarity : 0.01
They are the same question: False
</pre>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Shall we dance?"</span><span class="p">,</span> <span class="s2">"Shall I fart?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[19382   138  4201    16]]
Q2 = [[19382    20 18288    16]]
Similarity : 0.71
They are the same question: True
</pre>
<p>Hm… surprising that "fart" was in the data set, and it's the same as dancing.</p>
<div class="highlight">
<pre><span></span><span class="n">farts</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="n">loader</span><span class="o">.</span><span class="n">training_data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">"fart[^a-z]"</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">farts</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">farts</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
<pre class="example">
16
19820                                    Can penguins fart?
60745       How do I control a fart when I'm about to fart?
83124           What word square starts with the word fart?
96707         Which part of human body is called fart pump?
120727    Why do people fart more when they wake up in t...
Name: question2, dtype: object
</pre>
<p>Maybe I shouldn't have been surprised.</p>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Am I man or gorilla?"</span><span class="p">,</span> <span class="s2">"Am I able to eat the pasta?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[4311   20 1215   75 7438   16    1    1]]
Q2 = [[ 4311    20   461    37   922    70 14552    16]]
Similarity : 0.20
They are the same question: False
</pre>
<p>It looks like the model only looks at the first words… at least when the sentences are short.</p>
<div class="highlight">
<pre><span></span><span class="n">predict</span><span class="p">(</span><span class="s2">"Will we return to Mars or go instead to Venus?"</span><span class="p">,</span> <span class="s2">"Will we eat rice with plums and cherry topping?"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Q1  = [[  168   141  8303    34  6861    72  1315  4536    34 15555    16     1
      1     1     1     1]]
Q2 = [[  168   141   927  7612   121     0     9 19275     0    16     1     1
      1     1     1     1]]
Similarity : 0.67
They are the same question: False
</pre>
<p>Siamese networks are important and useful. Many times there are several questions that are already asked in quora, or other platforms and you can use Siamese networks to avoid question duplicates.</p>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-evaluating-the-model/">Siamese Networks: Evaluating the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-evaluating-the-model/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:39:59-08:00" itemprop="datePublished" title="2021-01-25 19:39">2021-01-25 19:39</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#org593171c">Evaluating the Siamese Network</a>
<ul>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#org92dd2c8">Force CPU Use</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#org79ef208">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#org17b6116">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#orge69d78d">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#orgf014e34">The Timer</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#orgc361ae5">The Model</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/#orga28ab98">Classify</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org593171c">
<h2 id="org593171c">Evaluating the Siamese Network</h2>
<div class="outline-text-2" id="text-org593171c"></div>
<div class="outline-3" id="outline-container-org92dd2c8">
<h3 id="org92dd2c8">Force CPU Use</h3>
<div class="outline-text-3" id="text-org92dd2c8">
<p>For some reason the model eats up more and more memory on the GPU until it runs out. Seems like a memory leak. Anyway, for reasons that I don't know, the way that tensorflow tells you to disable using the GPU doesn't work (it's in the second code block) so to get this to work I have to essentially break the CUDA settings.</p>
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">""</span>
</pre></div>
<p>This is the way they tell you to do it.</p>
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="n">tensorflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">([],</span> <span class="s2">"GPU"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org79ef208">
<h3 id="org79ef208">Imports</h3>
<div class="outline-text-3" id="text-org79ef208">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DataGenerator</span><span class="p">,</span>
    <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">SiameseModel</span><span class="p">,</span>
 <span class="p">)</span>

<span class="c1"># other</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org17b6116">
<h3 id="org17b6116">Set Up</h3>
<div class="outline-text-3" id="text-org17b6116"></div>
<div class="outline-4" id="outline-container-orge69d78d">
<h4 id="orge69d78d">The Data</h4>
<div class="outline-text-4" id="text-orge69d78d">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>

<span class="n">vocabulary_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span>
<span class="n">testing</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test</span>

<span class="k">del</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
<span class="k">del</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf014e34">
<h4 id="orgf014e34">The Timer</h4>
<div class="outline-text-4" id="text-orgf014e34">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc361ae5">
<h4 id="orgc361ae5">The Model</h4>
<div class="outline-text-4" id="text-orgc361ae5">
<div class="highlight">
<pre><span></span><span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="n">vocabulary_length</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/siamese_networks/model.pkl.gz"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orga28ab98">
<h2 id="orga28ab98">Classify</h2>
<div class="outline-text-2" id="text-orga28ab98">
<p>To determine the accuracy of the model, we will utilize the test set that was configured earlier. While in training we used only positive examples, the test data, Q1_test, Q2_test and y_test, is setup as pairs of questions, some of which are duplicates some are not.</p>
<p>This routine will run all the test question pairs through the model, compute the cosine simlarity of each pair, threshold it and compare the result to y_test - the correct response from the data set. The results are accumulated to produce an accuracy.</p>
<p><b>Instructions</b></p>
<ul class="org-ul">
<li>Loop through the incoming data in batch_size chunks</li>
<li>Use the data generator to load q1, q2 a batch at a time. <b>Don't forget to set shuffle=False!</b></li>
<li>copy a batch_size chunk of y into y_test</li>
<li>compute v1, v2 using the model</li>
<li>for each element of the batch
<ul class="org-ul">
<li>compute the cos similarity of each pair of entries, v1[j],v2[j]</li>
<li>determine if d &gt; threshold</li>
<li>increment accuracy if that result matches the expected results (y_test[j])</li>
</ul>
</li>
<li>compute the final accuracy and return</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">Outcome</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Outcome"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"true_positive"</span><span class="p">,</span>
                                 <span class="s2">"true_negative"</span><span class="p">,</span> <span class="s2">"false_positive"</span><span class="p">,</span>
                                 <span class="s2">"false_negative"</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">data_generator</span><span class="p">:</span> <span class="nb">iter</span><span class="p">,</span>
             <span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
             <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
             <span class="n">model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">):</span>
    <span class="sd">"""Function to test the accuracy of the model.</span>

<span class="sd">    Args:</span>
<span class="sd">      data_generator: batch generator,</span>
<span class="sd">      y: Array of actual target.</span>
<span class="sd">      threshold: minimum distance to be considered the same</span>
<span class="sd">      model: The Siamese model.</span>
<span class="sd">    Returns:</span>
<span class="sd">       float: Accuracy of the model.</span>
<span class="sd">    """</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">true_positive</span> <span class="o">=</span> <span class="n">false_positive</span> <span class="o">=</span> <span class="n">true_negative</span> <span class="o">=</span> <span class="n">false_negative</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">batch_start</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch_one</span><span class="p">,</span> <span class="n">batch_two</span> <span class="ow">in</span> <span class="n">data_generator</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_one</span><span class="p">)</span>
        <span class="n">batch_stop</span> <span class="o">=</span> <span class="n">batch_start</span> <span class="o">+</span> <span class="n">batch_size</span>

        <span class="k">if</span> <span class="n">batch_stop</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="k">break</span>
        <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">batch_start</span><span class="p">:</span> <span class="n">batch_stop</span><span class="p">]</span>
        <span class="n">vector_one</span><span class="p">,</span> <span class="n">vector_two</span> <span class="o">=</span> <span class="n">model</span><span class="p">((</span><span class="n">batch_one</span><span class="p">,</span> <span class="n">batch_two</span><span class="p">))</span>
        <span class="n">batch_start</span> <span class="o">=</span> <span class="n">batch_stop</span>

        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vector_one</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">vector_two</span><span class="p">[</span><span class="n">row</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">same_question</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">similarity</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">=</span> <span class="n">same_question</span> <span class="o">==</span> <span class="n">batch_labels</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">same_question</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">correct</span><span class="p">:</span>
                    <span class="n">true_positive</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">false_positive</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">correct</span><span class="p">:</span>
                    <span class="n">true_negative</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">false_negative</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">accuracy</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Outcome</span><span class="p">(</span><span class="n">accuracy</span><span class="o">=</span><span class="n">accuracy</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span>
                   <span class="n">true_positive</span> <span class="o">=</span> <span class="n">true_positive</span><span class="p">,</span>
                   <span class="n">true_negative</span> <span class="o">=</span> <span class="n">true_negative</span><span class="p">,</span>
                   <span class="n">false_positive</span> <span class="o">=</span> <span class="n">false_positive</span><span class="p">,</span>
                   <span class="n">false_negative</span> <span class="o">=</span> <span class="n">false_negative</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">testing</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">testing</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span>
                               <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">outcome</span> <span class="o">=</span> <span class="n">classify</span><span class="p">(</span>
        <span class="n">data_generator</span><span class="o">=</span><span class="n">data_generator</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">siamese</span><span class="o">.</span><span class="n">model</span>
    <span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Outcome: </span><span class="si">{</span><span class="n">outcome</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2021-02-10 21:42:27.320674
Ended: 2021-02-10 21:47:57.411380
Elapsed: 0:05:30.090706
Outcome: Outcome(accuracy=0.6546453536874203, true_positive=16439, true_negative=51832, false_positive=14425, false_negative=21240)
</pre>
<p>So, is that good or not? It might be more useful to look at the rates.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">outcome</span><span class="o">.</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">true_positive</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">true_positive</span>
<span class="n">false_negative</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">false_negative</span>
<span class="n">true_negative</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">true_negative</span>
<span class="n">false_positive</span> <span class="o">=</span> <span class="n">outcome</span><span class="o">.</span><span class="n">false_positive</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"True Positive Rate: </span><span class="si">{</span><span class="n">true_positive</span><span class="o">/</span><span class="p">(</span><span class="n">true_positive</span> <span class="o">+</span> <span class="n">false_negative</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"True Negative Rate: </span><span class="si">{</span><span class="n">true_negative</span><span class="o">/</span><span class="p">(</span><span class="n">true_negative</span> <span class="o">+</span> <span class="n">false_positive</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Precision: </span><span class="si">{</span><span class="n">outcome</span><span class="o">.</span><span class="n">true_positive</span><span class="o">/</span><span class="p">(</span><span class="n">true_positive</span> <span class="o">+</span> <span class="n">false_positive</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"False Negative Rate: </span><span class="si">{</span><span class="n">false_negative</span><span class="o">/</span><span class="p">(</span><span class="n">false_negative</span> <span class="o">+</span> <span class="n">true_positive</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"False Positive Rate: </span><span class="si">{</span><span class="n">false_positive</span><span class="o">/</span><span class="p">(</span><span class="n">false_positive</span> <span class="o">+</span> <span class="n">true_negative</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.65
True Positive Rate:  0.44
True Negative Rate: 0.78
Precision: 0.53
False Negative Rate: 0.56
False Positive Rate:  0.22
</pre>
<p>So, it was better at recognizing questions that were different. We could probably fiddle with the threshold to make it more one way or the other, if we needed to.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-training-the-model/">Siamese Networks: Training the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-training-the-model/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:38:08-08:00" itemprop="datePublished" title="2021-01-25 19:38">2021-01-25 19:38</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/#orgfd3d0f0">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org7cfc451">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org75acea2">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org79ee92c">The Timer And Plotting</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org27ebb9e">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org28666b6">The Data generator</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-training-the-model/#orgf413e15">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/#orgf6ab226">Training the Model</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org6168172">Training</a>
<ul>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org2a3b42b">Trial Two</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/#org3752b0a">Trial Three</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgfd3d0f0">
<h2 id="orgfd3d0f0">Beginning</h2>
<div class="outline-text-2" id="text-orgfd3d0f0">
<p>Now we are going to train the Siamese Network Model model. As usual, we have to define the cost function and the optimizer. We also have to feed in the built model. Before, going into the training, we will use a special data set up. We will define the inputs using the data generator we built above. The lambda function acts as a seed to remember the last batch that was given. Run the cell below to get the question pairs inputs.</p>
</div>
<div class="outline-3" id="outline-container-org7cfc451">
<h3 id="org7cfc451">Imports</h3>
<div class="outline-text-3" id="text-org7cfc451">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryFile</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">holoviews</span> <span class="kn">import</span> <span class="n">opts</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">trax</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DataGenerator</span><span class="p">,</span>
    <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">SiameseModel</span><span class="p">,</span>
    <span class="n">TOKENS</span><span class="p">,</span>
    <span class="n">triplet_loss_layer</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span><span class="p">,</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org75acea2">
<h3 id="org75acea2">Set Up</h3>
<div class="outline-text-3" id="text-org75acea2"></div>
<div class="outline-4" id="outline-container-org79ee92c">
<h4 id="org79ee92c">The Timer And Plotting</h4>
<div class="outline-text-4" id="text-org79ee92c">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">slug</span> <span class="o">=</span> <span class="s2">"siamese-networks-training-the-model"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">slug</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Plot"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"width"</span><span class="p">,</span> <span class="s2">"height"</span><span class="p">,</span> <span class="s2">"fontscale"</span><span class="p">,</span> <span class="s2">"tan"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"red"</span><span class="p">])</span>
<span class="n">PLOT</span> <span class="o">=</span> <span class="n">Plot</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org27ebb9e">
<h4 id="org27ebb9e">The Data</h4>
<div class="outline-text-4" id="text-org27ebb9e">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org28666b6">
<h4 id="org28666b6">The Data generator</h4>
<div class="outline-text-4" id="text-org28666b6">
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">train_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span>
                                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">validation_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span>
                                     <span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"training question 1 rows: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"validation question 1 rows: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
training question 1 rows: 89,179
validation question 1 rows: 22,295
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf413e15">
<h2 id="orgf413e15">Middle</h2>
<div class="outline-text-2" id="text-orgf413e15"></div>
<div class="outline-3" id="outline-container-orgf6ab226">
<h3 id="orgf6ab226">Training the Model</h3>
<div class="outline-text-3" id="text-orgf6ab226">
<p>We will now write a function that takes in the model and trains it. To train the model we have to decide how many times to iterate over the entire data set; each iteration is defined as an <code>epoch</code>. For each epoch, you have to go over all the data, using the training iterator.</p>
<ul class="org-ul">
<li>Create <code>TrainTask</code> and <code>EvalTask</code></li>
<li>Create the training loop <code>trax.supervised.training.Loop</code></li>
<li>Pass in the following depending on the context (train_task or eval_task):
<ul class="org-ul">
<li><code>labeled_data=generator</code></li>
<li><code>metrics</code>[TripletLoss()]=,</li>
<li><code>loss_layer=TripletLoss()</code></li>
<li><code>optimizer=trax.optimizers.Adam</code> with learning rate of 0.01</li>
<li><code>lr_schedule=lr_schedule</code>,</li>
<li><code>output_dir=output_dir</code></li>
</ul>
</li>
</ul>
<p>We will be using the triplet loss function with Adam optimizer. Please read the <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html?highlight=adam#trax.optimizers.adam.Adam">trax Adam</a> documentation to get a full understanding.</p>
<p>This function should return a <code>training.Loop</code> object. To read more about this check the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html?highlight=loop#trax.supervised.training.Loop">training.Loop</a> documentation.</p>
<div class="highlight">
<pre><span></span><span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">warmup_and_rsqrt_decay</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">Siamese</span><span class="p">,</span> <span class="n">TripletLoss</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">train_generator</span><span class="o">=</span><span class="n">train_generator</span><span class="p">,</span> <span class="n">val_generator</span><span class="o">=</span><span class="n">validation_generator</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">"~/models/siamese_networks/"</span><span class="p">,</span>
                <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="sd">"""Training the Siamese Model</span>

<span class="sd">    Args:</span>
<span class="sd">       Siamese (function): Function that returns the Siamese model.</span>
<span class="sd">       TripletLoss (function): Function that defines the TripletLoss loss function.</span>
<span class="sd">       lr_schedule (function): Trax multifactor schedule function.</span>
<span class="sd">       train_generator (generator, optional): Training generator. Defaults to train_generator.</span>
<span class="sd">       val_generator (generator, optional): Validation generator. Defaults to val_generator.</span>
<span class="sd">       output_dir (str, optional): Path to save model to. Defaults to 'model/'.</span>

<span class="sd">    Returns:</span>
<span class="sd">       trax.supervised.training.Loop: Training loop for the model.</span>
<span class="sd">    """</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>

    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

    <span class="n">train_task</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">TrainTask</span><span class="p">(</span>
        <span class="n">labeled_data</span><span class="o">=</span><span class="n">train_generator</span><span class="p">,</span>       <span class="c1"># Use generator (train)</span>
        <span class="n">loss_layer</span><span class="o">=</span><span class="n">TripletLoss</span><span class="p">(),</span>         <span class="c1"># Use triplet loss. Don't forget to instantiate this object</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">trax</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>          <span class="c1"># Don't forget to add the learning rate parameter</span>
        <span class="n">lr_schedule</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">,</span> <span class="c1"># Use Trax multifactor schedule function</span>
        <span class="n">n_steps_per_checkpoint</span><span class="o">=</span><span class="n">steps_per_checkpoint</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">eval_task</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">EvalTask</span><span class="p">(</span>
        <span class="n">labeled_data</span><span class="o">=</span><span class="n">val_generator</span><span class="p">,</span>       <span class="c1"># Use generator (val)</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">TripletLoss</span><span class="p">()],</span>          <span class="c1"># Use triplet loss. Don't forget to instantiate this object</span>
    <span class="p">)</span>

    <span class="c1">### END CODE HERE ###</span>

    <span class="n">training_loop</span> <span class="o">=</span> <span class="n">trax</span><span class="o">.</span><span class="n">supervised</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Loop</span><span class="p">(</span><span class="n">Siamese</span><span class="p">,</span>
                                                  <span class="p">[</span><span class="n">train_task</span><span class="p">],</span>
                                                  <span class="n">eval_tasks</span><span class="o">=</span><span class="p">[</span><span class="n">eval_task</span><span class="p">],</span>
                                                  <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">training_loop</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6168172">
<h3 id="org6168172">Training</h3>
<div class="outline-text-3" id="text-org6168172"></div>
<div class="outline-4" id="outline-container-org2a3b42b">
<h4 id="org2a3b42b">Trial Two</h4>
<div class="outline-text-4" id="text-org2a3b42b">
<p><b>Note:</b> I re-ran this next code block so it's actually the second run.</p>
<div class="highlight">
<pre><span></span><span class="n">train_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="n">training_loop</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">triplet_loss_layer</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">real_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

<span class="n">TIMER</span><span class="o">.</span><span class="n">emit</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TemporaryFile</span><span class="p">(</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">temp_file</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_steps</span><span class="p">)</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">real_stdout</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">TIMER</span><span class="o">.</span><span class="n">ended</span> <span class="o">-</span> <span class="n">TIMER</span><span class="o">.</span><span class="n">started</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0:19:46.056057
</pre>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">modes</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">metrics_for_mode</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span>
</pre></div>
<pre class="example">
eval
['metrics/TripletLoss']
train
['metrics/TripletLoss', 'training/gradients_l2', 'training/learning_rate', 'training/loss', 'training/steps per second', 'training/weights_l2']
</pre></div>
<ul class="org-ul">
<li><a id="org6ff1b0e"></a>Plotting the Metrics<br>
<div class="outline-text-5" id="text-org6ff1b0e">
<p><b>Note:</b> As of February 2021, the version of trax on pypi doesn't have a <i>history</i> attribute - to get it you have to install the code from the github repository.</p>
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/TripletLoss"</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch TripletLoss"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">TripletLoss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">TripletLoss</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"TripletLoss"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Triplet Loss"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_triplet_loss"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/siamese-networks-training-the-model/evaluation_triplet_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It looks the loss is stabilizing. If it doesn't perform well I'll re-train it.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org3752b0a">
<h4 id="org3752b0a">Trial Three</h4>
<div class="outline-text-4" id="text-org3752b0a">
<p>Let's see if the continues going down.</p>
<div class="highlight">
<pre><span></span><span class="n">train_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">siamese</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="n">training_loop</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">siamese</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">triplet_loss_layer</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">steps_per_checkpoint</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">real_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>

<span class="n">TIMER</span><span class="o">.</span><span class="n">emit</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TemporaryFile</span><span class="p">(</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">temp_file</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">temp_file</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_steps</span><span class="p">)</span>
<span class="n">TIMER</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">real_stdout</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">TIMER</span><span class="o">.</span><span class="n">ended</span> <span class="o">-</span> <span class="n">TIMER</span><span class="o">.</span><span class="n">started</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0:17:41.167719
</pre></div>
<ul class="org-ul">
<li><a id="org50f03f2"></a>Plotting the Metrics<br>
<div class="outline-text-5" id="text-org50f03f2">
<div class="highlight">
<pre><span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">training_loop</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eval"</span><span class="p">,</span> <span class="s2">"metrics/TripletLoss"</span><span class="p">),</span>
    <span class="n">columns</span><span class="o">=</span><span class="s2">"Batch TripletLoss"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">minimum</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">frame</span><span class="o">.</span><span class="n">TripletLoss</span><span class="o">.</span><span class="n">idxmin</span><span class="p">()]</span>
<span class="n">vline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">Batch</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">VLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">hline</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">minimum</span><span class="o">.</span><span class="n">TripletLoss</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">HLine</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">red</span><span class="p">))</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Batch"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"TripletLoss"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">opts</span><span class="o">.</span><span class="n">Curve</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">blue</span><span class="p">))</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">hline</span> <span class="o">*</span> <span class="n">vline</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">PLOT</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Evaluation Batch Triplet Loss (Third Run)"</span><span class="p">,</span>
                                   <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"evaluation_triplet_loss_third"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/siamese-networks-training-the-model/evaluation_triplet_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It looks like it stopped improving. Probably time to stop.</p>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-hard-negative-mining/">Siamese Networks: Hard Negative Mining</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-hard-negative-mining/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:37:28-08:00" itemprop="datePublished" title="2021-01-25 19:37">2021-01-25 19:37</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org6ed3de3">Hard Negative Mining</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org02d5688">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org8ca8587">Implementation</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#orgf7f64c2">More Detailed Instructions</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#orgc98e6c1">Cosine Similarity</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org4a92c64">Closest Negative</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org6deabbf">Mean Negative</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#orgec9b187">Bundle It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org7c6083d">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org556aea0">Triplet Loss</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#orgb73345b">Triplet Loss Layer</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/#org6b9ca5a">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org6ed3de3">
<h2 id="org6ed3de3">Hard Negative Mining</h2>
<div class="outline-text-2" id="text-org6ed3de3">
<p>Now we will now implement the <code>TripletLoss</code>. Loss is composed of two terms. One term utilizes the mean of all the non duplicates, the second utilizes the <b>closest negative</b>. Our loss expression is then:</p>
\begin{align} \mathcal{Loss_1(A,P,N)} &amp;=\max \left( -cos(A,P) + mean_{neg} +\alpha, 0\right) \\ \mathcal{Loss_2(A,P,N)} &amp;=\max \left( -cos(A,P) + closest_{neg} +\alpha, 0\right) \\ \mathcal{Loss(A,P,N)} &amp;= mean(Loss_1 + Loss_2) \\ \end{align}
<p>Here is a list of things we have to do:</p>
<ul class="org-ul">
<li>As this will be run inside trax, use <code>fastnp.xyz</code> when using any <code>xyz</code> numpy function</li>
<li>Use <code>fastnp.dot</code> to calculate the similarity matrix \(v_1v_2^T\) of dimension <code>batch_size</code> x <code>batch_size</code></li>
<li>Take the score of the duplicates on the diagonal <code>fastnp.diagonal</code></li>
<li>Use the <code>trax</code> functions <code>fastnp.eye</code> and <code>fastnp.maximum</code> for the identity matrix and the maximum.</li>
</ul>
</div>
<div class="outline-3" id="outline-container-org02d5688">
<h3 id="org02d5688">Imports</h3>
<div class="outline-text-3" id="text-org02d5688">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastnp</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8ca8587">
<h2 id="org8ca8587">Implementation</h2>
<div class="outline-text-2" id="text-org8ca8587"></div>
<div class="outline-3" id="outline-container-orgf7f64c2">
<h3 id="orgf7f64c2">More Detailed Instructions</h3>
<div class="outline-text-3" id="text-orgf7f64c2">
<p>We'll describe the algorithm using a detailed example. Below, V1, V2 are the output of the normalization blocks in our model. Here we will use a batch_size of 4 and a d_model of 3. The inputs, Q1, Q2 are arranged so that corresponding inputs are duplicates while non-corresponding entries are not. The outputs will have the same pattern.</p>
<p>This testcase arranges the outputs, v1,v2, to highlight different scenarios. Here, the first two outputs V1[0], V2[0] match exactly - so the model is generating the same vector for Q1[0] and Q2[0] inputs. The second outputs differ, circled in orange, we set, V2[1] is set to match V2[**2**], simulating a model which is generating very poor results. V1[3] and V2[3] match exactly again while V1[4] and V2[4] are set to be exactly wrong - 180 degrees from each other, circled in blue.</p>
</div>
<div class="outline-4" id="outline-container-orgc98e6c1">
<h4 id="orgc98e6c1">Cosine Similarity</h4>
<div class="outline-text-4" id="text-orgc98e6c1">
<p>The first step is to compute the cosine similarity matrix or <code>score</code> in the code. This is \(V_1 V_2^T\) which is generated with <code>fastnp.dot</code>.</p>
<p>The clever arrangement of inputs creates the data needed for positive <b>and</b> negative examples without having to run all pair-wise combinations. Because Q1[n] is a duplicate of only Q2[n], other combinations are explicitly created negative examples or <b>Hard Negative</b> examples. The matrix multiplication efficiently produces the cosine similarity of all positive/negative combinations as shown above on the left side of the diagram. 'Positive' are the results of duplicate examples and 'negative' are the results of explicitly created negative examples. The results for our test case are as expected, V1[0]V2[0] match producing '1' while our other 'positive' cases (in green) don't match well, as was arranged. The V2[2] was set to match V1[3] producing a poor match at <code>score[2,2]</code> and an undesired 'negative' case of a '1' shown in grey.</p>
<p>With the similarity matrix (<code>score</code>) we can begin to implement the loss equations. First, we can extract \(\cos(A,P)\) by utilizing <code>fastnp.diagonal</code>. The goal is to grab all the green entries in the diagram above. This is <code>positive</code> in the code.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org4a92c64">
<h4 id="org4a92c64">Closest Negative</h4>
<div class="outline-text-4" id="text-org4a92c64">
<p>Next, we will create the <b>closest_negative</b>. This is the nonduplicate entry in V2 that is closest (has largest cosine similarity) to an entry in V1. Each row, n, of <code>score</code> represents all comparisons of the results of Q1[n] vs Q2[x] within a batch. A specific example in our testcase is row <code>score[2,:]</code>. It has the cosine similarity of V1[2] and V2[x]. The <b>closest_negative</b>, as was arranged, is V2[2] which has a score of 1. This is the maximum value of the 'negative' entries (blue entries in the diagram).</p>
<p>To implement this, we need to pick the maximum entry on a row of <code>score</code>, ignoring the 'positive'/green entries. To avoid selecting the 'positive'/green entries, we can make them larger negative numbers. Multiply <code>fastnp.eye(batch_size)</code> with 2.0 and subtract it out of <code>scores</code>. The result is <code>negative_without_positive</code>. Now we can use <code>fastnp.max</code>, row by row (axis=1), to select the maximum which is <code>closest_negative</code>.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org6deabbf">
<h4 id="org6deabbf">Mean Negative</h4>
<div class="outline-text-4" id="text-org6deabbf">
<p>Next, we'll create <b>mean_negative</b>. As the name suggests, this is the mean of all the 'negative'/blue values in <code>score</code> on a row by row basis. We can use <code>fastnp.eye(batch_size)</code> and a constant, this time to create a mask with zeros on the diagonal. Element-wise multiply this with <code>score</code> to get just the 'negative values. This is <code>negative_zero_on_duplicate</code> in the code. Compute the mean by using <code>fastnp.sum</code> on <code>negative_zero_on_duplicate</code> for <code>axis=1</code> and divide it by <code>(batch_size - 1)</code> . This is <code>mean_negative</code>.</p>
<p>Now, we can compute loss using the two equations above and <code>fastnp.maximum</code>. This will form <code>triplet_loss1</code> and <code>triplet_loss2</code>.</p>
<p><code>triple_loss</code> is the <code>fastnp.mean</code> of the sum of the two individual losses.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">TripletLossFn</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                  <span class="n">margin</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jax</span><span class="o">.</span><span class="n">interpreters</span><span class="o">.</span><span class="n">xla</span><span class="o">.</span><span class="n">DeviceArray</span><span class="p">:</span>
    <span class="sd">"""Custom Loss function.</span>

<span class="sd">    Args:</span>
<span class="sd">       v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.</span>
<span class="sd">       v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.</span>
<span class="sd">       margin (float, optional): Desired margin. Defaults to 0.25.</span>

<span class="sd">    Returns:</span>
<span class="sd">       jax.interpreters.xla.DeviceArray: Triplet Loss.</span>
<span class="sd">    """</span>
    <span class="c1"># use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="c1"># calculate new batch size</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="c1"># use fastnp to grab all postive =diagonal= entries in =scores=</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>  <span class="c1"># the positive ones (duplicates)</span>
    <span class="c1"># multiply =fastnp.eye(batch_size)= with 2.0 and subtract it out of =scores=</span>
    <span class="n">negative_without_positive</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">-</span> <span class="p">(</span><span class="n">fastnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span><span class="p">)</span>
    <span class="c1"># take the row by row =max= of =negative_without_positive=. </span>
    <span class="c1"># Hint: negative_without_positive.max(axis = [?])  </span>
    <span class="n">closest_negative</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">negative_without_positive</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># subtract =fastnp.eye(batch_size)= out of 1.0 and do element-wise multiplication with =scores=</span>
    <span class="n">negative_zero_on_duplicate</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span> <span class="o">*</span> <span class="n">scores</span>
    <span class="c1"># use =fastnp.sum= on =negative_zero_on_duplicate= for =axis=1= and divide it by =(batch_size - 1)= </span>
    <span class="n">mean_negative</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">negative_zero_on_duplicate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># compute =fastnp.maximum= among 0.0 and =A=</span>
    <span class="c1"># A = subtract =positive= from =margin= and add =closest_negative= </span>
    <span class="n">triplet_loss1</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span> <span class="o">+</span> <span class="n">closest_negative</span><span class="p">)</span>
    <span class="c1"># compute =fastnp.maximum= among 0.0 and =B=</span>
    <span class="c1"># B = subtract =positive= from =margin= and add =mean_negative=</span>
    <span class="n">triplet_loss2</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean_negative</span><span class="p">)</span>
    <span class="c1"># add the two losses together and take the =fastnp.mean= of it</span>
    <span class="n">triplet_loss</span> <span class="o">=</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">triplet_loss1</span> <span class="o">+</span> <span class="n">triplet_loss2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">triplet_loss</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.26726124</span><span class="p">,</span> <span class="mf">0.53452248</span><span class="p">,</span> <span class="mf">0.80178373</span><span class="p">],[</span><span class="mf">0.5178918</span> <span class="p">,</span> <span class="mf">0.57543534</span><span class="p">,</span> <span class="mf">0.63297887</span><span class="p">]])</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.26726124</span><span class="p">,</span>  <span class="mf">0.53452248</span><span class="p">,</span>  <span class="mf">0.80178373</span><span class="p">],[</span><span class="o">-</span><span class="mf">0.5178918</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.57543534</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.63297887</span><span class="p">]])</span>
<span class="n">triplet_loss</span> <span class="o">=</span> <span class="n">TripletLossFn</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Triplet Loss: </span><span class="si">{</span><span class="n">triplet_loss</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">triplet_loss</span> <span class="o">==</span> <span class="mf">0.5</span>
</pre></div>
<pre class="example">
Triplet Loss: 0.5
</pre>
<p>To make a layer out of a function with no trainable variables, use <code>tl.Fn</code>.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="k">def</span> <span class="nf">TripletLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
    <span class="n">triplet_loss_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">TripletLossFn</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s1">'TripletLoss'</span><span class="p">,</span> <span class="n">triplet_loss_fn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgec9b187">
<h2 id="orgec9b187">Bundle It Up</h2>
<div class="outline-text-2" id="text-orgec9b187">
<p>Unfortunately trax does some kind of weirdness where it counts the arguments of the things you use as layers, so class-based stuff won't work (because it counts the <code>self</code> argument, giving it too many to expect). There might be a way to work around this, but it doesn't appear to be documented so this has to be done with only functions. That's not bad, it's just unexpected (and not well documented).</p>
</div>
<div class="outline-3" id="outline-container-org7c6083d">
<h3 id="org7c6083d">Imports</h3>
<div class="outline-text-3" id="text-org7c6083d">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastmath_numpy</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org556aea0">
<h3 id="org556aea0">Triplet Loss</h3>
<div class="outline-text-3" id="text-org556aea0">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">triplet_loss</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
             <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">margin</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">jax</span><span class="o">.</span><span class="n">interpreters</span><span class="o">.</span><span class="n">xla</span><span class="o">.</span><span class="n">DeviceArray</span><span class="p">:</span>
    <span class="sd">"""Calculates the triplet loss</span>

<span class="sd">    Args:</span>
<span class="sd">     v1: normalized batch for question 1</span>
<span class="sd">     v2: normalized batch for question 2</span>

<span class="sd">    Returns:</span>
<span class="sd">     triplet loss</span>
<span class="sd">    """</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="n">negative_without_positive</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">-</span> <span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span><span class="p">)</span>
    <span class="n">closest_negative</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">negative_without_positive</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">negative_zero_on_duplicate</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span> <span class="o">*</span> <span class="n">scores</span>
    <span class="n">mean_negative</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">negative_zero_on_duplicate</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">triplet_loss1</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span> <span class="o">+</span> <span class="n">closest_negative</span><span class="p">)</span>
    <span class="n">triplet_loss2</span> <span class="o">=</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">margin</span> <span class="o">-</span> <span class="n">positive</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean_negative</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">triplet_loss1</span> <span class="o">+</span> <span class="n">triplet_loss2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb73345b">
<h3 id="orgb73345b">Triplet Loss Layer</h3>
<div class="outline-text-3" id="text-orgb73345b">
<p>Another not well documented limitation is that the function you create the layer from isn't allowed to take have default values, so if we want to allow the <code>margin</code> to have a default, we have to use <code>partial</code> to set the value before creating the layer…</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">triplet_loss_layer</span><span class="p">(</span><span class="n">margin</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">:</span>
    <span class="sd">"""Converts the triplet_loss function to a trax layer"""</span>
    <span class="n">with_margin</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">triplet_loss</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="n">margin</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"TripletLoss"</span><span class="p">,</span> <span class="n">with_margin</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6b9ca5a">
<h3 id="org6b9ca5a">Check It Out</h3>
<div class="outline-text-3" id="text-org6b9ca5a">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">triplet_loss_layer</span>

<span class="n">layer</span> <span class="o">=</span> <span class="n">triplet_loss_layer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">))</span>
</pre></div>
<pre class="example">
&lt;class 'trax.layers.base.PureLayer'&gt;
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-defining-the-model/">Siamese Networks: Defining the Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-defining-the-model/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:36:23-08:00" itemprop="datePublished" title="2021-01-25 19:36">2021-01-25 19:36</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org4d1266c">Understanding the Siamese Network</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org810ccd7">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org75914f9">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#orgcabf205">Implementation</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org77318ef">Check the Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org9ae1356">Bundle It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org0f22292">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org7b90d49">Constants</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org10d3332">Normalize</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#orgcac7a3d">The Siamese Model</a>
<ul>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org3155aee">The Processor</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org1e4bf1d">The Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/#org202660d">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4d1266c">
<h2 id="org4d1266c">Understanding the Siamese Network</h2>
<div class="outline-text-2" id="text-org4d1266c">
<p>A Siamese network is a neural network which uses the same weights while working in tandem on two different input vectors to compute comparable output vectors.</p>
<p>You get the question embedding, run it through an LSTM layer, normalize \(v_1\) and \(v_2\), and finally use a triplet loss (explained below) to get the corresponding cosine similarity for each pair of questions. As usual, you will start by importing the data set. The triplet loss makes use of a baseline (anchor) input that is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized. In math equations, you are trying to maximize the following.</p>
<p>\[ \mathcal{L}(A, P, N)=\max \left(\|\mathrm{f}(A)-\mathrm{f}(P)\|^{2}-\|\mathrm{f}(A)-\mathrm{f}(N)\|^{2}+\alpha, 0\right) \]</p>
<p><i>A</i> is the anchor input, for example \(q1_1\), \(P\) the duplicate input, for example, \(q2_1\), and \(N\) the negative input (the non duplicate question), for example \(q2_2\). \(\alpha\) is a margin; you can think about it as a safety net, or by how much you want to push the duplicates from the non duplicates.</p>
</div>
<div class="outline-3" id="outline-container-org810ccd7">
<h3 id="org810ccd7">Imports</h3>
<div class="outline-text-3" id="text-org810ccd7">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">trax.fastmath.numpy</span> <span class="k">as</span> <span class="nn">fastnp</span>
<span class="kn">import</span> <span class="nn">trax.layers</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="c1"># This Project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org75914f9">
<h3 id="org75914f9">Set Up</h3>
<div class="outline-text-3" id="text-org75914f9">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgcabf205">
<h2 id="orgcabf205">Implementation</h2>
<div class="outline-text-2" id="text-orgcabf205">
<p>To implement this model, you will be using `trax`. Concretely, you will be using the following functions.</p>
<ul class="org-ul">
<li><code>tl.Serial</code>: Combinator that applies layers serially (by function composition) allows you set up the overall structure of the feedforward. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/combinators.py#L26">source code</a>
<ul class="org-ul">
<li>You can pass in the layers as arguments to <code>Serial</code>, separated by commas.</li>
<li>For example: <code>tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))</code></li>
</ul>
</li>
<li><code>tl.Embedding</code>: Maps discrete tokens to vectors. It will have shape (vocabulary length X dimension of output vectors). The dimension of output vectors (also called d_feature) is the number of elements in the word embedding. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113">source code</a>
<ul class="org-ul">
<li><code>tl.Embedding(vocab_size, d_feature)</code>.</li>
<li><code>vocab_size</code> is the number of unique words in the given vocabulary.</li>
<li><code>d_feature</code> is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).</li>
</ul>
</li>
<li><code>tl.LSTM</code> The LSTM layer. It leverages another Trax layer called <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTMCell"><code>LSTMCell</code></a>. The number of units should be specified and should match the number of elements in the word embedding. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/rnn.py#L87">source code</a>
<ul class="org-ul">
<li><code>tl.LSTM(n_units)</code> Builds an LSTM layer of n_units.</li>
</ul>
</li>
<li><code>tl.Mean</code>: Computes the mean across a desired axis. Mean uses one tensor axis to form groups of values and replaces each group with the mean value of that group. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L276">source code</a>
<ul class="org-ul">
<li><code>tl.Mean(axis=1)</code> mean over columns.</li>
</ul>
</li>
<li><code>tl.Fn</code> Layer with no weights that applies the function f, which should be specified using a lambda syntax. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn">docs</a> / <a href="https://github.com/google/trax/blob/70f5364dcaf6ec11aabbd918e5f5e4b0f5bfb995/trax/layers/base.py#L576">source code</a>
<ul class="org-ul">
<li><i>x</i> -&gt; This is used for cosine similarity.</li>
<li><code>tl.Fn('Normalize', lambda x: normalize(x))</code> Returns a layer with no weights that applies the function <code>f</code></li>
</ul>
</li>
<li><code>tl.parallel</code>: It is a combinator layer (like <code>Serial</code>) that applies a list of layers in parallel to its inputs. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Parallel">docs</a> / <a href="https://github.com/google/trax/blob/37aba571a89a8ad86be76a569d0ec4a46bdd8642/trax/layers/combinators.py#L152">source code</a></li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Siamese</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">),</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'train'</span><span class="p">):</span>
    <span class="sd">"""Returns a Siamese model.</span>

<span class="sd">    Args:</span>
<span class="sd">       vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).</span>
<span class="sd">       d_model (int, optional): Depth of the model. Defaults to 128.</span>
<span class="sd">       mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.</span>

<span class="sd">    Returns:</span>
<span class="sd">       trax.layers.combinators.Parallel: A Siamese model. </span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  <span class="c1"># normalizes the vectors to have L2 norm 1</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fastnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="n">q_processor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>  <span class="c1"># Processor will run on Q1 and Q2.</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="c1"># Embedding layer</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">),</span> <span class="c1"># LSTM layer</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># Mean over columns</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span>  <span class="c1"># Apply normalize function</span>
    <span class="p">)</span>  <span class="c1"># Returns one vector of shape [batch_size, d_model].</span>

    <span class="c1"># Run on Q1 and Q2 in parallel.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">q_processor</span><span class="p">,</span> <span class="n">q_processor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org77318ef">
<h3 id="org77318ef">Check the Model</h3>
<div class="outline-text-3" id="text-org77318ef">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Siamese</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgd45ef27">
Parallel_in2_out2[
  Serial[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize
  ]
  Serial[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize
  ]
]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org9ae1356">
<h2 id="org9ae1356">Bundle It Up</h2>
<div class="outline-text-2" id="text-org9ae1356">
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">constants</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">normalize</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">siamese</span><span class="o">-</span><span class="n">network</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">the</span><span class="o">-</span><span class="n">processor</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">the</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org0f22292">
<h3 id="org0f22292">Imports</h3>
<div class="outline-text-3" id="text-org0f22292">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastmath_numpy</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7b90d49">
<h3 id="org7b90d49">Constants</h3>
<div class="outline-text-3" id="text-org7b90d49">
<div class="highlight">
<pre><span></span><span class="n">Axis</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Axis"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"columns"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">])</span>
<span class="n">Constants</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Constants"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"model_depth"</span><span class="p">,</span> <span class="s2">"axis"</span><span class="p">])</span>

<span class="n">AXIS</span> <span class="o">=</span> <span class="n">Axis</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">CONSTANTS</span> <span class="o">=</span> <span class="n">Constants</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">AXIS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org10d3332">
<h3 id="org10d3332">Normalize</h3>
<div class="outline-text-3" id="text-org10d3332">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Normalizes the vectors to have L2 norm 1</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the array of vectors to normalize</span>

<span class="sd">    Returns:</span>
<span class="sd">     normalized version of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">/</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>
                                                    <span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">last</span><span class="p">,</span>
                                                    <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcac7a3d">
<h3 id="orgcac7a3d">The Siamese Model</h3>
<div class="outline-text-3" id="text-orgcac7a3d">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SiameseModel</span><span class="p">:</span>
    <span class="sd">"""The Siamese network model</span>

<span class="sd">    Args:</span>
<span class="sd">     vocabulary_size: number of tokens in the vocabulary</span>
<span class="sd">     model_depth: depth of our embedding layer</span>
<span class="sd">     mode: train|eval|predict</span>
<span class="sd">    """</span>
    <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">model_depth</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">model_depth</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"train"</span>
    <span class="n">_processor</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Parallel</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3155aee">
<h4 id="org3155aee">The Processor</h4>
<div class="outline-text-4" id="text-org3155aee">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">processor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
    <span class="sd">"""The Question Processor"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span> 
        <span class="p">)</span> 
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1e4bf1d">
<h4 id="org1e4bf1d">The Model</h4>
<div class="outline-text-4" id="text-org1e4bf1d">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">:</span>
    <span class="sd">"""The Siamese Model"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">processor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span> 
        <span class="p">)</span> 

        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">processor</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org202660d">
<h3 id="org202660d">Check It Out</h3>
<div class="outline-text-3" id="text-org202660d">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">SiameseModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgcd304f3">
Parallel_in4_out2[
  Serial_in2[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize_in2
  ]
  Serial_in2[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize_in2
  ]
]
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-the-data-generator/">Siamese Networks: The Data Generator</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-the-data-generator/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:35:05-08:00" itemprop="datePublished" title="2021-01-25 19:35">2021-01-25 19:35</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orgdc25248">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#org4bfa254">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#org08111e1">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orgd2f1dc0">Our Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orgde12247">The Idiotic Names</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#org6a783e7">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orga3a0f8b">Try It Out</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orge7ba6f1">Bundling It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#org2d3b93b">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#org0b5e432">The Data Generator</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orge1baf90">The Generator Definition</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orgf30ff56">The Generator</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#org9225959">The Iter Method</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orgfe51830">The Next Method</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/#orgb792b48">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgdc25248">
<h2 id="orgdc25248">Beginning</h2>
<div class="outline-text-2" id="text-orgdc25248">
<p>Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. If you were to use stochastic gradient descent with one example at a time, it would take you forever to build a model. In this example, we show you how you can build a data generator that takes in \(Q1\) and \(Q2\) and returns a batch of size <code>batch_size</code> in the following format \(([q1_1, q1_2, q1_3, ...]\), \([q2_1, q2_2,q2_3, ...])\). The tuple consists of two arrays and each array has <code>batch_size</code> questions. Again, \(q1_i\) and \(q2_i\) are duplicates, but they are not duplicates with any other elements in the batch.</p>
<p>The iterator that we're going to create returns a pair of arrays of questions.</p>
<p>We'll implement the data generator below. Here are some things we will need.</p>
<ul class="org-ul">
<li>While true loop.</li>
<li>if <code>index &gt;</code> len_Q1=, set the <code>idx</code> to \(0\).</li>
<li>The generator should return shuffled batches of data. To achieve this without modifying the actual question lists, a list containing the indexes of the questions is created. This list can be shuffled and used to get random batches everytime the index is reset.</li>
<li>Append elements of \(Q1\) and \(Q2\) to <code>input1</code> and <code>input2</code> respectively.</li>
<li>if <code>len(input1) =</code> batch_size=, determine <code>max_len</code> as the longest question in <code>input1</code> and <code>input2</code>. Ceil <code>max_len</code> to a power of \(2\) (for computation purposes) using the following command: <code>max_len = 2**int(np.ceil(np.log2(max_len)))</code>.</li>
<li>Pad every question by <code>vocab['&lt;PAD&gt;']</code> until you get the length <code>max_len</code>.</li>
<li>Use yield to return <code>input1, input2</code>.</li>
<li>Don't forget to reset <code>input1, input2</code> to empty arrays at the end (data generator resumes from where it last left).</li>
</ul>
</div>
<div class="outline-3" id="outline-container-org4bfa254">
<h3 id="org4bfa254">Imports</h3>
<div class="outline-text-3" id="text-org4bfa254">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org08111e1">
<h3 id="org08111e1">Set Up</h3>
<div class="outline-text-3" id="text-org08111e1"></div>
<div class="outline-4" id="outline-container-orgd2f1dc0">
<h4 id="orgd2f1dc0">Our Data</h4>
<div class="outline-text-4" id="text-orgd2f1dc0">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgde12247">
<h4 id="orgde12247">The Idiotic Names</h4>
<div class="outline-text-4" id="text-orgde12247">
<div class="highlight">
<pre><span></span><span class="n">np</span> <span class="o">=</span> <span class="n">numpy</span>
<span class="n">rnd</span> <span class="o">=</span> <span class="n">random</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org6a783e7">
<h2 id="org6a783e7">Middle</h2>
<div class="outline-text-2" id="text-org6a783e7">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="n">Q1</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">Q2</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                   <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Generator function that yields batches of data</span>

<span class="sd">    Args:</span>
<span class="sd">       Q1 (list): List of transformed (to tensor) questions.</span>
<span class="sd">       Q2 (list): List of transformed (to tensor) questions.</span>
<span class="sd">       batch_size (int): Number of elements per batch.</span>
<span class="sd">       pad (int, optional): Pad character from the vocab. Defaults to 1.</span>
<span class="sd">       shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.</span>

<span class="sd">    Yields:</span>
<span class="sd">       tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)</span>
<span class="sd">       NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates</span>
<span class="sd">             input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates</span>
<span class="sd">    """</span>

    <span class="n">input1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">input2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">len_q</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Q1</span><span class="p">)</span>
    <span class="n">question_indexes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">len_q</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">rnd</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">len_q</span><span class="p">:</span>
            <span class="c1"># if idx is greater than or equal to len_q, set idx accordingly </span>
            <span class="c1"># (Hint: look at the instructions above)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># shuffle to get random batches if shuffle is set to True</span>
            <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
                <span class="n">rnd</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>

        <span class="c1"># get questions at the `question_indexes[idx]` position in Q1 and Q2</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="n">Q1</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
        <span class="n">q2</span> <span class="o">=</span> <span class="n">Q2</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>

        <span class="c1"># increment idx by 1</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># append q1</span>
        <span class="n">input1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>
        <span class="c1"># append q2</span>
        <span class="n">input2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q2</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input1</span><span class="p">)</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="c1"># determine max_len as the longest question in input1 & input 2</span>
            <span class="c1"># Hint: use the `max` function. </span>
            <span class="c1"># take max of input1 & input2 and then max out of the two of them.</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">input1</span><span class="p">),</span>
                          <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">input2</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
            <span class="c1"># pad to power-of-2 (Hint: look at the instructions above)</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">max_len</span><span class="p">)))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">max_len</span><span class="p">)</span>
            <span class="n">b1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">b2</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">q1</span><span class="p">,</span> <span class="n">q2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">):</span>
                <span class="c1"># add [pad] to q1 until it reaches max_len</span>
                <span class="n">q1</span> <span class="o">=</span> <span class="n">q1</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">q1</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="n">pad</span><span class="p">])</span>
                <span class="c1"># add [pad] to q2 until it reaches max_len</span>
                <span class="n">q2</span> <span class="o">=</span> <span class="n">q2</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">q2</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="n">pad</span><span class="p">])</span>
                <span class="c1"># append q1</span>
                <span class="n">b1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q1</span><span class="p">)</span>
                <span class="c1"># append q2</span>
                <span class="n">b2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q2</span><span class="p">)</span>
            <span class="c1"># use b1 and b2</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
            <span class="c1"># reset the batches</span>
            <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>  <span class="c1"># reset the batches</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orga3a0f8b">
<h3 id="orga3a0f8b">Try It Out</h3>
<div class="outline-text-3" id="text-orga3a0f8b">
<div class="highlight">
<pre><span></span><span class="n">rnd</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">34</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">result_1</span><span class="p">,</span> <span class="n">result_2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First questions  : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_1</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Second questions : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_2</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org960e73f">
11
16
First questions  : 
[[  34   37   13   50  536 1303 6428   25  924  157   28    1    1    1
     1    1]
 [  34   95  573 1444 2343   28    1    1    1    1    1    1    1    1
     1    1]]

Second questions : 
[[  34   37   13  575 1303 6428   25  924  157   28    1    1    1    1
     1    1]
 [   9  151   25  573 5642   28    1    1    1    1    1    1    1    1
     1    1]]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orge7ba6f1">
<h2 id="orge7ba6f1">Bundling It Up</h2>
<div class="outline-text-2" id="text-orge7ba6f1"></div>
<div class="outline-3" id="outline-container-org2d3b93b">
<h3 id="org2d3b93b">Imports</h3>
<div class="outline-text-3" id="text-org2d3b93b">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0b5e432">
<h3 id="org0b5e432">The Data Generator</h3>
<div class="outline-text-3" id="text-org0b5e432">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">:</span>
    <span class="sd">"""Batch Generator for Quora question dataset</span>

<span class="sd">    Args:</span>
<span class="sd">     question_one: tensorized question 1</span>
<span class="sd">     question_two: tensorized question 2</span>
<span class="sd">     batch_size: size of generated batches</span>
<span class="sd">     padding: token to use to pad the lists</span>
<span class="sd">     shuffle: whether to shuffle the questions around</span>
<span class="sd">    """</span>
    <span class="n">question_one</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">question_two</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">TOKENS</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">_batch</span><span class="p">:</span> <span class="nb">iter</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orge1baf90">
<h4 id="orge1baf90">The Generator Definition</h4>
<div class="outline-text-4" id="text-orge1baf90">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Generator function that yields batches of data</span>

<span class="sd">    Yields:</span>
<span class="sd">       tuple: (batch_question_1, batch_question_2)</span>
<span class="sd">    """</span>
    <span class="n">unpadded_1</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">unpadded_2</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">number_of_questions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span>
    <span class="n">question_indexes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">number_of_questions</span><span class="p">))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;=</span> <span class="n">number_of_questions</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
                <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">question_indexes</span><span class="p">)</span>

        <span class="n">unpadded_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question_one</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">index</span><span class="p">]])</span>
        <span class="n">unpadded_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question_two</span><span class="p">[</span><span class="n">question_indexes</span><span class="p">[</span><span class="n">index</span><span class="p">]])</span>

        <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unpadded_1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">unpadded_1</span><span class="p">),</span>
                          <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question</span><span class="p">)</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">unpadded_2</span><span class="p">))</span>
            <span class="n">max_len</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">max_len</span><span class="p">)))</span>
            <span class="n">padded_1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">padded_2</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">question_1</span><span class="p">,</span> <span class="n">question_2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unpadded_1</span><span class="p">,</span> <span class="n">unpadded_2</span><span class="p">):</span>
                <span class="n">padded_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">question_1</span> <span class="o">+</span> <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">question_1</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">]))</span>
                <span class="n">padded_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">question_2</span> <span class="o">+</span>  <span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">question_2</span><span class="p">))</span> <span class="o">*</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">]))</span>
            <span class="k">yield</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">padded_1</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">padded_2</span><span class="p">)</span>
            <span class="n">unpadded_1</span><span class="p">,</span> <span class="n">unpadded_2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf30ff56">
<h4 id="orgf30ff56">The Generator</h4>
<div class="outline-text-4" id="text-orgf30ff56">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""The generator instance"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_generator</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9225959">
<h4 id="org9225959">The Iter Method</h4>
<div class="outline-text-4" id="text-org9225959">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfe51830">
<h4 id="orgfe51830">The Next Method</h4>
<div class="outline-text-4" id="text-orgfe51830">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb792b48">
<h3 id="orgb792b48">Check It Out</h3>
<div class="outline-text-3" id="text-orgb792b48">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataGenerator</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_two</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">34</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">result_1</span><span class="p">,</span> <span class="n">result_2</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First questions  : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_1</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Second questions : </span><span class="se">\n</span><span class="si">{</span><span class="n">result_2</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgaef0e54">
First questions  : 
[[  34   37   13   50  536 1303 6428   25  924  157   28    1    1    1
     1    1]
 [  34   95  573 1444 2343   28    1    1    1    1    1    1    1    1
     1    1]]

Second questions : 
[[  34   37   13  575 1303 6428   25  924  157   28    1    1    1    1
     1    1]
 [   9  151   25  573 5642   28    1    1    1    1    1    1    1    1
     1    1]]
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-the-data/">Siamese Networks: The Data</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-the-data/" rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:32:40-08:00" itemprop="datePublished" title="2021-01-25 19:32">2021-01-25 19:32</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#org65b3c3c">Transforming the Data</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#orgd9ef756">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgb0dea28">Set Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#org42d3ccf">The Timer</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orge28884a">NLTK</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgdaeb0a1">The Training Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/#org29d9aed">Middle</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#orga9935b0">Inspecting the Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgb8cc25c">Train Test Split</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org86bf570">Filtering Out Non-Duplicates</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgeb917d5">Encoding the Words</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#org3fe5433">Build the Vocabulary</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgf883d15">Converting a question to a tensor</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org373686c">Validation Set</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/#org2cea09b">Bundling It Up</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#org4156b57">Imports</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org949ce19">NLTK Setup</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org01a2409">Constants and Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org231b05e">The Data Tokenizer</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#org97d4d97">Question 1</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org36be039">Question 2</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/#org013d52a">The Data Tensorizer</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#org7f4b929">Tensorized 1</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgf3209b5">Tensorized 2</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org901a9a9">To Index</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/#org2da1df0">The Data Transformer</a>
<ul>
<li><a href="posts/nlp/siamese-networks-the-data/#orga41020a">Data Path</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orga42a73f">Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org2b26168">Training Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org6ad21f9">Testing Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org6261960">Duplicates</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgcf59e0f">Train Tokenizer</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgd26c157">Test Tokenizer</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org4afc2fd">The Vocabulary</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org1f1d269">Tensorized Train</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgef93b90">Tensorized Test</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#org864487c">Test Labels</a></li>
<li><a href="posts/nlp/siamese-networks-the-data/#orgc5789fc">The Final Data</a></li>
</ul>
</li>
<li><a href="posts/nlp/siamese-networks-the-data/#org9c7aeff">Test It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org65b3c3c">
<h2 id="org65b3c3c">Transforming the Data</h2>
<div class="outline-text-2" id="text-org65b3c3c">
<p>We'll will be using the <a href="https://www.kaggle.com/c/quora-question-pairs/">Quora question answer</a> dataset to build a model that could identify similar questions. This is a useful task because you don't want to have several versions of the same question posted. Several times when teaching I end up responding to similar questions on piazza, or on other community forums. This data set has been labeled for you. Run the cell below to import some of the packages you will be using.</p>
</div>
<div class="outline-3" id="outline-container-orgd9ef756">
<h3 id="orgd9ef756">Imports</h3>
<div class="outline-text-3" id="text-orgd9ef756">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="n">expect</span><span class="p">,</span> <span class="n">contain_exactly</span>

<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># my other stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb0dea28">
<h3 id="orgb0dea28">Set Up</h3>
<div class="outline-text-3" id="text-orgb0dea28"></div>
<div class="outline-4" id="outline-container-org42d3ccf">
<h4 id="org42d3ccf">The Timer</h4>
<div class="outline-text-4" id="text-org42d3ccf">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge28884a">
<h4 id="orge28884a">NLTK</h4>
<div class="outline-text-4" id="text-orge28884a">
<p>We need to download the <code>punkt</code> data to be able to tokenize our sentences.</p>
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"punkt"</span><span class="p">)</span>
</pre></div>
<pre class="example">
[nltk_data] Downloading package punkt to
[nltk_data]     /home/neurotic/data/datasets/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgdaeb0a1">
<h4 id="orgdaeb0a1">The Training Data</h4>
<div class="outline-text-4" id="text-orgdaeb0a1">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"QUORA_TRAIN"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org29d9aed">
<h2 id="org29d9aed">Middle</h2>
<div class="outline-text-2" id="text-org29d9aed"></div>
<div class="outline-3" id="outline-container-orga9935b0">
<h3 id="orga9935b0">Inspecting the Data</h3>
<div class="outline-text-3" id="text-orga9935b0">
<div class="highlight">
<pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Rows: </span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> Columns: </span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Rows: 404,290 Columns: 6
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
id                                                              0
qid1                                                            1
qid2                                                            2
question1       What is the step by step guide to invest in sh...
question2       What is the step by step guide to invest in sh...
is_duplicate                                                    0
Name: 0, dtype: object
</pre>
<p>So, you can see that we have a row ID, followed by IDs for each of the questions, followed by the question-pair, and finally a label of whether the two questions are duplicates (1) or not (0).</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgb8cc25c">
<h3 id="orgb8cc25c">Train Test Split</h3>
<div class="outline-text-3" id="text-orgb8cc25c">
<p>For the moment we're going to use a straight splitting of the dataset, rather than using a shuffled split. We're going for a roughly 75-25 split.</p>
<div class="highlight">
<pre><span></span><span class="n">training_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">10</span><span class="o">**</span><span class="mi">5</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">training_size</span><span class="p">]</span>
<span class="n">testing_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">training_size</span><span class="p">:]</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span> <span class="o">==</span> <span class="n">training_size</span>
</pre></div>
<p>Since the data set is large, we'll delete the original pandas DataFrame to save memory.</p>
<div class="highlight">
<pre><span></span><span class="k">del</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org86bf570">
<h3 id="org86bf570">Filtering Out Non-Duplicates</h3>
<div class="outline-text-3" id="text-org86bf570">
<p>We are going to use only the question pairs that are duplicate to train the model.</p>
<p>We build two batches as input for the Siamese network and we assume that question \(q1_i\) (question <i>i</i> in the first batch) is a duplicate of \(q2_i\) (question <i>i</i> in the second batch), but all other questions in the second batch are not duplicates of \(q1_i\).</p>
<p>The test set uses the original pairs of questions and the status describing if the questions are duplicates.</p>
<div class="highlight">
<pre><span></span><span class="n">duplicates</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">training_data</span><span class="o">.</span><span class="n">is_duplicate</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">question2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">is_duplicate</span><span class="p">)</span>
</pre></div>
<pre class="example">
Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?
I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?
1
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">duplicates</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> duplicates for the training data."</span><span class="p">)</span>
</pre></div>
<pre class="example">
There are 111,473 duplicates for the training data.
</pre>
<p>We only took the duplicated questions for training our model because the data generator will produce batches \(([q1_1, q1_2, q1_3, ...]\), [q2_1, q2_2,q2_3, …])\) where \(q1_i\) and \(q2_k\) are duplicate if and only if \(i = k\).</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgeb917d5">
<h3 id="orgeb917d5">Encoding the Words</h3>
<div class="outline-text-3" id="text-orgeb917d5">
<p>Now we'll encode each word of the selected duplicate pairs with an index. Given a question, we can then just encode it as a list of numbers.</p>
<p>First we'll tokenize the questions using <code>nltk.word_tokenize</code>.</p>
<p>We'll also need a python default dictionary which later, during inference, assigns the value <i>0</i> to all Out Of Vocabulary (OOV) words.</p>
</div>
<div class="outline-4" id="outline-container-org3fe5433">
<h4 id="org3fe5433">Build the Vocabulary</h4>
<div class="outline-text-4" id="text-org3fe5433">
<p>We'll start by resetting the index. Pandas preserves the original index, but since we dropped the non-duplicates it's missing rows so resetting it will start it at 0 again. By default it normally keeps the original index as a column, but passing in <code>drop=True</code> prevents that.</p>
<div class="highlight">
<pre><span></span><span class="n">reindexed</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<p>Now we'll build the vocabulary by mapping the words to the "index" for that word in the dictionary.</p>
<div class="highlight">
<pre><span></span><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">vocabulary</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">question_1_train</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="n">question_2_train</span> <span class="o">=</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="n">combined</span> <span class="o">=</span> <span class="n">question_1_train</span> <span class="o">+</span> <span class="n">question_2_train</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">combined</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="n">vocabulary</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> words in the vocabulary."</span><span class="p">)</span>            
</pre></div>
<pre class="example">
Started: 2021-01-30 18:36:26.773827
Ended: 2021-01-30 18:36:46.522680
Elapsed: 0:00:19.748853
There are 36,278 words in the vocabulary.
</pre>
<p>Some example vocabulary words.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s1">'Astrology'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">[</span><span class="s1">'Astronomy'</span><span class="p">])</span>
</pre></div>
<pre class="example">
1
7
0
</pre>
<p>The last <code>0</code> indicates that, while <i>Astrology</i> is in our vocabulary, <i>Astronomy</i> is not. Peculiar.</p>
<p>Now we'll set up the test arrays. One of the Question 1 entries is empty so we'll have to drop it first.</p>
<div class="highlight">
<pre><span></span><span class="n">testing_data</span> <span class="o">=</span> <span class="n">testing_data</span><span class="p">[</span><span class="o">~</span><span class="n">testing_data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">Q1_test_words</span> <span class="o">=</span> <span class="n">testing_data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="n">Q2_test_words</span> <span class="o">=</span> <span class="n">testing_data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2021-01-30 16:43:08.891230
Ended: 2021-01-30 16:43:27.954422
Elapsed: 0:00:19.063192
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf883d15">
<h3 id="orgf883d15">Converting a question to a tensor</h3>
<div class="outline-text-3" id="text-orgf883d15">
<p>We'll now convert every question to a tensor, or an array of numbers, using the vocabulary we built above.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">words_to_index</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>

<span class="n">Q1_train</span> <span class="o">=</span> <span class="n">question_1_train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>
<span class="n">Q2_train</span> <span class="o">=</span> <span class="n">question_2_train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>

<span class="n">Q1_test</span> <span class="o">=</span> <span class="n">Q1_test_words</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>
<span class="n">Q2_test</span> <span class="o">=</span> <span class="n">Q2_test_words</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">words_to_index</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'first question in the train set:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">question_1_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="s1">'encoded version:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Q1_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
first question in the train set:

['Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?'] 

encoded version:
[7, 6, 17, 26, 22, 12, 15, 14, 2, 24, 16, 19, 31, 8, 9, 21, 25, 3, 23, 29] 

</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
77,068
</pre></div>
</div>
<div class="outline-3" id="outline-container-org373686c">
<h3 id="org373686c">Validation Set</h3>
<div class="outline-text-3" id="text-org373686c">
<p>You will now split your train set into a training/validation set so that you can use it to train and evaluate your Siamese model.</p>
<div class="highlight">
<pre><span></span><span class="n">TRAINING_FRACTION</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">cut_off</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question_1_train</span><span class="p">)</span> <span class="o">*</span> <span class="n">TRAINING_FRACTION</span><span class="p">)</span>
<span class="n">train_question_1</span><span class="p">,</span> <span class="n">train_question_2</span> <span class="o">=</span> <span class="n">Q1_train</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">],</span> <span class="n">Q2_train</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">]</span>
<span class="n">validation_question_1</span><span class="p">,</span> <span class="n">validation_question_2</span> <span class="o">=</span> <span class="n">Q1_train</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:</span> <span class="p">],</span> <span class="n">Q2_train</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of duplicate questions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">Q1_train</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the training set is:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_question_1</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the validation set is: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_question_1</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Number of duplicate questions: 111,473
The length of the training set is:  89,178
The length of the validation set is: 22,295
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org2cea09b">
<h2 id="org2cea09b">Bundling It Up</h2>
<div class="outline-text-2" id="text-org2cea09b"></div>
<div class="outline-3" id="outline-container-org4156b57">
<h3 id="org4156b57">Imports</h3>
<div class="outline-text-3" id="text-org4156b57">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org949ce19">
<h3 id="org949ce19">NLTK Setup</h3>
<div class="outline-text-3" id="text-org949ce19">
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"punkt"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org01a2409">
<h3 id="org01a2409">Constants and Data</h3>
<div class="outline-text-3" id="text-org01a2409">
<div class="highlight">
<pre><span></span><span class="n">Tokens</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Tokens"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"unknown"</span><span class="p">,</span> <span class="s2">"padding"</span><span class="p">,</span> <span class="s2">"padding_token"</span><span class="p">])</span>
<span class="n">TOKENS</span> <span class="o">=</span> <span class="n">Tokens</span><span class="p">(</span><span class="n">unknown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">padding_token</span><span class="o">=</span><span class="s2">"&lt;PAD&gt;"</span><span class="p">)</span>

<span class="n">Question</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Question"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"question_one"</span><span class="p">,</span> <span class="s2">"question_two"</span><span class="p">])</span>
<span class="n">Data</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Data"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"train"</span><span class="p">,</span> <span class="s2">"validate"</span><span class="p">,</span> <span class="s2">"test"</span><span class="p">,</span> <span class="s2">"y_test"</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org231b05e">
<h3 id="org231b05e">The Data Tokenizer</h3>
<div class="outline-text-3" id="text-org231b05e">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataTokenizer</span><span class="p">:</span>
    <span class="sd">"""Converts questions to tokens</span>

<span class="sd">    Args:</span>
<span class="sd">     data: the data-frame to tokenize</span>
<span class="sd">    """</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span>
    <span class="n">_question_1</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_question_2</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org97d4d97">
<h4 id="org97d4d97">Question 1</h4>
<div class="outline-text-4" id="text-org97d4d97">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">question_1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sd">"""tokenized version of question 1"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_question_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_1</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org36be039">
<h4 id="org36be039">Question 2</h4>
<div class="outline-text-4" id="text-org36be039">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">question_2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sd">"""tokenized version of question 2"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_question_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_question_2</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org013d52a">
<h3 id="org013d52a">The Data Tensorizer</h3>
<div class="outline-text-3" id="text-org013d52a">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataTensorizer</span><span class="p">:</span>
    <span class="sd">"""Convert tokenized words to numbers</span>

<span class="sd">    Args:</span>
<span class="sd">     vocabulary: word to integer mapping</span>
<span class="sd">     question_1: data to convert</span>
<span class="sd">     question_2: other data to convert</span>
<span class="sd">    """</span>
    <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="n">question_1</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span>
    <span class="n">question_2</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span>
    <span class="n">_tensorized_1</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tensorized_2</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org7f4b929">
<h4 id="org7f4b929">Tensorized 1</h4>
<div class="outline-text-4" id="text-org7f4b929">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sd">"""numeric version of question 1"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">question_1</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_1</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf3209b5">
<h4 id="orgf3209b5">Tensorized 2</h4>
<div class="outline-text-4" id="text-orgf3209b5">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sd">"""Numeric version of question 2"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">question_2</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_2</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org901a9a9">
<h4 id="org901a9a9">To Index</h4>
<div class="outline-text-4" id="text-org901a9a9">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">to_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Convert list of words to list of integers"""</span>
    <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2da1df0">
<h3 id="org2da1df0">The Data Transformer</h3>
<div class="outline-text-3" id="text-org2da1df0">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DataLoader</span><span class="p">:</span>
    <span class="sd">"""Loads and transforms the data</span>

<span class="sd">    Args:</span>
<span class="sd">     env: The path to the .env file with the raw-data path</span>
<span class="sd">     key: key in the environment with the path to the data</span>
<span class="sd">     train_validation_size: number of entries for the training/validation set</span>
<span class="sd">     training_fraction: what fraction of the training/valdiation set for training</span>
<span class="sd">    """</span>
    <span class="n">env</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"posts/nlp/.env"</span>
    <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"QUORA_TRAIN"</span>
    <span class="n">train_validation_size</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">300000</span>
    <span class="n">training_fraction</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.8</span>
    <span class="n">_data_path</span><span class="p">:</span> <span class="n">Path</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_raw_data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_training_data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_testing_data</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_duplicates</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tokenized_train</span><span class="p">:</span> <span class="n">DataTokenizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tokenized_test</span><span class="p">:</span> <span class="n">DataTokenizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vocabulary</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tensorized_train</span><span class="p">:</span> <span class="n">DataTensorizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tensorized_test</span><span class="p">:</span> <span class="n">DataTensorizer</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_test_labels</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="o">=</span><span class="kc">None</span>    
    <span class="n">_data</span><span class="p">:</span> <span class="n">namedtuple</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga41020a">
<h4 id="orga41020a">Data Path</h4>
<div class="outline-text-4" id="text-orga41020a">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">data_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
    <span class="sd">"""Where to find the data file"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">load_dotenv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga42a73f">
<h4 id="orga42a73f">Data</h4>
<div class="outline-text-4" id="text-orga42a73f">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">raw_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">"""The raw-data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="p">[</span><span class="o">~</span><span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span><span class="o">.</span><span class="n">question2</span><span class="o">.</span><span class="n">isna</span><span class="p">()]</span>        
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raw_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2b26168">
<h4 id="org2b26168">Training Data</h4>
<div class="outline-text-4" id="text-org2b26168">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">training_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">"""The training/validation part of the data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">train_validation_size</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6ad21f9">
<h4 id="org6ad21f9">Testing Data</h4>
<div class="outline-text-4" id="text-org6ad21f9">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">testing_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">"""The testing portion of the raw data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_testing_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_testing_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_validation_size</span><span class="p">:]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_testing_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6261960">
<h4 id="org6261960">Duplicates</h4>
<div class="outline-text-4" id="text-org6261960">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">duplicates</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">"""training-validation data that has duplicate questions"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_duplicates</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_duplicates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="o">.</span><span class="n">is_duplicate</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_duplicates</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcf59e0f">
<h4 id="orgcf59e0f">Train Tokenizer</h4>
<div class="outline-text-4" id="text-orgcf59e0f">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tokenized_train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTokenizer</span><span class="p">:</span>
    <span class="sd">"""training tokenized    </span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_train</span> <span class="o">=</span> <span class="n">DataTokenizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">duplicates</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_train</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd26c157">
<h4 id="orgd26c157">Test Tokenizer</h4>
<div class="outline-text-4" id="text-orgd26c157">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tokenized_test</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTokenizer</span><span class="p">:</span>
    <span class="sd">"""Test Tokenizer"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_test</span> <span class="o">=</span> <span class="n">DataTokenizer</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">testing_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenized_test</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4afc2fd">
<h4 id="org4afc2fd">The Vocabulary</h4>
<div class="outline-text-4" id="text-org4afc2fd">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""The token:index map"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">unknown</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">[</span><span class="n">TOKENS</span><span class="o">.</span><span class="n">padding_token</span><span class="p">]</span> <span class="o">=</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">padding</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_1</span>
                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_2</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">combined</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
                      <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span>            
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1f1d269">
<h4 id="org1f1d269">Tensorized Train</h4>
<div class="outline-text-4" id="text-org1f1d269">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_train</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTensorizer</span><span class="p">:</span>
    <span class="sd">"""Tensorizer for the training data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_train</span> <span class="o">=</span> <span class="n">DataTensorizer</span><span class="p">(</span>
            <span class="n">vocabulary</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span>
            <span class="n">question_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_1</span><span class="p">,</span>
            <span class="n">question_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_train</span><span class="o">.</span><span class="n">question_2</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_train</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgef93b90">
<h4 id="orgef93b90">Tensorized Test</h4>
<div class="outline-text-4" id="text-orgef93b90">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tensorized_test</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTensorizer</span><span class="p">:</span>
    <span class="sd">"""Tensorizer for the testing data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_test</span> <span class="o">=</span> <span class="n">DataTensorizer</span><span class="p">(</span>
            <span class="n">vocabulary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">,</span>
            <span class="n">question_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_test</span><span class="o">.</span><span class="n">question_1</span><span class="p">,</span>
            <span class="n">question_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenized_test</span><span class="o">.</span><span class="n">question_2</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensorized_test</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org864487c">
<h4 id="org864487c">Test Labels</h4>
<div class="outline-text-4" id="text-org864487c">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">test_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sd">"""The labels for the test data</span>

<span class="sd">    0 : not duplicate questions</span>
<span class="sd">    1 : is duplicate</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">testing_data</span><span class="o">.</span><span class="n">is_duplicate</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_labels</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc5789fc">
<h4 id="orgc5789fc">The Final Data</h4>
<div class="outline-text-4" id="text-orgc5789fc">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">namedtuple</span><span class="p">:</span>
    <span class="sd">"""The final tensorized data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cut_off</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">duplicates</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_fraction</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span>
            <span class="n">train</span><span class="o">=</span><span class="n">Question</span><span class="p">(</span>
                <span class="n">question_one</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_1</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                <span class="n">question_two</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_2</span><span class="p">[:</span><span class="n">cut_off</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
            <span class="n">validate</span><span class="o">=</span><span class="n">Question</span><span class="p">(</span>
                <span class="n">question_one</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_1</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                <span class="n">question_two</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_train</span><span class="o">.</span><span class="n">tensorized_2</span><span class="p">[</span><span class="n">cut_off</span><span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
            <span class="n">test</span><span class="o">=</span><span class="n">Question</span><span class="p">(</span>
                <span class="n">question_one</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_test</span><span class="o">.</span><span class="n">tensorized_1</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
                <span class="n">question_two</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensorized_test</span><span class="o">.</span><span class="n">tensorized_2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span>
            <span class="n">y_test</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_labels</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9c7aeff">
<h3 id="org9c7aeff">Test It Out</h3>
<div class="outline-text-3" id="text-org9c7aeff">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of duplicate questions: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">duplicates</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the training set is:  </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The length of the validation set is: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validate</span><span class="o">.</span><span class="n">question_one</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Number of duplicate questions: 111,474
The length of the training set is:  89,179
The length of the validation set is: 22,295
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'first question in the train set:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">duplicates</span><span class="o">.</span><span class="n">question1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'encoded version:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">question_one</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">Q1_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
<pre class="example">
first question in the train set:

Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?
encoded version:
[7, 6, 17, 26, 22, 12, 15, 14, 2, 24, 16, 19, 31, 8, 9, 21, 25, 3, 23, 29] 

</pre>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="k">assert</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
77,068
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/siamese-networks-duplicate-questions/">Siamese Networks: Duplicate Questions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/siamese-networks-duplicate-questions/" rel="bookmark"><time class="published dt-published" datetime="2021-01-23T20:20:18-08:00" itemprop="datePublished" title="2021-01-23 20:20">2021-01-23 20:20</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/siamese-networks-duplicate-questions/#orgb8527ea">Beginning</a>
<ul>
<li><a href="posts/nlp/siamese-networks-duplicate-questions/#orge2b30b3">The Posts</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgb8527ea">
<h2 id="orgb8527ea">Beginning</h2>
<div class="outline-text-2" id="text-orgb8527ea">
<p>In this series of posts we will:</p>
<ul class="org-ul">
<li>Learn about Siamese networks</li>
<li>Understand how the triplet loss works</li>
<li>Understand how to evaluate accuracy</li>
<li>Use cosine similarity between the model's outputted vectors</li>
<li>Use the data generator to get batches of questions</li>
<li>Make predictions using the own model</li>
</ul>
</div>
<div class="outline-3" id="outline-container-orge2b30b3">
<h3 id="orge2b30b3">The Posts</h3>
<div class="outline-text-3" id="text-orge2b30b3">
<ul class="org-ul">
<li><a href="posts/nlp/siamese-networks-the-data/">The Data</a></li>
<li><a href="posts/nlp/siamese-networks-the-data-generator/">The Data Generator</a></li>
<li><a href="posts/nlp/siamese-networks-defining-the-model/">The Model</a></li>
<li><a href="posts/nlp/siamese-networks-hard-negative-mining/">Defining the Loss</a></li>
<li><a href="posts/nlp/siamese-networks-training-the-model/">Training the Model</a></li>
<li><a href="posts/nlp/siamese-networks-evaluating-the-model/">Evaluating the Model</a></li>
<li><a href="posts/nlp/siamese-networks-new-questions/">Testing Questions Outside the Dataset</a></li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/evaluating-a-siamese-model/">Evaluating a Siamese Model</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/evaluating-a-siamese-model/" rel="bookmark"><time class="published dt-published" datetime="2021-01-21T18:34:27-08:00" itemprop="datePublished" title="2021-01-21 18:34">2021-01-21 18:34</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/evaluating-a-siamese-model/#org2bf9ce3">Beginning</a>
<ul>
<li><a href="posts/nlp/evaluating-a-siamese-model/#orga4f9f78">Imports</a></li>
<li><a href="posts/nlp/evaluating-a-siamese-model/#org4d62a97">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/evaluating-a-siamese-model/#org7d9390e">Middle</a>
<ul>
<li><a href="posts/nlp/evaluating-a-siamese-model/#orgeb16209">Data</a></li>
<li><a href="posts/nlp/evaluating-a-siamese-model/#org3fda1ca">Calculating the accuracy</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org2bf9ce3">
<h2 id="org2bf9ce3">Beginning</h2>
<div class="outline-text-2" id="text-org2bf9ce3">
<p>We are going to learn how to evaluate a Siamese model using the accuracy metric.</p>
</div>
<div class="outline-3" id="outline-container-orga4f9f78">
<h3 id="orga4f9f78">Imports</h3>
<div class="outline-text-3" id="text-orga4f9f78">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="kn">import</span> <span class="nn">trax.fastmath.numpy</span> <span class="k">as</span> <span class="nn">trax_numpy</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4d62a97">
<h3 id="org4d62a97">Set Up</h3>
<div class="outline-text-3" id="text-org4d62a97">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">PREFIX</span> <span class="o">=</span> <span class="s2">"SIAMESE_"</span>
<span class="n">q1</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"Q1"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">q2</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"Q2"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"V1"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"V2"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">PREFIX</span> <span class="o">+</span> <span class="s2">"Y_TEST"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7d9390e">
<h2 id="org7d9390e">Middle</h2>
<div class="outline-text-2" id="text-org7d9390e"></div>
<div class="outline-3" id="outline-container-orgeb16209">
<h3 id="orgeb16209">Data</h3>
<div class="outline-text-3" id="text-orgeb16209">
<p>We're going to use some pre-made data rather than start from scratch to (hopefully) make the actual evaluation clearer.</p>
<p>These are the data structures:</p>
<ul class="org-ul">
<li><code>q1</code>: vector with dimension <code>(batch_size X max_length)</code> containing first questions to compare in the test set.</li>
<li><code>q2</code>: vector with dimension <code>(batch_size X max_length)</code> containing second questions to compare in the test set.</li>
</ul>
<p><b>Notice that for each pair of vectors within a batch \(([q1_1, q1_2, q1_3, \ldots]\), \([q2_1, q2_2,q2_3, ...])\) \(q1_i\) is associated with \(q2_k\).</b></p>
<ul class="org-ul">
<li><code>y_test</code>: 1 if \(q1_i\) and \(q2_k\) are duplicates, 0 otherwise.</li>
<li><code>v1</code>: output vector from the model's prediction associated with the first questions.</li>
<li><code>v2</code>: output vector from the model's prediction associated with the second questions.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'q1 has shape: </span><span class="si">{</span><span class="n">q1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And it looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">q1</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgd5a7a96">
q1 has shape: (512, 64) 

And it looks like this: 

 [[ 32  38   4 ...   1   1   1]
 [ 30 156  78 ...   1   1   1]
 [ 32  38   4 ...   1   1   1]
 ...
 [ 32  33   4 ...   1   1   1]
 [ 30 156 317 ...   1   1   1]
 [ 30 156   6 ...   1   1   1]]
</pre>
<p>The ones on the right side are padding values.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'q2 has shape: </span><span class="si">{</span><span class="n">q2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">q2</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgca8be16">
q2 has shape: (512, 64) 

And looks like this: 

 [[   30   156    78 ...     1     1     1]
 [  283   156    78 ...     1     1     1]
 [   32    38     4 ...     1     1     1]
 ...
 [   32    33     4 ...     1     1     1]
 [   30   156    78 ...     1     1     1]
 [   30   156 10596 ...     1     1     1]]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'y_test has shape: </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">y_test</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org8f4e6b2">
y_test has shape: (512,) 

And looks like this: 

 [0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0
 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0
 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0
 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1
 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1
 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1
 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0
 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0
 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0
 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1
 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1
 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'v1 has shape: </span><span class="si">{</span><span class="n">v1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">v1</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org52a014f">
v1 has shape: (512, 128) 

And looks like this: 

 [[ 0.01273625 -0.1496373  -0.01982759 ...  0.02205012 -0.00169148
  -0.01598107]
 [-0.05592084  0.05792497 -0.02226785 ...  0.08156938 -0.02570007
  -0.00503111]
 [ 0.05686752  0.0294889   0.04522024 ...  0.03141788 -0.08459651
  -0.00968536]
 ...
 [ 0.15115018  0.17791134  0.02200656 ... -0.00851707  0.00571415
  -0.00431194]
 [ 0.06995274  0.13110274  0.0202337  ... -0.00902792 -0.01221745
   0.00505962]
 [-0.16043712 -0.11899089 -0.15950686 ...  0.06544471 -0.01208312
  -0.01183368]]
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'v2 has shape: </span><span class="si">{</span><span class="n">v2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> </span><span class="se">\n\n</span><span class="s1">And looks like this: </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">v2</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org1eb8b73">
v2 has shape: (512, 128) 

And looks like this: 

 [[ 0.07437647  0.02804951 -0.02974014 ...  0.02378932 -0.01696189
  -0.01897198]
 [ 0.03270066  0.15122835 -0.02175895 ...  0.00517202 -0.14617395
   0.00204823]
 [ 0.05635608  0.05454165  0.042222   ...  0.03831453 -0.05387777
  -0.01447786]
 ...
 [ 0.04727105 -0.06748016  0.04194937 ...  0.07600753 -0.03072828
   0.00400715]
 [ 0.00269269  0.15222628  0.01714724 ...  0.01482705 -0.0197884
   0.01389528]
 [-0.15475044 -0.15718803 -0.14732707 ...  0.04299919 -0.01070975
  -0.01318042]]
</pre></div>
</div>
<div class="outline-3" id="outline-container-org3fda1ca">
<h3 id="org3fda1ca">Calculating the accuracy</h3>
<div class="outline-text-3" id="text-org3fda1ca">
<p>You will calculate the accuracy by iterating over the test set and checking if the model predicts right or wrong.</p>
<p>You will also need the <code>batch size</code> and the <code>threshold</code> that will determine if two questions are the same or not.</p>
<p><b>Note:</b> A higher threshold means that only very similar questions will be considered as the same question.</p>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
<p>The process is pretty straightforward:</p>
<ul class="org-ul">
<li>Iterate over each one of the elements in the batch</li>
<li>Compute the cosine similarity between the predictions
<ul class="org-ul">
<li>For computing the cosine similarity, the two output vectors should have been normalized using L2 normalization meaning their magnitude will be 1. This has been taken care off by the Siamese network. Hence the cosine similarity here is just dot product between two vectors. You can check by implementing the usual cosine similarity formula and check if this holds or not.</li>
</ul>
</li>
<li>Determine if this value is greater than the threshold (If it is, consider the two questions as the same and return 1 else 0)</li>
<li>Compare against the actual target and if the prediction matches, add 1 to the accuracy (increment the correct prediction counter)</li>
<li>Divide the accuracy by the number of processed elements</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">trax_numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">v2</span><span class="p">[</span><span class="n">row</span><span class="p">])</span>
    <span class="n">similar_enough</span> <span class="o">=</span> <span class="n">similarity</span> <span class="o">&gt;</span> <span class="n">threshold</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">element</span><span class="p">]</span> <span class="o">==</span> <span class="n">similar_enough</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">batch_size</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The accuracy of the model is: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
</pre></div>
<pre class="example">
The accuracy of the model is: 0.6621.
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/modified-triplet-loss/">Modified Triplet Loss</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/modified-triplet-loss/" rel="bookmark"><time class="published dt-published" datetime="2021-01-21T18:34:00-08:00" itemprop="datePublished" title="2021-01-21 18:34">2021-01-21 18:34</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#orgf20668f">Beginning</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#org258fe0f">Background</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org9770dc5">Imports</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/#org8d0034a">Middle</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#org73d850f">Similarity Scores</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#orgd91b0ca">Two Vectors</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org257faab">Similarity score</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/#org16bc5d9">Two Batches of Vectors</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#org333b695">Check</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/#org9b5b3ba">Hard Negative Mining</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#orgceb13b8">Mean Negative</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org61371e6">Closest Negative</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#orga16fa5e">Positives</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org8477a99">Negatives</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org19e650d">Mean negative</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org2fdaf68">Closest negative</a></li>
</ul>
</li>
<li><a href="posts/nlp/modified-triplet-loss/#orgf3b5532">The Loss Functions</a>
<ul>
<li><a href="posts/nlp/modified-triplet-loss/#orgdc033ba">Modified triplet loss</a></li>
<li><a href="posts/nlp/modified-triplet-loss/#org8ea85c6">Cost</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgf20668f">
<h2 id="orgf20668f">Beginning</h2>
<div class="outline-text-2" id="text-orgf20668f">
<p>We'll be looking at how to calculate the full triplet loss as well as a matrix of similarity scores.</p>
</div>
<div class="outline-3" id="outline-container-org258fe0f">
<h3 id="org258fe0f">Background</h3>
<div class="outline-text-3" id="text-org258fe0f">
<p>This is the original triplet loss function:</p>
<p>\[ \mathcal{L_\mathrm{Original}} = \max{(\mathrm{s}(A,N) -\mathrm{s}(A,P) +\alpha, 0)} \]</p>
<p>It can be improved by including the mean negative and the closest negative, to create a new full loss function. The inputs are the Anchor \(\mathrm{A}\), Positive \(\mathrm{P}\) and Negative \(\mathrm{N}\).</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{Full}} &amp;= \mathcal{L_\mathrm{1}} + \mathcal{L_\mathrm{2}}\\ \end{align}</div>
</div>
<div class="outline-3" id="outline-container-org9770dc5">
<h3 id="org9770dc5">Imports</h3>
<div class="outline-text-3" id="text-org9770dc5">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8d0034a">
<h2 id="org8d0034a">Middle</h2>
<div class="outline-text-2" id="text-org8d0034a"></div>
<div class="outline-3" id="outline-container-org73d850f">
<h3 id="org73d850f">Similarity Scores</h3>
<div class="outline-text-3" id="text-org73d850f">
<p>The first step is to calculate the matrix of similarity scores using cosine similarity so that you can look up \(\mathrm{s}(A,P)\), \(\mathrm{s}(A,N)\) as needed for the loss formulas.</p>
</div>
<div class="outline-4" id="outline-container-orgd91b0ca">
<h4 id="orgd91b0ca">Two Vectors</h4>
<div class="outline-text-4" id="text-orgd91b0ca">
<p>First, this is how to calculate the similarity score, using cosine similarity, for 2 vectors.</p>
<p>\[ \mathrm{s}(v_1,v_2) = \mathrm{cosine \ similarity}(v_1,v_2) = \frac{v_1 \cdot v_2}{||v_1||~||v_2||} \]</p>
</div>
</div>
<div class="outline-4" id="outline-container-org257faab">
<h4 id="org257faab">Similarity score</h4>
<div class="outline-text-4" id="text-org257faab">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">v2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""Calculates the cosine similarity between two vectors</span>

<span class="sd">    Args:</span>
<span class="sd">     v1: first vector</span>
<span class="sd">     v2: vector to compare to v1</span>

<span class="sd">    Returns:</span>
<span class="sd">     the cosine similarity between v1 and v2</span>
<span class="sd">    """</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v1</span><span class="p">))</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org9cb3a99"></a>Similar vectors<br>
<div class="outline-text-5" id="text-org9cb3a99">
<div class="highlight">
<pre><span></span><span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : 0.9974
</pre></div>
</li>
<li><a id="org92056fa"></a>Identical Vectors<br>
<div class="outline-text-5" id="text-org92056fa">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="n">v1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : 1.0000
</pre></div>
</li>
<li><a id="org2f209a6"></a>Opposite Vectors<br>
<div class="outline-text-5" id="text-org2f209a6">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="o">-</span><span class="n">v1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : -1.0000
</pre></div>
</li>
<li><a id="org6f4bba1"></a>Dissimilar Vectors<br>
<div class="outline-text-5" id="text-org6f4bba1">
<div class="highlight">
<pre><span></span><span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">42</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cosine similarity : </span><span class="si">{</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span><span class="si">:</span><span class="s2">0.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
cosine similarity : -0.5153
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org16bc5d9">
<h3 id="org16bc5d9">Two Batches of Vectors</h3>
<div class="outline-text-3" id="text-org16bc5d9">
<p>Now let's look at how to calculate the similarity scores, using cosine similarity, for 2 batches of vectors. These are rows of individual vectors, just like in the example above, but stacked vertically into a matrix. They would look like the image below for a batch size (row count) of 4 and embedding size (column count) of 5.</p>
<p>The data is setup so that \(v_{1\_1}\) and \(v_{2\_1}\) represent duplicate inputs, but they are not duplicates with any other rows in the batch. This means \(v_{1\_1}\) and \(v_{2\_1}\) (green and green) have more similar vectors than say \(v_{1\_1}\) and \(v_{2\_2}\) (green and magenta).</p>
<p>We'll use two different methods for calculating the matrix of similarities from 2 batches of vectors.</p>
<p>The Input data.</p>
<div class="highlight">
<pre><span></span><span class="n">v1_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">v1_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">v1_3</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">v1_4</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">v1_1</span><span class="p">,</span> <span class="n">v1_2</span><span class="p">,</span> <span class="n">v1_3</span><span class="p">,</span> <span class="n">v1_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v1 :"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="n">v2_1</span> <span class="o">=</span> <span class="n">v1_1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># add some noise to create approximate duplicate</span>
<span class="n">v2_2</span> <span class="o">=</span> <span class="n">v1_2</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2_3</span> <span class="o">=</span> <span class="n">v1_3</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2_4</span> <span class="o">=</span> <span class="n">v1_4</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">v2_1</span><span class="p">,</span> <span class="n">v2_2</span><span class="p">,</span> <span class="n">v2_3</span><span class="p">,</span> <span class="n">v2_4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"v2 :"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgddc231a">
v1 :
[[ 1  2  3]
 [ 9  8  7]
 [-1 -4 -2]
 [ 1 -7  2]] 

v2 :
[[ 1.34263076  1.18510671  1.04373534]
 [ 8.96692933  6.50763316  7.03243982]
 [-3.4497247  -6.08808183 -4.54327564]
 [-0.77144774 -9.08449817  4.4633513 ]] 
</pre>
<p>For this to work the batch sizes must match.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>
</pre></div>
<p>Now let's look at the similarity scores.</p>
</div>
<ul class="org-ul">
<li><a id="orgc0976e2"></a>Option 1 : nested loops and the cosine similarity function<br>
<div class="outline-text-5" id="text-orgc0976e2">
<div class="highlight">
<pre><span></span><span class="n">batch_size</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">v1</span><span class="o">.</span><span class="n">shape</span>
<span class="n">scores_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">])</span>

<span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">scores_1</span><span class="o">.</span><span class="n">shape</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
        <span class="n">scores_1</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">v2</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Option 1 : Loop"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores_1</span><span class="p">)</span>
</pre></div>
<pre class="example">
Option 1 : Loop
[[ 0.88245143  0.87735873 -0.93717609 -0.14613242]
 [ 0.99999485  0.99567656 -0.95998199 -0.34214656]
 [-0.86016573 -0.81584759  0.96484391  0.60584372]
 [-0.31943701 -0.23354642  0.49063636  0.96181686]]
</pre></div>
</li>
<li><a id="orgf071160"></a>Option 2 : Vector Normalization and the Dot Product<br>
<div class="outline-text-5" id="text-orgf071160">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Normalize x"""</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">scores_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">v1</span><span class="p">),</span> <span class="n">norm</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Option 2 : Vector Norm & dot product"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores_2</span><span class="p">)</span>
</pre></div>
<pre class="example">
Option 2 : Vector Norm & dot product
[[ 0.88245143  0.87735873 -0.93717609 -0.14613242]
 [ 0.99999485  0.99567656 -0.95998199 -0.34214656]
 [-0.86016573 -0.81584759  0.96484391  0.60584372]
 [-0.31943701 -0.23354642  0.49063636  0.96181686]] 

</pre></div>
</li>
</ul>
<div class="outline-4" id="outline-container-org333b695">
<h4 id="org333b695">Check</h4>
<div class="outline-text-4" id="text-org333b695">
<p>Let's make sure we get the same answer in both cases.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">scores_1</span><span class="p">,</span> <span class="n">scores_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9b5b3ba">
<h3 id="org9b5b3ba">Hard Negative Mining</h3>
<div class="outline-text-3" id="text-org9b5b3ba">
<p>Now we'll calculate the mean negative \(mean\_neg\) and the closest negative \(close\_neg\) used in calculating \(\mathcal{L_\mathrm{1}}\) and \(\mathcal{L_\mathrm{2}}\).</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \end{align}
<p>We'll do this using the matrix of similarity scores for a batch size of 4. The diagonal of the matrix contains all the \(\mathrm{s}(A,P)\) values, similarities from duplicate question pairs (aka Positives). This is an important attribute for the calculations to follow.</p>
</div>
<div class="outline-4" id="outline-container-orgceb13b8">
<h4 id="orgceb13b8">Mean Negative</h4>
<div class="outline-text-4" id="text-orgceb13b8">
<p><i>mean_neg</i> is the average of the off diagonals, the \(\mathrm{s}(A,N)\) values, for each row.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org61371e6">
<h4 id="org61371e6">Closest Negative</h4>
<div class="outline-text-4" id="text-org61371e6">
<p><i>closest_neg</i> is the largest off diagonal value, \(\mathrm{s}(A,N)\), that is smaller than the diagonal \(\mathrm{s}(A,P)\) for each row.</p>
<p>We'll start with some hand-made similarity scores.</p>
<div class="highlight">
<pre><span></span><span class="n">similarity_scores</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga16fa5e">
<h4 id="orga16fa5e">Positives</h4>
<div class="outline-text-4" id="text-orga16fa5e">
<p>All the <i>s(A,P)</i> values are similarities from duplicate question pairs (aka Positives). These are along the diagonal.</p>
<div class="highlight">
<pre><span></span><span class="n">sim_ap</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">similarity_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"s(A, P) :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim_ap</span><span class="p">))</span>
</pre></div>
<pre class="example">
s(A, P) :

[[ 0.9  0.   0.   0. ]
 [ 0.   0.5  0.   0. ]
 [ 0.   0.  -0.4  0. ]
 [ 0.   0.   0.   0.5]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org8477a99">
<h4 id="org8477a99">Negatives</h4>
<div class="outline-text-4" id="text-org8477a99">
<p>All the <i>s(A,N)</i> values are similarities of the non duplicate question pairs (aka Negatives). These are in the cells not on the diagonal.</p>
<div class="highlight">
<pre><span></span><span class="n">sim_an</span> <span class="o">=</span> <span class="n">similarity_scores</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sim_ap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"s(A, N) :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sim_an</span><span class="p">)</span>
</pre></div>
<pre class="example">
s(A, N) :

[[ 0.  -0.8  0.3 -0.5]
 [-0.4  0.   0.1 -0.1]
 [ 0.3  0.1  0.  -0.8]
 [-0.5 -0.2 -0.7  0. ]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org19e650d">
<h4 id="org19e650d">Mean negative</h4>
<div class="outline-text-4" id="text-org19e650d">
<p>This is the average of the <i>s(A,N)</i> values for each row.</p>
<div class="highlight">
<pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">similarity_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mean_neg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sim_an</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"mean_neg :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_neg</span><span class="p">)</span>
</pre></div>
<pre class="example">
mean_neg :

[[-0.33333333]
 [-0.13333333]
 [-0.13333333]
 [-0.46666667]]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org2fdaf68">
<h4 id="org2fdaf68">Closest negative</h4>
<div class="outline-text-4" id="text-org2fdaf68">
<p>These are the Max <i>s(A,N)</i> that is &lt;= s(A,P) for each row.</p>
<div class="highlight">
<pre><span></span><span class="n">mask_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>            <span class="c1"># mask to exclude the diagonal</span>
<span class="n">mask_2</span> <span class="o">=</span> <span class="n">sim_an</span> <span class="o">&gt;</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># mask to exclude sim_an &gt; sim_ap</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">mask_1</span> <span class="o">|</span> <span class="n">mask_2</span>
<span class="n">sim_an_masked</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">sim_an</span><span class="p">)</span>         <span class="c1"># create a copy to preserve sim_an</span>
<span class="n">sim_an_masked</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>

<span class="n">closest_neg</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">sim_an_masked</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Closest Negative :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">closest_neg</span><span class="p">)</span>
</pre></div>
<pre class="example">
Closest Negative :

[[ 0.3]
 [ 0.1]
 [-0.8]
 [-0.2]]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf3b5532">
<h3 id="orgf3b5532">The Loss Functions</h3>
<div class="outline-text-3" id="text-orgf3b5532">
<p>The last step is to calculate the loss functions.</p>
\begin{align} \mathcal{L_\mathrm{1}} &amp;= \max{(mean\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{2}} &amp;= \max{(closest\_neg -\mathrm{s}(A,P) +\alpha, 0)}\\ \mathcal{L_\mathrm{Full}} &amp;= \mathcal{L_\mathrm{1}} + \mathcal{L_\mathrm{2}}\\ \end{align}
<p>The Alpha margin.</p>
<div class="highlight">
<pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.25</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgdc033ba">
<h4 id="orgdc033ba">Modified triplet loss</h4>
<div class="outline-text-4" id="text-orgdc033ba">
<div class="highlight">
<pre><span></span><span class="n">loss_1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">mean_neg</span> <span class="o">-</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">loss_2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">closest_neg</span> <span class="o">-</span> <span class="n">sim_ap</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">loss_full</span> <span class="o">=</span> <span class="n">loss_1</span> <span class="o">+</span> <span class="n">loss_2</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8ea85c6">
<h4 id="org8ea85c6">Cost</h4>
<div class="outline-text-4" id="text-org8ea85c6">
<div class="highlight">
<pre><span></span><span class="n">cost</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">loss_full</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Loss Full :</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss_full</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">cost : </span><span class="si">{</span><span class="n">cost</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Loss Full :

[[0.        ]
 [0.        ]
 [0.51666667]
 [0.        ]]

cost : 0.517
</pre></div>
</div>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="next"><a href="index-19.html" rel="next">Older posts</a></li>
</ul>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script><!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
