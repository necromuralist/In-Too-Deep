<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Detecting faces in images." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Human Face Detection | Neurotic Networking</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nano/dog-breed-classifier/human-face-detection/" rel="canonical"><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/nano/dog-breed-classifier/custom-data-loader/" rel="prev" title="Custom Data Loader" type="text/html">
<link href="/posts/nano/dog-breed-classifier/dog-app/" rel="next" title="Dog App" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Human Face Detection" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nano/dog-breed-classifier/human-face-detection/" property="og:url">
<meta content="Detecting faces in images." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-01-02T13:51:55-08:00" property="article:published_time">
<meta content="dlib" property="article:tag">
<meta content="face detection" property="article:tag">
<meta content="opencv" property="article:tag">
<meta content="project" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/nano/dog-breed-classifier/human-face-detection/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/nano/dog-breed-classifier/human-face-detection/">Human Face Detection</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/nano/dog-breed-classifier/human-face-detection/" rel="bookmark"><time class="published dt-published" datetime="2019-01-02T13:51:55-08:00" itemprop="datePublished" title="2019-01-02 13:51">2019-01-02 13:51</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/nano/dog-breed-classifier/human-face-detection/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/nano/dog-breed-classifier/human-face-detection/#org8ccafff">Introduction</a></li>
<li><a href="/posts/nano/dog-breed-classifier/human-face-detection/#org2df0fca">Set Up</a></li>
<li><a href="/posts/nano/dog-breed-classifier/human-face-detection/#orgb48bb51">The Data</a></li>
<li><a href="/posts/nano/dog-breed-classifier/human-face-detection/#org342a25b">OpenCV</a></li>
<li><a href="/posts/nano/dog-breed-classifier/human-face-detection/#orgfe77076">DLIB</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org8ccafff">
<h2 id="org8ccafff">Introduction</h2>
<div class="outline-text-2" id="text-org8ccafff">
<p>In this post, I'll use two libraries to detect human faces in images - <a href="https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html">OpenCV</a> and a python interface to <a href="http://dlib.net/">dlib</a> called <a href="https://github.com/ageitgey/face_recognition"><code>face_recognition</code></a>.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org2df0fca">
<h2 id="org2df0fca">Set Up</h2>
<div class="outline-text-2" id="text-org2df0fca"></div>
<div class="outline-3" id="outline-container-org546176c">
<h3 id="org546176c">Imports</h3>
<div class="outline-text-3" id="text-org546176c"></div>
<div class="outline-4" id="outline-container-org9231c9e">
<h4 id="org9231c9e">Python</h4>
<div class="outline-text-4" id="text-org9231c9e">
<div class="highlight">
<pre><span></span>from functools import partial
import os
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8002826">
<h4 id="org8002826">PyPi</h4>
<div class="outline-text-4" id="text-org8002826">
<div class="highlight">
<pre><span></span>from dotenv import load_dotenv
from PIL import Image
import cv2
import face_recognition
import matplotlib
import matplotlib.image as matplotlib_image
import matplotlib.patches as patches
import matplotlib.pyplot as pyplot
import numpy
import seaborn
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3fce608">
<h4 id="org3fce608">This Project</h4>
<div class="outline-text-4" id="text-org3fce608">
<div class="highlight">
<pre><span></span>from neurotic.tangles.data_paths import DataPathTwo
from neurotic.tangles.f1_scorer import F1Scorer
from neurotic.tangles.timer import Timer
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgef1232c">
<h3 id="orgef1232c">Set Up the Plotting</h3>
<div class="outline-text-3" id="text-orgef1232c">
<div class="highlight">
<pre><span></span>get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
seaborn.set(style="whitegrid",
            rc={"axes.grid": False,
                "font.family": ["sans-serif"],
                "font.sans-serif": ["Open Sans", "Latin Modern Sans", "Lato"],
                "figure.figsize": (8, 6)},
            font_scale=1)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge7b7e5c">
<h3 id="orge7b7e5c">Build the Timer</h3>
<div class="outline-text-3" id="text-orge7b7e5c">
<div class="highlight">
<pre><span></span>timer = Timer()
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0508817">
<h3 id="org0508817">Helpers</h3>
<div class="outline-text-3" id="text-org0508817">
<div class="highlight">
<pre><span></span>def first_prediction(source: list, start:int=0) -&gt; int:
    """Gets the index of the first True prediction

    Args:
     source: list of True/False predictions
     start: index to start the search from

    Returns:
     index of first True prediction found
    """
    for index, prediction in enumerate(source[start:]):
        if prediction:
            print("{}: {}".format(start + index, prediction))
            break
    return start + index
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7fe3e64">
<h3 id="org7fe3e64">Set the Random Seed</h3>
<div class="outline-text-3" id="text-org7fe3e64">
<div class="highlight">
<pre><span></span>numpy.random.seed(2019)
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb48bb51">
<h2 id="orgb48bb51">The Data</h2>
<div class="outline-text-2" id="text-orgb48bb51">
<p>Download the <a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip">human dataset</a> (this is a download link), unzip the folder, and place it in a folder named <code>/lfw</code>.</p>
<p>The <a href="http://vis-www.cs.umass.edu/lfw/lfw.tgz">human dataset</a> is the <a href="http://vis-www.cs.umass.edu/lfw/">Labeled Faces in the Wild</a> data set which was built to study the problem of facial recognition. It's made up of real photos of people taken from the web. Each photo sits in a sub-folder that was given the name of the person (e.g. <a href="https://en.wikipedia.org/wiki/Michelle_Yeoh">Michelle_Yeoh</a>). The folder hasn't been split inte train-test-validiation folders the way the dog dataset was.</p>
<p>The <a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip">dog dataset</a> (this is also a download link) is in a zip-file hosted on Amazon Web Services. The folder should contain three folders (<code>test</code>, <code>train</code>, and <code>valid</code>) and each of these folders should have 133 folders, one for each dog-breed. It looks like the <a href="http://vision.stanford.edu/aditya86/ImageNetDogs/">Stanford Dogs Dataset</a>, but the Stanford data set has 120 breeds, so I don't know the actual source.</p>
<p>You might be thinking <i>Why are we loading dog images if this is about detecting human faces?</i> but our goal is to discern human images from dog images so the dog images will act as our negative data set (the one we don't want to detect faces in).</p>
</div>
<div class="outline-3" id="outline-container-org9d7af45">
<h3 id="org9d7af45">The Paths to the Data</h3>
<div class="outline-text-3" id="text-org9d7af45">
<div class="highlight">
<pre><span></span>load_dotenv()
dog_path = DataPathTwo(folder_key="DOG_PATH")
print(dog_path.folder)
assert dog_path.folder.is_dir()
for folder in dog_path.folder.iterdir():
    print("Dog: {}".format(folder))
human_path = DataPathTwo(folder_key="HUMAN_PATH")
print(human_path.folder)
assert human_path.folder.is_dir()

for name in human_path.folder.glob("Gina*"):
    print(name)
</pre></div>
<pre class="example">
/home/hades/datasets/dog-breed-classification/dogImages
Dog: /home/hades/datasets/dog-breed-classification/dogImages/valid
Dog: /home/hades/datasets/dog-breed-classification/dogImages/train
Dog: /home/hades/datasets/dog-breed-classification/dogImages/test
/home/hades/datasets/dog-breed-classification/lfw
/home/hades/datasets/dog-breed-classification/lfw/Gina_Torres
/home/hades/datasets/dog-breed-classification/lfw/Gina_Centrello
/home/hades/datasets/dog-breed-classification/lfw/Gina_Gershon
/home/hades/datasets/dog-breed-classification/lfw/Gina_Lollobrigida

</pre>
<div class="highlight">
<pre><span></span>timer.start()
people = len(set(human_path.folder.iterdir()))
images = len(set(human_path.folder.glob("*/*")))
print("People Count: {:,}".format(people))
print("Image Count: {:,}".format(images))
print("Images Per Person: {:.2f}".format(images/people))
timer.end()
</pre></div>
<pre class="example">
People Count: 5,749
Image Count: 13,233
Images Per Person: 2.30
Ended: 2019-01-02 19:28:11.529962
Elapsed: 0:00:00.550351

</pre></div>
</div>
<div class="outline-3" id="outline-container-org31dc53f">
<h3 id="org31dc53f">Load All the Files</h3>
<div class="outline-text-3" id="text-org31dc53f">
<div class="highlight">
<pre><span></span>timer.start()
human_files = numpy.array(list(human_path.folder.glob("*/*")))
dog_files = numpy.array(list(dog_path.folder.glob("*/*/*")))
print('There are {:,} total human images.'.format(len(human_files)))
print('There are {:,} total dog images.'.format(len(dog_files)))
timer.end()
</pre></div>
<pre class="example">
There are 13,233 total human images.
There are 8,351 total dog images.
Ended: 2019-01-02 19:28:20.426379
Elapsed: 0:00:00.816752

</pre>
<p>The <code>human_files</code> and <code>dog_files</code> are numpy arrays of python <code>Path</code> objects pointing to image files. Note that at this point we've thrown away all the dog-breed information as well as the names of the people in the images. We're only going for a binary split - human or not human.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org2de2438">
<h3 id="org2de2438">Test Sets</h3>
<div class="outline-text-3" id="text-org2de2438">
<p>The models we're going to use are pre-trained so we're just going to choose 100 images from each set to see how well they do.</p>
<div class="highlight">
<pre><span></span>human_files_short = numpy.random.choice(human_files, 100)
dog_files_short = numpy.random.choice(dog_files, 100)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgec506dd">
<h3 id="orgec506dd">The Scorer</h3>
<div class="outline-text-3" id="text-orgec506dd">
<p>The <code>human_scorer</code> will score how well the detectors did on our data sets. The only thing that needs to be passed into it is the detector/predictor that decides if an image has a human in it. Calling it will produce an org-table with some metrics about how well it did.</p>
<div class="highlight">
<pre><span></span>human_scorer = partial(F1Scorer,
                       true_images=human_files_short,
                       false_images=dog_files_short)
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org342a25b">
<h2 id="org342a25b">OpenCV</h2>
<div class="outline-text-2" id="text-org342a25b">
<p>We're going to use OpenCV's implementation of <a href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html">Haar feature-based cascade classifiers</a> to detect human faces in images.</p>
<p>OpenCV provides pre-trained face detectors stored as XML files on <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">github</a>. The detector I'm going to use is stored in a directory named <code>haarcascades</code>. Here's a demonstration of how to use this face detector to find a human face in an image.</p>
</div>
<div class="outline-3" id="outline-container-orga371315">
<h3 id="orga371315">Extract the Pre-Trained Face Detector</h3>
<div class="outline-text-3" id="text-orga371315">
<div class="highlight">
<pre><span></span>haar_path = DataPathTwo("haarcascade_frontalface_alt.xml", folder_key="HAAR_CASCADES")
assert haar_path.from_folder.is_file()
</pre></div>
<pre class="example">
Ended: 2019-01-02 19:28:33.152747
Elapsed: 0:00:00.000933

</pre>
<p>As you can see from the file-name this detector is tuned for faces looking at the camera (as opposed to, say, a face in profile). Now we need to build the classifier using the XML file.</p>
<div class="highlight">
<pre><span></span>class OpenCVFaceDetector:
    """OpenCV Face Detector

    Args:
     path: path to the model's XML file
    """
    def __init__(self, path: str) -&gt; None:
        self.path = path
        self._classifier = None
        return

    @property
    def classifier(self) -&gt; cv2.CascadeClassifier:
        """Face Classifier"""
        if self._classifier is None:
            self._classifier = cv2.CascadeClassifier(self.path)
        return self._classifier

    def detect_faces(self, image_path: str) -&gt; numpy.ndarray:
        """Find faces in an image

        Args:
         image_path: path to the image

        Returns:
         array of bounding boxes
        """
        # this creates a Matplotlib Image
        image = cv2.imread(str(image_path))
        # the classifier needs a grayscale image
        grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        return self.classifier.detectMultiScale(grayscale)

    def add_bounding_boxes(self, image_path: str) -&gt; numpy.ndarray:
        """Adds bounding boxes to the image

        Args:
         image: path to the image

        Returns:
         RGB image with faces boxed in
        """
        faces = self.detect_faces(image_path)
        # this is redundant, but it's only for troubleshooting
        image = cv2.imread(str(image_path))

        # The arguments to the ``cv2.rectangle`` call are
        #  - image
        #  - the top-left coordinates of the rectangle
        #  - the bottom-right coordinates of the rectangle
        #  - the color
        #  - the thickness of the line.
        for top_left_x, top_left_y ,width, height in faces:
            cv2.rectangle(image,
                  (top_left_x, top_left_y),
                  (top_left_x + width, top_left_y + height),
                  (255,0,0), 2)
        # the image is BGR, so the triplet setting the color =(200, 0, 0)=
        # is setting the rectangle to blue.
        # before we convert it to RGB
        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    def has_face(self, image_path: str) -&gt; bool:
        """Checks if the image contains faces

        Args:
         image_path: path to the image file

        Returns:
         True if there is at least one face in the image
        """
        return len(self.detect_faces(image_path)) &gt; 0
</pre></div>
<div class="highlight">
<pre><span></span>open_cv_detector = OpenCVFaceDetector(str(haar_path.from_folder))
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb4a7c9e">
<h3 id="orgb4a7c9e">Check Out How It Works On An Image</h3>
<div class="outline-text-3" id="text-orgb4a7c9e">
<p>Before trying to use it, let's see how it does on one of our faces.</p>
<div class="highlight">
<pre><span></span>figure, axe = pyplot.subplots()
figure.suptitle("OpenCV Face-Detection Bounding Box", weight="bold")
image = axe.imshow(open_cv_detector.add_bounding_boxes(human))
</pre></div>
<div class="figure">
<p><img alt="opencv_face_bounded.png" src="/posts/nano/dog-breed-classifier/human-face-detection/opencv_face_bounded.png"></p>
</div>
<p>Seems like it did a reasonable job. If you run this enough times you'll note that it draws the tightest box when the person is facing the camera directly and grabs more negative space when the person angles their head away from the camera.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org531c5b5">
<h3 id="org531c5b5">Face Detector</h3>
<div class="outline-text-3" id="text-org531c5b5">
<p>Now that we have something that will draw bounding boxes for any faces it finds in photographs we can create a face-detector that just returns <code>True</code> if there is a face or <code>False</code> if there isn't one.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orga19c839">
<h3 id="orga19c839">Testing the Face Detector</h3>
<div class="outline-text-3" id="text-orga19c839">
<p>Here we're going to see how well the face detector does at detecting human faces and not mistaking dogs for humans.</p>
<div class="highlight">
<pre><span></span>open_cv_scorer = human_scorer(open_cv_detector.has_face)
open_cv_scorer()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Metric</th>
<th class="org-right" scope="col">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Accuracy</td>
<td class="org-right">0.92</td>
</tr>
<tr>
<td class="org-left">Precision</td>
<td class="org-right">0.85</td>
</tr>
<tr>
<td class="org-left">Recall</td>
<td class="org-right">1.00</td>
</tr>
<tr>
<td class="org-left">Specificity</td>
<td class="org-right">0.83</td>
</tr>
<tr>
<td class="org-left">F1</td>
<td class="org-right">0.92</td>
</tr>
<tr>
<td class="org-left">Ended</td>
<td class="org-right">2019-01-03 14:01:49.321416</td>
</tr>
<tr>
<td class="org-left">Elapsed</td>
<td class="org-right">0:00:17.670546</td>
</tr>
</tbody>
</table>
<p>It did pretty well, but was penalized for some false-positives. What did a false positive look like?</p>
</div>
</div>
<div class="outline-3" id="outline-container-orge1c413e">
<h3 id="orge1c413e">Looking at the False Positives</h3>
<div class="outline-text-3" id="text-orge1c413e">
<div class="highlight">
<pre><span></span>dogman_index = first_prediction(open_cv_scorer.false_image_predictions)
</pre></div>
<pre class="example">
1: True

</pre>
<p>So the image at index 1 was a dog that the OpenCV detector thought was a human.</p>
<div class="highlight">
<pre><span></span>figure, axe = pyplot.subplots()
source = dog_files_short[dogman_index]
name = " ".join(
    os.path.splitext(
        os.path.basename(source))[0].split("_")[:-1]).title()
figure.suptitle("Dog-Human OpenCV Prediction ({})".format(
    name), weight="bold")
image = Image.open(source)
image = axe.imshow(image)
</pre></div>
<div class="figure">
<p><img alt="opencv_dog_man.png" src="/posts/files/posts/nano/dog-breed-classifier/human-face-detection/opencv_dog_man.png"></p>
</div>
<div class="figure">
<p><img alt="opencv_dog_man.png" src="/posts/nano/dog-breed-classifier/human-face-detection/opencv_dog_man.png"></p>
</div>
<p>This doesn't really look like a human, but I don't think the detector is specifically trained for <i>humans</i> so much as <i>features</i> that human have when looking straight at the camera, so I'm guessing straight-on views will create false positives. Although the mouth seems to be kind of inhuman.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgfe77076">
<h2 id="orgfe77076">DLIB</h2>
<div class="outline-text-2" id="text-orgfe77076">
<p>Now for another face-detector, this time using <a href="https://github.com/ageitgey/face_recognition"><code>face_recognition</code></a>, a python interface to <a href="http://dlib.net/">dlib's</a> facial recognition code.</p>
</div>
<div class="outline-3" id="outline-container-org5c752e6">
<h3 id="org5c752e6">Testing It With an Image</h3>
<div class="outline-text-3" id="text-org5c752e6">
<p>Let's see how the bounding box it produces looks given the same image that the <code>OpenCV</code> detector was given.</p>
<p>The face-recognition code is much simpler, but to make it consistent I'll add a class that matches the <code>OpenCVFaceDetector</code>.</p>
<div class="highlight">
<pre><span></span>class DlibFaceDetector:
    """DLIB (via face_detector) face detector"""
    def detect_faces(self, image_path: str) -&gt; numpy.ndarray:
        """Finds the locations of faces

        Args:
         image_path: path to the image

        Returns:
         array of bounding box coordinates for the face(s)
        """
        image = face_recognition.load_image_file(str(image_path))
        return face_recognition.face_locations(image)

    def add_bounding_boxes(self, image_path: str,
                           axe: matplotlib.axes.Axes) -&gt; None:
        """Adds patches to the current matplotlib figure

        Args:
         image_path: path to the image file
         axe: axes to add the rectangle to
        """
        for (top, right, bottom, left) in self.detect_faces(image_path):
            width = right - left
            height = top - bottom
            rectangle = patches.Rectangle((top, right), width, height,
                                          fill=False)
            axe.add_patch(rectangle)
        return

    def has_face(self, image_path: str) -&gt; bool:
        """Checks if there is at least one face in the image

        Args:
         image_path: path to the image file

        Returns:
         True if there's at least one face in the image
        """
        return len(self.detect_faces(image_path)) &gt; 0
</pre></div>
<div class="highlight">
<pre><span></span>dlib_detector = DlibFaceDetector()
</pre></div>
<div class="highlight">
<pre><span></span>figure, axe = pyplot.subplots()
image = matplotlib_image.imread(str(human))
figure.suptitle("dlib Face Recognition Bounding-Box", weight='bold')
dlib_detector.add_bounding_boxes(str(human), axe)
plot = axe.imshow(image)
</pre></div>
<div class="figure">
<p><img alt="dlib_box.png" src="/posts/files/posts/nano/dog-breed-classifier/human-face-detection/dlib_box.png"></p>
</div>
<div class="figure">
<p><img alt="dlib_box.png" src="/posts/nano/dog-breed-classifier/human-face-detection/dlib_box.png"></p>
</div>
<p>It seems pretty comparable to what the <code>OpenCV</code> detector came up with.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orge8df15e">
<h3 id="orge8df15e">Measuring Performance</h3>
<div class="outline-text-3" id="text-orge8df15e">
<p>Once again I'll run it through the FI scorer to see what's what.</p>
<div class="highlight">
<pre><span></span>dlib_scorer = human_scorer(dlib_detector.has_face)
dlib_scorer()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Metric</th>
<th class="org-right" scope="col">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Accuracy</td>
<td class="org-right">0.92</td>
</tr>
<tr>
<td class="org-left">Precision</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-left">Recall</td>
<td class="org-right">1.00</td>
</tr>
<tr>
<td class="org-left">Specificity</td>
<td class="org-right">0.84</td>
</tr>
<tr>
<td class="org-left">F1</td>
<td class="org-right">0.93</td>
</tr>
<tr>
<td class="org-left">Ended</td>
<td class="org-right">2019-01-03 14:31:36.848015</td>
</tr>
<tr>
<td class="org-left">Elapsed</td>
<td class="org-right">0:00:47.395556</td>
</tr>
</tbody>
</table>
<p>The dlib model did <i>slightly</i> better with its avoidance of false positives, but it might not be enough to justify the extra time.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org914fc96">
<h3 id="org914fc96">False Humans</h3>
<div class="outline-text-3" id="text-org914fc96">
<p>What kind of image did the DLib Classifier classify as human when it came from the dog images?</p>
<div class="highlight">
<pre><span></span>dlib_dog_human_index = first_prediction(dlib_scorer.false_image_predictions)
</pre></div>
<pre class="example">
11: True

</pre>
<div class="highlight">
<pre><span></span>figure, axe = pyplot.subplots()
source = dog_files_short[dlib_dog_human_index]
name = " ".join(
    os.path.splitext(
        os.path.basename(source))[0].split("_")[:-1]).title()
figure.suptitle("Dog-Human DLib Prediction ({})".format(
    name), weight="bold")
image = Image.open(source)
image = axe.imshow(image)
</pre></div>
<div class="figure">
<p><img alt="dlib_dog_man.png" src="/posts/files/posts/nano/dog-breed-classifier/human-face-detection/dlib_dog_man.png"></p>
</div>
<div class="figure">
<p><img alt="dlib_dog_man.png" src="/posts/nano/dog-breed-classifier/human-face-detection/dlib_dog_man.png"></p>
</div>
<p>Well, this was a bit of a surprise. I don't know that it's really fair to be using this type of image, but what can you do?</p>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/dlib/" rel="tag">dlib</a></li>
<li><a class="tag p-category" href="/categories/face-detection/" rel="tag">face detection</a></li>
<li><a class="tag p-category" href="/categories/opencv/" rel="tag">opencv</a></li>
<li><a class="tag p-category" href="/categories/project/" rel="tag">project</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/nano/dog-breed-classifier/custom-data-loader/" rel="prev" title="Custom Data Loader">Previous post</a></li>
<li class="next"><a href="/posts/nano/dog-breed-classifier/dog-app/" rel="next" title="Dog App">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
