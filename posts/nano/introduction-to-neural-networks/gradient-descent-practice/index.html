<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Practice implementing gradient descent." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Gradient Descent Practice | Neurotic Networking</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nano/introduction-to-neural-networks/gradient-descent-practice/" rel="canonical"><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../gradient-descent/" rel="prev" title="Gradient Descent" type="text/html">
<link href="../student-admissions/" rel="next" title="Student Admissions" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Gradient Descent Practice" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nano/introduction-to-neural-networks/gradient-descent-practice/" property="og:url">
<meta content="Practice implementing gradient descent." property="og:description">
<meta content="article" property="og:type">
<meta content="2018-10-26T19:32:58-07:00" property="article:published_time">
<meta content="gradient descent" property="article:tag">
<meta content="practice" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Gradient Descent Practice</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2018-10-26T19:32:58-07:00" itemprop="datePublished" title="2018-10-26 19:32">2018-10-26 19:32</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgfc1b463">Imports</a></li>
<li><a href="#org93110af">Helpers</a></li>
<li><a href="#org1f2545f">The Data</a></li>
<li><a href="#org70369e4">The Basic Functions</a></li>
<li><a href="#orgf10cd38">Training function</a></li>
<li><a href="#org78cfdf9">Simpler Training</a></li>
</ul>
</div>
</div>
<p>This will implement the basic functions of the Gradient Descent algorithm to find the boundary in a small dataset.</p>
<div class="outline-2" id="outline-container-orgfc1b463">
<h2 id="orgfc1b463">Imports</h2>
<div class="outline-text-2" id="text-orgfc1b463"></div>
<div class="outline-3" id="outline-container-orgc28be19">
<h3 id="orgc28be19">From Pypi</h3>
<div class="outline-text-3" id="text-orgc28be19">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8d56c46">
<h3 id="org8d56c46">This Project</h3>
<div class="outline-text-3" id="text-org8d56c46">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPath</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org93110af">
<h2 id="org93110af">Helpers</h2>
<div class="outline-text-2" id="text-org93110af"></div>
<div class="outline-3" id="outline-container-org29dde66">
<h3 id="org29dde66">For Plotting</h3>
<div class="outline-text-3" id="text-org29dde66"></div>
<div class="outline-4" id="outline-container-org886f620">
<h4 id="org886f620">Plot Points</h4>
<div class="outline-text-4" id="text-org886f620">
<p>This first function is used to plot the data points as a scatter plot.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">plot_points</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axe</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Makes a scatter plot</span>

<span class="sd">    Args:</span>
<span class="sd">     X: array of inputs</span>
<span class="sd">     y: array of labels (1's and 0's)</span>
<span class="sd">     axe: matplotlib axis object</span>

<span class="sd">    Return:</span>
<span class="sd">     axe: matplotlib axis</span>
<span class="sd">    """</span>
    <span class="n">admitted</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">rejected</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">axe</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
    <span class="n">axe</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">axe</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">axe</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">rejected</span><span class="p">],</span>
                <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">rejected</span><span class="p">],</span>
                <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"blue"</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">"k"</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">"Rejects"</span><span class="p">)</span>
    <span class="n">axe</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">admitted</span><span class="p">],</span>
                   <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">admitted</span><span class="p">],</span>
                   <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Accepted"</span><span class="p">)</span>
    <span class="n">axe</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">axe</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org67d6781">
<h4 id="org67d6781">Display</h4>
<div class="outline-text-4" id="text-org67d6781">
<p>The somewhat obscurely named <code>display</code> function is used to plot the separation lines of our model.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">display</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g--'</span><span class="p">,</span> <span class="n">axe</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Makes a line plot</span>

<span class="sd">    Args:</span>
<span class="sd">     m: slope for the line</span>
<span class="sd">     b: intercept for the line</span>
<span class="sd">     color: color and line type for plot</span>
<span class="sd">     axe: matplotlib axis</span>

<span class="sd">    Return:</span>
<span class="sd">     axe: matplotlib axis</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">axe</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">axe</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">)</span>
<span class="n">FIGURE_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1f2545f">
<h2 id="org1f2545f">The Data</h2>
<div class="outline-text-2" id="text-org1f2545f">
<p>We'll load the data from <code>data.csv</code> which has three columns - the first two are the inputs and the third is the label that we are trying to predict for the inputs.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"data.csv"</span><span class="p">)</span>
</pre></div>
<p>My setup is a little different than the Udacity setup so I'm going to have to get into the habit of setting the file before submission.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="p">)</span>
<span class="n">DATA_FILE</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">from_folder</span>
</pre></div>
<pre class="example">
../../../data/introduction_to_neural_networks/data.csv
</pre>
<p>I'm not sure exactly why, but the data is loaded as a pandas DataFrame (with <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html">read_csv</a>) and then converted into two <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html">arrays</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_FILE</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Data</th>
<th class="org-right" scope="col">Rows</th>
<th class="org-left" scope="col">Columns</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">X</td>
<td class="org-right">100</td>
<td class="org-left">2</td>
</tr>
<tr>
<td class="org-left">y</td>
<td class="org-right">100</td>
<td class="org-left">N/A</td>
</tr>
</tbody>
</table>
<p>Here's what our data looks like. I don't know what the inputs represent so I didn't label the axes, but it is a plot of the first input variable vs the second input variable, with the colors determined by the labels (y-values).</p>
<div class="highlight">
<pre><span></span><span class="n">axe</span> <span class="o">=</span> <span class="n">plot_points</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org0f44551">
<p><img alt="data_scatter.png" src="data_scatter.png"></p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org70369e4">
<h2 id="org70369e4">The Basic Functions</h2>
<div class="outline-text-2" id="text-org70369e4"></div>
<div class="outline-3" id="outline-container-org3b0e31e">
<h3 id="org3b0e31e">The Sigmoid activation function</h3>
<div class="outline-text-3" id="text-org3b0e31e">
<p>This is the function that pushes the probabilities that are produced to be close to 1 or 0 so we can classify the inputs.</p>
<p>\[\sigma(x) = \frac{1}{1+e^{-x}}\]</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Calculates the sigmoid of x</span>

<span class="sd">    Args:</span>
<span class="sd">     x: input to classify</span>

<span class="sd">    Returns:</span>
<span class="sd">     sigmoid of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org509f74b">
<p><img alt="sigmoid.png" src="sigmoid.png"></p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org5c0f46f">
<h3 id="org5c0f46f">Output (prediction) formula</h3>
<div class="outline-text-3" id="text-org5c0f46f">
<p>This function takes the dot product of the weights and inputs and adds the bias before returning the sigmoid of the calculation.</p>
<p>\[\hat{y} = \sigma(w_1 x_1 + w_2 x_2 + b)\]</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">output_formula</span><span class="p">(</span><span class="n">features</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                   <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                   <span class="n">bias</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Predicts the outcomes for the inputs</span>

<span class="sd">    Args:</span>
<span class="sd">     features: inputs variables</span>
<span class="sd">     weights: array of weights for the variables</span>
<span class="sd">     bias: array of constants to adjust the output</span>

<span class="sd">    Returns:</span>
<span class="sd">     an array of predicted labels for the inputs</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org07aaf17">
<h3 id="org07aaf17">Error function (log-loss)</h3>
<div class="outline-text-3" id="text-org07aaf17">
<p>This is used for reporting, since the actual updating of the weights uses the gradient.</p>
<p>\[Error(y, \hat{y}) = - y \log(\hat{y}) - (1-y) \log(1-\hat{y})\]</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">error_formula</span><span class="p">(</span><span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Calculates the amount of error</span>

<span class="sd">    Args:</span>
<span class="sd">     y: the true labels</span>
<span class="sd">     output: the predicted labels</span>

<span class="sd">    Returns:</span>
<span class="sd">     amount of error in the output</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">y</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgea6be8a">
<h3 id="orgea6be8a">The function that updates the weights (the gradient descent step)</h3>
<div class="outline-text-3" id="text-orgea6be8a">
<p>This makes a prediction of the labels based on the inputs (using <code>output_formula</code>) and then updates the weights and bias based on the amount of error it had in the predictions.</p>
<p>\[ w_i \longrightarrow w_i + \alpha (y - \hat{y}) x_i\\ b \longrightarrow b + \alpha (y - \hat{y})\\ \]</p>
<p>Where \(\alpha\) is our learning rate and \(\hat{y}\) is our prediction for <i>y</i>.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">update_weights</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""Updates the weights based on the amount of error</span>

<span class="sd">    Args:</span>
<span class="sd">     x: inputs</span>
<span class="sd">     y: actual labels</span>
<span class="sd">     weights: amount to weight each input</span>
<span class="sd">     bias: constant to adjust the output</span>
<span class="sd">     learning_rate: how much to adjust the weights</span>

<span class="sd">    Return:</span>
<span class="sd">     w, b: the updated weights</span>
<span class="sd">    """</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">output_formula</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">+=</span>  <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
    <span class="n">bias</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf10cd38">
<h2 id="orgf10cd38">Training function</h2>
<div class="outline-text-2" id="text-orgf10cd38">
<p>This function will help us iterate the gradient descent algorithm through all the data, for a number of epochs. It will also plot the data, and some of the boundary lines obtained as we run the algorithm.</p>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">44</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">graph_lines</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""Trains a model using gradient descent</span>

<span class="sd">    Args:</span>
<span class="sd">     features: matrix of inputs</span>
<span class="sd">     targets: array of labels for the inputs</span>
<span class="sd">     epochs: number of times to train the model</span>
<span class="sd">     learning_rate: how much to adjust the weights per epoch</span>

<span class="sd">    Returns:</span>
<span class="sd">     weights, bias, errors, plot_x, plot_y: What we learned and how we improved</span>
<span class="sd">    """</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_records</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">last_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n_features</span><span class="o">**.</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_features</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">plot_x</span><span class="p">,</span> <span class="n">plot_y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># train on each row in the training data</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output_formula</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">error_formula</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
            <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">update_weights</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># Printing out the log-loss error on the training set</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">output_formula</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error_formula</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">out</span><span class="p">))</span>
        <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">========== Epoch </span><span class="si">{}</span><span class="s2"> =========="</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">last_loss</span> <span class="ow">and</span> <span class="n">last_loss</span> <span class="o">&lt;</span> <span class="n">loss</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"Training loss: "</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s2">"  WARNING - Loss Increasing"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"Training loss: "</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
            <span class="n">last_loss</span> <span class="o">=</span> <span class="n">loss</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">out</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Accuracy: "</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">graph_lines</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plot_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">plot_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">bias</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="n">plot_x</span><span class="p">,</span> <span class="n">plot_y</span>
</pre></div>
<p>Time to train the algorithm.</p>
<p>When we run the function, we'll obtain the following:</p>
<ul class="org-ul">
<li>10 updates with the current training loss and accuracy</li>
<li>A plot of the data and some of the boundary lines obtained. The final one is in black. Notice how the lines get closer and closer to the best fit, as we go through more epochs.</li>
<li>A plot of the error function. Notice how it decreases as we go through more epochs.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="n">plot_x</span><span class="p">,</span> <span class="n">plot_y</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org994e5d4">

========== Epoch 0 ==========
Training loss:  0.7135845195381634
Accuracy:  0.4

========== Epoch 10 ==========
Training loss:  0.6225835210454962
Accuracy:  0.59

========== Epoch 20 ==========
Training loss:  0.5548744083669508
Accuracy:  0.74

========== Epoch 30 ==========
Training loss:  0.501606141872473
Accuracy:  0.84

========== Epoch 40 ==========
Training loss:  0.4593334641861401
Accuracy:  0.86

========== Epoch 50 ==========
Training loss:  0.42525543433469976
Accuracy:  0.93

========== Epoch 60 ==========
Training loss:  0.3973461571671399
Accuracy:  0.93

========== Epoch 70 ==========
Training loss:  0.3741469765239074
Accuracy:  0.93

========== Epoch 80 ==========
Training loss:  0.35459973368161973
Accuracy:  0.94

========== Epoch 90 ==========
Training loss:  0.3379273658879921
Accuracy:  0.94
</pre>
<p>As you can see from the output the accuracy is getting better while the training loss (the mean of the error) is going down.</p>
<div class="highlight">
<pre><span></span><span class="c1"># Plotting the solution boundary</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Solution boundary"</span><span class="p">)</span>
<span class="n">learning</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">plot_x</span><span class="p">,</span> <span class="n">plot_y</span><span class="p">)</span>
<span class="k">for</span> <span class="n">learn_x</span><span class="p">,</span> <span class="n">learn_y</span> <span class="ow">in</span> <span class="n">learning</span><span class="p">:</span>
    <span class="n">display</span><span class="p">(</span><span class="n">learn_x</span><span class="p">,</span> <span class="n">learn_y</span><span class="p">,</span> <span class="n">axe</span><span class="o">=</span><span class="n">axe</span><span class="p">)</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">display</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="n">bias</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">axe</span><span class="p">)</span>

<span class="c1"># Plotting the data</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">plot_points</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">axe</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org7cf8ba1">
<p><img alt="training.png" src="training.png"></p>
</div>
<p>The green lines are the boundary as the model is trained, the black line is the final separator. While pretty, the green lines kind of obscure how well the sepration did. Here's just the final line with the input data.</p>
<div class="highlight">
<pre><span></span><span class="c1"># Plotting the solution boundary</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"The Final Model"</span><span class="p">)</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">display</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="n">bias</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">axe</span><span class="p">)</span>

<span class="c1"># Plotting the data</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">plot_points</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">axe</span><span class="p">)</span>
</pre></div>
<div class="figure" id="orgb5216e6">
<p><img alt="model.png" src="model.png"></p>
</div>
<p>Finally, this is the amount of error as the model is trained.</p>
<div class="highlight">
<pre><span></span><span class="c1"># Plotting the error</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Error Plot"</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Number of epochs'</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Error'</span><span class="p">)</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">axe</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
</pre></div>
<div class="figure" id="orgaf09f83">
<p><img alt="error.png" src="error.png"></p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org78cfdf9">
<h2 id="org78cfdf9">Simpler Training</h2>
<div class="outline-text-2" id="text-org78cfdf9">
<p>If you squint at the <code>train</code> function you might notice that a considerable amount of it is used for reporting, making it a little harder to read than necessary. This is the same function without the extra reporting.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">only_train</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""Trains a model using gradient descent</span>

<span class="sd">    Args:</span>
<span class="sd">     features: matrix of inputs</span>
<span class="sd">     targets: array of labels for the inputs</span>
<span class="sd">     epochs: number of times to train the model</span>
<span class="sd">     learning_rate: how much to adjust the weights per epoch</span>

<span class="sd">    Returns:</span>
<span class="sd">     weights, bias: Our final model</span>
<span class="sd">    """</span>
    <span class="n">number_of_records</span><span class="p">,</span> <span class="n">number_of_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">number_of_records</span><span class="o">**.</span><span class="mi">5</span><span class="p">,</span>
                                  <span class="n">size</span><span class="o">=</span><span class="n">number_of_features</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">update_weights</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">only_train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Plotting the solution boundary</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FIGURE_SIZE</span><span class="p">)</span>
<span class="n">axe</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"The Final Model"</span><span class="p">)</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">display</span><span class="p">(</span><span class="o">-</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="n">bias</span><span class="o">/</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'black'</span><span class="p">,</span> <span class="n">axe</span><span class="p">)</span>

<span class="c1"># Plotting the data</span>
<span class="n">axe</span> <span class="o">=</span> <span class="n">plot_points</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">axe</span><span class="p">)</span>
</pre></div>
<div class="figure" id="orgbbaac32">
<p><img alt="model_2.png" src="model_2.png"></p>
</div>
<p>And the model for our linear classifier:</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">((</span><span class="s2">"</span><span class="se">\\</span><span class="s2">[</span><span class="se">\n</span><span class="s2">w_0 x_0 + w_1 x_1 + b "</span>
       <span class="s2">"= </span><span class="si">{:.2f}</span><span class="s2">x_0 + </span><span class="si">{:.2f}</span><span class="s2">x_1 + </span><span class="si">{:.2f}</span><span class="se">\n\\</span><span class="s2">]"</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                       <span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                                       <span class="n">bias</span><span class="p">))</span>
</pre></div>
<p>\[ w_0 x_0 + w_1 x_1 + b = -3.13x_0 + -3.62x_1 + 3.31 \]</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../../categories/gradient-descent/" rel="tag">gradient descent</a></li>
<li><a class="tag p-category" href="../../../../categories/practice/" rel="tag">practice</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../gradient-descent/" rel="prev" title="Gradient Descent">Previous post</a></li>
<li class="next"><a href="../student-admissions/" rel="next" title="Student Admissions">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
