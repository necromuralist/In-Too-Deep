<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="A simple autoencoder." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Simple Autoencoder | In Too Deep</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/posts/nano/autoencoders/simple-autoencoder/" rel="canonical"><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="../../cnn/weight-initialization/" rel="prev" title="Weight Initialization" type="text/html">
<link href="../convolutional-autoencoder/" rel="next" title="Convolutional Autoencoder" type="text/html">
<meta content="In Too Deep" property="og:site_name">
<meta content="Simple Autoencoder" property="og:title">
<meta content="https://necromuralist.github.io/In-Too-Deep/posts/nano/autoencoders/simple-autoencoder/" property="og:url">
<meta content="A simple autoencoder." property="og:description">
<meta content="article" property="og:type">
<meta content="2018-12-17T23:30:13-08:00" property="article:published_time">
<meta content="autoencoder" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Simple Autoencoder</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2018-12-17T23:30:13-08:00" itemprop="datePublished" title="2018-12-17 23:30">2018-12-17 23:30</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org03f4a64">Introduction</a></li>
<li><a href="#org012edb1">Compressed Representation</a></li>
<li><a href="#orgf4e626d">Set Up</a></li>
<li><a href="#org977aacd">Visualize the Data</a></li>
<li><a href="#orgb9947e2">Linear Autoencoder</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org03f4a64">
<h2 id="org03f4a64">Introduction</h2>
<div class="outline-text-2" id="text-org03f4a64">
<p>We'll start off by building a simple autoencoder to compress the MNIST dataset. With autoencoders, we pass input data through an encoder that makes a compressed representation of the input. Then, this representation is passed through a decoder to reconstruct the input data. Generally the encoder and decoder will be built with neural networks, then trained on example data.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org012edb1">
<h2 id="org012edb1">Compressed Representation</h2>
<div class="outline-text-2" id="text-org012edb1">
<p>A compressed representation can be great for saving and sharing any kind of data in a way that is more efficient than storing raw data. In practice, the compressed representation often holds key information about an input image and we can use it for denoising images or other kinds of reconstruction and transformation!</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgf4e626d">
<h2 id="orgf4e626d">Set Up</h2>
<div class="outline-text-2" id="text-orgf4e626d">
<p>In this notebook, we'll be build a simple network architecture for the encoder and decoder. Let's get started by importing our libraries and getting the dataset.</p>
</div>
<div class="outline-3" id="outline-container-orgf8a7c60">
<h3 id="orgf8a7c60">Imports</h3>
<div class="outline-text-3" id="text-orgf8a7c60"></div>
<div class="outline-4" id="outline-container-orgabfd2d6">
<h4 id="orgabfd2d6">PyPi</h4>
<div class="outline-text-4" id="text-orgabfd2d6">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfb529c2">
<h4 id="orgfb529c2">This Project</h4>
<div class="outline-text-4" id="text-orgfb529c2">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPathTwo</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org8f5acb2">
<h3 id="org8f5acb2">Plotting</h3>
<div class="outline-text-3" id="text-org8f5acb2">
<div class="highlight">
<pre><span></span><span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'inline'</span><span class="p">)</span>
<span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'config'</span><span class="p">,</span> <span class="s2">"InlineBackend.figure_format = 'retina'"</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">,</span>
            <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
                <span class="s2">"font.family"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"sans-serif"</span><span class="p">],</span>
                <span class="s2">"font.sans-serif"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"Open Sans"</span><span class="p">,</span> <span class="s2">"Latin Modern Sans"</span><span class="p">,</span> <span class="s2">"Lato"</span><span class="p">],</span>
                <span class="s2">"figure.figsize"</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)},</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5b6e789">
<h3 id="org5b6e789">The Data</h3>
<div class="outline-text-3" id="text-org5b6e789"></div>
<div class="outline-4" id="outline-container-org4963f3e">
<h4 id="org4963f3e">Data Transformer</h4>
<div class="outline-text-4" id="text-org4963f3e">
<div class="highlight">
<pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga6787f9">
<h4 id="orga6787f9">Load the Data</h4>
<div class="outline-text-4" id="text-orga6787f9">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">()</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">DataPathTwo</span><span class="p">(</span><span class="n">folder_key</span><span class="o">=</span><span class="s2">"MNIST"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="p">)</span>
</pre></div>
<pre class="example">
/home/hades/datasets/MNIST

</pre>
<div class="highlight">
<pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                           <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org30f94bd">
<h4 id="org30f94bd">Training and Test Batch Loaders</h4>
<div class="outline-text-4" id="text-org30f94bd"></div>
<ul class="org-ul">
<li><a id="orga45d904"></a>Some Constants<br>
<div class="outline-text-5" id="text-orga45d904">
<div class="highlight">
<pre><span></span><span class="c1"># number of subprocesses to use for data loading</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># how many samples per batch to load</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>
<p>Prepare the loaders.</p>
<div class="highlight">
<pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                           <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                          <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org977aacd">
<h2 id="org977aacd">Visualize the Data</h2>
<div class="outline-text-2" id="text-org977aacd"></div>
<div class="outline-3" id="outline-container-org218d3a1">
<h3 id="org218d3a1">Obtain One Batch of Training Images</h3>
<div class="outline-text-3" id="text-org218d3a1">
<div class="highlight">
<pre><span></span><span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">dataiter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6fec079">
<h3 id="org6fec079">Get One Image From the Batch</h3>
<div class="outline-text-3" id="text-org6fec079">
<div class="highlight">
<pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">figure</span><span class="p">,</span> <span class="n">axe</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">figure</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">"First Image"</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">"bold"</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">axe</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="first_image.png" src="first_image.png"></p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb9947e2">
<h2 id="orgb9947e2">Linear Autoencoder</h2>
<div class="outline-text-2" id="text-orgb9947e2"></div>
<div class="outline-3" id="outline-container-org149abb6">
<h3 id="org149abb6">Description</h3>
<div class="outline-text-3" id="text-org149abb6">
<p>We'll train an autoencoder with these images by flattening them into 784 length vectors. The images from this dataset are already normalized such that the values are between 0 and 1. Let's start by building a simple autoencoder. The encoder and decoder should be made of <b>one linear layer</b>. The units that connect the encoder and decoder will be the <i>compressed representation</i>.</p>
<p>Since the images are normalized between 0 and 1, we need to use a <b>sigmoid activation on the output layer</b> to get values that match this input value range.</p>
<ul class="org-ul">
<li>The input images will be flattened into 784 length vectors. The targets are the same as the inputs.</li>
<li>The encoder and decoder will be made of two linear layers, each.</li>
<li>The depth dimensions should change as follows: 784 inputs &gt; <b>encoding_dim</b> &gt; 784 outputs.</li>
<li>All layers will have ReLu activations applied except for the final output layer, which has a sigmoid activation.</li>
</ul>
<p><b>The compressed representation should be a vector with dimension <code>encoding_dim=32</code>.</b></p>
</div>
</div>
<div class="outline-3" id="outline-container-orgf99ce43">
<h3 id="orgf99ce43">Architecture Definition</h3>
<div class="outline-text-3" id="text-orgf99ce43">
<div class="highlight">
<pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span>
<span class="n">IMAGE_DIMENSION</span> <span class="o">=</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">columns</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Autoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">""""" simple autoencoder-decoder</span>

<span class="sd">    Args:</span>
<span class="sd">     encoding_dim: the dimension of the encoded image</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">IMAGE_DIMENSION</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation_one</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">,</span> <span class="n">IMAGE_DIMENSION</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation_output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="k">return</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""Does one feed-forward pass</span>

<span class="sd">       Args:</span>
<span class="sd">        x: flattened MNIST image</span>

<span class="sd">       Returns:</span>
<span class="sd">        the encoded-decoded version of the image</span>
<span class="sd">       """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_one</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgaa1dc60">
<h3 id="orgaa1dc60">Initialize the Auto-Encoder</h3>
<div class="outline-text-3" id="text-orgaa1dc60">
<div class="highlight">
<pre><span></span><span class="n">encoding_dim</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
Autoencoder(
  (encoder): Linear(in_features=784, out_features=32, bias=True)
  (activation_one): ReLU()
  (decoder): Linear(in_features=32, out_features=784, bias=True)
  (activation_output): Sigmoid()
)

</pre></div>
</div>
<div class="outline-3" id="outline-container-orgc83b9bf">
<h3 id="orgc83b9bf">Training</h3>
<div class="outline-text-3" id="text-orgc83b9bf">
<p>Here I'll write a bit of code to train the network. I'm not too interested in validation here, so I'll just monitor the training loss and the test loss afterwards.</p>
<p>We are not concerned with labels in this case, just images, which we can get from the <code>train_loader</code>. Because we're comparing pixel values in input and output images, it will be best to use a loss that is meant for a regression task. Regression is all about comparing <i>quantities</i> rather than probabilistic values. So, in this case, I'll use <a href="https://pytorch.org/docs/stable/nn.html?highlight=mseloss#torch.nn.MSELoss"><code>MSELoss</code></a>, which calculates the Mean-Squared Error between the predicted and the actual value, and compare output images and input images as follows:</p>
<div class="highlight">
<pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
</pre></div>
<p>Otherwise, this is pretty straightfoward training with PyTorch. We flatten our images, pass them into the autoencoder, and record the training loss as we go.</p>
</div>
<div class="outline-4" id="outline-container-org36e463a">
<h4 id="org36e463a">Specify the Loss Function</h4>
<div class="outline-text-4" id="text-org36e463a">
<div class="highlight">
<pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga6dc7ac">
<h4 id="orga6dc7ac">Specifiy the Optimizer</h4>
<div class="outline-text-4" id="text-orga6dc7ac">
<p>We're going to use the <a href="https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam">Adam</a> optimizer instead of Stochastic Gradient Descent.</p>
<div class="highlight">
<pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga9c1b4c">
<h4 id="orga9c1b4c">And Now We Train</h4>
<div class="outline-text-4" id="text-orga9c1b4c">
<div class="highlight">
<pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">20</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># monitor training loss</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1">###################</span>
    <span class="c1"># train the model #</span>
    <span class="c1">###################</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># _ stands in for labels, here</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data</span>
        <span class="c1"># flatten images</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># clear the gradients of all optimized variables</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="c1"># calculate the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>
        <span class="c1"># backward pass: compute gradient of the loss with respect to model parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># perform a single optimization step (parameter update)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># update running training loss</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># print avg training statistics </span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'Epoch: {} </span><span class="se">\t</span><span class="s1">Training Loss: {:.6f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">epoch</span><span class="p">,</span> 
        <span class="n">train_loss</span>
        <span class="p">))</span>
</pre></div>
<pre class="example">
Epoch: 1        Training Loss: 0.622334
Epoch: 2        Training Loss: 0.297601
Epoch: 3        Training Loss: 0.258895
Epoch: 4        Training Loss: 0.250710
Epoch: 5        Training Loss: 0.247124
Epoch: 6        Training Loss: 0.244808
Epoch: 7        Training Loss: 0.243222
Epoch: 8        Training Loss: 0.242119
Epoch: 9        Training Loss: 0.241254
Epoch: 10       Training Loss: 0.240563
Epoch: 11       Training Loss: 0.239997
Epoch: 12       Training Loss: 0.239529
Epoch: 13       Training Loss: 0.239120
Epoch: 14       Training Loss: 0.238747
Epoch: 15       Training Loss: 0.238395
Epoch: 16       Training Loss: 0.238030
Epoch: 17       Training Loss: 0.237546
Epoch: 18       Training Loss: 0.237213
Epoch: 19       Training Loss: 0.236916
Epoch: 20       Training Loss: 0.236473
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1a3cb0f">
<h3 id="org1a3cb0f">Checking out the results</h3>
<div class="outline-text-3" id="text-org1a3cb0f">
<p>Below I've plotted some of the test images along with their reconstructions. For the most part these look pretty good except for some blurriness in some parts.</p>
</div>
<div class="outline-4" id="outline-container-org6e22374">
<h4 id="org6e22374">Obtain One Batch Of Test Images</h4>
<div class="outline-text-4" id="text-org6e22374">
<div class="highlight">
<pre><span></span><span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">dataiter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

<span class="n">images_flatten</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># get sample outputs</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images_flatten</span><span class="p">)</span>
<span class="c1"># prep images for display</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="c1"># output is resized into a batch of images</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="c1"># use detach when it's an output that requires_grad</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">figure</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="c1"># input images on top row, reconstructions on bottom</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">images</span><span class="p">,</span> <span class="n">output</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">get_xaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">get_yaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="recomposed.png" src="recomposed.png"></p>
</div>
</div>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../../categories/autoencoder/" rel="tag">autoencoder</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../../cnn/weight-initialization/" rel="prev" title="Weight Initialization">Previous post</a></li>
<li class="next"><a href="../convolutional-autoencoder/" rel="next" title="Convolutional Autoencoder">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2019 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
