<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Loading image data with pytorch." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Part 7 - Loading Image Data | Neurotic Networking</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nano/pytorch/part-7-loading-image-data/" rel="canonical"><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../part-6-saving-and-loading-models/" rel="prev" title="Part 6 - Saving and Loading Models" type="text/html">
<link href="../part-8-transfer-learning/" rel="next" title="Part 8 - Transfer Learning" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Part 7 - Loading Image Data" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nano/pytorch/part-7-loading-image-data/" property="og:url">
<meta content="Loading image data with pytorch." property="og:description">
<meta content="article" property="og:type">
<meta content="2018-11-22T17:08:56-08:00" property="article:published_time">
<meta content="exercise" property="article:tag">
<meta content="pytorch" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Part 7 - Loading Image Data</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2018-11-22T17:08:56-08:00" itemprop="datePublished" title="2018-11-22 17:08">2018-11-22 17:08</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org284d4e4">Introduction</a></li>
<li><a href="#orgf44ef33">Set Up</a></li>
<li><a href="#org1d34725">The Data</a></li>
<li><a href="#org84740b8">Data Augmentation</a></li>
<li><a href="#org808bdf7">A Naive Dropout model</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org284d4e4">
<h2 id="org284d4e4">Introduction</h2>
<div class="outline-text-2" id="text-org284d4e4">
<p>This is from <a href="https://github.com/udacity/deep-learning-v2-pytorch.git">Udacity's Deep Learning Repository</a> which supports their Deep Learning Nanodegree.</p>
<p>So far we've been working with fairly artificial datasets that you wouldn't typically be using in real projects (28 x 28 pixels is very low resolution). Instead, you'll likely be dealing with full-sized images like you'd get from cameras. In this notebook, we'll look at how to load images and use them to train neural networks.</p>
<p>We'll be using a <a href="https://www.kaggle.com/c/dogs-vs-cats">dataset of cat and dog photos</a> available from Kaggle that was created to test whether a machine would be able to defeat the <a href="https://www.microsoft.com/en-us/research/publication/asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization/">Asirra</a> <a href="https://en.wikipedia.org/wiki/CAPTCHA">CAPTCHA</a> system by identifying whether an image had a cat or a dog.</p>
<p>We'll use this dataset to train a neural network that can differentiate between cats and dogs. These days it doesn't seem like a big accomplishment, but five years ago it was a serious challenge for computer vision systems.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgf44ef33">
<h2 id="orgf44ef33">Set Up</h2>
<div class="outline-text-2" id="text-orgf44ef33"></div>
<div class="outline-3" id="outline-container-orgd641c83">
<h3 id="orgd641c83">Imports</h3>
<div class="outline-text-3" id="text-orgd641c83"></div>
<div class="outline-4" id="outline-container-orgeef7a9e">
<h4 id="orgeef7a9e">PyPi</h4>
<div class="outline-text-4" id="text-orgeef7a9e">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6a57e92">
<h4 id="org6a57e92">Udacity Code</h4>
<div class="outline-text-4" id="text-org6a57e92">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">nano.pytorch</span> <span class="kn">import</span> <span class="n">helper</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdfd9e81">
<h4 id="orgdfd9e81">This Project</h4>
<div class="outline-text-4" id="text-orgdfd9e81">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPathTwo</span>
<span class="kn">from</span> <span class="nn">neurotic.models.fashion</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DropoutModel</span><span class="p">,</span>
    <span class="n">train</span><span class="p">,</span>
    <span class="n">HyperParameters</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgaa469d4">
<h3 id="orgaa469d4">Plotting</h3>
<div class="outline-text-3" id="text-orgaa469d4">
<div class="highlight">
<pre><span></span><span class="n">get_python</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'inline'</span><span class="p">)</span>
<span class="n">get_python</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'config'</span><span class="p">,</span> <span class="s2">"InlineBackend.figure_format = 'retina'"</span><span class="p">)</span>

<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">,</span>
            <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
                <span class="s2">"font.family"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"sans-serif"</span><span class="p">],</span>
                <span class="s2">"font.sans-serif"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"Latin Modern Sans"</span><span class="p">,</span> <span class="s2">"Lato"</span><span class="p">],</span>
                <span class="s2">"figure.figsize"</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)},</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1d34725">
<h2 id="org1d34725">The Data</h2>
<div class="outline-text-2" id="text-org1d34725">
<p>The easiest way to load image data is with <a href="http://pytorch.org/docs/master/torchvision/datasets.html#imagefolder"><code>datasets.ImageFolder</code></a> from <code>torchvision</code>. In general you'll use <code>ImageFolder</code> like so:</p>
<div class="highlight">
<pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="s1">'path/to/data'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>
</pre></div>
<p>where <code>path/to/data</code> is the file path to the data directory and <code>transforms</code> is a list of processing steps built with the <a href="http://pytorch.org/docs/master/torchvision/transforms.html"><code>transforms</code></a> module from <code>torchvision</code>. ImageFolder expects the files and directories to be constructed like so:</p>
<pre class="example">
root/dog/xxx.png
root/dog/xxy.png
root/dog/xxz.png

root/cat/123.png
root/cat/nsdf3.png
root/cat/asd932_.png
</pre>
<p>where each class has it's own directory (<code>cat</code> and <code>dog</code>) for the images. The images are then labeled with the class taken from the directory name. So here, the image <code>123.png</code> would be loaded with the class label <code>cat</code>. You can download the dataset already structured like this <a href="https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip">from here</a>. I've also split it into a training set and test set (note that the data-set is almost 600 Megabytes so make sure you have broadband if you want to download it).</p>
</div>
<div class="outline-3" id="outline-container-orga7040fd">
<h3 id="orga7040fd">Transforms</h3>
<div class="outline-text-3" id="text-orga7040fd">
<p>When you load in the data with <code>ImageFolder</code>, you'll need to define some transforms. For example, the images are different sizes but we'll need them to all be the same size for training. You can either resize them with <code>transforms.Resize()</code> or crop with <code>transforms.CenterCrop()</code>, <code>transforms.RandomResizedCrop()</code>, etc. We'll also need to convert the images to PyTorch tensors with <code>transforms.ToTensor()</code>. Typically you'll combine these transforms into a pipeline with <code>transforms.Compose()</code>, which accepts a list of transforms and runs them in sequence. It looks something like this to scale, then crop, then convert to a tensor:</p>
<div class="highlight">
<pre><span></span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
                                 <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                                 <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
</pre></div>
<p>There are plenty of transforms available, you should read through the <a href="http://pytorch.org/docs/master/torchvision/transforms.html">documentation</a>.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org9f8ae49">
<h3 id="org9f8ae49">Data Loaders</h3>
<div class="outline-text-3" id="text-org9f8ae49">
<p>With the <code>ImageFolder</code> loaded, you have to pass it to a <a href="http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>. The <code>DataLoader</code> takes a dataset (such as you would get from <code>ImageFolder</code>) and returns batches of images and the corresponding labels. You can set various parameters like the batch size and if the data is shuffled after each epoch.</p>
<div class="highlight">
<pre><span></span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<p>Here <code>dataloader</code> is a <a href="https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained">generator</a>. To get data out of it, you need to loop through it or convert it to an iterator and call <code>next()</code>.</p>
<p>Looping through it, get a batch on each loop:</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="c1"># Get one batch</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org764a3cb">
<h3 id="org764a3cb">Actually Load the Data</h3>
<div class="outline-text-3" id="text-org764a3cb">
<p>Now we're going to actually do what we spoke of earlier.</p>
</div>
<div class="outline-4" id="outline-container-orgc155073">
<h4 id="orgc155073">Set the Path</h4>
<div class="outline-text-4" id="text-orgc155073">
<p>This is where we set the folder path. The actual data-set was a zipped folder on an amazon web server so I downloaded it by hand instead of using the <code>datasets</code> method like we did with the earlier data sets.</p>
<div class="highlight">
<pre><span></span><span class="n">train_path</span> <span class="o">=</span> <span class="n">DataPathTwo</span><span class="p">(</span><span class="n">folder_key</span><span class="o">=</span><span class="s2">"CAT_DOG_TRAIN"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga2d7406">
<h4 id="orga2d7406">Transform the Data</h4>
<div class="outline-text-4" id="text-orga2d7406">
<p>We're going to:</p>
<ul class="org-ul">
<li>resize the images (passing in a single number means it will match the smallest side (height or width))</li>
<li>crop the images (CenterCrop means it measures from the center, and a single value makes it a square)</li>
<li>convert the image to a tensor</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">transformations</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
                                      <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                                      <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc57b0e5">
<h4 id="orgc57b0e5">Load the Training Image Folder</h4>
<div class="outline-text-4" id="text-orgc57b0e5">
<div class="highlight">
<pre><span></span><span class="n">training</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">train_path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span>
                                <span class="n">transform</span><span class="o">=</span><span class="n">transformations</span><span class="p">)</span>
</pre></div>
<p>The <code>ImageLoader</code> couldn't handle the <code>~</code> in my path so I changed the <code>DataPathTwo</code> to expand it by default. Now we'll load the data into an iterator that hands out batches of 32 images.</p>
<div class="highlight">
<pre><span></span><span class="n">training_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">training</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<p>Now we can test the data loader.</p>
<div class="highlight">
<pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">training_batches</span><span class="p">))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="test_loader.png" src="test_loader.png"></p>
</div>
<p>If it worked we should see something that looks like a dog or a cat in a square image.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org84740b8">
<h2 id="org84740b8">Data Augmentation</h2>
<div class="outline-text-2" id="text-org84740b8">
<p>A common strategy for training neural networks is to introduce randomness in the input data itself. For example, you can randomly rotate, mirror, scale, and/or crop your images during training. This will help your network generalize as it's seeing the same images but in different locations, with different sizes, in different orientations, etc.</p>
<p>To randomly rotate, scale and crop, then flip your images you would define your transforms like this:</p>
<div class="highlight">
<pre><span></span><span class="n">train_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> 
                                                            <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])])</span>
</pre></div>
<p>You'll also typically want to normalize images with <code>transforms.Normalize</code>. You pass in a list of means and list of standard deviations, then the color channels are normalized like so</p>
<div class="highlight">
<pre><span></span><span class="nb">input</span><span class="p">[</span><span class="n">channel</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="n">channel</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">[</span><span class="n">channel</span><span class="p">])</span> <span class="o">/</span> <span class="n">std</span><span class="p">[</span><span class="n">channel</span><span class="p">]</span>
</pre></div>
<p>Subtracting <code>mean</code> centers the data around zero and dividing by <code>std</code> squishes the values to be between -1 and 1. Normalizing helps keep the network work weights near zero which in turn makes backpropagation more stable. Without normalization, networks will tend to fail to learn.</p>
<p>You can find a list of all the available transforms <a href="http://pytorch.org/docs/0.3.0/torchvision/transforms.html">here</a> . When you're testing however, you'll want to use images that aren't altered (except you'll need to normalize the same way). So, for validation/test images, you'll typically just resize and crop.</p>
<p>The Training Transformations:</p>
<ul class="org-ul">
<li>RandomRotation: takes the maximum number of degrees to rotate the image</li>
<li>RandomResizedCrop: scales and crops the image - we're only passing in the expected output size</li>
<li>RandomHorizontalFlip: 50-50 chance that the image will be flipped horizontally.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">means</span> <span class="o">=</span> <span class="n">deviations</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">train_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                       <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> 
                                                            <span class="n">deviations</span><span class="p">)])</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">test_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
                                      <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                                      <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                      <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">means</span><span class="p">,</span>
                                                           <span class="n">std</span><span class="o">=</span><span class="n">deviations</span><span class="p">)])</span>
</pre></div>
<p>Now we create the testing and training data. Although I loaded the training data before, I didn't apply all the extra transforms so I'm going to re-load it</p>
<div class="highlight">
<pre><span></span><span class="n">test_path</span> <span class="o">=</span> <span class="n">DataPathTwo</span><span class="p">(</span><span class="n">folder_key</span><span class="o">=</span><span class="s2">"CAT_DOG_TEST"</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">train_path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_transforms</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">test_path</span><span class="o">.</span><span class="n">folder</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">test_transforms</span><span class="p">)</span>

<span class="n">train_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">test_batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<p>Here are the first four images in the training set after they were transformed.</p>
<div class="highlight">
<pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_batches</span><span class="p">)</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="n">helper</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="transformed_train_image.png" src="transformed_train_image.png"></p>
</div>
<p>At this point you should be able to load data for training and testing. Now, you should try building a network that can classify cats vs dogs. This is quite a bit more complicated than before with the MNIST and Fashion-MNIST datasets. To be honest, you probably won't get it to work with a fully-connected network, no matter how deep. These images have three color channels and at a higher resolution (so far you've seen 28x28 images which are tiny).</p>
</div>
</div>
<div class="outline-2" id="outline-container-org808bdf7">
<h2 id="org808bdf7">A Naive Dropout model</h2>
<div class="outline-text-2" id="text-org808bdf7">
<p>I'm just going to try and apply the Dropout Model from the FASHION-MNIST examples and see what happens. But, it turns out that the input shapes are wrong. Each image is a (3, 100, 100) tensor.</p>
<div class="highlight">
<pre><span></span><span class="n">parameters</span> <span class="o">=</span> <span class="n">HyperParameters</span><span class="p">()</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">DropoutModel</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">HyperParameters</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                 <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
                 <span class="n">train_batches</span><span class="o">=</span><span class="n">train_batches</span><span class="p">,</span>
                 <span class="n">test_batches</span><span class="o">=</span><span class="n">test_batches</span><span class="p">)</span>
</pre></div>
<p>Okay, this doesn't work, there's a mismatched size problem that I can't figure out. Maybe I'll come back to this.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../../categories/exercise/" rel="tag">exercise</a></li>
<li><a class="tag p-category" href="../../../../categories/pytorch/" rel="tag">pytorch</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../part-6-saving-and-loading-models/" rel="prev" title="Part 6 - Saving and Loading Models">Previous post</a></li>
<li class="next"><a href="../part-8-transfer-learning/" rel="next" title="Part 8 - Transfer Learning">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
