<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Walking through an embeddings exercise." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>NLP Classification Exercise | In Too Deep</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/posts/keras/nlp-classification-exercise/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/keras/embeddings-from-scratch/" rel="prev" title="Embeddings from Scratch" type="text/html">
<meta content="In Too Deep" property="og:site_name">
<meta content="NLP Classification Exercise" property="og:title">
<meta content="https://necromuralist.github.io/In-Too-Deep/posts/keras/nlp-classification-exercise/" property="og:url">
<meta content="Walking through an embeddings exercise." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-09-29T11:28:06-07:00" property="article:published_time">
<meta content="embeddings" property="article:tag">
<meta content="nlp" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/keras/nlp-classification-exercise/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/keras/nlp-classification-exercise/">NLP Classification Exercise</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/nlp-classification-exercise/" rel="bookmark"><time class="published dt-published" datetime="2019-09-29T11:28:06-07:00" itemprop="datePublished" title="2019-09-29 11:28">2019-09-29 11:28</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/keras/nlp-classification-exercise/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/nlp-classification-exercise/#orgc80bbaf">Beginning</a>
<ul>
<li><a href="/posts/keras/nlp-classification-exercise/#orgcbbc543">Imports</a>
<ul>
<li><a href="/posts/keras/nlp-classification-exercise/#orgfc80db3">Python</a></li>
<li><a href="/posts/keras/nlp-classification-exercise/#org3de621d">PyPi</a></li>
<li><a href="/posts/keras/nlp-classification-exercise/#org8a76c4e">Others</a></li>
</ul>
</li>
<li><a href="/posts/keras/nlp-classification-exercise/#orgb78e97f">Set Up</a>
<ul>
<li><a href="/posts/keras/nlp-classification-exercise/#orgf2905f2">The Plotting</a></li>
<li><a href="/posts/keras/nlp-classification-exercise/#org4d4abb7">The Dataset</a></li>
<li><a href="/posts/keras/nlp-classification-exercise/#orga10f168">Some Constants</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/keras/nlp-classification-exercise/#orgef6aa59">Middle</a>
<ul>
<li><a href="/posts/keras/nlp-classification-exercise/#org20dd0a2">The Data</a></li>
<li><a href="/posts/keras/nlp-classification-exercise/#org678d36c">The Tokenizer</a></li>
<li><a href="/posts/keras/nlp-classification-exercise/#org9b560ee">GloVe</a></li>
</ul>
</li>
<li><a href="/posts/keras/nlp-classification-exercise/#orge8bbce5">End</a>
<ul>
<li><a href="/posts/keras/nlp-classification-exercise/#orgb1b77eb">Citations</a></li>
</ul>
</li>
<li><a href="/posts/keras/nlp-classification-exercise/#orgc31f4fe">Raw</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgc80bbaf">
<h2 id="orgc80bbaf">Beginning</h2>
<div class="outline-text-2" id="text-orgc80bbaf"></div>
<div class="outline-3" id="outline-container-orgcbbc543">
<h3 id="orgcbbc543">Imports</h3>
<div class="outline-text-3" id="text-orgcbbc543"></div>
<div class="outline-4" id="outline-container-orgfc80db3">
<h4 id="orgfc80db3">Python</h4>
<div class="outline-text-4" id="text-orgfc80db3">
<div class="highlight">
<pre><span></span>from argparse import Namespace
from functools import partial
from pathlib import Path
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3de621d">
<h4 id="org3de621d">PyPi</h4>
<div class="outline-text-4" id="text-org3de621d">
<div class="highlight">
<pre><span></span>from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
import hvplot.pandas
import numpy
import pandas
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8a76c4e">
<h4 id="org8a76c4e">Others</h4>
<div class="outline-text-4" id="text-org8a76c4e">
<div class="highlight">
<pre><span></span>from graeae import (CountPercentage,
                    EmbedHoloviews,
                    SubPathLoader,
                    ZipDownloader)
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb78e97f">
<h3 id="orgb78e97f">Set Up</h3>
<div class="outline-text-3" id="text-orgb78e97f"></div>
<div class="outline-4" id="outline-container-orgf2905f2">
<h4 id="orgf2905f2">The Plotting</h4>
<div class="outline-text-4" id="text-orgf2905f2">
<div class="highlight">
<pre><span></span>slug = "nlp-classification-exercise"
Embed = partial(EmbedHoloviews, folder_path=f"../../files/posts/keras/{slug}")
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4d4abb7">
<h4 id="org4d4abb7">The Dataset</h4>
<div class="outline-text-4" id="text-org4d4abb7">
<p>It isn't mentioned in the notebook where the data originally came from, but it looks like it's the <a href="http://help.sentiment140.com/home">Sentiment140</a> dataset, which consists of tweets whose sentiment was inferred by emoticons in each tweet.</p>
<div class="highlight">
<pre><span></span>url = "http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
path = Path("~/data/datasets/texts/sentiment140/").expanduser()
download = ZipDownloader(url, path)
download()
</pre></div>
<pre class="example">
2019-09-29 12:26:31,866 [1mZipDownloader[0m start: ([1mZipDownloader[0m) Started: 2019-09-29 12:26:31.866085
2019-09-29 12:26:31,867 [1mZipDownloader[0m download: Downloading the zip file
2019-09-29 12:26:57,309 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Ended: 2019-09-29 12:26:57.309619
2019-09-29 12:26:57,311 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Elapsed: 0:00:25.443534

</pre>
<div class="highlight">
<pre><span></span>columns = ["polarity", "tweet_id", "datetime", "query", "user", "text"]
training = pandas.read_csv(path/"training.1600000.processed.noemoticon.csv", 
                           encoding="latin-1", names=columns, header=None)
testing = pandas.read_csv(path/"testdata.manual.2009.06.14.csv", 
                           encoding="latin-1", names=columns, header=None)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga10f168">
<h4 id="orga10f168">Some Constants</h4>
<div class="outline-text-4" id="text-orga10f168">
<div class="highlight">
<pre><span></span>Text = Namespace(
    embedding_dim = 100,
    max_length = 16,
    trunc_type='post',
    padding_type='post',
    oov_tok = "&lt;OOV&gt;",
    training_size=16000,
)
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgef6aa59">
<h2 id="orgef6aa59">Middle</h2>
<div class="outline-text-2" id="text-orgef6aa59"></div>
<div class="outline-3" id="outline-container-org20dd0a2">
<h3 id="org20dd0a2">The Data</h3>
<div class="outline-text-3" id="text-org20dd0a2">
<div class="highlight">
<pre><span></span>print(training.sample().iloc[0])
</pre></div>
<pre class="example">
polarity                                                    4
tweet_id                                           2001983272
datetime                         Tue Jun 02 02:44:58 PDT 2009
query                                                NO_QUERY
user                                                    pod13
text        @wkdjellybaby to private email??? I will check...
Name: 1283818, dtype: object

</pre>
<div class="highlight">
<pre><span></span>CountPercentage(training.polarity)()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Value</th>
<th class="org-left" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">4</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
</tbody>
</table>
<p>The <code>polarity</code> is what might also be called the "sentiment" of the tweet - <i>0</i> mean a negative tweet and <i>4</i> means a positive tweet.</p>
<p>But, for our purposes, we would be better off if the positive polarity was <code>1</code>, not <code>4</code>, so let's convert it.</p>
<div class="highlight">
<pre><span></span>training.loc[training.polarity==4, "polarity"] = 1
counts = CountPercentage(training.polarity)()
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Value</th>
<th class="org-left" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-left">800,000</td>
<td class="org-right">50.00</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="outline-3" id="outline-container-org678d36c">
<h3 id="org678d36c">The Tokenizer</h3>
<div class="outline-text-3" id="text-org678d36c">
<p>As you can see from the sample, the data is still in text form so we need to convert it to a numeric form with a Tokenizer.</p>
<div class="highlight">
<pre><span></span>tokenizer = Tokenizer()
tokenizer.fit_on_texts(training.text.values)
</pre></div>
<div class="highlight">
<pre><span></span>word_index = tokenizer.word_index
vocabulary_size = len(tokenizer.word_index)
</pre></div>
<div class="highlight">
<pre><span></span>sequences = tokenizer.texts_to_sequences(training.text.values)
padded = pad_sequences(sequences, maxlen=Text.max_length,
                       truncating=Text.trunc_type)

splits = train_test_split(
    padded, training.polarity, test_size=.2)

training_sequences, test_sequences, training_labels, test_labels = splits
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9b560ee">
<h3 id="org9b560ee">GloVe</h3>
<div class="outline-text-3" id="text-org9b560ee">
<p>GloVe is short for <i>Global Vectors for Word Representation</i>. It is an <i>unsupervised</i> algorithm that creates vector representations for words. They have a <a href="https://nlp.stanford.edu/projects/glove/">site</a> where you can download pre-trained models or get the code and train one yourself. We're going to use one of their pre-trained models.</p>
<div class="highlight">
<pre><span></span>path = Path("~/models/glove/").expanduser()
url = "http://nlp.stanford.edu/data/glove.6B.zip"
ZipDownloader(url, path)()
</pre></div>
<pre class="example">
Files exist, not downloading

</pre>
<p>The GloVe data is stored as a series of space separated lines with the first column being the word that's encoded and the rest of the columns being the values for the vector. To make this work we're going to split the word off from the vector and put each into a dictionary.</p>
<div class="highlight">
<pre><span></span>embeddings = {}
with open(path/"glove.6B.100d.txt") as lines:
    for line in lines:
        tokens = line.split()
        embeddings[tokens[0]] = numpy.array(tokens[1:])
</pre></div>
<div class="highlight">
<pre><span></span>print(f"{len(embeddings):,}")
</pre></div>
<pre class="example">
400,000

</pre>
<p>So, our vocabulary consists of 400,000 "words" (tokens is more accurate, since they also include punctuation). The problem we have to deal with next is that our data set wasn't part of the dataset used to train the embeddings, so there will probably be some tokens in our data set that aren't in the embeddings. To handle this we need to add zeroed embeddings for the extra tokens.</p>
<p>Rather than adding to the dict, we'll create a matrix of zeros with rows for each word in our datasets vocabulary, then we'll iterate over the words in our dataset and if there's a match in the GloVE embeddings we'll insert it into the matrix.</p>
<div class="highlight">
<pre><span></span>embeddings_matrix = numpy.zeros((vocabulary_size+1, Text.embedding_dim));
for word, index in word_index.items():
    embedding_vector = embeddings.get(word);
    if embedding_vector is not None:
        embeddings_matrix[index] = embedding_vector;
</pre></div>
<div class="highlight">
<pre><span></span>print(f"{len(embeddings_matrix):,}")
</pre></div>
<pre class="example">
690,961

</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orge8bbce5">
<h2 id="orge8bbce5">End</h2>
<div class="outline-text-2" id="text-orge8bbce5"></div>
<div class="outline-3" id="outline-container-orgb1b77eb">
<h3 id="orgb1b77eb">Citations</h3>
<div class="outline-text-3" id="text-orgb1b77eb">
<ul class="org-ul">
<li>Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc31f4fe">
<h2 id="orgc31f4fe">Raw</h2>
<div class="outline-text-2" id="text-orgc31f4fe"></div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/embeddings/" rel="tag">embeddings</a></li>
<li><a class="tag p-category" href="/categories/nlp/" rel="tag">nlp</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/keras/embeddings-from-scratch/" rel="prev" title="Embeddings from Scratch">Previous post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2019 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
