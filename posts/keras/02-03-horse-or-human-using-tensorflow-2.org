#+BEGIN_COMMENT
.. title: Horse Or Human Using TensorFlow 2.0
.. slug: horse-or-human-using-tensorflow-20
.. date: 2019-08-05 12:37:31 UTC-07:00
.. tags: cnn,transfer learning,tensorflow
.. category: Transfer Learning
.. link: 
.. description: Using transfer learning with TensorFlow 2.0 (beta) to classify horses and humans.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+begin_src jupyter-python :session horses :results none :exports none
%load_ext autoreload
%autoreload 2
#+end_src
* Beginning
** Imports
*** Python
#+begin_src jupyter-python :session horses :results none
from functools import partial
from pathlib import Path
#+end_src
*** PyPi
#+begin_src jupyter-python :session horses :results none
from holoviews.operation.datashader import datashade
from tensorflow.keras import layers
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import holoviews
import matplotlib.pyplot as pyplot
import tensorflow
#+end_src

*** Graeae
#+begin_src jupyter-python :session horses :results none
from graeae import EmbedHoloviews, ZipDownloader
#+end_src
** Setup
*** Plotting
#+begin_src jupyter-python :session horses :results none
Embed = partial(
    EmbedHoloviews,
    folder_path="../../files/posts/keras/horse-or-human-using-tensorflow-20")
holoviews.extension("bokeh")
#+end_src
*** Storage
#+begin_src jupyter-python :session horses :results none
MODELS = Path("~/models/horses-vs-humans/").expanduser()
#+end_src
* Middle
** The Data Set
#+begin_src jupyter-python :session horses :results output :exports both
OUTPUT = "~/data/datasets/images/horse-or-human/training/"
URL = ("https://storage.googleapis.com/"
       "laurencemoroney-blog.appspot.com/"
       "horse-or-human.zip")

download = ZipDownloader(url=URL, target=OUTPUT)
download()
#+end_src

#+RESULTS:
:RESULTS:
: 2019-08-13 13:51:57,970 [1mZipDownloader[0m start: ([1mZipDownloader[0m) Started: 2019-08-13 13:51:57.970533
: 2019-08-13 13:51:57,972 [1mZipDownloader[0m download: Downloading the zip file
: 2019-08-13 13:52:08,157 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Ended: 2019-08-13 13:52:08.157484
: 2019-08-13 13:52:08,159 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Elapsed: 0:00:10.186951

#+begin_src jupyter-python :session horses :results none
output_path = download.target
#+end_src

The convention for training models for computer vision appears to be that you use the folder names to label the contents of the images within them. In this case we have =horses= and =humans=.

Here's what some of the files themselves are named.

#+begin_src jupyter-python :session horses :results output :exports both
horses_path = output_path/"horses"
humans_path = output_path/"humans"

for path in (horses_path, humans_path):
    print(path.name)
    for index, image in enumerate(path.iterdir()):
        print(f"File: {image.name}")
        if index == 9:
            break
    print()
#+end_src

#+RESULTS:
#+begin_example
horses
File: horse15-3.png
File: horse12-0.png
File: horse41-4.png
File: horse08-5.png
File: horse49-9.png
File: horse47-9.png
File: horse47-1.png
File: horse44-0.png
File: horse45-9.png
File: horse41-3.png

humans
File: human08-02.png
File: human03-19.png
File: human04-02.png
File: human17-17.png
File: human14-19.png
File: human16-03.png
File: human15-09.png
File: human01-11.png
File: human11-04.png
File: human03-24.png
#+end_example

So, in this case you can tell what they are from the file-names as well. How many images are there?

#+begin_src jupyter-python :session horses :results output :exports both
horse_files = list(horses_path.iterdir())
human_files = list(humans_path.iterdir())
print(f"Horse Images: {len(horse_files)}")
print(f"Human Images: {len(human_files)})")
print(f"Image Shape: {pyplot.imread(str(horse_files[0])).shape}")
#+end_src

#+RESULTS:
: Horse Images: 500
: Human Images: 527)
: Image Shape: (300, 300, 4)

This is sort of a small data-set, and it's odd that there are more humans than horses. Let's see what some of them look like. I'm assuming all the files have the same shape. In this case it looks like they are 300 x 300 with four channels (RGB and alpha?).

#+begin_src jupyter-python :session horses :results output raw :exports both
height = width = 300
count = 4
columns = 2
horse_plots = [datashade(holoviews.RGB.load_image(str(horse)).opts(
    height=height,
    width=width,
))
               for horse in horse_files[:count]]
human_plots = [datashade(holoviews.RGB.load_image(str(human))).opts(
    height=height,
    width=width,
)
               for human in human_files[:count]]

plot = holoviews.Layout(horse_plots + human_plots).cols(2).opts(
    title="Horses and Humans")
Embed(plot=plot, file_name="horses_and_humans", 
      height_in_pixels=900)()
#+end_src

#+RESULTS:
#+begin_export html
<object type="text/html" data="horses_and_humans.html" style="width:100%" height=900>
  <p>Figure Missing</p>
</object>
#+end_export


As you can see, the people in the images aren't really humans (and it may not be so obvious, but they aren't horses either), these are computer-generated images.

** The Model
#+begin_src jupyter-python :session horses :results none
input_shape = (300, 300, 3)
base_model = InceptionV3(input_shape=input_shape, include_top=False)
base_model.trainable = False
#+end_src

#+begin_src jupyter-python :session horses :results output :exports both
print(base_model.summary())
#+end_src

#+RESULTS:
#+begin_example
Model: "inception_v3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 300, 300, 3) 0                                            
__________________________________________________________________________________________________
conv2d_188 (Conv2D)             (None, 149, 149, 32) 864         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_188 (BatchN (None, 149, 149, 32) 96          conv2d_188[0][0]                 
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 149, 149, 32) 0           batch_normalization_188[0][0]    
__________________________________________________________________________________________________
conv2d_189 (Conv2D)             (None, 147, 147, 32) 9216        activation_188[0][0]             
__________________________________________________________________________________________________
batch_normalization_189 (BatchN (None, 147, 147, 32) 96          conv2d_189[0][0]                 
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 147, 147, 32) 0           batch_normalization_189[0][0]    
__________________________________________________________________________________________________
conv2d_190 (Conv2D)             (None, 147, 147, 64) 18432       activation_189[0][0]             
__________________________________________________________________________________________________
batch_normalization_190 (BatchN (None, 147, 147, 64) 192         conv2d_190[0][0]                 
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 147, 147, 64) 0           batch_normalization_190[0][0]    
__________________________________________________________________________________________________
max_pooling2d_8 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_190[0][0]             
__________________________________________________________________________________________________
conv2d_191 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_8[0][0]            
__________________________________________________________________________________________________
batch_normalization_191 (BatchN (None, 73, 73, 80)   240         conv2d_191[0][0]                 
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 73, 73, 80)   0           batch_normalization_191[0][0]    
__________________________________________________________________________________________________
conv2d_192 (Conv2D)             (None, 71, 71, 192)  138240      activation_191[0][0]             
__________________________________________________________________________________________________
batch_normalization_192 (BatchN (None, 71, 71, 192)  576         conv2d_192[0][0]                 
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 71, 71, 192)  0           batch_normalization_192[0][0]    
__________________________________________________________________________________________________
max_pooling2d_9 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_192[0][0]             
__________________________________________________________________________________________________
conv2d_196 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
batch_normalization_196 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_196[0][0]    
__________________________________________________________________________________________________
conv2d_194 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_197 (Conv2D)             (None, 35, 35, 96)   55296       activation_196[0][0]             
__________________________________________________________________________________________________
batch_normalization_194 (BatchN (None, 35, 35, 48)   144         conv2d_194[0][0]                 
__________________________________________________________________________________________________
batch_normalization_197 (BatchN (None, 35, 35, 96)   288         conv2d_197[0][0]                 
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 35, 35, 48)   0           batch_normalization_194[0][0]    
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 35, 35, 96)   0           batch_normalization_197[0][0]    
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_193 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_195 (Conv2D)             (None, 35, 35, 64)   76800       activation_194[0][0]             
__________________________________________________________________________________________________
conv2d_198 (Conv2D)             (None, 35, 35, 96)   82944       activation_197[0][0]             
__________________________________________________________________________________________________
conv2d_199 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
batch_normalization_193 (BatchN (None, 35, 35, 64)   192         conv2d_193[0][0]                 
__________________________________________________________________________________________________
batch_normalization_195 (BatchN (None, 35, 35, 64)   192         conv2d_195[0][0]                 
__________________________________________________________________________________________________
batch_normalization_198 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 
__________________________________________________________________________________________________
batch_normalization_199 (BatchN (None, 35, 35, 32)   96          conv2d_199[0][0]                 
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 35, 35, 64)   0           batch_normalization_193[0][0]    
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 35, 35, 64)   0           batch_normalization_195[0][0]    
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_198[0][0]    
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 35, 35, 32)   0           batch_normalization_199[0][0]    
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_193[0][0]             
                                                                 activation_195[0][0]             
                                                                 activation_198[0][0]             
                                                                 activation_199[0][0]             
__________________________________________________________________________________________________
conv2d_203 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_203 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_203[0][0]    
__________________________________________________________________________________________________
conv2d_201 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_204 (Conv2D)             (None, 35, 35, 96)   55296       activation_203[0][0]             
__________________________________________________________________________________________________
batch_normalization_201 (BatchN (None, 35, 35, 48)   144         conv2d_201[0][0]                 
__________________________________________________________________________________________________
batch_normalization_204 (BatchN (None, 35, 35, 96)   288         conv2d_204[0][0]                 
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 35, 35, 48)   0           batch_normalization_201[0][0]    
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 35, 35, 96)   0           batch_normalization_204[0][0]    
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_200 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_202 (Conv2D)             (None, 35, 35, 64)   76800       activation_201[0][0]             
__________________________________________________________________________________________________
conv2d_205 (Conv2D)             (None, 35, 35, 96)   82944       activation_204[0][0]             
__________________________________________________________________________________________________
conv2d_206 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
batch_normalization_200 (BatchN (None, 35, 35, 64)   192         conv2d_200[0][0]                 
__________________________________________________________________________________________________
batch_normalization_202 (BatchN (None, 35, 35, 64)   192         conv2d_202[0][0]                 
__________________________________________________________________________________________________
batch_normalization_205 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 
__________________________________________________________________________________________________
batch_normalization_206 (BatchN (None, 35, 35, 64)   192         conv2d_206[0][0]                 
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 35, 35, 64)   0           batch_normalization_200[0][0]    
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 35, 35, 64)   0           batch_normalization_202[0][0]    
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_205[0][0]    
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 35, 35, 64)   0           batch_normalization_206[0][0]    
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_200[0][0]             
                                                                 activation_202[0][0]             
                                                                 activation_205[0][0]             
                                                                 activation_206[0][0]             
__________________________________________________________________________________________________
conv2d_210 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    
__________________________________________________________________________________________________
conv2d_208 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_211 (Conv2D)             (None, 35, 35, 96)   55296       activation_210[0][0]             
__________________________________________________________________________________________________
batch_normalization_208 (BatchN (None, 35, 35, 48)   144         conv2d_208[0][0]                 
__________________________________________________________________________________________________
batch_normalization_211 (BatchN (None, 35, 35, 96)   288         conv2d_211[0][0]                 
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 35, 35, 48)   0           batch_normalization_208[0][0]    
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 35, 35, 96)   0           batch_normalization_211[0][0]    
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_207 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_209 (Conv2D)             (None, 35, 35, 64)   76800       activation_208[0][0]             
__________________________________________________________________________________________________
conv2d_212 (Conv2D)             (None, 35, 35, 96)   82944       activation_211[0][0]             
__________________________________________________________________________________________________
conv2d_213 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 
__________________________________________________________________________________________________
batch_normalization_209 (BatchN (None, 35, 35, 64)   192         conv2d_209[0][0]                 
__________________________________________________________________________________________________
batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 
__________________________________________________________________________________________________
batch_normalization_213 (BatchN (None, 35, 35, 64)   192         conv2d_213[0][0]                 
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 35, 35, 64)   0           batch_normalization_209[0][0]    
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 35, 35, 64)   0           batch_normalization_213[0][0]    
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_207[0][0]             
                                                                 activation_209[0][0]             
                                                                 activation_212[0][0]             
                                                                 activation_213[0][0]             
__________________________________________________________________________________________________
conv2d_215 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_215 (BatchN (None, 35, 35, 64)   192         conv2d_215[0][0]                 
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 35, 35, 64)   0           batch_normalization_215[0][0]    
__________________________________________________________________________________________________
conv2d_216 (Conv2D)             (None, 35, 35, 96)   55296       activation_215[0][0]             
__________________________________________________________________________________________________
batch_normalization_216 (BatchN (None, 35, 35, 96)   288         conv2d_216[0][0]                 
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 35, 35, 96)   0           batch_normalization_216[0][0]    
__________________________________________________________________________________________________
conv2d_214 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_217 (Conv2D)             (None, 17, 17, 96)   82944       activation_216[0][0]             
__________________________________________________________________________________________________
batch_normalization_214 (BatchN (None, 17, 17, 384)  1152        conv2d_214[0][0]                 
__________________________________________________________________________________________________
batch_normalization_217 (BatchN (None, 17, 17, 96)   288         conv2d_217[0][0]                 
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 17, 17, 384)  0           batch_normalization_214[0][0]    
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 17, 17, 96)   0           batch_normalization_217[0][0]    
__________________________________________________________________________________________________
max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_214[0][0]             
                                                                 activation_217[0][0]             
                                                                 max_pooling2d_10[0][0]           
__________________________________________________________________________________________________
conv2d_222 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_222 (BatchN (None, 17, 17, 128)  384         conv2d_222[0][0]                 
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 17, 17, 128)  0           batch_normalization_222[0][0]    
__________________________________________________________________________________________________
conv2d_223 (Conv2D)             (None, 17, 17, 128)  114688      activation_222[0][0]             
__________________________________________________________________________________________________
batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    
__________________________________________________________________________________________________
conv2d_219 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             
__________________________________________________________________________________________________
batch_normalization_219 (BatchN (None, 17, 17, 128)  384         conv2d_219[0][0]                 
__________________________________________________________________________________________________
batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 17, 17, 128)  0           batch_normalization_219[0][0]    
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    
__________________________________________________________________________________________________
conv2d_220 (Conv2D)             (None, 17, 17, 128)  114688      activation_219[0][0]             
__________________________________________________________________________________________________
conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             
__________________________________________________________________________________________________
batch_normalization_220 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 
__________________________________________________________________________________________________
batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_220[0][0]    
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_218 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_221 (Conv2D)             (None, 17, 17, 192)  172032      activation_220[0][0]             
__________________________________________________________________________________________________
conv2d_226 (Conv2D)             (None, 17, 17, 192)  172032      activation_225[0][0]             
__________________________________________________________________________________________________
conv2d_227 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_218 (BatchN (None, 17, 17, 192)  576         conv2d_218[0][0]                 
__________________________________________________________________________________________________
batch_normalization_221 (BatchN (None, 17, 17, 192)  576         conv2d_221[0][0]                 
__________________________________________________________________________________________________
batch_normalization_226 (BatchN (None, 17, 17, 192)  576         conv2d_226[0][0]                 
__________________________________________________________________________________________________
batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 17, 17, 192)  0           batch_normalization_218[0][0]    
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 17, 17, 192)  0           batch_normalization_221[0][0]    
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_226[0][0]    
__________________________________________________________________________________________________
activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_218[0][0]             
                                                                 activation_221[0][0]             
                                                                 activation_226[0][0]             
                                                                 activation_227[0][0]             
__________________________________________________________________________________________________
conv2d_232 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_232 (BatchN (None, 17, 17, 160)  480         conv2d_232[0][0]                 
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 17, 17, 160)  0           batch_normalization_232[0][0]    
__________________________________________________________________________________________________
conv2d_233 (Conv2D)             (None, 17, 17, 160)  179200      activation_232[0][0]             
__________________________________________________________________________________________________
batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    
__________________________________________________________________________________________________
conv2d_229 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             
__________________________________________________________________________________________________
batch_normalization_229 (BatchN (None, 17, 17, 160)  480         conv2d_229[0][0]                 
__________________________________________________________________________________________________
batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 17, 17, 160)  0           batch_normalization_229[0][0]    
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    
__________________________________________________________________________________________________
conv2d_230 (Conv2D)             (None, 17, 17, 160)  179200      activation_229[0][0]             
__________________________________________________________________________________________________
conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             
__________________________________________________________________________________________________
batch_normalization_230 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 
__________________________________________________________________________________________________
batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_230[0][0]    
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_231 (Conv2D)             (None, 17, 17, 192)  215040      activation_230[0][0]             
__________________________________________________________________________________________________
conv2d_236 (Conv2D)             (None, 17, 17, 192)  215040      activation_235[0][0]             
__________________________________________________________________________________________________
conv2d_237 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 
__________________________________________________________________________________________________
batch_normalization_231 (BatchN (None, 17, 17, 192)  576         conv2d_231[0][0]                 
__________________________________________________________________________________________________
batch_normalization_236 (BatchN (None, 17, 17, 192)  576         conv2d_236[0][0]                 
__________________________________________________________________________________________________
batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 
__________________________________________________________________________________________________
activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 17, 17, 192)  0           batch_normalization_231[0][0]    
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_236[0][0]    
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_228[0][0]             
                                                                 activation_231[0][0]             
                                                                 activation_236[0][0]             
                                                                 activation_237[0][0]             
__________________________________________________________________________________________________
conv2d_242 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_242 (BatchN (None, 17, 17, 160)  480         conv2d_242[0][0]                 
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 17, 17, 160)  0           batch_normalization_242[0][0]    
__________________________________________________________________________________________________
conv2d_243 (Conv2D)             (None, 17, 17, 160)  179200      activation_242[0][0]             
__________________________________________________________________________________________________
batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    
__________________________________________________________________________________________________
conv2d_239 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             
__________________________________________________________________________________________________
batch_normalization_239 (BatchN (None, 17, 17, 160)  480         conv2d_239[0][0]                 
__________________________________________________________________________________________________
batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 17, 17, 160)  0           batch_normalization_239[0][0]    
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    
__________________________________________________________________________________________________
conv2d_240 (Conv2D)             (None, 17, 17, 160)  179200      activation_239[0][0]             
__________________________________________________________________________________________________
conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             
__________________________________________________________________________________________________
batch_normalization_240 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 
__________________________________________________________________________________________________
batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_240[0][0]    
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_241 (Conv2D)             (None, 17, 17, 192)  215040      activation_240[0][0]             
__________________________________________________________________________________________________
conv2d_246 (Conv2D)             (None, 17, 17, 192)  215040      activation_245[0][0]             
__________________________________________________________________________________________________
conv2d_247 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 
__________________________________________________________________________________________________
batch_normalization_241 (BatchN (None, 17, 17, 192)  576         conv2d_241[0][0]                 
__________________________________________________________________________________________________
batch_normalization_246 (BatchN (None, 17, 17, 192)  576         conv2d_246[0][0]                 
__________________________________________________________________________________________________
batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 17, 17, 192)  0           batch_normalization_241[0][0]    
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_246[0][0]    
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_238[0][0]             
                                                                 activation_241[0][0]             
                                                                 activation_246[0][0]             
                                                                 activation_247[0][0]             
__________________________________________________________________________________________________
conv2d_252 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    
__________________________________________________________________________________________________
conv2d_253 (Conv2D)             (None, 17, 17, 192)  258048      activation_252[0][0]             
__________________________________________________________________________________________________
batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    
__________________________________________________________________________________________________
conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             
__________________________________________________________________________________________________
batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 
__________________________________________________________________________________________________
batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    
__________________________________________________________________________________________________
conv2d_250 (Conv2D)             (None, 17, 17, 192)  258048      activation_249[0][0]             
__________________________________________________________________________________________________
conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             
__________________________________________________________________________________________________
batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 
__________________________________________________________________________________________________
batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    
__________________________________________________________________________________________________
average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             
__________________________________________________________________________________________________
conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             
__________________________________________________________________________________________________
conv2d_257 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 
__________________________________________________________________________________________________
batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 
__________________________________________________________________________________________________
batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 
__________________________________________________________________________________________________
batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_248[0][0]             
                                                                 activation_251[0][0]             
                                                                 activation_256[0][0]             
                                                                 activation_257[0][0]             
__________________________________________________________________________________________________
conv2d_260 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_260 (BatchN (None, 17, 17, 192)  576         conv2d_260[0][0]                 
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 17, 17, 192)  0           batch_normalization_260[0][0]    
__________________________________________________________________________________________________
conv2d_261 (Conv2D)             (None, 17, 17, 192)  258048      activation_260[0][0]             
__________________________________________________________________________________________________
batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 
__________________________________________________________________________________________________
activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    
__________________________________________________________________________________________________
conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             
__________________________________________________________________________________________________
batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 
__________________________________________________________________________________________________
batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    
__________________________________________________________________________________________________
activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    
__________________________________________________________________________________________________
conv2d_259 (Conv2D)             (None, 8, 8, 320)    552960      activation_258[0][0]             
__________________________________________________________________________________________________
conv2d_263 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             
__________________________________________________________________________________________________
batch_normalization_259 (BatchN (None, 8, 8, 320)    960         conv2d_259[0][0]                 
__________________________________________________________________________________________________
batch_normalization_263 (BatchN (None, 8, 8, 192)    576         conv2d_263[0][0]                 
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 8, 8, 320)    0           batch_normalization_259[0][0]    
__________________________________________________________________________________________________
activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_263[0][0]    
__________________________________________________________________________________________________
max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_259[0][0]             
                                                                 activation_263[0][0]             
                                                                 max_pooling2d_11[0][0]           
__________________________________________________________________________________________________
conv2d_268 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_268 (BatchN (None, 8, 8, 448)    1344        conv2d_268[0][0]                 
__________________________________________________________________________________________________
activation_268 (Activation)     (None, 8, 8, 448)    0           batch_normalization_268[0][0]    
__________________________________________________________________________________________________
conv2d_265 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_269 (Conv2D)             (None, 8, 8, 384)    1548288     activation_268[0][0]             
__________________________________________________________________________________________________
batch_normalization_265 (BatchN (None, 8, 8, 384)    1152        conv2d_265[0][0]                 
__________________________________________________________________________________________________
batch_normalization_269 (BatchN (None, 8, 8, 384)    1152        conv2d_269[0][0]                 
__________________________________________________________________________________________________
activation_265 (Activation)     (None, 8, 8, 384)    0           batch_normalization_265[0][0]    
__________________________________________________________________________________________________
activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_269[0][0]    
__________________________________________________________________________________________________
conv2d_266 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             
__________________________________________________________________________________________________
conv2d_267 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             
__________________________________________________________________________________________________
conv2d_270 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             
__________________________________________________________________________________________________
conv2d_271 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_264 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_266 (BatchN (None, 8, 8, 384)    1152        conv2d_266[0][0]                 
__________________________________________________________________________________________________
batch_normalization_267 (BatchN (None, 8, 8, 384)    1152        conv2d_267[0][0]                 
__________________________________________________________________________________________________
batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_270[0][0]                 
__________________________________________________________________________________________________
batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_271[0][0]                 
__________________________________________________________________________________________________
conv2d_272 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
batch_normalization_264 (BatchN (None, 8, 8, 320)    960         conv2d_264[0][0]                 
__________________________________________________________________________________________________
activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_266[0][0]    
__________________________________________________________________________________________________
activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_267[0][0]    
__________________________________________________________________________________________________
activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    
__________________________________________________________________________________________________
activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    
__________________________________________________________________________________________________
batch_normalization_272 (BatchN (None, 8, 8, 192)    576         conv2d_272[0][0]                 
__________________________________________________________________________________________________
activation_264 (Activation)     (None, 8, 8, 320)    0           batch_normalization_264[0][0]    
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_266[0][0]             
                                                                 activation_267[0][0]             
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_270[0][0]             
                                                                 activation_271[0][0]             
__________________________________________________________________________________________________
activation_272 (Activation)     (None, 8, 8, 192)    0           batch_normalization_272[0][0]    
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_264[0][0]             
                                                                 mixed9_0[0][0]                   
                                                                 concatenate_4[0][0]              
                                                                 activation_272[0][0]             
__________________________________________________________________________________________________
conv2d_277 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_277 (BatchN (None, 8, 8, 448)    1344        conv2d_277[0][0]                 
__________________________________________________________________________________________________
activation_277 (Activation)     (None, 8, 8, 448)    0           batch_normalization_277[0][0]    
__________________________________________________________________________________________________
conv2d_274 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_278 (Conv2D)             (None, 8, 8, 384)    1548288     activation_277[0][0]             
__________________________________________________________________________________________________
batch_normalization_274 (BatchN (None, 8, 8, 384)    1152        conv2d_274[0][0]                 
__________________________________________________________________________________________________
batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_278[0][0]                 
__________________________________________________________________________________________________
activation_274 (Activation)     (None, 8, 8, 384)    0           batch_normalization_274[0][0]    
__________________________________________________________________________________________________
activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    
__________________________________________________________________________________________________
conv2d_275 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             
__________________________________________________________________________________________________
conv2d_276 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             
__________________________________________________________________________________________________
conv2d_279 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             
__________________________________________________________________________________________________
conv2d_280 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_273 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 
__________________________________________________________________________________________________
batch_normalization_276 (BatchN (None, 8, 8, 384)    1152        conv2d_276[0][0]                 
__________________________________________________________________________________________________
batch_normalization_279 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 
__________________________________________________________________________________________________
batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_280[0][0]                 
__________________________________________________________________________________________________
conv2d_281 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
batch_normalization_273 (BatchN (None, 8, 8, 320)    960         conv2d_273[0][0]                 
__________________________________________________________________________________________________
activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    
__________________________________________________________________________________________________
activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_276[0][0]    
__________________________________________________________________________________________________
activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_279[0][0]    
__________________________________________________________________________________________________
activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    
__________________________________________________________________________________________________
batch_normalization_281 (BatchN (None, 8, 8, 192)    576         conv2d_281[0][0]                 
__________________________________________________________________________________________________
activation_273 (Activation)     (None, 8, 8, 320)    0           batch_normalization_273[0][0]    
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_275[0][0]             
                                                                 activation_276[0][0]             
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_279[0][0]             
                                                                 activation_280[0][0]             
__________________________________________________________________________________________________
activation_281 (Activation)     (None, 8, 8, 192)    0           batch_normalization_281[0][0]    
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_273[0][0]             
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_5[0][0]              
                                                                 activation_281[0][0]             
==================================================================================================
Total params: 21,802,784
Trainable params: 0
Non-trainable params: 21,802,784
__________________________________________________________________________________________________
None
#+end_example

*** Create the Output Layers
#+begin_src jupyter-python :session horses :results none
x = layers.GlobalAveragePooling2D()(base_model.output)
x = layers.Dense(1024, activation="relu")(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(1, activation="sigmoid")(x)
#+end_src

Now build the model combining the pre-built layer with a Dense layer (that we're going to train). Since we only have two classes the activation function is the /sigmoid/.

#+begin_src jupyter-python :session horses :results output :exports both
model = tensorflow.keras.Model(
    base_model.input,
    x,
)
print(model.summary())
#+end_src

#+RESULTS:
#+begin_example
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 300, 300, 3) 0                                            
__________________________________________________________________________________________________
conv2d_188 (Conv2D)             (None, 149, 149, 32) 864         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_188 (BatchN (None, 149, 149, 32) 96          conv2d_188[0][0]                 
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 149, 149, 32) 0           batch_normalization_188[0][0]    
__________________________________________________________________________________________________
conv2d_189 (Conv2D)             (None, 147, 147, 32) 9216        activation_188[0][0]             
__________________________________________________________________________________________________
batch_normalization_189 (BatchN (None, 147, 147, 32) 96          conv2d_189[0][0]                 
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 147, 147, 32) 0           batch_normalization_189[0][0]    
__________________________________________________________________________________________________
conv2d_190 (Conv2D)             (None, 147, 147, 64) 18432       activation_189[0][0]             
__________________________________________________________________________________________________
batch_normalization_190 (BatchN (None, 147, 147, 64) 192         conv2d_190[0][0]                 
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 147, 147, 64) 0           batch_normalization_190[0][0]    
__________________________________________________________________________________________________
max_pooling2d_8 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_190[0][0]             
__________________________________________________________________________________________________
conv2d_191 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_8[0][0]            
__________________________________________________________________________________________________
batch_normalization_191 (BatchN (None, 73, 73, 80)   240         conv2d_191[0][0]                 
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 73, 73, 80)   0           batch_normalization_191[0][0]    
__________________________________________________________________________________________________
conv2d_192 (Conv2D)             (None, 71, 71, 192)  138240      activation_191[0][0]             
__________________________________________________________________________________________________
batch_normalization_192 (BatchN (None, 71, 71, 192)  576         conv2d_192[0][0]                 
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 71, 71, 192)  0           batch_normalization_192[0][0]    
__________________________________________________________________________________________________
max_pooling2d_9 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_192[0][0]             
__________________________________________________________________________________________________
conv2d_196 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
batch_normalization_196 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_196[0][0]    
__________________________________________________________________________________________________
conv2d_194 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_197 (Conv2D)             (None, 35, 35, 96)   55296       activation_196[0][0]             
__________________________________________________________________________________________________
batch_normalization_194 (BatchN (None, 35, 35, 48)   144         conv2d_194[0][0]                 
__________________________________________________________________________________________________
batch_normalization_197 (BatchN (None, 35, 35, 96)   288         conv2d_197[0][0]                 
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 35, 35, 48)   0           batch_normalization_194[0][0]    
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 35, 35, 96)   0           batch_normalization_197[0][0]    
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_193 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            
__________________________________________________________________________________________________
conv2d_195 (Conv2D)             (None, 35, 35, 64)   76800       activation_194[0][0]             
__________________________________________________________________________________________________
conv2d_198 (Conv2D)             (None, 35, 35, 96)   82944       activation_197[0][0]             
__________________________________________________________________________________________________
conv2d_199 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
batch_normalization_193 (BatchN (None, 35, 35, 64)   192         conv2d_193[0][0]                 
__________________________________________________________________________________________________
batch_normalization_195 (BatchN (None, 35, 35, 64)   192         conv2d_195[0][0]                 
__________________________________________________________________________________________________
batch_normalization_198 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 
__________________________________________________________________________________________________
batch_normalization_199 (BatchN (None, 35, 35, 32)   96          conv2d_199[0][0]                 
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 35, 35, 64)   0           batch_normalization_193[0][0]    
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 35, 35, 64)   0           batch_normalization_195[0][0]    
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_198[0][0]    
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 35, 35, 32)   0           batch_normalization_199[0][0]    
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_193[0][0]             
                                                                 activation_195[0][0]             
                                                                 activation_198[0][0]             
                                                                 activation_199[0][0]             
__________________________________________________________________________________________________
conv2d_203 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_203 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_203[0][0]    
__________________________________________________________________________________________________
conv2d_201 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_204 (Conv2D)             (None, 35, 35, 96)   55296       activation_203[0][0]             
__________________________________________________________________________________________________
batch_normalization_201 (BatchN (None, 35, 35, 48)   144         conv2d_201[0][0]                 
__________________________________________________________________________________________________
batch_normalization_204 (BatchN (None, 35, 35, 96)   288         conv2d_204[0][0]                 
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 35, 35, 48)   0           batch_normalization_201[0][0]    
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 35, 35, 96)   0           batch_normalization_204[0][0]    
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_200 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_202 (Conv2D)             (None, 35, 35, 64)   76800       activation_201[0][0]             
__________________________________________________________________________________________________
conv2d_205 (Conv2D)             (None, 35, 35, 96)   82944       activation_204[0][0]             
__________________________________________________________________________________________________
conv2d_206 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
batch_normalization_200 (BatchN (None, 35, 35, 64)   192         conv2d_200[0][0]                 
__________________________________________________________________________________________________
batch_normalization_202 (BatchN (None, 35, 35, 64)   192         conv2d_202[0][0]                 
__________________________________________________________________________________________________
batch_normalization_205 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 
__________________________________________________________________________________________________
batch_normalization_206 (BatchN (None, 35, 35, 64)   192         conv2d_206[0][0]                 
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 35, 35, 64)   0           batch_normalization_200[0][0]    
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 35, 35, 64)   0           batch_normalization_202[0][0]    
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_205[0][0]    
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 35, 35, 64)   0           batch_normalization_206[0][0]    
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_200[0][0]             
                                                                 activation_202[0][0]             
                                                                 activation_205[0][0]             
                                                                 activation_206[0][0]             
__________________________________________________________________________________________________
conv2d_210 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    
__________________________________________________________________________________________________
conv2d_208 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_211 (Conv2D)             (None, 35, 35, 96)   55296       activation_210[0][0]             
__________________________________________________________________________________________________
batch_normalization_208 (BatchN (None, 35, 35, 48)   144         conv2d_208[0][0]                 
__________________________________________________________________________________________________
batch_normalization_211 (BatchN (None, 35, 35, 96)   288         conv2d_211[0][0]                 
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 35, 35, 48)   0           batch_normalization_208[0][0]    
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 35, 35, 96)   0           batch_normalization_211[0][0]    
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_207 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_209 (Conv2D)             (None, 35, 35, 64)   76800       activation_208[0][0]             
__________________________________________________________________________________________________
conv2d_212 (Conv2D)             (None, 35, 35, 96)   82944       activation_211[0][0]             
__________________________________________________________________________________________________
conv2d_213 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 
__________________________________________________________________________________________________
batch_normalization_209 (BatchN (None, 35, 35, 64)   192         conv2d_209[0][0]                 
__________________________________________________________________________________________________
batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 
__________________________________________________________________________________________________
batch_normalization_213 (BatchN (None, 35, 35, 64)   192         conv2d_213[0][0]                 
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 35, 35, 64)   0           batch_normalization_209[0][0]    
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 35, 35, 64)   0           batch_normalization_213[0][0]    
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_207[0][0]             
                                                                 activation_209[0][0]             
                                                                 activation_212[0][0]             
                                                                 activation_213[0][0]             
__________________________________________________________________________________________________
conv2d_215 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_215 (BatchN (None, 35, 35, 64)   192         conv2d_215[0][0]                 
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 35, 35, 64)   0           batch_normalization_215[0][0]    
__________________________________________________________________________________________________
conv2d_216 (Conv2D)             (None, 35, 35, 96)   55296       activation_215[0][0]             
__________________________________________________________________________________________________
batch_normalization_216 (BatchN (None, 35, 35, 96)   288         conv2d_216[0][0]                 
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 35, 35, 96)   0           batch_normalization_216[0][0]    
__________________________________________________________________________________________________
conv2d_214 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_217 (Conv2D)             (None, 17, 17, 96)   82944       activation_216[0][0]             
__________________________________________________________________________________________________
batch_normalization_214 (BatchN (None, 17, 17, 384)  1152        conv2d_214[0][0]                 
__________________________________________________________________________________________________
batch_normalization_217 (BatchN (None, 17, 17, 96)   288         conv2d_217[0][0]                 
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 17, 17, 384)  0           batch_normalization_214[0][0]    
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 17, 17, 96)   0           batch_normalization_217[0][0]    
__________________________________________________________________________________________________
max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_214[0][0]             
                                                                 activation_217[0][0]             
                                                                 max_pooling2d_10[0][0]           
__________________________________________________________________________________________________
conv2d_222 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_222 (BatchN (None, 17, 17, 128)  384         conv2d_222[0][0]                 
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 17, 17, 128)  0           batch_normalization_222[0][0]    
__________________________________________________________________________________________________
conv2d_223 (Conv2D)             (None, 17, 17, 128)  114688      activation_222[0][0]             
__________________________________________________________________________________________________
batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    
__________________________________________________________________________________________________
conv2d_219 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             
__________________________________________________________________________________________________
batch_normalization_219 (BatchN (None, 17, 17, 128)  384         conv2d_219[0][0]                 
__________________________________________________________________________________________________
batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 17, 17, 128)  0           batch_normalization_219[0][0]    
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    
__________________________________________________________________________________________________
conv2d_220 (Conv2D)             (None, 17, 17, 128)  114688      activation_219[0][0]             
__________________________________________________________________________________________________
conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             
__________________________________________________________________________________________________
batch_normalization_220 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 
__________________________________________________________________________________________________
batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_220[0][0]    
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_218 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_221 (Conv2D)             (None, 17, 17, 192)  172032      activation_220[0][0]             
__________________________________________________________________________________________________
conv2d_226 (Conv2D)             (None, 17, 17, 192)  172032      activation_225[0][0]             
__________________________________________________________________________________________________
conv2d_227 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_218 (BatchN (None, 17, 17, 192)  576         conv2d_218[0][0]                 
__________________________________________________________________________________________________
batch_normalization_221 (BatchN (None, 17, 17, 192)  576         conv2d_221[0][0]                 
__________________________________________________________________________________________________
batch_normalization_226 (BatchN (None, 17, 17, 192)  576         conv2d_226[0][0]                 
__________________________________________________________________________________________________
batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 17, 17, 192)  0           batch_normalization_218[0][0]    
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 17, 17, 192)  0           batch_normalization_221[0][0]    
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_226[0][0]    
__________________________________________________________________________________________________
activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_218[0][0]             
                                                                 activation_221[0][0]             
                                                                 activation_226[0][0]             
                                                                 activation_227[0][0]             
__________________________________________________________________________________________________
conv2d_232 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_232 (BatchN (None, 17, 17, 160)  480         conv2d_232[0][0]                 
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 17, 17, 160)  0           batch_normalization_232[0][0]    
__________________________________________________________________________________________________
conv2d_233 (Conv2D)             (None, 17, 17, 160)  179200      activation_232[0][0]             
__________________________________________________________________________________________________
batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    
__________________________________________________________________________________________________
conv2d_229 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             
__________________________________________________________________________________________________
batch_normalization_229 (BatchN (None, 17, 17, 160)  480         conv2d_229[0][0]                 
__________________________________________________________________________________________________
batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 17, 17, 160)  0           batch_normalization_229[0][0]    
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    
__________________________________________________________________________________________________
conv2d_230 (Conv2D)             (None, 17, 17, 160)  179200      activation_229[0][0]             
__________________________________________________________________________________________________
conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             
__________________________________________________________________________________________________
batch_normalization_230 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 
__________________________________________________________________________________________________
batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_230[0][0]    
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_231 (Conv2D)             (None, 17, 17, 192)  215040      activation_230[0][0]             
__________________________________________________________________________________________________
conv2d_236 (Conv2D)             (None, 17, 17, 192)  215040      activation_235[0][0]             
__________________________________________________________________________________________________
conv2d_237 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 
__________________________________________________________________________________________________
batch_normalization_231 (BatchN (None, 17, 17, 192)  576         conv2d_231[0][0]                 
__________________________________________________________________________________________________
batch_normalization_236 (BatchN (None, 17, 17, 192)  576         conv2d_236[0][0]                 
__________________________________________________________________________________________________
batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 
__________________________________________________________________________________________________
activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 17, 17, 192)  0           batch_normalization_231[0][0]    
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_236[0][0]    
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_228[0][0]             
                                                                 activation_231[0][0]             
                                                                 activation_236[0][0]             
                                                                 activation_237[0][0]             
__________________________________________________________________________________________________
conv2d_242 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_242 (BatchN (None, 17, 17, 160)  480         conv2d_242[0][0]                 
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 17, 17, 160)  0           batch_normalization_242[0][0]    
__________________________________________________________________________________________________
conv2d_243 (Conv2D)             (None, 17, 17, 160)  179200      activation_242[0][0]             
__________________________________________________________________________________________________
batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    
__________________________________________________________________________________________________
conv2d_239 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             
__________________________________________________________________________________________________
batch_normalization_239 (BatchN (None, 17, 17, 160)  480         conv2d_239[0][0]                 
__________________________________________________________________________________________________
batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 17, 17, 160)  0           batch_normalization_239[0][0]    
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    
__________________________________________________________________________________________________
conv2d_240 (Conv2D)             (None, 17, 17, 160)  179200      activation_239[0][0]             
__________________________________________________________________________________________________
conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             
__________________________________________________________________________________________________
batch_normalization_240 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 
__________________________________________________________________________________________________
batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_240[0][0]    
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_241 (Conv2D)             (None, 17, 17, 192)  215040      activation_240[0][0]             
__________________________________________________________________________________________________
conv2d_246 (Conv2D)             (None, 17, 17, 192)  215040      activation_245[0][0]             
__________________________________________________________________________________________________
conv2d_247 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 
__________________________________________________________________________________________________
batch_normalization_241 (BatchN (None, 17, 17, 192)  576         conv2d_241[0][0]                 
__________________________________________________________________________________________________
batch_normalization_246 (BatchN (None, 17, 17, 192)  576         conv2d_246[0][0]                 
__________________________________________________________________________________________________
batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 17, 17, 192)  0           batch_normalization_241[0][0]    
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_246[0][0]    
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_238[0][0]             
                                                                 activation_241[0][0]             
                                                                 activation_246[0][0]             
                                                                 activation_247[0][0]             
__________________________________________________________________________________________________
conv2d_252 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    
__________________________________________________________________________________________________
conv2d_253 (Conv2D)             (None, 17, 17, 192)  258048      activation_252[0][0]             
__________________________________________________________________________________________________
batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    
__________________________________________________________________________________________________
conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             
__________________________________________________________________________________________________
batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 
__________________________________________________________________________________________________
batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    
__________________________________________________________________________________________________
conv2d_250 (Conv2D)             (None, 17, 17, 192)  258048      activation_249[0][0]             
__________________________________________________________________________________________________
conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             
__________________________________________________________________________________________________
batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 
__________________________________________________________________________________________________
batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    
__________________________________________________________________________________________________
average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             
__________________________________________________________________________________________________
conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             
__________________________________________________________________________________________________
conv2d_257 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 
__________________________________________________________________________________________________
batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 
__________________________________________________________________________________________________
batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 
__________________________________________________________________________________________________
batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_248[0][0]             
                                                                 activation_251[0][0]             
                                                                 activation_256[0][0]             
                                                                 activation_257[0][0]             
__________________________________________________________________________________________________
conv2d_260 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_260 (BatchN (None, 17, 17, 192)  576         conv2d_260[0][0]                 
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 17, 17, 192)  0           batch_normalization_260[0][0]    
__________________________________________________________________________________________________
conv2d_261 (Conv2D)             (None, 17, 17, 192)  258048      activation_260[0][0]             
__________________________________________________________________________________________________
batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 
__________________________________________________________________________________________________
activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    
__________________________________________________________________________________________________
conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             
__________________________________________________________________________________________________
batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 
__________________________________________________________________________________________________
batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    
__________________________________________________________________________________________________
activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    
__________________________________________________________________________________________________
conv2d_259 (Conv2D)             (None, 8, 8, 320)    552960      activation_258[0][0]             
__________________________________________________________________________________________________
conv2d_263 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             
__________________________________________________________________________________________________
batch_normalization_259 (BatchN (None, 8, 8, 320)    960         conv2d_259[0][0]                 
__________________________________________________________________________________________________
batch_normalization_263 (BatchN (None, 8, 8, 192)    576         conv2d_263[0][0]                 
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 8, 8, 320)    0           batch_normalization_259[0][0]    
__________________________________________________________________________________________________
activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_263[0][0]    
__________________________________________________________________________________________________
max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_259[0][0]             
                                                                 activation_263[0][0]             
                                                                 max_pooling2d_11[0][0]           
__________________________________________________________________________________________________
conv2d_268 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_268 (BatchN (None, 8, 8, 448)    1344        conv2d_268[0][0]                 
__________________________________________________________________________________________________
activation_268 (Activation)     (None, 8, 8, 448)    0           batch_normalization_268[0][0]    
__________________________________________________________________________________________________
conv2d_265 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_269 (Conv2D)             (None, 8, 8, 384)    1548288     activation_268[0][0]             
__________________________________________________________________________________________________
batch_normalization_265 (BatchN (None, 8, 8, 384)    1152        conv2d_265[0][0]                 
__________________________________________________________________________________________________
batch_normalization_269 (BatchN (None, 8, 8, 384)    1152        conv2d_269[0][0]                 
__________________________________________________________________________________________________
activation_265 (Activation)     (None, 8, 8, 384)    0           batch_normalization_265[0][0]    
__________________________________________________________________________________________________
activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_269[0][0]    
__________________________________________________________________________________________________
conv2d_266 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             
__________________________________________________________________________________________________
conv2d_267 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             
__________________________________________________________________________________________________
conv2d_270 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             
__________________________________________________________________________________________________
conv2d_271 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_264 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_266 (BatchN (None, 8, 8, 384)    1152        conv2d_266[0][0]                 
__________________________________________________________________________________________________
batch_normalization_267 (BatchN (None, 8, 8, 384)    1152        conv2d_267[0][0]                 
__________________________________________________________________________________________________
batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_270[0][0]                 
__________________________________________________________________________________________________
batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_271[0][0]                 
__________________________________________________________________________________________________
conv2d_272 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
batch_normalization_264 (BatchN (None, 8, 8, 320)    960         conv2d_264[0][0]                 
__________________________________________________________________________________________________
activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_266[0][0]    
__________________________________________________________________________________________________
activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_267[0][0]    
__________________________________________________________________________________________________
activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    
__________________________________________________________________________________________________
activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    
__________________________________________________________________________________________________
batch_normalization_272 (BatchN (None, 8, 8, 192)    576         conv2d_272[0][0]                 
__________________________________________________________________________________________________
activation_264 (Activation)     (None, 8, 8, 320)    0           batch_normalization_264[0][0]    
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_266[0][0]             
                                                                 activation_267[0][0]             
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_270[0][0]             
                                                                 activation_271[0][0]             
__________________________________________________________________________________________________
activation_272 (Activation)     (None, 8, 8, 192)    0           batch_normalization_272[0][0]    
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_264[0][0]             
                                                                 mixed9_0[0][0]                   
                                                                 concatenate_4[0][0]              
                                                                 activation_272[0][0]             
__________________________________________________________________________________________________
conv2d_277 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_277 (BatchN (None, 8, 8, 448)    1344        conv2d_277[0][0]                 
__________________________________________________________________________________________________
activation_277 (Activation)     (None, 8, 8, 448)    0           batch_normalization_277[0][0]    
__________________________________________________________________________________________________
conv2d_274 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_278 (Conv2D)             (None, 8, 8, 384)    1548288     activation_277[0][0]             
__________________________________________________________________________________________________
batch_normalization_274 (BatchN (None, 8, 8, 384)    1152        conv2d_274[0][0]                 
__________________________________________________________________________________________________
batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_278[0][0]                 
__________________________________________________________________________________________________
activation_274 (Activation)     (None, 8, 8, 384)    0           batch_normalization_274[0][0]    
__________________________________________________________________________________________________
activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    
__________________________________________________________________________________________________
conv2d_275 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             
__________________________________________________________________________________________________
conv2d_276 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             
__________________________________________________________________________________________________
conv2d_279 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             
__________________________________________________________________________________________________
conv2d_280 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_273 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 
__________________________________________________________________________________________________
batch_normalization_276 (BatchN (None, 8, 8, 384)    1152        conv2d_276[0][0]                 
__________________________________________________________________________________________________
batch_normalization_279 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 
__________________________________________________________________________________________________
batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_280[0][0]                 
__________________________________________________________________________________________________
conv2d_281 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
batch_normalization_273 (BatchN (None, 8, 8, 320)    960         conv2d_273[0][0]                 
__________________________________________________________________________________________________
activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    
__________________________________________________________________________________________________
activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_276[0][0]    
__________________________________________________________________________________________________
activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_279[0][0]    
__________________________________________________________________________________________________
activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    
__________________________________________________________________________________________________
batch_normalization_281 (BatchN (None, 8, 8, 192)    576         conv2d_281[0][0]                 
__________________________________________________________________________________________________
activation_273 (Activation)     (None, 8, 8, 320)    0           batch_normalization_273[0][0]    
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_275[0][0]             
                                                                 activation_276[0][0]             
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_279[0][0]             
                                                                 activation_280[0][0]             
__________________________________________________________________________________________________
activation_281 (Activation)     (None, 8, 8, 192)    0           batch_normalization_281[0][0]    
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_273[0][0]             
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_5[0][0]              
                                                                 activation_281[0][0]             
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1024)         0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    
==================================================================================================
Total params: 23,901,985
Trainable params: 2,099,201
Non-trainable params: 21,802,784
__________________________________________________________________________________________________
None
#+end_example
** Compile the Model
#+begin_src jupyter-python :session horses :results none
model.compile(optimizer = RMSprop(lr=0.0001), 
              loss = 'binary_crossentropy', 
              metrics = ['acc'])
#+end_src
** Train the Model
*** A Model Saver
#+begin_src jupyter-python :session horses :results none
checkpoint = tensorflow.keras.callbacks.ModelCheckpoint(
    str(MODELS/"inception_transfer.hdf5"), monitor="val_acc", verbose=1, 
    save_best_only=True)
#+end_src
*** A Data Generator
    This bundles up the steps to build the data generator.

#+begin_src jupyter-python :session horses :results none
class Data:
    """creates the data generators

    Args:
     path: path to the images
     validation_split: fraction that goes to the validation set
     batch_size: size for the batches in the epochs
    """
    def __init__(self, path: str, validation_split: float=0.2,
                 batch_size: int=20) -> None:
        self.path = path
        self.validation_split = validation_split
        self.batch_size = batch_size
        self._data_generator = None
        self._testing_data_generator = None
        self._training_generator = None
        self._validation_generator = None
        return
    
    @property
    def data_generator(self) -> ImageDataGenerator:
        """The data generator for training and validation"""
        if self._data_generator is None:
            self._data_generator = ImageDataGenerator(
                rescale=1/255,
                rotation_range=40,
                width_shift_range=0.2,
                height_shift_range=0.2,
                horizontal_flip=True,
                shear_range=0.2,
                zoom_range=0.2,
                fill_mode="nearest",
                validation_split=self.validation_split)
        return self._data_generator
    
    @property
    def training_generator(self):
        """The training data generator"""
        if self._training_generator is None:
            self._training_generator = (self.data_generator
                                        .flow_from_directory)(
                                            self.path,
                                            batch_size=self.batch_size,
                                            class_mode="binary",
                                            target_size=(150, 150),
                                            subset="training",
            )
        return self._training_generator
    
    @property
    def validation_generator(self):
        """the validation data generator"""
        if self._validation_generator is None:
            self._validation_generator = (self.data_generator
                                          .flow_from_directory)(
                                              self.path,
                                              batch_size=self.batch_size,
                                              class_mode="binary",
                                              target_size = (150, 150),
                                              subset="validation",
            )
        return self._validation_generator
    
    def __str__(self) -> str:
        return (f"(Data) - Path: {self.path}, "
                f"Validation Split: {self.validation_split},"
                f"Batch Size: {self.batch_size}")
#+end_src

*** A Model Builder
#+begin_src jupyter-python :session horses :results none
class Network:
    """The model to categorize the images

    Args:
     model: model to train
     path: path to the training data
     epochs: number of epochs to train
     batch_size: size of the batches for each epoch
     convolution_layers: layers of cnn/max-pooling
     callbacks: things to stop the training
     set_steps: whether to set the training steps-per-epoch
    """
    def __init__(self, model, path: str, epochs: int=15,
                 batch_size: int=128, convolution_layers: int=3,
                 set_steps: bool=True,
                 callbacks: list=None) -> None:
        self.model = model
        self.path = path
        self.epochs = epochs
        self.batch_size = batch_size
        self.convolution_layers = convolution_layers
        self.set_steps = set_steps
        self.callbacks = callbacks
        self._data = None
        self._model = None
        self.history = None
        return
    
    @property
    def data(self) -> Data:
        """The data generator builder"""
        if self._data is None:
            self._data = Data(self.path, batch_size=self.batch_size)
        return self._data

    def summary(self) -> None:
        """Prints the model summary"""
        print(self.model.summary())
        return

    def train(self) -> None:
        """Trains the model"""
        callbacks = self.callbacks if self.callbacks else []
        arguments = dict(
            generator=self.data.training_generator,
            validation_data=self.data.validation_generator,
            epochs = self.epochs,
            callbacks = callbacks,
            verbose=2,
        )
        if self.set_steps:
            arguments["steps_per_epoch"] = int(
                self.data.training_generator.samples/self.batch_size)
            arguments["validation_steps"] = int(
                self.data.validation_generator.samples/self.batch_size)
            
        self.history = self.model.fit_generator(**arguments)
        return
    
    def __str__(self) -> str:
        return (f"(Network) - \nPath: {self.path}\n Epochs: {self.epochs}\n "
                f"Batch Size: {self.batch_size}\n Callbacks: {self.callbacks}\n"
                f"Data: {self.data}\n"
                f"Callbacks: {self.callbacks}")
#+end_src
** Train It
#+begin_src jupyter-python :session horses :results output :exports both
network = Network(str(training_path), 
                  set_steps = True,
                  epochs = 10,
                  callbacks=[checkpoint],
                  batch_size=1)
network._model = model
with TIMER:
    network.train()
#+end_src

#+RESULTS:
#+begin_example
2019-08-03 19:28:04,102 graeae.timers.timer start: Started: 2019-08-03 19:28:04.102954
I0803 19:28:04.102986 139918777980736 timer.py:70] Started: 2019-08-03 19:28:04.102954
Found 20000 images belonging to 2 classes.
Found 5000 images belonging to 2 classes.
Epoch 1/10

Epoch 00001: val_acc improved from -inf to 0.43660, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 615s - loss: 0.7032 - acc: 0.4977 - val_loss: 0.8069 - val_acc: 0.4366
Epoch 2/10

Epoch 00002: val_acc improved from 0.43660 to 0.43780, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 631s - loss: 0.6933 - acc: 0.5049 - val_loss: 0.7958 - val_acc: 0.4378
Epoch 3/10

Epoch 00003: val_acc did not improve from 0.43780
20000/20000 - 670s - loss: 0.6932 - acc: 0.4990 - val_loss: 0.8142 - val_acc: 0.4230
Epoch 4/10

Epoch 00004: val_acc improved from 0.43780 to 0.45020, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 666s - loss: 0.6932 - acc: 0.4990 - val_loss: 0.7856 - val_acc: 0.4502
Epoch 5/10

Epoch 00005: val_acc did not improve from 0.45020
20000/20000 - 636s - loss: 0.6932 - acc: 0.4983 - val_loss: 0.7982 - val_acc: 0.4312
Epoch 6/10

Epoch 00006: val_acc did not improve from 0.45020
20000/20000 - 618s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.8018 - val_acc: 0.4326
Epoch 7/10

Epoch 00007: val_acc did not improve from 0.45020
20000/20000 - 614s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.7870 - val_acc: 0.4484
Epoch 8/10

Epoch 00008: val_acc improved from 0.45020 to 0.45660, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 607s - loss: 0.6932 - acc: 0.4981 - val_loss: 0.7773 - val_acc: 0.4566
Epoch 9/10

Epoch 00009: val_acc did not improve from 0.45660
20000/20000 - 608s - loss: 0.6932 - acc: 0.4891 - val_loss: 0.7811 - val_acc: 0.4414
Epoch 10/10

Epoch 00010: val_acc did not improve from 0.45660
20000/20000 - 619s - loss: 0.6932 - acc: 0.5010 - val_loss: 0.7878 - val_acc: 0.4474
2019-08-03 21:12:49,142 graeae.timers.timer end: Ended: 2019-08-03 21:12:49.142478
I0803 21:12:49.142507 139918777980736 timer.py:77] Ended: 2019-08-03 21:12:49.142478
2019-08-03 21:12:49,143 graeae.timers.timer end: Elapsed: 1:44:45.039524
I0803 21:12:49.143225 139918777980736 timer.py:78] Elapsed: 1:44:45.039524
#+end_example


* End
** Sources
   - [[https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#horses_or_humans][Horses Or Humans Dataset]]. Moroney Laurence. Feb 2019. url: http://laurencemoroney.com/horses-or-humans-dataset
* Raw
#+begin_comment
import os
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import Model


# In[ ]:


# Download the inception v3 weights
get_ipython().system('wget --no-check-certificate     https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5     -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')

# Import the inception model  
from tensorflow.keras.applications.inception_v3 import InceptionV3

# Create an instance of the inception model from the local pre-trained weights
local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'

pre_trained_model = # Your Code Here

pre_trained_model.load_weights(local_weights_file)

# Make all the layers in the pre-trained model non-trainable
for layer in pre_trained_model.layers:
  # Your Code Here
  
# Print the model summary
pre_trained_model.summary()

# Expected Output is extremely large, but should end with:

#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 
#__________________________________________________________________________________________________
#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] 
#__________________________________________________________________________________________________
#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             
#                                                                 activation_276[0][0]             
#__________________________________________________________________________________________________
#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             
#                                                                 activation_280[0][0]             
#__________________________________________________________________________________________________
#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] 
#__________________________________________________________________________________________________
#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             
#                                                                 mixed9_1[0][0]                   
#                                                                 concatenate_5[0][0]              
#                                                                 activation_281[0][0]             
#==================================================================================================
#Total params: 21,802,784
#Trainable params: 0
#Non-trainable params: 21,802,784


# In[ ]:


last_layer = pre_trained_model.get_layer(# Your Code Here)
print('last layer output shape: ', last_layer.output_shape)
last_output = # Your Code Here

# Expected Output:
# ('last layer output shape: ', (None, 7, 7, 768))


# In[ ]:


# Define a Callback class that stops training once accuracy reaches 99.9%
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('acc')>0.999):
      print("\nReached 99.9% accuracy so cancelling training!")
      self.model.stop_training = True

      


# In[ ]:


from tensorflow.keras.optimizers import RMSprop

# Flatten the output layer to 1 dimension
x = layers.Flatten()(last_output)
# Add a fully connected layer with 1,024 hidden units and ReLU activation
x = layers.Dense(# Your Code Here)(x)
# Add a dropout rate of 0.2
x = layers.Dropout(# Your Code Here)(x)                  
# Add a final sigmoid layer for classification
x = layers.Dense  (# Your Code Here)(x)           

model = Model( # Your Code Here, x) 

model.compile(optimizer = RMSprop(lr=0.0001), 
              loss = # Your Code Here, 
              metrics = # Your Code Here)

model.summary()

# Expected output will be large. Last few lines should be:

# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             
#                                                                  activation_251[0][0]             
#                                                                  activation_256[0][0]             
#                                                                  activation_257[0][0]             
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     
# __________________________________________________________________________________________________
# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    
# __________________________________________________________________________________________________
# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  
# ==================================================================================================
# Total params: 47,512,481
# Trainable params: 38,537,217
# Non-trainable params: 8,975,264


# In[ ]:


# Get the Horse or Human dataset
get_ipython().system('wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip')

# Get the Horse or Human Validation dataset
get_ipython().system('wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip ')
  
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import zipfile

local_zip = '//tmp/horse-or-human.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/training')
zip_ref.close()

local_zip = '//tmp/validation-horse-or-human.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/validation')
zip_ref.close()


# In[ ]:


train_horses_dir = # Your Code Here
train_humans_dir = # Your Code Here
validation_horses_dir = # Your Code Here
validation_humans_dir = # Your Code Here

train_horses_fnames = # Your Code Here
train_humans_fnames = # Your Code Here
validation_horses_fnames = # Your Code Here
validation_humans_fnames = # Your Code Here
print(# Your Code Here)
print(# Your Code Here)
print(# Your Code Here)
print(# Your Code Here)

# Expected Output:
# 500
# 527
# 128
# 128


# In[ ]:


# Define our example directories and files
train_dir = '/tmp/training'
validation_dir = '/tmp/validation'

# Add our data-augmentation parameters to ImageDataGenerator
train_datagen = ImageDataGenerator(# Your Code Here)

# Note that the validation data should not be augmented!
test_datagen = ImageDataGenerator(# Your Code Here )

# Flow training images in batches of 20 using train_datagen generator
train_generator = train_datagen.flow_from_directory(# Your Code Here)     

# Flow validation images in batches of 20 using test_datagen generator
validation_generator =  test_datagen.flow_from_directory( # Your Code Here)

# Expected Output:
# Found 1027 images belonging to 2 classes.
# Found 256 images belonging to 2 classes.


# In[ ]:


# Run this and see how many epochs it should take before the callback
# fires, and stops training at 99.9% accuracy
# (It should take less than 100 epochs)

callbacks = # Your Code Here
history = model.fit_generator(# Your Code Here)


# In[ ]:


import matplotlib.pyplot as plt
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()


plt.show()
#+end_comment
