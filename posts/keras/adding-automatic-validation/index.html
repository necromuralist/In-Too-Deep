<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Adding validation to the training and testing." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Adding Automatic Validation | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/keras/adding-automatic-validation/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/keras/horses-and-humans/" rel="prev" title="Horses And Humans" type="text/html">
<link href="/posts/keras/cats-and-dogs/" rel="next" title="Cats and Dogs" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Adding Automatic Validation" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/keras/adding-automatic-validation/" property="og:url">
<meta content="Adding validation to the training and testing." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-07-05T18:35:00-07:00" property="article:published_time">
<meta content="cnn" property="article:tag">
<meta content="validation" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/keras/adding-automatic-validation/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/keras/adding-automatic-validation/">Adding Automatic Validation</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/adding-automatic-validation/" rel="bookmark"><time class="published dt-published" datetime="2019-07-05T18:35:00-07:00" itemprop="datePublished" title="2019-07-05 18:35">2019-07-05 18:35</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/keras/adding-automatic-validation/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/adding-automatic-validation/#orgd44abe7">Beginning</a>
<ul>
<li><a href="/posts/keras/adding-automatic-validation/#org1f11a9b">Imports</a></li>
<li><a href="/posts/keras/adding-automatic-validation/#org201d013">Set Up</a></li>
</ul>
</li>
<li><a href="/posts/keras/adding-automatic-validation/#org061a28f">Middle</a>
<ul>
<li><a href="/posts/keras/adding-automatic-validation/#org04553da">Examining the Data</a></li>
<li><a href="/posts/keras/adding-automatic-validation/#org85379e4">The Model</a></li>
<li><a href="/posts/keras/adding-automatic-validation/#org39305e0">Training The Model</a></li>
<li><a href="/posts/keras/adding-automatic-validation/#org857ab7c">A re-try with smaller images.</a></li>
<li><a href="/posts/keras/adding-automatic-validation/#org72b8c0f">A re-try with smaller images.</a></li>
</ul>
</li>
<li><a href="/posts/keras/adding-automatic-validation/#org9fdc85a">End</a>
<ul>
<li><a href="/posts/keras/adding-automatic-validation/#orge51177f">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgd44abe7">
<h2 id="orgd44abe7">Beginning</h2>
<div class="outline-text-2" id="text-orgd44abe7"></div>
<div class="outline-3" id="outline-container-org1f11a9b">
<h3 id="org1f11a9b">Imports</h3>
<div class="outline-text-3" id="text-org1f11a9b"></div>
<div class="outline-4" id="outline-container-org2cdbb1e">
<h4 id="org2cdbb1e">Python</h4>
<div class="outline-text-4" id="text-org2cdbb1e">
<div class="highlight">
<pre><span></span>from functools import partial
from pathlib import Path
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdc8d0d4">
<h4 id="orgdc8d0d4">PyPi</h4>
<div class="outline-text-4" id="text-orgdc8d0d4">
<div class="highlight">
<pre><span></span>from holoviews.operation.datashader import datashade
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
import holoviews
import numpy
import tensorflow
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org558fa31">
<h4 id="org558fa31">Graeae</h4>
<div class="outline-text-4" id="text-org558fa31">
<div class="highlight">
<pre><span></span>from graeae import EmbedHoloviews, ZipDownloader
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org201d013">
<h3 id="org201d013">Set Up</h3>
<div class="outline-text-3" id="text-org201d013"></div>
<div class="outline-4" id="outline-container-orgc0cb909">
<h4 id="orgc0cb909">The Plotting</h4>
<div class="outline-text-4" id="text-orgc0cb909">
<div class="highlight">
<pre><span></span>Embed = partial(
    EmbedHoloviews, 
    folder_path="../../files/posts/keras/adding-automatic-validation/")
holoviews.extension("bokeh")
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5e48c49">
<h4 id="org5e48c49">The Training Images</h4>
<div class="outline-text-4" id="text-org5e48c49">
<div class="highlight">
<pre><span></span>URL = ("https://storage.googleapis.com/"
        "laurencemoroney-blog.appspot.com/"
       "horse-or-human.zip")
BASE = "~/data/datasets/images/horse-or-human/"
TARGET = f"{BASE}training"
download = ZipDownloader(url=URL, target=TARGET)
download()
training_path = download.target
</pre></div>
<pre class="example">
Files exist, not downloading

</pre></div>
</div>
<div class="outline-4" id="outline-container-orgc0c2035">
<h4 id="orgc0c2035">The Validation Images</h4>
<div class="outline-text-4" id="text-orgc0c2035">
<div class="highlight">
<pre><span></span>URL = (
    "https://storage.googleapis.com/"
    "laurencemoroney-blog.appspot.com/"
    "validation-horse-or-human.zip")
TARGET = f"{BASE}validation"
download = ZipDownloader(url=URL, target=TARGET)
download()
validation_path = download.target
</pre></div>
<pre class="example">
Downloading the zip file

</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org061a28f">
<h2 id="org061a28f">Middle</h2>
<div class="outline-text-2" id="text-org061a28f"></div>
<div class="outline-3" id="outline-container-org04553da">
<h3 id="org04553da">Examining the Data</h3>
<div class="outline-text-3" id="text-org04553da">
<p>The training set is the same one that I used before to train a model to recognize whether a picture contained a human or a horse, but the validation set is new.</p>
<div class="highlight">
<pre><span></span>print("Training")
for path in training_path.iterdir():
    print(path.name)

print("\nValidation")
for path in validation_path.iterdir():
    print(path.name)
</pre></div>
<pre class="example">
Training
horses
humans

Validation
horses
humans

</pre>
<p>How many images do we have?</p>
<div class="highlight">
<pre><span></span>print("Training")
for path in training_path.iterdir():
    print(f"{len(list(path.iterdir())):,} images in {path.name}")

print("\nValidation")
for path in validation_path.iterdir():
    print(f"{len(list(path.iterdir())):,} images in {path.name}")    
</pre></div>
<pre class="example">
Training
500 images in horses
527 images in humans

Validation
128 images in horses
128 images in humans

</pre></div>
<div class="outline-4" id="outline-container-orgcc1ae94">
<h4 id="orgcc1ae94">Looking At A Few Images</h4>
<div class="outline-text-4" id="text-orgcc1ae94">
<p>As I noted, the training set is the same one I looked at before, but still, it never hurts to look.</p>
<div class="highlight">
<pre><span></span>height = width = 300
human_files = list((training_path/"humans").iterdir())
horse_files = list((training_path/"horses").iterdir())
human_indexes = numpy.random.randint(0, 527, 2)
horse_indexes = numpy.random.randint(0, 500, 2)

humans = [holoviews.RGB.load_image(str(human_files[index])).opts(
    width = width,
    height = height,
) for index in human_indexes]
horses = [holoviews.RGB.load_image(str(horse_files[index])).opts(
    width = width,
    height = height,
) for index in horse_indexes]
plot = holoviews.Layout(humans + horses).cols(2).opts(
    title="Sample Training Images"
)
Embed(plot=plot, file_name="training_images", height_in_pixels=700)()
</pre></div>
<object data="/posts/keras/adding-automatic-validation/training_images.html" height="700" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
<div class="outline-4" id="outline-container-orgd42811a">
<h4 id="orgd42811a">Preprocessing the Data</h4>
<div class="outline-text-4" id="text-orgd42811a">
<p>When we train the model we'll use a batch generator. This next bit of code is just a convenience class to bundle the code together.</p>
<div class="highlight">
<pre><span></span>class Data:
    """creates the data generator

    Args:
     path: path to the dataset
     target_size: tuple of pixel size for the generated images
    """
    def __init__(self, path: str, target_size: tuple=(300, 300)) -&gt; None:
        self.path = path
        self.target_size = target_size
        self._batches = None
        return

    @property
    def batches(self) -&gt; tensorflow.keras.preprocessing.image.DirectoryIterator:
        """Generator of image batches"""
        if self._batches is None:
            data_generator = ImageDataGenerator(rescale=1/255)
            self._batches = data_generator.flow_from_directory(
                self.path,
                target_size=self.target_size,
                batch_size=128,
                class_mode="binary",
            )
        return self._batches
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org85379e4">
<h3 id="org85379e4">The Model</h3>
<div class="outline-text-3" id="text-org85379e4">
<p>This bundles together the different parts needed to train and use the model.</p>
<div class="highlight">
<pre><span></span>class Model:
    """A CNN Builder

    Args:
     training_path: training data folder path
     validation_path: validation data folder path
     image_size: single-dimension for the inputs to the model
     epochs: number of training epochs
     callback: something to stop the training
    """
    def __init__(self, training_path: str, validation_path: str, 
                 image_size: int=300,
                 epochs: int=15, 
                 callback: tensorflow.keras.callbacks.Callback=None) -&gt; None:
        self.training_path = training_path
        self.validation_path = validation_path
        self.image_size = image_size
        self.epochs = epochs
        self.callback = callback
        self._model = None
        self._training_data = None
        self._validation_data = None
        return

    @property
    def training_data(self) -&gt; (tensorflow.keras.preprocessing
                                     .image.DirectoryIterator):
        """generator of training data batches"""
        if self._training_data is None: 
           self._training_data = Data(
               self.training_path,
               (self.image_size, self.image_size)).batches
        return self._training_data

    @property
    def validation_data(self) -&gt; (tensorflow.keras.preprocessing
                                       .image.DirectoryIterator):
        """generator of validation batches"""
        if self._validation_data is None:
            self._validation_data = Data(
                self.validation_path,
                (self.image_size, self.image_size)).batches
        return self._validation_data

    @property
    def model(self) -&gt; tensorflow.keras.models.Sequential:
        """A model with five CNN layers"""
        if self._model is None:
            self._model = tensorflow.keras.models.Sequential()
            for layer in (
                    tensorflow.keras.layers.Conv2D(
                        16, (3,3), 
                        activation='relu', 
                        input_shape=(self.image_size, self.image_size, 3)),
                    tensorflow.keras.layers.MaxPooling2D(2, 2),

                    tensorflow.keras.layers.Conv2D(32, (3,3), 
                                                   activation='relu'),
                    tensorflow.keras.layers.MaxPooling2D(2,2),

                    tensorflow.keras.layers.Conv2D(64, (3,3), 
                                                   activation='relu'),
                    tensorflow.keras.layers.MaxPooling2D(2,2),

                    tensorflow.keras.layers.Conv2D(64, (3,3), 
                                                   activation='relu'),
                    tensorflow.keras.layers.MaxPooling2D(2,2),

                    tensorflow.keras.layers.Conv2D(64, (3,3), 
                                                   activation='relu'),
                    tensorflow.keras.layers.MaxPooling2D(2,2),

                    tensorflow.keras.layers.Flatten(),

                    tensorflow.keras.layers.Dense(512, 
                                                  activation='relu'),
                    tensorflow.keras.layers.Dense(1, activation='sigmoid'),
            ):
                self._model.add(layer)

            self._model.compile(loss='binary_crossentropy',
                                optimizer=RMSprop(lr=0.001),
                                metrics=['acc'])
        return self._model

    def print_summary(self) -&gt; None:
        """Prints a summary of the model's layers"""
        print(self.model.summary())
        return

    def train(self) -&gt; None:
        """Trains the model"""
        fit = partial(self.model.fit_generator,
                      self.training_data,
                      steps_per_epoch=8,  
                      epochs=self.epochs,
                      verbose=2,
                      validation_data = self.validation_data,
                      validation_steps=8)
        if self.callback:
            fit(callbacks=[self.callback])
        else:
            fit()
        return

    def predict(self, image) -&gt; str:
        """Predicts whether the image contains a horse or a human

        Returns:
         label: label for the image
        """
        classes = self.model.predict(image)
        return "human" if classes[0] else "horse"
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org39305e0">
<h3 id="org39305e0">Training The Model</h3>
<div class="outline-text-3" id="text-org39305e0">
<div class="highlight">
<pre><span></span>model = Model(str(training_path), str(validation_path))
model.train()
</pre></div>
<pre class="example">
Found 1027 images belonging to 2 classes.
Found 256 images belonging to 2 classes.
Epoch 1/15
8/8 - 9s - loss: 1.5885 - acc: 0.5640 - val_loss: 0.9410 - val_acc: 0.5000
Epoch 2/15
8/8 - 7s - loss: 0.7624 - acc: 0.6407 - val_loss: 0.7195 - val_acc: 0.5000
Epoch 3/15
8/8 - 7s - loss: 0.8388 - acc: 0.6908 - val_loss: 0.6150 - val_acc: 0.6758
Epoch 4/15
8/8 - 7s - loss: 0.3347 - acc: 0.8818 - val_loss: 1.4559 - val_acc: 0.7070
Epoch 5/15
8/8 - 7s - loss: 0.2710 - acc: 0.8832 - val_loss: 1.2360 - val_acc: 0.8242
Epoch 6/15
8/8 - 6s - loss: 0.1465 - acc: 0.9433 - val_loss: 1.5440 - val_acc: 0.8320
Epoch 7/15
8/8 - 6s - loss: 0.4357 - acc: 0.8454 - val_loss: 1.2532 - val_acc: 0.8242
Epoch 8/15
8/8 - 6s - loss: 0.3896 - acc: 0.8888 - val_loss: 1.4711 - val_acc: 0.8008
Epoch 9/15
8/8 - 5s - loss: 0.1057 - acc: 0.9588 - val_loss: 2.0512 - val_acc: 0.8164
Epoch 10/15
8/8 - 5s - loss: 0.1610 - acc: 0.9366 - val_loss: 1.3215 - val_acc: 0.6602
Epoch 11/15
8/8 - 8s - loss: 0.0889 - acc: 0.9736 - val_loss: 1.7946 - val_acc: 0.8281
Epoch 12/15
8/8 - 7s - loss: 0.0163 - acc: 0.9944 - val_loss: 1.6159 - val_acc: 0.8672
Epoch 13/15
8/8 - 7s - loss: 0.5203 - acc: 0.8915 - val_loss: 0.9708 - val_acc: 0.8125
Epoch 14/15
8/8 - 6s - loss: 0.1073 - acc: 0.9800 - val_loss: 1.1768 - val_acc: 0.8438
Epoch 15/15
8/8 - 7s - loss: 0.0305 - acc: 0.9922 - val_loss: 1.4107 - val_acc: 0.8555
</pre>
<p>It looks like the accuracy for both the training and the validation sets are going up. Maybe a little more training will help.</p>
<div class="highlight">
<pre><span></span>model.epochs = 5
model.train()
</pre></div>
<pre class="example">
Epoch 1/5
8/8 - 7s - loss: 0.0109 - acc: 0.9978 - val_loss: 1.6156 - val_acc: 0.8672
Epoch 2/5
8/8 - 7s - loss: 0.0067 - acc: 0.9989 - val_loss: 2.5671 - val_acc: 0.8242
Epoch 3/5
8/8 - 7s - loss: 0.2348 - acc: 0.9477 - val_loss: 1.2397 - val_acc: 0.8633
Epoch 4/5
8/8 - 7s - loss: 0.0132 - acc: 0.9961 - val_loss: 1.5193 - val_acc: 0.8750
Epoch 5/5
8/8 - 7s - loss: 0.0101 - acc: 0.9978 - val_loss: 0.9305 - val_acc: 0.8945
</pre>
<p>Everything is still improving. Try a little more.</p>
<div class="highlight">
<pre><span></span>model.epochs = 10
model.train()
</pre></div>
<pre class="example">
Epoch 1/10
8/8 - 8s - loss: 0.0413 - acc: 0.9844 - val_loss: 0.8631 - val_acc: 0.9062
Epoch 2/10
8/8 - 7s - loss: 0.2625 - acc: 0.9244 - val_loss: 1.3837 - val_acc: 0.8438
Epoch 3/10
8/8 - 7s - loss: 0.7150 - acc: 0.8776 - val_loss: 8.2253 - val_acc: 0.6328
Epoch 4/10
8/8 - 7s - loss: 0.0937 - acc: 0.9785 - val_loss: 1.9342 - val_acc: 0.8281
Epoch 5/10
8/8 - 7s - loss: 0.0126 - acc: 0.9978 - val_loss: 1.7459 - val_acc: 0.8672
Epoch 6/10
8/8 - 7s - loss: 0.0064 - acc: 1.0000 - val_loss: 1.8857 - val_acc: 0.8633
Epoch 7/10
8/8 - 6s - loss: 0.0025 - acc: 1.0000 - val_loss: 2.1456 - val_acc: 0.8672
Epoch 8/10
8/8 - 6s - loss: 0.0027 - acc: 1.0000 - val_loss: 2.0877 - val_acc: 0.8711
Epoch 9/10
8/8 - 6s - loss: 9.8538e-04 - acc: 1.0000 - val_loss: 2.3224 - val_acc: 0.8672
Epoch 10/10
8/8 - 6s - loss: 4.4454e-04 - acc: 1.0000 - val_loss: 2.8453 - val_acc: 0.8672
</pre>
<p>The training loss and accuracy keeps getting better but it looks like it might be overfitting, after about epoch 21, since the validation metrics start to get worse.</p>
<p>I'll try making a callback that stops whene the validation accuracy reaches 90 %.</p>
<div class="highlight">
<pre><span></span>class Stop(tensorflow.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get("val_acc") &gt;= 0.9):
            print(f"Stopping point reached at epoch {epoch}")
            self.model.stop_training = True
</pre></div>
<div class="highlight">
<pre><span></span>callback = Stop()
model = Model(str(training_path), str(validation_path), 
              epochs=30,
              callback=callback)
model.train()
</pre></div>
<pre class="example">
Found 1027 images belonging to 2 classes.
Found 256 images belonging to 2 classes.
Epoch 1/30
8/8 - 8s - loss: 1.7387 - acc: 0.5006 - val_loss: 0.6752 - val_acc: 0.5000
Epoch 2/30
8/8 - 7s - loss: 0.6397 - acc: 0.6630 - val_loss: 0.4168 - val_acc: 0.8438
Epoch 3/30
8/8 - 7s - loss: 0.8124 - acc: 0.6162 - val_loss: 0.5096 - val_acc: 0.7617
Epoch 4/30
8/8 - 7s - loss: 0.3740 - acc: 0.8498 - val_loss: 0.8950 - val_acc: 0.7891
Epoch 5/30
8/8 - 7s - loss: 0.2619 - acc: 0.8867 - val_loss: 0.8874 - val_acc: 0.8477
Epoch 6/30
8/8 - 6s - loss: 0.2136 - acc: 0.9010 - val_loss: 0.5653 - val_acc: 0.8789
Epoch 7/30
8/8 - 6s - loss: 0.0980 - acc: 0.9566 - val_loss: 1.4001 - val_acc: 0.8320
Epoch 8/30
8/8 - 6s - loss: 0.2865 - acc: 0.8665 - val_loss: 0.5963 - val_acc: 0.8906
Epoch 9/30
8/8 - 5s - loss: 0.1949 - acc: 0.9288 - val_loss: 0.9161 - val_acc: 0.8984
Epoch 10/30
8/8 - 5s - loss: 0.1328 - acc: 0.9488 - val_loss: 1.7331 - val_acc: 0.8164
Epoch 11/30
8/8 - 7s - loss: 0.1825 - acc: 0.9266 - val_loss: 1.1965 - val_acc: 0.8438
Epoch 12/30
8/8 - 7s - loss: 0.1108 - acc: 0.9633 - val_loss: 1.8896 - val_acc: 0.7852
Epoch 13/30
8/8 - 7s - loss: 0.0309 - acc: 0.9883 - val_loss: 1.7577 - val_acc: 0.8477
Epoch 14/30
8/8 - 7s - loss: 0.0140 - acc: 0.9956 - val_loss: 2.0667 - val_acc: 0.8320
Epoch 15/30
8/8 - 6s - loss: 1.5402 - acc: 0.8359 - val_loss: 1.3396 - val_acc: 0.8203
Epoch 16/30
8/8 - 6s - loss: 0.0144 - acc: 0.9990 - val_loss: 1.8488 - val_acc: 0.8203
Epoch 17/30
8/8 - 6s - loss: 0.0092 - acc: 0.9989 - val_loss: 2.0972 - val_acc: 0.8320
Epoch 18/30
8/8 - 5s - loss: 0.0031 - acc: 1.0000 - val_loss: 1.9660 - val_acc: 0.8594
Epoch 19/30
8/8 - 6s - loss: 0.0752 - acc: 0.9785 - val_loss: 2.6233 - val_acc: 0.7578
Epoch 20/30
8/8 - 7s - loss: 0.0086 - acc: 0.9987 - val_loss: 2.2535 - val_acc: 0.8203
Epoch 21/30
8/8 - 7s - loss: 0.0012 - acc: 1.0000 - val_loss: 2.5086 - val_acc: 0.8242
Epoch 22/30
8/8 - 7s - loss: 8.1537e-04 - acc: 1.0000 - val_loss: 2.6183 - val_acc: 0.8203
Epoch 23/30
8/8 - 7s - loss: 4.3476e-04 - acc: 1.0000 - val_loss: 2.5576 - val_acc: 0.8477
Epoch 24/30
8/8 - 7s - loss: 1.6678e-04 - acc: 1.0000 - val_loss: 2.7958 - val_acc: 0.8398
Epoch 25/30
8/8 - 6s - loss: 2.6736e-04 - acc: 1.0000 - val_loss: 2.8162 - val_acc: 0.8398
Epoch 26/30
8/8 - 6s - loss: 6.3831e-05 - acc: 1.0000 - val_loss: 3.0070 - val_acc: 0.8398
Epoch 27/30
8/8 - 6s - loss: 3.5260e-05 - acc: 1.0000 - val_loss: 3.4427 - val_acc: 0.8320
Epoch 28/30
8/8 - 5s - loss: 2.8581e-05 - acc: 1.0000 - val_loss: 3.0836 - val_acc: 0.8594
Epoch 29/30
8/8 - 7s - loss: 1.9179 - acc: 0.8610 - val_loss: 1.5853 - val_acc: 0.8281
Epoch 30/30
8/8 - 7s - loss: 0.0118 - acc: 0.9951 - val_loss: 2.7055 - val_acc: 0.8086
</pre>
<p>So this time it never reached 90 % accuracy the way it did previously so the callback didn't work. Maybe I'll just set it to use 21 epochs.</p>
<div class="highlight">
<pre><span></span>model = Model(str(training_path), str(validation_path), epochs=21)
model.train()
</pre></div>
<pre class="example">
Found 1027 images belonging to 2 classes.
Found 256 images belonging to 2 classes.
Epoch 1/21
8/8 - 8s - loss: 0.8662 - acc: 0.5428 - val_loss: 0.6637 - val_acc: 0.5000
Epoch 2/21
8/8 - 7s - loss: 0.7301 - acc: 0.6118 - val_loss: 0.5114 - val_acc: 0.8398
Epoch 3/21
8/8 - 7s - loss: 0.5781 - acc: 0.8516 - val_loss: 0.4985 - val_acc: 0.8203
Epoch 4/21
8/8 - 6s - loss: 0.6889 - acc: 0.8346 - val_loss: 0.8576 - val_acc: 0.7969
Epoch 5/21
8/8 - 6s - loss: 0.2113 - acc: 0.9310 - val_loss: 2.0597 - val_acc: 0.6875
Epoch 6/21
8/8 - 6s - loss: 0.3143 - acc: 0.8865 - val_loss: 0.8110 - val_acc: 0.8320
Epoch 7/21
8/8 - 6s - loss: 0.1289 - acc: 0.9570 - val_loss: 1.1169 - val_acc: 0.8672
Epoch 8/21
8/8 - 6s - loss: 0.1513 - acc: 0.9288 - val_loss: 1.1159 - val_acc: 0.8398
Epoch 9/21
8/8 - 6s - loss: 0.0882 - acc: 0.9700 - val_loss: 1.4653 - val_acc: 0.8125
Epoch 10/21
8/8 - 5s - loss: 0.1803 - acc: 0.9522 - val_loss: 1.2575 - val_acc: 0.8711
Epoch 11/21
8/8 - 7s - loss: 0.0753 - acc: 0.9766 - val_loss: 1.0846 - val_acc: 0.8633
Epoch 12/21
8/8 - 8s - loss: 0.1993 - acc: 0.9580 - val_loss: 0.9569 - val_acc: 0.8672
Epoch 13/21
8/8 - 8s - loss: 0.0452 - acc: 0.9867 - val_loss: 1.1035 - val_acc: 0.8906
Epoch 14/21
8/8 - 6s - loss: 0.0139 - acc: 0.9948 - val_loss: 1.7541 - val_acc: 0.8516
Epoch 15/21
8/8 - 6s - loss: 0.0191 - acc: 0.9911 - val_loss: 1.6554 - val_acc: 0.8555
Epoch 16/21
8/8 - 6s - loss: 0.0327 - acc: 0.9967 - val_loss: 10.3868 - val_acc: 0.6523
Epoch 17/21
8/8 - 6s - loss: 2.2541 - acc: 0.9004 - val_loss: 0.9508 - val_acc: 0.8594
Epoch 18/21
8/8 - 6s - loss: 0.0282 - acc: 0.9889 - val_loss: 1.3172 - val_acc: 0.8672
Epoch 19/21
8/8 - 5s - loss: 0.0064 - acc: 0.9989 - val_loss: 1.6202 - val_acc: 0.8477
Epoch 20/21
8/8 - 7s - loss: 0.0033 - acc: 1.0000 - val_loss: 2.0371 - val_acc: 0.8125
Epoch 21/21
8/8 - 8s - loss: 0.0066 - acc: 0.9990 - val_loss: 1.8340 - val_acc: 0.8672
</pre>
<p>It looks like the 90 % validation accuracy was a fluke.</p>
</div>
<div class="outline-4" id="outline-container-orgb2aa039">
<h4 id="orgb2aa039">Looking At Some Predictions</h4>
<div class="outline-text-4" id="text-orgb2aa039">
<p>These are the same images I tested previously. The architecture of the model is the same, but I didn't train it for as many epochs on the current pass through this data set.</p>
<div class="highlight">
<pre><span></span>test_path = Path("~/test_images/").expanduser()
</pre></div>
<div class="highlight">
<pre><span></span>height = width = 400
plots = [datashade(holoviews.RGB.load_image(str(path))).opts(
    title=f"{path.name}",
    height=height,
    width=width
) for path in test_path.iterdir()]
plot = holoviews.Layout(plots).cols(2).opts(title="Test Images")
Embed(plot=plot, file_name="test_images", height_in_pixels=900)()
</pre></div>
<object data="/posts/keras/adding-automatic-validation/test_images.html" height="900" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span>target_size = (300, 300)

images = (("horse.jpg", "Horse"), 
          ("centaur.jpg", "Centaur"), 
          ("tomb_figure.jpg", "Statue of a Man Riding a Horse"),
          ("rembrandt.jpg", "Woman"))
for filename, label in images:
    loaded = cv2.imread(str(test_path/filename))
    x = cv2.resize(loaded, target_size)
    x = numpy.reshape(x, (1, 300, 300, 3))
    prediction = model.predict(x)
    print(f"The {label} is a {prediction}.")
</pre></div>
<pre class="example">
The Horse is a horse.
The Centaur is a horse.
The Statue of a Man Riding a Horse is a human.
The Woman is a horse.

</pre>
<p>Well, now it got the horse right and the woman wrong. Peculiar.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org857ab7c">
<h3 id="org857ab7c">A re-try with smaller images.</h3>
<div class="outline-text-3" id="text-org857ab7c">
<div class="highlight">
<pre><span></span>model = Model(str(training_path), str(validation_path), 
              image_size=150, 
              epochs=21)
model.train()
</pre></div>
<pre class="example">
Found 1027 images belonging to 2 classes.
Found 256 images belonging to 2 classes.
Epoch 1/21
8/8 - 6s - loss: 0.7257 - acc: 0.5072 - val_loss: 0.6794 - val_acc: 0.6719
Epoch 2/21
8/8 - 6s - loss: 0.6691 - acc: 0.6118 - val_loss: 0.4503 - val_acc: 0.8633
Epoch 3/21
8/8 - 6s - loss: 0.5535 - acc: 0.7402 - val_loss: 0.4486 - val_acc: 0.7969
Epoch 4/21
8/8 - 5s - loss: 0.5850 - acc: 0.7959 - val_loss: 0.4330 - val_acc: 0.8555
Epoch 5/21
8/8 - 4s - loss: 0.1967 - acc: 0.9321 - val_loss: 1.1319 - val_acc: 0.7891
Epoch 6/21
8/8 - 4s - loss: 0.1969 - acc: 0.9310 - val_loss: 0.8440 - val_acc: 0.8125
Epoch 7/21
8/8 - 4s - loss: 0.1309 - acc: 0.9522 - val_loss: 1.4648 - val_acc: 0.8008
Epoch 8/21
8/8 - 5s - loss: 0.2732 - acc: 0.9023 - val_loss: 0.8364 - val_acc: 0.8398
Epoch 9/21
8/8 - 4s - loss: 0.1071 - acc: 0.9611 - val_loss: 1.2082 - val_acc: 0.8359
Epoch 10/21
8/8 - 4s - loss: 0.0725 - acc: 0.9711 - val_loss: 1.9165 - val_acc: 0.7148
Epoch 11/21
8/8 - 6s - loss: 0.2651 - acc: 0.9062 - val_loss: 0.8687 - val_acc: 0.8398
Epoch 12/21
8/8 - 6s - loss: 0.0568 - acc: 0.9789 - val_loss: 1.0587 - val_acc: 0.8359
Epoch 13/21
8/8 - 5s - loss: 0.1405 - acc: 0.9522 - val_loss: 1.3749 - val_acc: 0.7773
Epoch 14/21
8/8 - 5s - loss: 0.2003 - acc: 0.9395 - val_loss: 0.7942 - val_acc: 0.8555
Epoch 15/21
8/8 - 4s - loss: 0.0313 - acc: 0.9889 - val_loss: 0.8540 - val_acc: 0.8594
Epoch 16/21
8/8 - 4s - loss: 0.0280 - acc: 0.9922 - val_loss: 0.9602 - val_acc: 0.8516
Epoch 17/21
8/8 - 4s - loss: 0.1560 - acc: 0.9544 - val_loss: 0.6488 - val_acc: 0.8359
Epoch 18/21
8/8 - 4s - loss: 0.0366 - acc: 0.9933 - val_loss: 1.0103 - val_acc: 0.8555
Epoch 19/21
8/8 - 4s - loss: 0.0238 - acc: 0.9967 - val_loss: 0.7084 - val_acc: 0.8555
Epoch 20/21
8/8 - 5s - loss: 0.0555 - acc: 0.9778 - val_loss: 0.9348 - val_acc: 0.8594
Epoch 21/21
8/8 - 6s - loss: 0.0046 - acc: 1.0000 - val_loss: 1.1267 - val_acc: 0.8633
</pre>
<div class="highlight">
<pre><span></span>target_size = (150, 150)

images = (("horse.jpg", "Horse"), 
          ("centaur.jpg", "Centaur"), 
          ("tomb_figure.jpg", "Statue of a Man Riding a Horse"),
          ("rembrandt.jpg", "Woman"))
for filename, label in images:
    loaded = cv2.imread(str(test_path/filename))
    x = cv2.resize(loaded, target_size)
    x = numpy.reshape(x, (1, 150, 150, 3))
    prediction = model.predict(x)
    print(f"The {label} is a {prediction}.")
</pre></div>
<pre class="example">
The Horse is a horse.
The Centaur is a horse.
The Statue of a Man Riding a Horse is a horse.
The Woman is a horse.

</pre>
<p>Although it looked like it did about the same except getting to high accuracy, it now appears to predict everything is a horse.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org72b8c0f">
<h3 id="org72b8c0f">A re-try with smaller images.</h3>
<div class="outline-text-3" id="text-org72b8c0f">
<div class="highlight">
<pre><span></span>model = Model(str(training_path), str(validation_path), 
              image_size=150, 
              epochs=21)
model.train()
</pre></div>
<pre class="example">
Found 1027 images belonging to 2 classes.
Found 256 images belonging to 2 classes.
Epoch 1/21
8/8 - 6s - loss: 0.7257 - acc: 0.5072 - val_loss: 0.6794 - val_acc: 0.6719
Epoch 2/21
8/8 - 6s - loss: 0.6691 - acc: 0.6118 - val_loss: 0.4503 - val_acc: 0.8633
Epoch 3/21
8/8 - 6s - loss: 0.5535 - acc: 0.7402 - val_loss: 0.4486 - val_acc: 0.7969
Epoch 4/21
8/8 - 5s - loss: 0.5850 - acc: 0.7959 - val_loss: 0.4330 - val_acc: 0.8555
Epoch 5/21
8/8 - 4s - loss: 0.1967 - acc: 0.9321 - val_loss: 1.1319 - val_acc: 0.7891
Epoch 6/21
8/8 - 4s - loss: 0.1969 - acc: 0.9310 - val_loss: 0.8440 - val_acc: 0.8125
Epoch 7/21
8/8 - 4s - loss: 0.1309 - acc: 0.9522 - val_loss: 1.4648 - val_acc: 0.8008
Epoch 8/21
8/8 - 5s - loss: 0.2732 - acc: 0.9023 - val_loss: 0.8364 - val_acc: 0.8398
Epoch 9/21
8/8 - 4s - loss: 0.1071 - acc: 0.9611 - val_loss: 1.2082 - val_acc: 0.8359
Epoch 10/21
8/8 - 4s - loss: 0.0725 - acc: 0.9711 - val_loss: 1.9165 - val_acc: 0.7148
Epoch 11/21
8/8 - 6s - loss: 0.2651 - acc: 0.9062 - val_loss: 0.8687 - val_acc: 0.8398
Epoch 12/21
8/8 - 6s - loss: 0.0568 - acc: 0.9789 - val_loss: 1.0587 - val_acc: 0.8359
Epoch 13/21
8/8 - 5s - loss: 0.1405 - acc: 0.9522 - val_loss: 1.3749 - val_acc: 0.7773
Epoch 14/21
8/8 - 5s - loss: 0.2003 - acc: 0.9395 - val_loss: 0.7942 - val_acc: 0.8555
Epoch 15/21
8/8 - 4s - loss: 0.0313 - acc: 0.9889 - val_loss: 0.8540 - val_acc: 0.8594
Epoch 16/21
8/8 - 4s - loss: 0.0280 - acc: 0.9922 - val_loss: 0.9602 - val_acc: 0.8516
Epoch 17/21
8/8 - 4s - loss: 0.1560 - acc: 0.9544 - val_loss: 0.6488 - val_acc: 0.8359
Epoch 18/21
8/8 - 4s - loss: 0.0366 - acc: 0.9933 - val_loss: 1.0103 - val_acc: 0.8555
Epoch 19/21
8/8 - 4s - loss: 0.0238 - acc: 0.9967 - val_loss: 0.7084 - val_acc: 0.8555
Epoch 20/21
8/8 - 5s - loss: 0.0555 - acc: 0.9778 - val_loss: 0.9348 - val_acc: 0.8594
Epoch 21/21
8/8 - 6s - loss: 0.0046 - acc: 1.0000 - val_loss: 1.1267 - val_acc: 0.8633
</pre>
<div class="highlight">
<pre><span></span>target_size = (150, 150)

images = (("horse.jpg", "Horse"), 
          ("centaur.jpg", "Centaur"), 
          ("tomb_figure.jpg", "Statue of a Man Riding a Horse"),
          ("rembrandt.jpg", "Woman"))
for filename, label in images:
    loaded = cv2.imread(str(test_path/filename))
    x = cv2.resize(loaded, target_size)
    x = numpy.reshape(x, (1, 150, 150, 3))
    prediction = model.predict(x)
    print(f"The {label} is a {prediction}.")
</pre></div>
<pre class="example">
The Horse is a horse.
The Centaur is a horse.
The Statue of a Man Riding a Horse is a horse.
The Woman is a horse.

</pre>
<p>Although it looked like it did about the same except getting to high accuracy, it now appears to predict everything is a horse.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org9fdc85a">
<h2 id="org9fdc85a">End</h2>
<div class="outline-text-2" id="text-org9fdc85a"></div>
<div class="outline-3" id="outline-container-orge51177f">
<h3 id="orge51177f">Source</h3>
<div class="outline-text-3" id="text-orge51177f">
<p>This is a walk-through of the <a href="https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%208%20-%20Lesson%203%20-%20Notebook.ipynb">Course 1 - Part 8 - Lesson 3 - Notebook.ipynb</a> on github.</p>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/cnn/" rel="tag">cnn</a></li>
<li><a class="tag p-category" href="/categories/validation/" rel="tag">validation</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/keras/horses-and-humans/" rel="prev" title="Horses And Humans">Previous post</a></li>
<li class="next"><a href="/posts/keras/cats-and-dogs/" rel="next" title="Cats and Dogs">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
