#+BEGIN_COMMENT
.. title: Rock-Paper-Scissors
.. slug: rock-paper-scissors
.. date: 2019-08-19 15:16:52 UTC-07:00
.. tags: cnn
.. category: CNN 
.. link: 
.. description: Classifying hands for rock-paper-scissors.
.. type: text
#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+begin_src ipython :session cnn :results none :exports none
%load_ext autoreload
%autoreload 2
#+end_src
* Beginning
** Imports
*** Python
#+begin_src ipython :session cnn :results none
from pathlib import Path
#+end_src
*** PyPi
#+begin_src ipython :session cnn :results none
import matplotlib.pyplot as pyplot
import matplotlib.image as matplotlib_image
import seaborn
#+end_src
*** graeae
#+begin_src ipython :session cnn :results none
from graeae import SubPathLoader, Timer, ZipDownloader
#+end_src
** Set Up
*** Plotting
#+BEGIN_SRC python :session cnn :results none
get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
seaborn.set(style="whitegrid",
            rc={"axes.grid": False,
                "font.family": ["sans-serif"],
                "font.sans-serif": ["Open Sans", "Latin Modern Sans", "Lato"],
                "figure.figsize": (8, 6)},
            font_scale=1)
FIGURE_SIZE = (12, 10)
#+END_SRC

*** The Timer
#+begin_src ipython :session cnn :results none
TIMER = Timer()
#+end_src
*** The Environment
#+begin_src ipython :session cnn :results none
ENVIRONMENT = SubPathLoader("DATASETS")
#+end_src
* Middle
** The Data
*** Downloading it
#+begin_src ipython :session cnn :results output :exports both
TRAINING_URL = "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip"
TEST_URL = "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip"
OUT_PATH = Path(ENVIRONMENT["ROCK_PAPER_SCISSORS"]).expanduser()
download_train = ZipDownloader(TRAINING_URL, OUT_PATH/"train")
download_test = ZipDownloader(TEST_URL, OUT_PATH/"test")
download_train()
download_test()
#+end_src

#+RESULTS:
: 2019-08-22 12:59:26,255 [1mZipDownloader[0m start: ([1mZipDownloader[0m) Started: 2019-08-22 12:59:26.255501
: 2019-08-22 12:59:26,256 [1mZipDownloader[0m download: Downloading the zip file
: 2019-08-22 12:59:36,907 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Ended: 2019-08-22 12:59:36.907286
: 2019-08-22 12:59:36,909 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Elapsed: 0:00:10.651785
: 2019-08-22 12:59:38,733 [1mZipDownloader[0m start: ([1mZipDownloader[0m) Started: 2019-08-22 12:59:38.733192
: 2019-08-22 12:59:38,734 [1mZipDownloader[0m download: Downloading the zip file
: 2019-08-22 12:59:41,261 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Ended: 2019-08-22 12:59:41.261043
: 2019-08-22 12:59:41,261 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Elapsed: 0:00:02.527851

The data structure for the folders is fairly deep, so I'll make some shortcuts.

#+begin_src ipython :session cnn :results none
training = OUT_PATH/"train/rps"
rocks = training/"rock"
papers = training/"paper"
scissors = training/"scissors"
assert papers.is_dir()
assert rocks.is_dir()
assert scissors.is_dir()
#+end_src

#+begin_src ipython :session cnn :results output :exports both
rock_images = list(rocks.iterdir())
paper_images = list(papers.iterdir())
scissors_images = list(scissors.iterdir())
print(f"Rocks: {len(rock_images):,}")
print(f"Papers: {len(paper_images):,}")
print(f"Scissors: {len(scissors_images):,}")
#+end_src

#+RESULTS:
: Rocks: 840
: Papers: 840
: Scissors: 840

*** Some Examples
#+begin_src ipython :session cnn :results raw drawer :ipyfile ../../files/posts/keras/rock-paper-scissors/samples.png
count = 2

rock_sample = rock_images[:count]
paper_sample = paper_images[:count]
scissors_sample = scissors_images[:count]

for index, path in enumerate(rock_sample + paper_sample + scissors_sample):
  image = matplotlib_image.imread(str(path))
  pyplot.imshow(image)
  pyplot.axis('Off')
  pyplot.show()
#+end_src

#+RESULTS:
:results:
# Out[18]:
[[file:../../files/posts/keras/rock-paper-scissors/samples.png]]
:end:

* End
* Raw
#+begin_comment


# In[21]:


import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

TRAINING_DIR = "/tmp/rps/"
training_datagen = ImageDataGenerator(
      rescale = 1./255,
	  rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

VALIDATION_DIR = "/tmp/rps-test-set/"
validation_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = training_datagen.flow_from_directory(
	TRAINING_DIR,
	target_size=(150,150),
	class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
	VALIDATION_DIR,
	target_size=(150,150),
	class_mode='categorical'
)

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])


model.summary()

model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit_generator(train_generator, epochs=25, validation_data = validation_generator, verbose = 1)

model.save("rps.h5")


# In[22]:


import matplotlib.pyplot as plt
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()


plt.show()


# In[26]:


import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(fn)
  print(classes)


#+end_comment
