#+BEGIN_COMMENT
.. title: Rock-Paper-Scissors
.. slug: rock-paper-scissors
.. date: 2019-08-19 15:16:52 UTC-07:00
.. tags: cnn
.. category: CNN 
.. link: 
.. description: Classifying hands for rock-paper-scissors.
.. type: text
#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+begin_src ipython :session cnn :results none :exports none
%load_ext autoreload
%autoreload 2
#+end_src
* Beginning
** Imports
*** Python
#+begin_src ipython :session cnn :results none
from pathlib import Path
import random
#+end_src
*** PyPi
#+begin_src ipython :session cnn :results none
import matplotlib.pyplot as pyplot
import matplotlib.image as matplotlib_image
import seaborn
#+end_src
*** graeae
#+begin_src ipython :session cnn :results none
from graeae import SubPathLoader, Timer, ZipDownloader
#+end_src
** Set Up
*** Plotting
#+BEGIN_SRC python :session cnn :results none
get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
seaborn.set(style="whitegrid",
            rc={"axes.grid": False,
                "font.family": ["sans-serif"],
                "font.sans-serif": ["Open Sans", "Latin Modern Sans", "Lato"],
                "figure.figsize": (8, 6)},
            font_scale=1)
FIGURE_SIZE = (12, 10)
#+END_SRC

*** The Timer
#+begin_src ipython :session cnn :results none
TIMER = Timer()
#+end_src
*** The Environment
#+begin_src ipython :session cnn :results none
ENVIRONMENT = SubPathLoader("DATASETS")
#+end_src
* Middle
** The Data
*** Downloading it
#+begin_src ipython :session cnn :results output :exports both
TRAINING_URL = "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip"
TEST_URL = "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip"
OUT_PATH = Path(ENVIRONMENT["ROCK_PAPER_SCISSORS"]).expanduser()
download_train = ZipDownloader(TRAINING_URL, OUT_PATH/"train")
download_test = ZipDownloader(TEST_URL, OUT_PATH/"test")
download_train()
download_test()
#+end_src

#+RESULTS:
: Files exist, not downloading
: Files exist, not downloading

The data structure for the folders is fairly deep, so I'll make some shortcuts.

#+begin_src ipython :session cnn :results none
training = OUT_PATH/"train/rps"
rocks = training/"rock"
papers = training/"paper"
scissors = training/"scissors"
assert papers.is_dir()
assert rocks.is_dir()
assert scissors.is_dir()
#+end_src

#+begin_src ipython :session cnn :results output :exports both
rock_images = list(rocks.iterdir())
paper_images = list(papers.iterdir())
scissors_images = list(scissors.iterdir())
print(f"Rocks: {len(rock_images):,}")
print(f"Papers: {len(paper_images):,}")
print(f"Scissors: {len(scissors_images):,}")
#+end_src

#+RESULTS:
: Rocks: 840
: Papers: 840
: Scissors: 840

*** Some Examples
#+begin_src ipython :session cnn :results raw drawer :ipyfile ../../files/posts/keras/rock-paper-scissors/rock.png
rock_sample = random.choice(rock_images[:count])

image = matplotlib_image.imread(str(rock_sample))
pyplot.title("Rock")
pyplot.imshow(image)
pyplot.axis('Off')
pyplot.show()
#+end_src

#+RESULTS:
:results:
# Out[19]:
[[file:../../files/posts/keras/rock-paper-scissors/rock.png]]
:end:

#+begin_src ipython :session cnn :results raw drawer :ipyfile ../../files/posts/keras/rock-paper-scissors/paper.png
paper_sample = random.choice(paper_images)
image = matplotlib_image.imread(str(paper_sample))
pyplot.title("Paper")
pyplot.imshow(image)
pyplot.axis('Off')
pyplot.show()
#+end_src

#+RESULTS:
:results:
# Out[20]:
[[file:../../files/posts/keras/rock-paper-scissors/paper.png]]
:end:

#+begin_src ipython :session cnn :results raw drawer :ipyfile ../../files/posts/keras/rock-paper-scissors/scissors.png
scissors_sample = random.choice(scissors_images)
image = matplotlib_image.imread(str(scissors_sample))
pyplot.title("Scissors")
pyplot.imshow(image)
pyplot.axis('Off')
pyplot.show()
#+end_src

#+RESULTS:
:results:
# Out[21]:
[[file:../../files/posts/keras/rock-paper-scissors/scissors.png]]
:end:
*** Data Generators

#+begin_src ipython :session cnn :results none
training_data_generator = ImageDataGenerator(
      rescale = 1./255,
	  rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

validation_data_generator = ImageDataGenerator(rescale = 1./255)

train_generator = training_datagen.flow_from_directory(
	TRAINING_DIR,
	target_size=(150,150),
	class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
	VALIDATION_DIR,
	target_size=(150,150),
	class_mode='categorical'
)

#+end_src
** A Four-CNN Model
#+begin_src ipython :session cnn :results none
model = tensorflow.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tensorflow.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tensorflow.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tensorflow.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tensorflow.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tensorflow.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tensorflow.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tensorflow.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tensorflow.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tensorflow.keras.layers.Flatten(),
    tensorflow.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tensorflow.keras.layers.Dense(512, activation='relu'),
    tensorflow.keras.layers.Dense(3, activation='softmax')
])

#+end_src
* End
* Raw
#+begin_comment
import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator




model.summary()

model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit_generator(train_generator, epochs=25, validation_data = validation_generator, verbose = 1)

model.save("rps.h5")


# In[22]:


import matplotlib.pyplot as plt
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()


plt.show()


# In[26]:


import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(fn)
  print(classes)


#+end_comment
