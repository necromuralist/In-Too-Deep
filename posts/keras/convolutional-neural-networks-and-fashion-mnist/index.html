<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Using a CNN to classify the Fashion MNIST data set." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Convolutional Neural Networks and Fashion MNIST | In Too Deep</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/posts/keras/convolutional-neural-networks-and-fashion-mnist/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/keras/handwriting-recognition-exercise/" rel="prev" title="Handwriting Recognition Exercise" type="text/html">
<link href="/posts/keras/convolution-exploration/" rel="next" title="Convolution Exploration" type="text/html">
<meta content="In Too Deep" property="og:site_name">
<meta content="Convolutional Neural Networks and Fashion MNIST" property="og:title">
<meta content="https://necromuralist.github.io/In-Too-Deep/posts/keras/convolutional-neural-networks-and-fashion-mnist/" property="og:url">
<meta content="Using a CNN to classify the Fashion MNIST data set." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-06-30T16:26:01-07:00" property="article:published_time">
<meta content="cnn" property="article:tag">
<meta content="keras" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/">Convolutional Neural Networks and Fashion MNIST</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/" rel="bookmark"><time class="published dt-published" datetime="2019-06-30T16:26:01-07:00" itemprop="datePublished" title="2019-06-30 16:26">2019-06-30 16:26</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgac9ea38">Beginning</a>
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgee1fd19">Imports</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org3b0c31c">Set Up</a></li>
</ul>
</li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org7ad72ca">Middle</a>
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org35ba2f6">Some Exploratory Work</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgfa49d17">10 Epochs</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgd431a6d">15 Epochs</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgb3bb004">20 Epochs</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org5bf2ff0">Visualizing the Convolutions and Pooling</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org7a83ea2">Exercises</a></li>
</ul>
</li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org8bf6957">End</a>
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orge6fbef4">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgac9ea38">
<h2 id="orgac9ea38">Beginning</h2>
<div class="outline-text-2" id="text-orgac9ea38">
<p>The goal of this exercise is to create a model that can classify the Fashion MNIST data better than our previous single hidden-layer model.</p>
</div>
<div class="outline-3" id="outline-container-orgee1fd19">
<h3 id="orgee1fd19">Imports</h3>
<div class="outline-text-3" id="text-orgee1fd19"></div>
<div class="outline-4" id="outline-container-orgbeecbde">
<h4 id="orgbeecbde">PyPi</h4>
<div class="outline-text-4" id="text-orgbeecbde">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9b70084">
<h4 id="org9b70084">My Stuff</h4>
<div class="outline-text-4" id="text-org9b70084">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.timers</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org3b0c31c">
<h3 id="org3b0c31c">Set Up</h3>
<div class="outline-text-3" id="text-org3b0c31c"></div>
<div class="outline-4" id="outline-container-org67e6cdd">
<h4 id="org67e6cdd">The Timer</h4>
<div class="outline-text-4" id="text-org67e6cdd">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3aef8e1">
<h4 id="org3aef8e1">The Data</h4>
<div class="outline-text-4" id="text-org3aef8e1">
<div class="highlight">
<pre><span></span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">())</span>

<span class="n">training_images</span> <span class="o">=</span> <span class="n">training_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">testing_images</span> <span class="o">=</span> <span class="n">testing_images</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3610f1f">
<h4 id="org3610f1f">Plotting</h4>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7ad72ca">
<h2 id="org7ad72ca">Middle</h2>
<div class="outline-text-2" id="text-org7ad72ca"></div>
<div class="outline-3" id="outline-container-org35ba2f6">
<h3 id="org35ba2f6">Some Exploratory Work</h3>
<div class="outline-text-3" id="text-org35ba2f6"></div>
<div class="outline-4" id="outline-container-org3ff9679">
<h4 id="org3ff9679">A Baseline Model</h4>
<div class="outline-text-4" id="text-org3ff9679">
<p>Our baseline that we want to beat is a model with a single dense hidden layer with 128 nodes.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span> 
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing Loss: {loss:.2f} Testing Accuracy: {accuracy: .2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
WARNING: Logging before flag parsing goes to stderr.
W0703 11:50:56.498819 140182964418368 deprecation.py:506] From /home/brunhilde/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2019-07-03 11:50:56,502 graeae.timers.timer start: Started: 2019-07-03 11:50:56.502607
I0703 11:50:56.502984 140182964418368 timer.py:70] Started: 2019-07-03 11:50:56.502607
Epoch 1/10
60000/60000 - 5s - loss: 0.4973 - acc: 0.8252
Epoch 2/10
60000/60000 - 5s - loss: 0.3742 - acc: 0.8656
Epoch 3/10
60000/60000 - 5s - loss: 0.3382 - acc: 0.8775
Epoch 4/10
60000/60000 - 5s - loss: 0.3146 - acc: 0.8839
Epoch 5/10
60000/60000 - 4s - loss: 0.2976 - acc: 0.8897
Epoch 6/10
60000/60000 - 4s - loss: 0.2818 - acc: 0.8963
Epoch 7/10
60000/60000 - 4s - loss: 0.2707 - acc: 0.9002
Epoch 8/10
60000/60000 - 5s - loss: 0.2597 - acc: 0.9039
Epoch 9/10
60000/60000 - 5s - loss: 0.2502 - acc: 0.9066
Epoch 10/10
60000/60000 - 5s - loss: 0.2409 - acc: 0.9094
2019-07-03 11:51:42,904 graeae.timers.timer end: Ended: 2019-07-03 11:51:42.904683
I0703 11:51:42.904865 140182964418368 timer.py:77] Ended: 2019-07-03 11:51:42.904683
2019-07-03 11:51:42,907 graeae.timers.timer end: Elapsed: 0:00:46.402076
I0703 11:51:42.907317 140182964418368 timer.py:78] Elapsed: 0:00:46.402076
Testing Loss: 0.36 Testing Accuracy:  0.87
</pre></div>
</div>
<div class="outline-4" id="outline-container-orged5da19">
<h4 id="orged5da19">A Convolutional Neural Network</h4>
<div class="outline-text-4" id="text-orged5da19">
<p>The convolutional layer expects a single tensor instead of a feed of many of them so you need to reshape the input to make it work.</p>
<div class="highlight">
<pre><span></span><span class="n">training_images</span> <span class="o">=</span> <span class="n">training_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">testing_images</span> <span class="o">=</span> <span class="n">testing_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>Our model starts with a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D">Conv2D layer</a>. The arguments we're using are:</p>
<ul class="org-ul">
<li><code>filters</code>: the dimensionality of the output space (the number of output filters in the convolution)</li>
<li><code>kernel_size</code>: The height and width of the convolution window</li>
<li><code>activation</code>: The activation function for the output</li>
<li><code>input_shape</code>: If this is the first layer in the model you have to tell it what the input shape is</li>
</ul>
<p>The output of the convolutional layers go to a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D">MaxPool2D</a> layer. The only argument we're passing in is <code>pool_size</code>, the factors by which to downsize the input. Using <code>(2, 2)</code> will reduce the size in half. After the convolutions and pooling are applied, the output is sent through a version of the fully-connected network that we were using before (see the baseline model above).</p>
</div>
<ul class="org-ul">
<li><a id="orge2c9f18"></a>A Model Builder<br>
<div class="outline-text-5" id="text-orge2c9f18">
<p>Something to make it a little easier to re-use things. Note that in the original notebook the first example has 64 filters in the CNN, but later it says that it's better to start with 32 (and the exercises expect that you used 32) so I'm using that as the default value.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_stop</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="k">class</span> <span class="nc">Stop</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">loss</span><span class="p">):</span>
                <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Stopping point reached at epoch {epoch}"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="n">Stop</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">stop</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">ModelBuilder</span><span class="p">:</span>
    <span class="sd">"""Builds, trains, and tests our model</span>

<span class="sd">    Args:</span>
<span class="sd">     training_images: images to train on</span>
<span class="sd">     training_labels: labels for the training data</span>
<span class="sd">     testing_images: images to test the trained model with</span>
<span class="sd">     testing_labels: labels for the testing data</span>
<span class="sd">     additional_convolutions: convolutions besides the input convolution</span>
<span class="sd">     epochs: number of times to repeat training</span>
<span class="sd">     filters: number of filters in the output of the convolutional layers</span>
<span class="sd">     use_callback: use the Stop to end trainig</span>
<span class="sd">     callback_loss: loss to use for the callback</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_images</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">training_images</span><span class="p">,</span>
                 <span class="n">training_labels</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">training_labels</span><span class="p">,</span>
                 <span class="n">testing_images</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">testing_images</span><span class="p">,</span>
                 <span class="n">testing_labels</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">testing_labels</span><span class="p">,</span>
                 <span class="n">additional_convolutions</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                 <span class="n">filters</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">use_callback</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">callback_loss</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_images</span> <span class="o">=</span> <span class="n">training_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_labels</span> <span class="o">=</span> <span class="n">training_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">testing_images</span> <span class="o">=</span> <span class="n">testing_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">testing_labels</span> <span class="o">=</span> <span class="n">testing_labels</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">additional_convolutions</span> <span class="o">=</span> <span class="n">additional_convolutions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filters</span> <span class="o">=</span> <span class="n">filters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_callback</span> <span class="o">=</span> <span class="n">use_callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_loss</span> <span class="o">=</span> <span class="n">callback_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">return</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Stop</span><span class="p">:</span>
        <span class="sd">"""The callback to stop the training"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">get_stop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">callback_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
        <span class="sd">"""Our CNN Model"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">,</span> 
                <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">convolution</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">additional_convolutions</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                                                               <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span> 
                                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>

    <span class="k">def</span> <span class="nf">print_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Print out the summary for the model"""</span>
        <span class="k">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">       Fit the model to the training data</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_callback</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_labels</span><span class="p">,</span> 
                           <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_labels</span><span class="p">,</span> 
                           <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">"""Check the loss and accuracy of the model against the testing set</span>

<span class="sd">       Returns:</span>
<span class="sd">        (loss, accuracy): the output of the evaluation of the testing data</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">testing_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Builds and tests the model"""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing Loss: {loss:.2f}  Testing Accuracy: {accuracy:.2f}"</span><span class="p">)</span>
        <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># model = create_model()</span>
<span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">builder</span><span class="o">.</span><span class="n">print_summary</span><span class="p">()</span>
</pre></div>
<pre class="example">
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 11, 11, 32)        9248      
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 5, 5, 32)          0         
_________________________________________________________________
flatten_17 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 128)               102528    
_________________________________________________________________
dense_35 (Dense)             (None, 10)                1290      
=================================================================
Total params: 113,386
Trainable params: 113,386
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org085b1ab">
<h4 id="org085b1ab">Layer By Layer</h4>
<div class="outline-text-4" id="text-org085b1ab">
<ul class="org-ul">
<li>Our input is a set of 28 x 28 images.</li>
<li>Because we didn't pad the images, the convolutional layer "trims" off one row and column on each side (the center cell can't reach the outermost cells) so we get a 26 x 26 grid with 64 filters (which is what we set up in the definition).</li>
<li>The Max Pooling layer the halves the image so we have 13 x 13 grid with 64 filters</li>
<li>The next convolution layer once again trims off one row on each side so we have a 11 x 11 grid with 64 filters</li>
<li>Then the Max Pooling halves the grid once again so we have a 5 x 5 grid with 64 filters</li>
<li>The Flatten layer outputs a vector with 1,600 cells (<i>5 x 5 x 64 = 1,600</i>).</li>
<li>The first Dense layer has 128 neurons in it so that's the size of the output</li>
<li>And the final Dense layer converts it to 10 outputs to match the number of labels we have</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/5
60000/60000 - 17s - loss: 0.4671 - acc: 0.8290
Epoch 2/5
60000/60000 - 17s - loss: 0.3149 - acc: 0.8844
Epoch 3/5
60000/60000 - 17s - loss: 0.2688 - acc: 0.9003
Epoch 4/5
60000/60000 - 17s - loss: 0.2414 - acc: 0.9112
Epoch 5/5
60000/60000 - 17s - loss: 0.2175 - acc: 0.9198
Testing Loss: 0.28  Testing Accuracy: 0.89
</pre>
<p>Using the Convolutional Neural Network we've gone from 88% to 91% accuracy.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgfa49d17">
<h3 id="orgfa49d17">10 Epochs</h3>
<div class="outline-text-3" id="text-orgfa49d17">
<p>Using five epochs it appears that the loss is still going down while the accuracy is going up. What happens with ten epochs?</p>
<div class="highlight">
<pre><span></span><span class="n">builder_10</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">builder_10</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/10
60000/60000 - 16s - loss: 0.4807 - acc: 0.8242
Epoch 2/10
60000/60000 - 16s - loss: 0.3233 - acc: 0.8825
Epoch 3/10
60000/60000 - 15s - loss: 0.2776 - acc: 0.8976
Epoch 4/10
60000/60000 - 16s - loss: 0.2474 - acc: 0.9082
Epoch 5/10
60000/60000 - 16s - loss: 0.2273 - acc: 0.9155
Epoch 6/10
60000/60000 - 16s - loss: 0.2030 - acc: 0.9240
Epoch 7/10
60000/60000 - 16s - loss: 0.1854 - acc: 0.9314
Epoch 8/10
60000/60000 - 16s - loss: 0.1693 - acc: 0.9361
Epoch 9/10
60000/60000 - 15s - loss: 0.1540 - acc: 0.9419
Epoch 10/10
60000/60000 - 16s - loss: 0.1419 - acc: 0.9467
Testing Loss: 0.26  Testing Accuracy: 0.91
</pre>
<p>It looks like it's still learning.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgd431a6d">
<h3 id="orgd431a6d">15 Epochs</h3>
<div class="outline-text-3" id="text-orgd431a6d">
<div class="highlight">
<pre><span></span><span class="n">builder_15</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">builder_15</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/15
60000/60000 - 16s - loss: 0.4754 - acc: 0.8260
Epoch 2/15
60000/60000 - 16s - loss: 0.3155 - acc: 0.8834
Epoch 3/15
60000/60000 - 16s - loss: 0.2725 - acc: 0.9001
Epoch 4/15
60000/60000 - 16s - loss: 0.2447 - acc: 0.9096
Epoch 5/15
60000/60000 - 16s - loss: 0.2199 - acc: 0.9180
Epoch 6/15
60000/60000 - 16s - loss: 0.1996 - acc: 0.9248
Epoch 7/15
60000/60000 - 16s - loss: 0.1813 - acc: 0.9316
Epoch 8/15
60000/60000 - 16s - loss: 0.1666 - acc: 0.9372
Epoch 9/15
60000/60000 - 16s - loss: 0.1525 - acc: 0.9430
Epoch 10/15
60000/60000 - 15s - loss: 0.1374 - acc: 0.9484
Epoch 11/15
60000/60000 - 16s - loss: 0.1257 - acc: 0.9527
Epoch 12/15
60000/60000 - 15s - loss: 0.1135 - acc: 0.9569
Epoch 13/15
60000/60000 - 16s - loss: 0.1025 - acc: 0.9615
Epoch 14/15
60000/60000 - 15s - loss: 0.0937 - acc: 0.9647
Epoch 15/15
60000/60000 - 16s - loss: 0.0849 - acc: 0.9682
Testing Loss: 0.34  Testing Accuracy: 0.91
</pre>
<p>It looks like it's started to overfit, the accuracy is okay, but the loss is a little worse.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgb3bb004">
<h3 id="orgb3bb004">20 Epochs</h3>
<div class="outline-text-3" id="text-orgb3bb004">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/20
60000/60000 - 16s - loss: 0.4759 - acc: 0.8264
Epoch 2/20
60000/60000 - 16s - loss: 0.3218 - acc: 0.8822
Epoch 3/20
60000/60000 - 16s - loss: 0.2767 - acc: 0.8982
Epoch 4/20
60000/60000 - 16s - loss: 0.2469 - acc: 0.9083
Epoch 5/20
60000/60000 - 16s - loss: 0.2218 - acc: 0.9177
Epoch 6/20
60000/60000 - 16s - loss: 0.2015 - acc: 0.9244
Epoch 7/20
60000/60000 - 16s - loss: 0.1848 - acc: 0.9309
Epoch 8/20
60000/60000 - 15s - loss: 0.1698 - acc: 0.9361
Epoch 9/20
60000/60000 - 14s - loss: 0.1525 - acc: 0.9424
Epoch 10/20
60000/60000 - 15s - loss: 0.1435 - acc: 0.9457
Epoch 11/20
60000/60000 - 16s - loss: 0.1306 - acc: 0.9504
Epoch 12/20
60000/60000 - 15s - loss: 0.1172 - acc: 0.9556
Epoch 13/20
60000/60000 - 15s - loss: 0.1079 - acc: 0.9594
Epoch 14/20
60000/60000 - 15s - loss: 0.0993 - acc: 0.9626
Epoch 15/20
60000/60000 - 15s - loss: 0.0900 - acc: 0.9658
Epoch 16/20
60000/60000 - 15s - loss: 0.0829 - acc: 0.9686
Epoch 17/20
60000/60000 - 15s - loss: 0.0746 - acc: 0.9720
Epoch 18/20
60000/60000 - 16s - loss: 0.0713 - acc: 0.9736
Epoch 19/20
60000/60000 - 15s - loss: 0.0638 - acc: 0.9760
Epoch 20/20
60000/60000 - 15s - loss: 0.0594 - acc: 0.9781
Testing Loss: 0.45  Testing Accuracy: 0.91
</pre>
<p>It looks like it might be overfitting - both the loss and the accuracy went down a little.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org5bf2ff0">
<h3 id="org5bf2ff0">Visualizing the Convolutions and Pooling</h3>
<div class="outline-text-3" id="text-org5bf2ff0">
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">testing_labels</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
<pre class="example">
[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7
 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6
 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]

</pre>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">builder_10</span><span class="o">.</span><span class="n">model</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axis_array</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">FIRST_IMAGE</span><span class="o">=</span><span class="mi">0</span>
<span class="n">SECOND_IMAGE</span><span class="o">=</span><span class="mi">7</span>
<span class="n">THIRD_IMAGE</span><span class="o">=</span><span class="mi">26</span>
<span class="n">CONVOLUTION_NUMBER</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">layer_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">]</span>

<span class="n">activation_model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">layer_outputs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">f1</span> <span class="o">=</span> <span class="n">activation_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">[</span><span class="n">FIRST_IMAGE</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:,</span> <span class="n">CONVOLUTION_NUMBER</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'inferno'</span><span class="p">)</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">f2</span> <span class="o">=</span> <span class="n">activation_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">[</span><span class="n">SECOND_IMAGE</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:,</span> <span class="n">CONVOLUTION_NUMBER</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'inferno'</span><span class="p">)</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">f3</span> <span class="o">=</span> <span class="n">activation_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">[</span><span class="n">THIRD_IMAGE</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f3</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:,</span> <span class="n">CONVOLUTION_NUMBER</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'inferno'</span><span class="p">)</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="layer_visualization.png" src="/posts/keras/convolutional-neural-networks-and-fashion-mnist/layer_visualization.png"></p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7a83ea2">
<h3 id="org7a83ea2">Exercises</h3>
<div class="outline-text-3" id="text-org7a83ea2"></div>
<div class="outline-4" id="outline-container-orgd28693f">
<h4 id="orgd28693f">1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.</h4>
<div class="outline-text-4" id="text-orgd28693f"></div>
<ul class="org-ul">
<li><a id="org5238cc7"></a>16 Nodes<br>
<div class="outline-text-5" id="text-org5238cc7">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 12:06:27,700 graeae.timers.timer start: Started: 2019-07-03 12:06:27.700578
I0703 12:06:27.700625 140182964418368 timer.py:70] Started: 2019-07-03 12:06:27.700578
Epoch 1/10
60000/60000 - 17s - loss: 0.5169 - acc: 0.8100
Epoch 2/10
60000/60000 - 17s - loss: 0.3536 - acc: 0.8714
Epoch 3/10
60000/60000 - 17s - loss: 0.3075 - acc: 0.8873
Epoch 4/10
60000/60000 - 17s - loss: 0.2808 - acc: 0.8959
Epoch 5/10
60000/60000 - 16s - loss: 0.2590 - acc: 0.9027
Epoch 6/10
60000/60000 - 17s - loss: 0.2419 - acc: 0.9100
Epoch 7/10
60000/60000 - 17s - loss: 0.2276 - acc: 0.9156
Epoch 8/10
60000/60000 - 17s - loss: 0.2140 - acc: 0.9182
Epoch 9/10
60000/60000 - 17s - loss: 0.2030 - acc: 0.9233
Epoch 10/10
60000/60000 - 17s - loss: 0.1934 - acc: 0.9266
2019-07-03 12:09:18,226 graeae.timers.timer end: Ended: 2019-07-03 12:09:18.226577
I0703 12:09:18.226756 140182964418368 timer.py:77] Ended: 2019-07-03 12:09:18.226577
2019-07-03 12:09:18,229 graeae.timers.timer end: Elapsed: 0:02:50.525999
I0703 12:09:18.229464 140182964418368 timer.py:78] Elapsed: 0:02:50.525999
Testing Loss: 0.29  Testing Accuracy: 0.90
</pre>
<p>The smaller model had slightly more loss than the 32 node model as well as a little less accuracy.</p>
</div>
</li>
<li><a id="org9c59cc6"></a>64 Nodes<br>
<div class="outline-text-5" id="text-org9c59cc6">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 12:09:19,711 graeae.timers.timer start: Started: 2019-07-03 12:09:19.711082
I0703 12:09:19.711113 140182964418368 timer.py:70] Started: 2019-07-03 12:09:19.711082
Epoch 1/10
60000/60000 - 19s - loss: 0.4367 - acc: 0.8428
Epoch 2/10
60000/60000 - 18s - loss: 0.2923 - acc: 0.8929
Epoch 3/10
60000/60000 - 18s - loss: 0.2472 - acc: 0.9087
Epoch 4/10
60000/60000 - 18s - loss: 0.2156 - acc: 0.9205
Epoch 5/10
60000/60000 - 18s - loss: 0.1893 - acc: 0.9298
Epoch 6/10
60000/60000 - 18s - loss: 0.1665 - acc: 0.9380
Epoch 7/10
60000/60000 - 18s - loss: 0.1460 - acc: 0.9456
Epoch 8/10
60000/60000 - 18s - loss: 0.1285 - acc: 0.9500
Epoch 9/10
60000/60000 - 18s - loss: 0.1142 - acc: 0.9568
Epoch 10/10
60000/60000 - 18s - loss: 0.0972 - acc: 0.9621
2019-07-03 12:12:23,275 graeae.timers.timer end: Ended: 2019-07-03 12:12:23.274851
I0703 12:12:23.275002 140182964418368 timer.py:77] Ended: 2019-07-03 12:12:23.274851
2019-07-03 12:12:23,277 graeae.timers.timer end: Elapsed: 0:03:03.563769
I0703 12:12:23.277686 140182964418368 timer.py:78] Elapsed: 0:03:03.563769
Testing Loss: 0.32  Testing Accuracy: 0.91
</pre>
<p>This has the same accuracy as the 32 node model but with a slight increase in the loss.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org32c934e">
<h4 id="org32c934e">2. Remove the final Convolution. What impact will this have on accuracy or training time?</h4>
<div class="outline-text-4" id="text-org32c934e">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">additional_convolutions</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 12:12:24,795 graeae.timers.timer start: Started: 2019-07-03 12:12:24.795249
I0703 12:12:24.795282 140182964418368 timer.py:70] Started: 2019-07-03 12:12:24.795249
Epoch 1/10
60000/60000 - 14s - loss: 0.3897 - acc: 0.8607
Epoch 2/10
60000/60000 - 14s - loss: 0.2642 - acc: 0.9042
Epoch 3/10
60000/60000 - 14s - loss: 0.2218 - acc: 0.9187
Epoch 4/10
60000/60000 - 14s - loss: 0.1883 - acc: 0.9306
Epoch 5/10
60000/60000 - 14s - loss: 0.1619 - acc: 0.9391
Epoch 6/10
60000/60000 - 14s - loss: 0.1387 - acc: 0.9482
Epoch 7/10
60000/60000 - 14s - loss: 0.1171 - acc: 0.9564
Epoch 8/10
60000/60000 - 14s - loss: 0.1000 - acc: 0.9629
Epoch 9/10
60000/60000 - 14s - loss: 0.0831 - acc: 0.9702
Epoch 10/10
60000/60000 - 14s - loss: 0.0728 - acc: 0.9729
2019-07-03 12:14:46,396 graeae.timers.timer end: Ended: 2019-07-03 12:14:46.396417
I0703 12:14:46.396641 140182964418368 timer.py:77] Ended: 2019-07-03 12:14:46.396417
2019-07-03 12:14:46,400 graeae.timers.timer end: Elapsed: 0:02:21.601168
I0703 12:14:46.400143 140182964418368 timer.py:78] Elapsed: 0:02:21.601168
Testing Loss: 0.31  Testing Accuracy: 0.92
</pre>
<p>Once again the accuracy is a little better than the 32 node model but the testing loss is also a little higher. We probably need more data.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org0584c2b">
<h4 id="org0584c2b">3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.</h4>
<div class="outline-text-4" id="text-org0584c2b">
<div class="highlight">
<pre><span></span>"results output"body
</pre></div>
<pre class="example">
# Out[21]:

</pre></div>
</div>
<div class="outline-4" id="outline-container-org6bdb8a3">
<h4 id="org6bdb8a3">4. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!</h4>
<div class="outline-text-4" id="text-org6bdb8a3">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">use_callback</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback_loss</span><span class="o">=</span><span class="mf">0.19</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 15:20:50,279 graeae.timers.timer start: Started: 2019-07-03 15:20:50.279833
I0703 15:20:50.279866 140182964418368 timer.py:70] Started: 2019-07-03 15:20:50.279833
Epoch 1/100
60000/60000 - 17s - loss: 0.4773 - acc: 0.8277
Epoch 2/100
60000/60000 - 17s - loss: 0.3204 - acc: 0.8840
Epoch 3/100
60000/60000 - 17s - loss: 0.2777 - acc: 0.8986
Epoch 4/100
60000/60000 - 17s - loss: 0.2463 - acc: 0.9089
Epoch 5/100
60000/60000 - 17s - loss: 0.2220 - acc: 0.9179
Epoch 6/100
60000/60000 - 17s - loss: 0.2029 - acc: 0.9250
Epoch 7/100
Stopping point reached at epoch 6
60000/60000 - 17s - loss: 0.1827 - acc: 0.9314
2019-07-03 15:22:51,538 graeae.timers.timer end: Ended: 2019-07-03 15:22:51.537895
I0703 15:22:51.538049 140182964418368 timer.py:77] Ended: 2019-07-03 15:22:51.537895
2019-07-03 15:22:51,540 graeae.timers.timer end: Elapsed: 0:02:01.258062
I0703 15:22:51.540425 140182964418368 timer.py:78] Elapsed: 0:02:01.258062
Testing Loss: 0.25  Testing Accuracy: 0.91
</pre>
<p>This does about the same as the 10 epoch version, so we didn't save much, but it gives us a way to stop without guessing the number of epochs.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8bf6957">
<h2 id="org8bf6957">End</h2>
<div class="outline-text-2" id="text-org8bf6957"></div>
<div class="outline-3" id="outline-container-orge6fbef4">
<h3 id="orge6fbef4">Source</h3>
<div class="outline-text-3" id="text-orge6fbef4">
<ul class="org-ul">
<li>This is a redo of the <a href="https://github.com/lmoroney/dlaicourse/blob/master/course%201%20-%20part%206%20-%20lesson%202%20-%20notebook.ipynb">Improving Computer Vision Accuracy Using Convolutions</a> notebook.</li>
</ul>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/cnn/" rel="tag">cnn</a></li>
<li><a class="tag p-category" href="/categories/keras/" rel="tag">keras</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/keras/handwriting-recognition-exercise/" rel="prev" title="Handwriting Recognition Exercise">Previous post</a></li>
<li class="next"><a href="/posts/keras/convolution-exploration/" rel="next" title="Convolution Exploration">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
