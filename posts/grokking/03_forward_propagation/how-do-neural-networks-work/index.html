<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content='Notes on Chapter Three of "Grokking Deep Learning".' name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>How Do Neural Networks Work? | In Too Deep</title>
<link href="../../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/how-do-neural-networks-work/" rel="canonical"><!--[if lt IE 9]><script src="../../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/grokking/how-do-machines-learn/" rel="prev" title="How Do Machines Learn?" type="text/html">
<link href="/posts/grokking/03_forward_propagation/how-do-you-handle-multiple-outputs/" rel="next" title="How do you handle multiple outputs?" type="text/html">
<meta content="In Too Deep" property="og:site_name">
<meta content="How Do Neural Networks Work?" property="og:title">
<meta content="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/how-do-neural-networks-work/" property="og:url">
<meta content="Notes on Chapter Three of &quot;Grokking Deep Learning&quot;." property="og:description">
<meta content="article" property="og:type">
<meta content="2018-10-17T15:04:33-07:00" property="article:published_time">
<meta content="grokking" property="article:tag">
<meta content="neural networks" property="article:tag">
<meta content="notes" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/">How Do Neural Networks Work?</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/" rel="bookmark"><time class="published dt-published" datetime="2018-10-17T15:04:33-07:00" itemprop="datePublished" title="2018-10-17 15:04">2018-10-17 15:04</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org63d4dda">Beginning</a>
<ul>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org7d09073">What is this about?</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org430344e">Imports</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#orgd982ef5">Set Up</a></li>
</ul>
</li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org52aaf29">Middle</a>
<ul>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org2cb6cde">What is the simplest neural network we can create to make this prediction?</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#orgedce55e">What does <i>knowledge</i> and <i>information</i> mean in our neural network?</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org8d50f07">What kind of memory does a neuron have?</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#orga2152f3">So weights are memory, but what is it memorizing?</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org7a92faf">So, how do you handle multiple inputs?</a></li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#org2c0e893">How would you do this with numpy?</a></li>
</ul>
</li>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#orgfad2c07">End</a>
<ul>
<li><a href="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/#orgbf8d0a7">Sources</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org63d4dda">
<h2 id="org63d4dda">Beginning</h2>
<div class="outline-text-2" id="text-org63d4dda"></div>
<div class="outline-3" id="outline-container-org7d09073">
<h3 id="org7d09073">What is this about?</h3>
<div class="outline-text-3" id="text-org7d09073">
<p>These are notes on Chapter Three of "Grokking Deep Learning". It is an explanation of how neural networks perform the first step of training the model - making predictions. This might seem like a step for after you finish training the model, but in order to correct the model you have to be able to make predictions to see how well it is doing. We'll look at a model that predicts whether a team will win a game based on a single feature (the average number of toes on the team).</p>
<p>Heres' the network.</p>
<div class="highlight">
<pre><span></span>SLUG = "how-do-neural-networks-work/"
PATH = "../../../files/posts/grokking/03_forward_propagation/" + SLUG
graph = Digraph(comment="Toes Model", format="png",
                graph_attr={"rankdir": "LR", "dpi": "200"})
graph.node("A", "Toes")
graph.node("B", "Win")
graph.edge("A", "B", label="w=0.1")
graph.render(PATH + "toes_model_1.dot")
graph
</pre></div>
<div class="figure">
<p><img alt="toes_model_1.dot.png" src="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/toes_model_1.dot.png"></p>
</div>
<p>Although we're calling it a network we're really creating only the first building block for a single neuron. A neuron works by doing three basic things:</p>
<ol class="org-ol">
<li>It receives signals from other neurons (over <i>dendrites</i>, the inputs to the neuron)</li>
<li>It aggregates the signals within the cell-body (<i>soma</i>) of the neurn</li>
<li>If the cell voltage crosses a threshold then it fires a signal out across its <i>axon</i></li>
</ol>
<p>We can kind of say there's an implied axon to our network, it just isn't shown, and we can read the <i>Toes</i> node as either another neuron and the edge between it and the <i>Win</i> node is a <i>synapse</i> (Greek for <i>conjunction</i>) which contains an axon coming out of <i>Toes</i> that joins the dendrite going into <i>Win</i>), and we might even say that it's a network of two nodes, but what we are truly missing is the test to see if the cell's charge exceeds a threshold. That will have to come later.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org430344e">
<h3 id="org430344e">Imports</h3>
<div class="outline-text-3" id="text-org430344e"></div>
<div class="outline-4" id="outline-container-orga655e6c">
<h4 id="orga655e6c">From Python</h4>
<div class="outline-text-4" id="text-orga655e6c">
<div class="highlight">
<pre><span></span> from functools import partial
 from typing import List
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdd7248b">
<h4 id="orgdd7248b">From PyPi</h4>
<div class="outline-text-4" id="text-orgdd7248b">
<div class="highlight">
<pre><span></span>from graphviz import Digraph
import holoviews
import hvplot.pandas
import numpy
import pandas
import torch
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8a0e72f">
<h4 id="org8a0e72f">Others</h4>
<div class="outline-text-4" id="text-org8a0e72f">
<div class="highlight">
<pre><span></span>from graeae import EmbedHoloviews
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd982ef5">
<h3 id="orgd982ef5">Set Up</h3>
<div class="outline-text-3" id="text-orgd982ef5"></div>
<div class="outline-4" id="outline-container-orge27885f">
<h4 id="orge27885f">Plotting</h4>
<div class="outline-text-4" id="text-orge27885f">
<div class="highlight">
<pre><span></span>Embed = partial(
    EmbedHoloviews,
    folder_path=PATH)

holoviews.opts(width=1000, height=800)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdeff283">
<h4 id="orgdeff283">Types</h4>
<div class="outline-text-4" id="text-orgdeff283">
<div class="highlight">
<pre><span></span>Numbers = List[float]
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org52aaf29">
<h2 id="org52aaf29">Middle</h2>
<div class="outline-text-2" id="text-org52aaf29"></div>
<div class="outline-3" id="outline-container-org2cb6cde">
<h3 id="org2cb6cde">What is the simplest neural network we can create to make this prediction?</h3>
<div class="outline-text-3" id="text-org2cb6cde"></div>
<div class="outline-4" id="outline-container-orgc904537">
<h4 id="orgc904537">Our Network</h4>
<div class="outline-text-4" id="text-orgc904537">
<div class="figure">
<p><img alt="toes_model_1.dot.png" src="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/toes_model_1.dot.png"></p>
</div>
<p>Our network represents two neurons with a synapse between them. The synapse/dendrite has a certain weight representing how much of the input signal (average number of toes) can get across it to the <i>Win</i> neuron - the higher the weight, the more signal it contributes to our <i>Win</i> neuron deciding whether to fire or not. In this case we have an arbitrary weight of 0.1. The input to the <i>Win</i> neuron is just the weight of the dendrite times the output of the <i>Toes</i> neuron.</p>
<p>In the book <i>Grokking Deep Learning</i> Andrew Trask uses the analogy of the weights being like the knob on a machine that turns the volume up and down (I don't think he says volume, but it's the same idea). This is something that I seem to recall seeing in books describing the coefficients for linear regression - every variable you add gives you another knob to tune, but since the more common analogy is to think of modeling artificial neurons in the brain, it might be better to think of the weights as the thickness of the dendrite.</p>
<div class="highlight">
<pre><span></span> def one_neuron(toes: float, weight: float=0.1) -&gt; float:
     """This is a model to predict whether a team will win

     Args:
      toes: Average number of toes on the team
      weight: how much to weight to give to the toes

     Returns:
      prediction: our guess as to the probability that they will win
     """
     return toes * weight
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5b11656">
<h4 id="org5b11656">Some Predictions</h4>
<div class="outline-text-4" id="text-org5b11656">
<p>We can test out what our model thinks with some test values.</p>
<div class="highlight">
<pre><span></span> average_toes = [8.5, 9, 9.5, 10]
 predictions = [one_neuron(toe) for toe in average_toes]
 print("| Toes | Probability of Winning (%)|")
 print("|-+-|")
 for index, toes in enumerate(average_toes):
     prediction = predictions[index] * 100
     print(f"| {toes} | {prediction:.0f} % |")
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Toes</th>
<th class="org-left" scope="col">Probability of Winning (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">8.5</td>
<td class="org-left">85 %</td>
</tr>
<tr>
<td class="org-right">9</td>
<td class="org-left">90 %</td>
</tr>
<tr>
<td class="org-right">9.5</td>
<td class="org-left">95 %</td>
</tr>
<tr>
<td class="org-right">10</td>
<td class="org-left">100 %</td>
</tr>
</tbody>
</table>
<div class="highlight">
<pre><span></span> data = pandas.DataFrame({"Average Toes": average_toes,
                          "Probability of Winning": predictions})
 plot = data.hvplot(x="Average Toes", y="Probability of Winning").opts(
     width=1000, height=800, title="Toe Model")
 Embed(plot=plot, file_name="toes_only_predictions")()
</pre></div>
<object data="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/toes_only_predictions.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>As you can see, it's just a straight line. If we think in terms of the familiar \(y=mx + b\) it's:</p>
<p>\[ probability = 0.1 \times toes \]</p>
<p>Where \(b=0\). So every toe contributes 10% to our prediction.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgedce55e">
<h3 id="orgedce55e">What does <i>knowledge</i> and <i>information</i> mean in our neural network?</h3>
<div class="outline-text-3" id="text-orgedce55e">
<p>The neural network stores its <i>knowledge</i> as weights and when given <i>information</i> (input) it converts them to a prediction (output).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org8d50f07">
<h3 id="org8d50f07">What kind of memory does a neuron have?</h3>
<div class="outline-text-3" id="text-org8d50f07">
<p>A neuron stores what its learned (long-term memory) as the weight on the edge(s). The neuron as we've implemented it doesn't have any short-term memory, it can only consider one input at a time and "forgets" the previous input that it got. To have short-term memory you need to employ a different method that uses multiple inputs at the same time.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orga2152f3">
<h3 id="orga2152f3">So weights are memory, but what is it memorizing?</h3>
<div class="outline-text-3" id="text-orga2152f3">
<p>Since the neuron represents one feature (average toes) the weight is how important this feature is to the outcome (winning). If you have multiple features, the weights turn up or down the volume for each of the features (thus the knob analogy).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org7a92faf">
<h3 id="org7a92faf">So, how do you handle multiple inputs?</h3>
<div class="outline-text-3" id="text-org7a92faf">
<p>If you have multiple inputs then your prediction is the sum of the individual outputs.</p>
<div class="highlight">
<pre><span></span> graph = Digraph(comment="Three Nodes", format="png")
 graph.node("A", "Toes")
 graph.node("B", "Wins")
 graph.node("C", "Fans")
 graph.node("D", "Prediction")
 graph.edges(["AD", "BD", "CD"])
 graph.render("graphs/three_nodes.dot")
</pre></div>
<div class="figure">
<p><img alt="three_nodes.dot.png" src="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/three_nodes.dot.png"></p>
</div>
</div>
<div class="outline-4" id="outline-container-orgad954bc">
<h4 id="orgad954bc">Weighted Sum</h4>
<div class="outline-text-4" id="text-orgad954bc">
<p>Since we have three nodes we need to return the sum of the weights and inputs. This is actually <a href="https://en.wikipedia.org/wiki/Dot_product">the dot-product</a>.</p>
<div class="highlight">
<pre><span></span> def weighted_sum(inputs: Numbers, weights: Numbers) -&gt; float:
     """calculates the sum of the products

     Args:
      inputs: list of input data
      weights: list of weights for the inputs

     Returns:
      sum: the sum of the product of the weights and inputs
     """
     assert len(inputs) == len(weights)
     return sum((inputs[item] * weights[item] for item in range(len(inputs))))
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbf2d059">
<h4 id="orgbf2d059">The Node</h4>
<div class="outline-text-4" id="text-orgbf2d059">
<p>For each of our features we will have a series of inputs and weights</p>
<div class="highlight">
<pre><span></span> def network(inputs: Numbers, weights:Numbers) -&gt; float:
     """Makes a prediction based on the inputs and weights"""
     return weighted_sum(inputs, weights)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org982e743">
<h4 id="org982e743">Some Statistics</h4>
<div class="outline-text-4" id="text-org982e743">
<p>We have some data collected about our team over four games.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Variable</th>
<th class="org-left" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>toes</code></td>
<td class="org-left">average number of toes the members have at game-time</td>
</tr>
<tr>
<td class="org-left"><code>record</code></td>
<td class="org-left">fraction of games won</td>
</tr>
<tr>
<td class="org-left"><code>fans</code></td>
<td class="org-left">Millions of fans that watched</td>
</tr>
</tbody>
</table>
<div class="highlight">
<pre><span></span> toes = [8.5, 9.5, 9.9, 9.0]
 record = [0.65, 0.8, 0.8, 0.9]
 fans = [1.2, 1.3, 0.5, 1.0]
</pre></div>
<div class="highlight">
<pre><span></span> weights = [0.1, 0.2, 0.0]
</pre></div>
<p>The weights correspond to <i>(toes, record, fans)</i> for each game so we weight the win-loss record the most and fans not at all.</p>
<div class="highlight">
<pre><span></span> predictions = [
     network([toes[game], record[game], fans[game]], weights)
                for game in range(len(toes))]
 assert abs(predictions[0] - 0.98) &lt; 0.1**5

 for game, prediction in enumerate(predictions):
     print("For game {} our prediction is {:.2f}".format(game + 2,
                                                     prediction))
</pre></div>
<pre class="example">
For game 2 our prediction is 0.98
For game 3 our prediction is 1.11
For game 4 our prediction is 1.15
For game 5 our prediction is 1.08
</pre>
<p>With the exception of game two we're predicting that the combination of toes and previous wins make the win pretty much inevitable.</p>
<div class="highlight">
<pre><span></span> data = pandas.DataFrame({"toes": toes, "record": record,
                          "prediction": predictions})
 data = data.sort_values(by="toes")
 prediction_plot = data.hvplot(x="toes", y="prediction")
 other = data.hvplot(x="toes", y="record")
 plot = (prediction_plot * other).opts(
     title="Toes vs Record & Prediction",
     width=1000,
     height=800,
 )

 Embed(plot=plot, file_name="toes_vs_record")()
</pre></div>
<object data="/posts/grokking/03_forward_propagation/how-do-neural-networks-work/toes_vs_record.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Looking at the plot you can see that the probability keeps climbing with the number of toes and the peak record (9 toes, 90% wins) is canceled out by the fact that it occurs with a team with fewer toes than the peak of 9.9 toes.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2c0e893">
<h3 id="org2c0e893">How would you do this with numpy?</h3>
<div class="outline-text-3" id="text-org2c0e893">
<p>Although we used for-loops to calculate the predictions, we can view each of the inputs as a vector and the weights as a vector and then the prediction becomes the dot product of the inputs and the weights, so we can use numpy's <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html">dot</a> method to calculate it for us.</p>
<div class="highlight">
<pre><span></span> network = numpy.array([toes, record, fans])
 predictions = network.T.dot(weights)
 assert abs(predictions[0] - 0.98) &lt; 0.1**5

 for game, prediction in enumerate(predictions):
     print("For game {} our prediction is {:.2f}".format(game + 2,
                                                     prediction))
</pre></div>
<pre class="example">
For game 2 our prediction is 0.98
For game 3 our prediction is 1.11
For game 4 our prediction is 1.15
For game 5 our prediction is 1.08
</pre></div>
<div class="outline-4" id="outline-container-org7407b2a">
<h4 id="org7407b2a">PyTorch Redo</h4>
<div class="outline-text-4" id="text-org7407b2a">
<p>Pytorch can act like numpy working on the GPU, making the calculations faster, but the syntax is a little different.</p>
<div class="highlight">
<pre><span></span>device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
inputs = torch.tensor([toes, record, fans], device=device)
weights = torch.tensor(weights, device=device)
predictions = inputs.T.matmul(weights)
for game, prediction in enumerate(predictions):
    print("For game {} our prediction is {:.2f}".format(game + 2,
                                                    prediction))
</pre></div>
<pre class="example">
For game 2 our prediction is 0.98
For game 3 our prediction is 1.11
For game 4 our prediction is 1.15
For game 5 our prediction is 1.08
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  This is separate from the ipykernel package so we can avoid doing imports until
</pre>
<p><b>Note:</b> In this simple case the pytorch version is much slower than the numpy version - sometimes "optimization" isn't really optimal.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgfad2c07">
<h2 id="orgfad2c07">End</h2>
<div class="outline-text-2" id="text-orgfad2c07"></div>
<div class="outline-3" id="outline-container-orgbf8d0a7">
<h3 id="orgbf8d0a7">Sources</h3>
<div class="outline-text-3" id="text-orgbf8d0a7"></div>
<div class="outline-4" id="outline-container-org32b64f7">
<h4 id="org32b64f7">[GDL] Trask AW. Grokking Deep Learning. Shelter Island: Manning; 2019. 309 p.</h4>
</div>
<div class="outline-4" id="outline-container-org372b24c">
<h4 id="org372b24c">[DLI] Krohn J. Deep Learning Illustrated: a visual, interactive guide to artificial intelligence. Boston, MA: Addison-Wesley; 2019.</h4>
</div>
<div class="outline-4" id="outline-container-org71d836e">
<h4 id="org71d836e"><a href="https://github.com/iamtrask/Grokking-Deep-Learning/blob/master/Chapter3%20-%20%20Forward%20Propagation%20-%20Intro%20to%20Neural%20Prediction.ipynb">iamtrask</a>: Andrew Trask's jupyter notebook (on github) for this chapter</h4>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/grokking/" rel="tag">grokking</a></li>
<li><a class="tag p-category" href="/categories/neural-networks/" rel="tag">neural networks</a></li>
<li><a class="tag p-category" href="/categories/notes/" rel="tag">notes</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/grokking/how-do-machines-learn/" rel="prev" title="How Do Machines Learn?">Previous post</a></li>
<li class="next"><a href="/posts/grokking/03_forward_propagation/how-do-you-handle-multiple-outputs/" rel="next" title="How do you handle multiple outputs?">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
