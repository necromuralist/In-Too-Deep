<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Classifying images of dogs and cats by breed." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Dog and Cat Breed Classification (What's Your Pet?) | In Too Deep</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="../../../assets/javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/pytorch/pytorch-60-minute-blitz/" rel="prev" title="Pytorch 60 Minute Blitz" type="text/html">
<link href="/posts/fastai/building-an-image-dataset/" rel="next" title="Building an image dataset" type="text/html">
<meta content="In Too Deep" property="og:site_name">
<meta content="Dog and Cat Breed Classification (What's Your Pet?)" property="og:title">
<meta content="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/" property="og:url">
<meta content="Classifying images of dogs and cats by breed." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-04-13T16:14:46-07:00" property="article:published_time">
<meta content="cnn" property="article:tag">
<meta content="deep learning" property="article:tag">
<meta content="fastai" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/fastai/dog-and-cat-breed-classification/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/fastai/dog-and-cat-breed-classification/">Dog and Cat Breed Classification (What's Your Pet?)</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/fastai/dog-and-cat-breed-classification/" rel="bookmark"><time class="published dt-published" datetime="2019-04-13T16:14:46-07:00" itemprop="datePublished" title="2019-04-13 16:14">2019-04-13 16:14</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/fastai/dog-and-cat-breed-classification/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgd023986">Departure</a>
<ul>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org42faee3">Imports</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org7284ee2">Some Setup</a></li>
</ul>
</li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org235ae34">Initiation</a>
<ul>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org7de525f">Downloading the Data</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgf372bcf">Looking At the Data</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgb15a918">Training: resnet34</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org8506651">Results</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org5487814">Unfreezing, fine-tuning, and learning rates</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgcb461ad">Training: resnet50</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org75aea58">Other Data Formats</a></li>
</ul>
</li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgf79e0ba">Return</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgd023986">
<h2 id="orgd023986">Departure</h2>
<div class="outline-text-2" id="text-orgd023986">
<p>This is lesson one from the <a href="https://www.fast.ai">fastai</a> course <a href="https://course.fast.ai/index.html">Practical Deep Learning for Coders, v3</a>, which I assume is the third version of the course, and not a reference to a <a href="https://www.wikiwand.com/en/Kamen_Rider_V3">Japanese television show</a>. It uses the <a href="http://www.fast.ai/2018/10/02/fastai-ai/">fastai V1 library</a> which uses <a href="https://hackernoon.com/pytorch-1-0-468332ba5163">Pytorch 1.0</a> but is an <a href="https://www.wikiwand.com/en/Convention_over_configuration">opinionated framework</a> that bundles some sensible defaults so you don't have to spend as much time building the networks.</p>
<p>The goal is to train a neural network to identify the breeds of cats and dogs based of photos of them. It uses the <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford-IIT Pet Dataset</a> which was created by researchers at Oxford University's <a href="http://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a>.</p>
</div>
<div class="outline-3" id="outline-container-org42faee3">
<h3 id="org42faee3">Imports</h3>
<div class="outline-text-3" id="text-org42faee3"></div>
<div class="outline-4" id="outline-container-orgacd8411">
<h4 id="orgacd8411">Python</h4>
<div class="outline-text-4" id="text-orgacd8411">
<p>Other than the <a href="https://docs.python.org/3.4/library/re.html"><code>re</code></a> none of the python imports were part of the original lesson. I'm importing <a href="https://docs.python.org/3/library/gc.html">gc</a> to do garbage collection because the lesson starts with a smaller network and then changes to a larger one which caused my machine to run out of memory on the GPU. The rest of the imports are for settings and setup.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8505bf8">
<h4 id="org8505bf8">PyPi</h4>
<div class="outline-text-4" id="text-org8505bf8">
<p><code>fastai</code> recommends using <code>*</code> to import everything, but I'd like to know where everything comes from and not import something that might conflict with my naming conventions so I'm going to (at least try to) import things individually. Luckily, unlike some projects (I'm looking at you, <a href="https://bokeh.pydata.org/en/latest/">bokeh</a>), their site has a search feature so you can look things up to see which module they come from.</p>
<p>I'll keep the <code>fast.ai</code> stuff separate to maybe make it easier to reference what comes from where.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">fastai.datasets</span> <span class="kn">import</span> <span class="n">untar_data</span><span class="p">,</span> <span class="n">URLs</span>
<span class="kn">from</span> <span class="nn">fastai.metrics</span> <span class="kn">import</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">error_rate</span>
<span class="kn">from</span> <span class="nn">fastai.train</span> <span class="kn">import</span> <span class="n">ClassificationInterpretation</span>
<span class="kn">from</span> <span class="nn">fastai.vision.data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_image_files</span><span class="p">,</span> 
    <span class="n">imagenet_stats</span><span class="p">,</span> 
    <span class="n">ImageDataBunch</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">fastai.vision.learner</span> <span class="kn">import</span> <span class="n">cnn_learner</span>
<span class="kn">from</span> <span class="nn">fastai.vision.models</span> <span class="kn">import</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">resnet50</span>
<span class="kn">from</span> <span class="nn">fastai.vision.transform</span> <span class="kn">import</span> <span class="n">get_transforms</span>
</pre></div>
<p>And the rest…</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">ipyexperiments</span> <span class="kn">import</span> <span class="n">IPyExperimentsPytorch</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0df3b3b">
<h4 id="org0df3b3b">My Stuff</h4>
<div class="outline-text-4" id="text-org0df3b3b">
<p>This is just some convenience stuff wrapped around other people's code (my lite-version of opinionated code).</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.tables</span> <span class="kn">import</span> <span class="n">CountPercentage</span>
<span class="kn">from</span> <span class="nn">graeae.timers</span> <span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">from</span> <span class="nn">graeae.visualization</span> <span class="kn">import</span> <span class="n">EmbedHoloview</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7284ee2">
<h3 id="org7284ee2">Some Setup</h3>
<div class="outline-text-3" id="text-org7284ee2"></div>
<div class="outline-4" id="outline-container-orgcca0c15">
<h4 id="orgcca0c15">Some Constants</h4>
<div class="outline-text-4" id="text-orgcca0c15">
<p>There's a lot of values scattered all over the place and I just wanted one place to keep track of them and maybe change them if needed.</p>
<div class="highlight">
<pre><span></span><span class="n">Net</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">low_memory_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0d4eebc">
<h4 id="org0d4eebc">The Random Seed</h4>
<div class="outline-text-4" id="text-org0d4eebc">
<p>To make this reproducible I'll set the random seed in numpy.</p>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">Net</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga5dbe7f">
<h4 id="orga5dbe7f">The Path</h4>
<div class="outline-text-4" id="text-orga5dbe7f">
<p>This loads where I put the image data-set.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">".env"</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"OXFORD_PET_DATASET"</span><span class="p">))</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge02627e">
<h4 id="orge02627e">Plotting</h4>
<div class="outline-text-4" id="text-orge02627e">
<p>Although I'd prefer to plot things in HoloViews/bokeh, some of their stuff is too tightly bundled to make it easy (and the image plots maybe don't need to be interactive) so this sets up some formatting for the matplotlib plots.</p>
</div>
<div class="outline-5" id="outline-container-org9074883">
<h5 id="org9074883">Matplotlib</h5>
<div class="outline-text-5" id="text-org9074883">
<div class="highlight">
<pre><span></span><span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'inline'</span><span class="p">)</span>
<span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'config'</span><span class="p">,</span> <span class="s2">"InlineBackend.figure_format = 'retina'"</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">,</span>
            <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">"font.family"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"sans-serif"</span><span class="p">],</span>
                <span class="s2">"font.sans-serif"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"Open Sans"</span><span class="p">,</span> <span class="s2">"Latin Modern Sans"</span><span class="p">,</span> <span class="s2">"Lato"</span><span class="p">],</span>
                <span class="s2">"figure.figsize"</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)},</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-5" id="outline-container-org4820f74">
<h5 id="org4820f74">The Bokeh</h5>
<div class="outline-text-5" id="text-org4820f74">
<p>This sets up some stuff for the javascript-based plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">holoviews</span><span class="o">.</span><span class="n">extension</span><span class="p">(</span><span class="s2">"bokeh"</span><span class="p">)</span>
<span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"dog-and-cat-breed-classification"</span>
<span class="n">OUTPUT_FOLDER</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/fastai/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloview</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_FOLDER</span><span class="p">)</span>
</pre></div>
<p>This is where I'm going to put the settings for the javascript-based plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">height</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfd96bae">
<h4 id="orgfd96bae">The Timer</h4>
<div class="outline-text-4" id="text-orgfd96bae">
<p>This times how long things take so I can estimate how long it will take if I re-run cells. It also speaks a message so I can do something else and will know that the code is done running without having to watch the messages.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3056f0f">
<h4 id="org3056f0f">Tabulate</h4>
<div class="outline-text-4" id="text-org3056f0f">
<p>This is to format tables in the org-mode format (since I'm running this in emacs org-babel).</p>
<div class="highlight">
<pre><span></span><span class="n">ORG_TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">,</span> 
                    <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                    <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org235ae34">
<h2 id="org235ae34">Initiation</h2>
<div class="outline-text-2" id="text-org235ae34"></div>
<div class="outline-3" id="outline-container-org7de525f">
<h3 id="org7de525f">Downloading the Data</h3>
<div class="outline-text-3" id="text-org7de525f">
<p>As I mentioned before, the data will be the <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford-IIIT Pet Dataset</a> by <a href="http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf">O. M. Parkhi et al., 2012</a>. In the dataset there are twelve breeds of cat and twenty-five breeds of dog. When the researchers performed their experiments in 2012 the best accuracy they got was 59.21 %.</p>
<p>The original lesson uses the <a href="https://docs.fast.ai/datasets.html#untar_data">untar_data</a> function to download the data-set.</p>
<div class="highlight">
<pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">untar_data</span><span class="p">)</span>
</pre></div>
<pre class="example">
Help on function untar_data in module fastai.datasets:

untar_data(url: str, fname: Union[pathlib.Path, str] = None, dest: Union[pathlib.Path, str] = None, data=True, force_download=False) -&gt; pathlib.Path
    Download `url` to `fname` if it doesn't exist, and un-tgz to folder `dest`.

</pre>
<p>This data set is 774 Megabytes and given my over-priced yet still incredibly slow CenturyLink speeds I found downloading it directly from the <a href="https://course.fast.ai/datasets#image-classification">fastai datasets page</a> a little more satisfactory, since the progress widget that runs during the download when <code>untar_data</code> downloads the dataset doesn't show up in emacs.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="n">DATA_PATH</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">)</span>
</pre></div>
<pre class="example">
/home/athena/data/datasets/images/oxford-iiit-pet
</pre>
<p>I didn't know it, but <code>Paths</code> have an <code>ls</code> method (so far as I could see this isn't in <a href="https://docs.python.org/3/library/pathlib.html">python's documentation</a>) which I mention because I found out because it was in the original lesson. This is nice because, well, it's easy to remember, but the way I'm using it <code>iterdir</code> makes more sense.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">DATA_PATH</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{path}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>/home/athena/data/datasets/images/oxford-iiit-pet/images_backup</li>
<li>/home/athena/data/datasets/images/oxford-iiit-pet/README.org</li>
<li>/home/athena/data/datasets/images/oxford-iiit-pet/images</li>
<li>/home/athena/data/datasets/images/oxford-iiit-pet/annotations</li>
</ul>
<p>Here's another trick I didn't know about, but learned from the lesson - instead of using the <code>joinpath</code> method you can just use a forward-slash.</p>
<div class="highlight">
<pre><span></span><span class="n">path_to_annotations</span> <span class="o">=</span> <span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'annotations'</span>
<span class="n">path_to_images</span> <span class="o">=</span> <span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'images'</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf372bcf">
<h3 id="orgf372bcf">Looking At the Data</h3>
<div class="outline-text-3" id="text-orgf372bcf"></div>
<div class="outline-4" id="outline-container-org33d63b4">
<h4 id="org33d63b4">Getting the Labels</h4>
<div class="outline-text-4" id="text-org33d63b4">
<p>Here's where we peek at our data set. The dataset is set up so that the breeds are used in the names of the image files. <code>fast.ai</code> has a convenient classmethod named <a href="https://docs.fast.ai/vision.data.html#ImageDataBunch.from_name_re">ImageDataBunch.from_name_re</a> that will extract the labels from the filenames using a <a href="https://docs.python.org/3.6/library/re.html">regular expression</a>.</p>
<p>Before we get to that, though, we can take a look at some file names using <a href="https://docs.fast.ai/vision.data.html#get_image_files">get_image_files</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">file_names</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_to_images</span><span class="p">)</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{path.name}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>Boxer_20.jpg</li>
<li>Saint_Bernard_195.jpg</li>
<li>Saint_Bernard_133.jpg</li>
<li>English_Cocker_Spaniel_43.jpg</li>
<li>Pug_51.jpg</li>
</ul>
<p>So it looks like the format is <code>&lt;breed&gt;_&lt;index&gt;.jpg</code>. Later on we're going to use the labels when we inspect the model so next I'm going to make the standardize the file-name cases to be title-cased.</p>
<div class="highlight">
<pre><span></span><span class="n">UNDERSCORE</span><span class="p">,</span> <span class="n">SPACE</span> <span class="o">=</span> <span class="s2">"_"</span><span class="p">,</span> <span class="s2">" "</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">:</span>
    <span class="n">name</span><span class="p">,</span> <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">UNDERSCORE</span><span class="p">,</span> <span class="n">SPACE</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="n">extension</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">SPACE</span><span class="p">,</span> <span class="n">UNDERSCORE</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
    <span class="n">path</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<span class="n">file_names</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_to_images</span><span class="p">)</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{path.name}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>Boxer_20.jpg</li>
<li>Saint_Bernard_195.jpg</li>
</ul>
<p>Now I'll construct the pattern to match the file-name.</p>
<div class="highlight">
<pre><span></span><span class="n">is_not_a</span> <span class="o">=</span> <span class="s2">"^"</span>
<span class="n">end_of_line</span> <span class="o">=</span> <span class="s2">"$"</span>
<span class="n">one_or_more</span> <span class="o">=</span> <span class="s2">"+"</span>
<span class="n">digit</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"\d"</span>
<span class="n">forward_slash</span> <span class="o">=</span> <span class="s2">"/"</span>
<span class="n">character_class</span> <span class="o">=</span> <span class="s2">"[</span><span class="si">{}</span><span class="s2">]"</span>
<span class="n">group</span> <span class="o">=</span> <span class="s2">"(</span><span class="si">{}</span><span class="s2">)"</span>

<span class="n">anything_but_a_slash</span> <span class="o">=</span> <span class="n">character_class</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{is_not_a}{forward_slash}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">index</span> <span class="o">=</span> <span class="sa">rf</span><span class="s2">"</span><span class="si">{digit}{one_or_more}</span><span class="s2">"</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{anything_but_a_slash}{one_or_more}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">file_extension</span> <span class="o">=</span> <span class="s2">".jpg"</span>

<span class="n">expression</span> <span class="o">=</span> <span class="sa">rf</span><span class="s1">'</span><span class="si">{forward_slash}{label}{UNDERSCORE}{index}{file_extension}{end_of_line}</span><span class="s1">'</span>
<span class="n">test</span> <span class="o">=</span> <span class="s2">"/home/athena/data/datasets/images/oxford-iiit-pet/images/Saint_Bernard_195.jpg"</span>
<span class="k">assert</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">expression</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span><span class="o">.</span><span class="n">groups</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"Saint_Bernard"</span>
</pre></div>
<p>The reason for the forward slash at the beginning of the expression is that we're passing in the entire path to each image, not just the name of the image.</p>
<p>Now on to the <code>ImageDataBunch</code>. Here's the arguments we need to pass in.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on method from_name_re in module fastai.vision.data:

from_name_re(path: Union[pathlib.Path, str], fnames: Collection[pathlib.Path], pat: str, valid_pct: float = 0.2, **kwargs) method of builtins.type instance
    Create from list of `fnames` in `path` with re expression `pat`.

None
</pre>
<p>Okay, so let's get the labels.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span><span class="n">path_to_images</span><span class="p">,</span> 
                                   <span class="n">file_names</span><span class="p">,</span> 
                                   <span class="n">expression</span><span class="p">,</span> 
                                   <span class="n">ds_tfms</span><span class="o">=</span><span class="n">get_transforms</span><span class="p">(),</span> 
                                   <span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> 
                                   <span class="n">bs</span><span class="o">=</span><span class="n">Net</span><span class="o">.</span><span class="n">batch_size</span>
                                  <span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">)</span>
</pre></div>
<p>One of the arguments we passed in (<code>ds_tfms</code>?) isn't particularly obviously named, unless you already know about applying transforms to images, but here's what we passed to it.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">get_transforms</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on function get_transforms in module fastai.vision.transform:

get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10.0, max_zoom:float=1.1, max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75, p_lighting:float=0.75, xtra_tfms:Union[Collection[fastai.vision.image.Transform], NoneType]=None) -&gt; Collection[fastai.vision.image.Transform]
    Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.

None
</pre>
<p><a href="https://docs.fast.ai/vision.transform.html#get_transforms">get_transforms</a> adds random changes to the images to augment the datasets for our training.</p>
<p>We also added a call to <a href="https://docs.fast.ai/vision.data.html#normalize">normalize</a> which sets the mean and standard deviation of the images to match those of the images used to train the model that we're going to use (<a href="https://arxiv.org/abs/1512.03385">ResNet</a>).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org4575311">
<h4 id="org4575311">Looking at Some of the Images</h4>
<div class="outline-text-4" id="text-org4575311">
<p>The <a href="https://docs.fast.ai/basic_data.html#DataBunch.show_batch">show_batch</a> method will plot some of the images in matplotlib. It retrieves them randomly so calling the method repeatedly will pull up different images. Unfortunately you can't pass in a figure or axes so it isn't easily configurable.</p>
<div class="highlight">
<pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">)</span>
</pre></div>
<pre class="example">
Help on method show_batch in module fastai.basic_data:

show_batch(rows:int=5, ds_type:fastai.basic_data.DatasetType=&lt;DatasetType.Train: 1&gt;, reverse:bool=False, **kwargs) -&gt; None method of fastai.vision.data.ImageDataBunch instance
    Show a batch of data in `ds_type` on a few `rows`.

</pre>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
<div class="figure">
<p><img alt="show_batch.png" src="/posts/fastai/dog-and-cat-breed-classification/show_batch.png"></p>
</div>
<p>I'm guessing that the reason why so many images look "off" is because the of the data-transforms being added, and not that the photographers were horrible (or drunk). Why don't we look at the representation of the data bunch?</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
<pre class="example">
ImageDataBunch;

Train: LabelList (5912 items)
x: ImageList
Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
y: CategoryList
Boxer,Saint_Bernard,Saint_Bernard,Ragdoll,Birman
Path: /home/athena/data/datasets/images/oxford-iiit-pet/images;

Valid: LabelList (1478 items)
x: ImageList
Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
y: CategoryList
Siamese,British_Shorthair,English_Cocker_Spaniel,Newfoundland,Russian_Blue
Path: /home/athena/data/datasets/images/oxford-iiit-pet/images;

Test: None
</pre>
<p>So it looks like the <code>ImageDataBunch</code> created a training and a validation set and each of the images has three channels and is 224 x 224 pixels.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb15a918">
<h3 id="orgb15a918">Training: resnet34</h3>
<div class="outline-text-3" id="text-orgb15a918">
<p>Here's where we train the model, a <a href="http://cs231n.github.io/convolutional-networks/">convolutional neural network</a> in the back with a fully-connected network at the end.</p>
<p>I'll use <code>fast.ai's</code> <a href="https://docs.fast.ai/vision.learner.html#cnn_learner">cnn_learner</a> to load the data, pre-trained model (<code>resnet34</code>), and the metric to use when training (<a href="https://docs.fast.ai/metrics.html#error_rate">error_rate</a>). If you look at the <a href="https://github.com/fastai/fastai/blob/master/fastai/vision/models/__init__.py">fast ai code</a> they are importing the <code>resnet34</code> model from <a href="https://pytorch.org/docs/stable/torchvision/models.html#id3">pytorch's torchvision</a>.</p>
<p>This next block sets up the <a href="https://github.com/stas00/ipyexperiments/blob/master/docs/ipyexperiments.md">IPyExperiments</a> which will delete all the variables that were created after it was created when it is deleted. This is to free up memory because the <code>resnet</code> architecture takes up a lot of memory on the GPU.</p>
<div class="highlight">
<pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">IPyExperimentsPytorch</span><span class="p">()</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org31edcd1">
<h4 id="org31edcd1">Experiment started with the Pytorch backend</h4>
<div class="outline-text-4" id="text-org31edcd1">
<p>Device: ID 0, GeForce GTX 1060 6GB (6069 RAM)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org17c0369">
<h4 id="org17c0369">Current state:</h4>
<div class="outline-text-4" id="text-org17c0369">
<p>RAM: Used Free Total Util CPU: 2,375 58,710 64,336 MB 3.69% GPU: 916 5,153 6,069 MB 15.10%</p>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.000 ･ CPU: 0 0 2,375 MB | ･ GPU: 0 0 916 MB |</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</pre></div>
<pre class="example">
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:01.758
･ CPU:          0          0      2,551 MB |
･ GPU:        114          0      1,030 MB |
</pre>
<pre class="example">
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /home/athena/.torch/models/resnet34-333f7ec4.pth
87306240it [00:26, 3321153.99it/s]
</pre>
<p>As you can see, it downloaded the stored model parameters from pytorch. This is because I've never downloaded this particular model before - if you run it again it shouldn't need to re-download it. Since this is a <a href="https://pytorch.org">pytorch</a> model we can look at it's represetantion to see the architecture of the network.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (1): Sequential(
    (0): AdaptiveConcatPool2d(
      (ap): AdaptiveAvgPool2d(output_size=1)
      (mp): AdaptiveMaxPool2d(output_size=1)
    )
    (1): Flatten()
    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.25)
    (4): Linear(in_features=1024, out_features=512, bias=True)
    (5): ReLU(inplace)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): Dropout(p=0.5)
    (8): Linear(in_features=512, out_features=37, bias=True)
  )
)
</pre>
<p>That's a pretty big network, but the main thing to notice is the last layer, which has 37 <code>out_features</code> which corresponds to the number of breeds we have in our data-set. If you were working directly with pytorch you'd have to remove the last layer and add it back yourself, but <code>fast.ai</code> has done this for us.</p>
<p>Now we need to train it using the <a href="https://docs.fast.ai/train.html#fit_one_cycle">fit_one_cycle</a> method. At first I thought 'one cycle' meant just one pass through the batches but according to the <a href="https://docs.fast.ai/callbacks.one_cycle.html">documentation</a>, this is a reference to a training method called the <a href="https://sgugger.github.io/the-1cycle-policy.html">1Cycle Policy</a> proposed by <a href="https://arxiv.org/abs/1803.09820">Leslie N. Smith</a> that changes the hyperparameters to make the model train faster.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">mesasge</span> <span class="o">=</span> <span class="s2">"Finished fitting the ResNet 34 Model."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:18:45.894630
Ended: 2019-04-21 18:22:09.988508
Elapsed: 0:03:24.093878
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:03:24.095
･ CPU:          0          0      2,999 MB |
･ GPU:        151      3,322      1,182 MB |
</pre>
<p>Depending on how busy the computer is this takes two to three minutes when I run it. Next let's store the parameters for the trained model to disk.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'stage-1'</span><span class="p">)</span>
</pre></div>
<pre class="example">
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.145
･ CPU:          0          0      3,000 MB |
･ GPU:         -1          0      1,181 MB |
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8506651">
<h3 id="org8506651">Results</h3>
<div class="outline-text-3" id="text-org8506651">
<p>Let's look at how the model did. If I was running this in a jupyter notebook there would be a table output of the accuracy, but I'm not, and I can't find any documentation on how to get that myself, so, tough luck, then. We can look at some things after the fact, though - the <a href="https://docs.fast.ai/train.html#ClassificationInterpretation">ClassificationInterpretation</a> class contains methods to help look at how the model did.</p>
<div class="highlight">
<pre><span></span><span class="n">interpreter</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</pre></div>
<p>The <a href="https://docs.fast.ai/vision.learner.html#ClassificationInterpretation.top_losses">top_losses</a> method returns a tuple of the highest losses along with the indices of the data that gave those losses. By default it actually gives all the losses sorted from largest to smallest, but you could pass in an integer to limit how much it returns.</p>
<div class="highlight">
<pre><span></span><span class="n">losses</span><span class="p">,</span> <span class="n">indexes</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">top_losses</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">valid_ds</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
</pre></div>
<pre class="example">
tensor([7.1777e+00, 6.8882e+00, 5.8577e+00,  ..., 3.8147e-06, 3.8147e-06,
        1.9073e-06])
tensor([1298, 1418,  166,  ...,  735,  404,  291])
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.002
･ CPU:          0          0      3,000 MB |
･ GPU:          0          0      1,181 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Distribution</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Loss Distribution"</span><span class="p">,</span> 
                                           <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span> 
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> 
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"loss_distribution"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/fastai/dog-and-cat-breed-classification/loss_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Although it looks like there are negative losses, that's just the way the distribution works out, it looks like most of the losses are around zero.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</pre></div>
<pre class="example">
tensor(7.1777)
tensor(1.9073e-06)
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001
･ CPU:          0          0      3,000 MB |
･ GPU:          7          0      1,188 MB |
</pre>
<p>Here's a count of the losses when they are broken up into ten bins.</p>
<div class="highlight">
<pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">percentage</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">total</span>
<span class="n">bins</span><span class="p">[</span><span class="s2">"percent"</span><span class="p">]</span> <span class="o">=</span> <span class="n">percentage</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"Range Count Percent(%)"</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Range</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent(%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">(-0.00718, 0.718]</td>
<td class="org-right">1349</td>
<td class="org-right">91.272</td>
</tr>
<tr>
<td class="org-left">(0.718, 1.436]</td>
<td class="org-right">61</td>
<td class="org-right">4.1272</td>
</tr>
<tr>
<td class="org-left">(1.436, 2.153]</td>
<td class="org-right">31</td>
<td class="org-right">2.09743</td>
</tr>
<tr>
<td class="org-left">(2.153, 2.871]</td>
<td class="org-right">14</td>
<td class="org-right">0.947226</td>
</tr>
<tr>
<td class="org-left">(2.871, 3.589]</td>
<td class="org-right">15</td>
<td class="org-right">1.01488</td>
</tr>
<tr>
<td class="org-left">(3.589, 4.307]</td>
<td class="org-right">3</td>
<td class="org-right">0.202977</td>
</tr>
<tr>
<td class="org-left">(4.307, 5.024]</td>
<td class="org-right">2</td>
<td class="org-right">0.135318</td>
</tr>
<tr>
<td class="org-left">(5.024, 5.742]</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">(5.742, 6.46]</td>
<td class="org-right">1</td>
<td class="org-right">0.067659</td>
</tr>
<tr>
<td class="org-left">(6.46, 7.178]</td>
<td class="org-right">2</td>
<td class="org-right">0.135318</td>
</tr>
</tbody>
</table>
<p>It's not entirely clear to me how to interpret the losses - what does a loss of seven mean, exactly? -0.00744? But, anyway, it looks like the vast majority are less than one.</p>
<p>Another thing we can do is plot the images that had the highest losses.</p>
<div class="highlight">
<pre><span></span><span class="n">interpreter</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">11</span><span class="p">))</span>
</pre></div>
<div class="figure">
<p><img alt="top_losses.png" src="/posts/fastai/dog-and-cat-breed-classification/top_losses.png"></p>
</div>
<p>It looks like the ones that had the most loss had some kind of weird flare effect applied to the image. Now that we've used it, maybe we can see how we're supposed to call <code>plot_top_losses</code>.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">interpreter</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on method _cl_int_plot_top_losses in module fastai.vision.learner:

_cl_int_plot_top_losses(k, largest=True, figsize=(12, 12), heatmap:bool=True, heatmap_thresh:int=16, return_fig:bool=None) -&gt; Union[matplotlib.figure.Figure, NoneType] method of fastai.train.ClassificationInterpretation instance
    Show images in `top_losses` along with their prediction, actual, loss, and probability of actual class.

None
</pre>
<p><b>Note:</b> in the original notebook they were using a function called <a href="https://github.com/fastai/fastai/blob/master/fastai/gen_doc/nbdoc.py#L126">doc</a>, which tries to open another window and will thus hang when run in emacs. They <i>really</i> want you to use jupyter.</p>
<p>Next let's look at the <a href="https://www.wikiwand.com/en/Confusion_matrix">confusion matrix</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">interpreter</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="confusion_matrix.png" src="/posts/fastai/dog-and-cat-breed-classification/confusion_matrix.png"></p>
</div>
<p>One way to interpret this is to look at the x-axis (the actual breed) and sweep vertically up to see the counts for the y-axis (what our model predicted it was). The diagonal cells from the top left to the bottom right is where the predicted matched the actual. In this case, the fact that almost all the counts are in the diagonal means our model did pretty well at predicting the breeds in the images.</p>
<p>If you compare the images with the worst losses to the confusion matrix you'll notice that they don't seem to correlate with the worst performances overall - the worst losses were one-offs, probably due to the flare effect. The most confused was the <i>Ragdoll</i> being confused for a <i>Birman</i>, but, as noted in the lecture, <a href="https://pets.thenest.com/birman-vs-ragdoll-cat-11758.html">distinguishing them is hard for people too</a>.</p>
<p>Here's the breeds that were the hardest for the model to predict.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">interpreter</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> 
                <span class="n">headers</span><span class="o">=</span><span class="s2">"Actual Predicted Count"</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Actual</th>
<th class="org-left" scope="col">Predicted</th>
<th class="org-right" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-right">10</td>
</tr>
<tr>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">American_Bulldog</td>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">Bengal</td>
<td class="org-left">Egyptian_Mau</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-left">American_Bulldog</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Miniature_Pinscher</td>
<td class="org-left">Chihuahua</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Ragdoll</td>
<td class="org-left">Birman</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Samoyed</td>
<td class="org-left">Great_Pyrenees</td>
<td class="org-right">3</td>
</tr>
</tbody>
</table>
<p>It doesn't look too bad, actually, other that the first few entries, maybe.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org5487814">
<h3 id="org5487814">Unfreezing, fine-tuning, and learning rates</h3>
<div class="outline-text-3" id="text-org5487814">
<p>So, this is what we get with a straight off-the-shelf setup from <code>fast.ai</code>, but we want more, don't we? Let's <a href="https://docs.fast.ai/basic_train.html#Learner.unfreeze"><b>unfreeze</b></a> the model (allow the entire model's weights to be trained) and train some more.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
<p>Since we are using a pre-trained model we normally freeze all but the last layer to do transfer learning, by unfreezing the model we'll train all the layers to our dataset.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Finished training the unfrozen model."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:29:47.149628
Ended: 2019-04-21 18:30:28.689325
Elapsed: 0:00:41.539697
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:41.541
･ CPU:          0          0      3,010 MB |
･ GPU:        694      1,923      1,883 MB |
</pre>
<p>Now we save the parameters to disk again.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'stage-1'</span><span class="p">);</span>
</pre></div>
<p>Now we're going to use the <a href="https://docs.fast.ai/callbacks.lr_finder.html">lr_find</a> method to find the best learning rate.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Finished finding the best learning rate."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:31:02.961941
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Ended: 2019-04-21 18:31:29.892324
Elapsed: 0:00:26.930383
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:26.931
･ CPU:          0          0      3,010 MB |
･ GPU:        339      1,646      2,218 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
<div class="figure">
<p><img alt="learning.png" src="/posts/fastai/dog-and-cat-breed-classification/learning.png"></p>
</div>
<p>So, it's kind of hard to see the exact number, but you can see that somewhere around a learning rate of 0.0001 we get a good loss and then after that the loss starts to go way up.</p>
<p>So next we're going to re-train it using an interval that hopefully gives us the best loss.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">1e-4</span><span class="p">)))</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:34:11.748741
None
Ended: 2019-04-21 18:35:34.827655
Elapsed: 0:01:23.078914
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:01:23.083
･ CPU:          0          0      3,011 MB |
･ GPU:          9      1,634      2,231 MB |
</pre>
<p>Now the experiment is over so let's free up some memory.</p>
<div class="highlight">
<pre><span></span><span class="k">del</span> <span class="n">experiment</span>
</pre></div>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.000 ･ CPU: 0 0 3,011 MB | ･ GPU: -17 0 2,214 MB |</p>
<p>IPyExperimentsPytorch: Finishing</p>
</div>
<div class="outline-4" id="outline-container-org9f99c76">
<h4 id="org9f99c76">Experiment finished in 00:20:22 (elapsed wallclock time)</h4>
</div>
<div class="outline-4" id="outline-container-orgebf1b41">
<h4 id="orgebf1b41">Newly defined local variables:</h4>
<div class="outline-text-4" id="text-orgebf1b41">
<p>Deleted: bins, codecs, indexes, interpreter, learn, losses, percentage, total</p>
</div>
</div>
<div class="outline-4" id="outline-container-org8630130">
<h4 id="org8630130">Circular ref objects gc collected during the experiment:</h4>
<div class="outline-text-4" id="text-org8630130">
<p>cleared 12 objects (only temporary leakage)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org5629bae">
<h4 id="org5629bae">Experiment memory:</h4>
<div class="outline-text-4" id="text-org5629bae">
<p>RAM: Consumed Reclaimed CPU: 636 0 MB ( 0.00%) GPU: 1,297 1,308 MB (100.82%)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org82929cd">
<h4 id="org82929cd">Current state:</h4>
<div class="outline-text-4" id="text-org82929cd">
<p>RAM: Used Free Total Util CPU: 3,011 57,984 64,336 MB 4.68% GPU: 906 5,163 6,069 MB 14.93%</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcb461ad">
<h3 id="orgcb461ad">Training: resnet50</h3>
<div class="outline-text-3" id="text-orgcb461ad">
<p>Okay, so we trained the <code>resnet34</code> model, and although I haven't figured out how to tell exactly how well it's doing, it seems to be doing pretty well. Now it's time to try the <code>resnet50</code> model, which has pretty much the same architecture but more layers. This means it should do better, but it also takes up a lot more memory.</p>
<p>Even after deleting the old model I still run out of memory so I'm going to have to fall back to a smaller batch-size.</p>
<div class="highlight">
<pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">IPyExperimentsPytorch</span><span class="p">()</span>
</pre></div>
<pre class="example">

*** Experiment started with the Pytorch backend
Device: ID 0, GeForce GTX 1060 6GB (6069 RAM)


*** Current state:
RAM:    Used    Free   Total       Util
CPU:   3,011  57,984  64,336 MB   4.68% 
GPU:     906   5,163   6,069 MB  14.93% 


･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000
･ CPU:          0          0      3,011 MB |
･ GPU:          0          0        906 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span>
    <span class="n">path_to_images</span><span class="p">,</span> 
    <span class="n">file_names</span><span class="p">,</span> 
    <span class="n">expression</span><span class="p">,</span> 
    <span class="n">ds_tfms</span><span class="o">=</span><span class="n">get_transforms</span><span class="p">(),</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">299</span><span class="p">,</span> 
    <span class="n">bs</span><span class="o">=</span><span class="n">Net</span><span class="o">.</span><span class="n">low_memory_batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">)</span>
</pre></div>
<p>Now I'll re-build the learner with the new pre-trained model.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">resnet50</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
<div class="figure">
<p><img alt="learning_50.png" src="/posts/fastai/dog-and-cat-breed-classification/learning_50.png"></p>
</div>
<p>So with this learner we can see that there's a rapid drop in loss followed by a sudden spike in loss.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Done fitting resnet 50"</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:42:03.987300
Ended: 2019-04-21 18:57:43.628598
Elapsed: 0:15:39.641298
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:15:39.643
･ CPU:          0          0      3,067 MB |
･ GPU:         17      4,474      1,117 MB |
</pre>
<p>Okay, so save the parameters again.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'stage-1-50'</span><span class="p">)</span>
</pre></div>
<p>Now we can try and unfreeze and re-train it.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Finished training resnet 50 with the optimal learning rate."</span>
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">1e-4</span><span class="p">))</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:58:22.070603
Ended: 2019-04-21 19:06:24.471347
Elapsed: 0:08:02.400744
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:08:02.406
･ CPU:          0          0      3,069 MB |
･ GPU:        259      4,586      1,376 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 19:08:37.971400
Ended: 2019-04-21 19:08:49.648814
Elapsed: 0:00:11.677414
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:11.679
･ CPU:          0          0      3,069 MB |
･ GPU:         22        410      1,398 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error Rate: </span><span class="si">{metrics[0]:.2f}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Error Rate: 0.15
</pre>
<p>Since it didn't improve let's go back to the previous model.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'stage-1-50'</span><span class="p">);</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Error Rate: </span><span class="si">{metrics[0]:.2f}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 19:09:19.655769
Ended: 2019-04-21 19:09:30.841289
Elapsed: 0:00:11.185520
Error Rate: 0.16
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:16.011
･ CPU:          1          1      3,069 MB |
･ GPU:        308        612      1,706 MB |
</pre></div>
<div class="outline-4" id="outline-container-org60de90e">
<h4 id="org60de90e">Interpreting the Result</h4>
<div class="outline-text-4" id="text-org60de90e">
<div class="highlight">
<pre><span></span><span class="n">interpreter</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-5" id="outline-container-orgac21c4e">
<h5 id="orgac21c4e">The Most Confusing Breeds</h5>
<div class="outline-text-5" id="text-orgac21c4e">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">interpreter</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                <span class="n">headers</span><span class="o">=</span><span class="s2">"Actual Predicted Count"</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Actual</th>
<th class="org-left" scope="col">Predicted</th>
<th class="org-right" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Bengal</td>
<td class="org-left">Egyptian_Mau</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">Ragdoll</td>
<td class="org-left">Birman</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">Bengal</td>
<td class="org-left">Abyssinian</td>
<td class="org-right">3</td>
</tr>
</tbody>
</table>
<p>It got fewer breeds with more than two wrong than the <code>resnet34</code> model did, but both of them seem to have trouble telling an American Pit Bull Terrier from a Staffordshire Bull Terrier.</p>
<div class="highlight">
<pre><span></span><span class="k">del</span> <span class="n">experiment</span>
</pre></div>
<pre class="example">
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org75aea58">
<h3 id="org75aea58">Other Data Formats</h3>
<div class="outline-text-3" id="text-org75aea58">
<p>This is a look at other data sets.</p>
</div>
<div class="outline-4" id="outline-container-org285daa1">
<h4 id="org285daa1">MNIST</h4>
<div class="outline-text-4" id="text-org285daa1">
<p>This is a set of handwritten digits. The originals are hosted on <a href="http://yann.lecun.com/exdb/mnist/">yann.lecun.com</a> but the <a href="https://course.fast.ai/datasets#image-classification">fast.ai datasets page</a> has the images converted from the original IDX format to the PNG format.</p>
<div class="highlight">
<pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">IPyExperimentsPytorch</span><span class="p">()</span>
</pre></div>
<pre class="example">

*** Experiment started with the Pytorch backend
Device: ID 0, GeForce GTX 1060 6GB (6069 RAM)


*** Current state:
RAM:    Used    Free   Total       Util
CPU:   3,070  57,254  64,336 MB   4.77% 
GPU:   1,706   4,363   6,069 MB  28.11% 


･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.097
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.043
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="n">mnist_path_original</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MNIST"</span><span class="p">))</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">mnist_path_original</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mnist_path_original</span><span class="p">)</span>
</pre></div>
<pre class="example">
/home/athena/data/datasets/images/mnist_png
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.046
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
</pre>
<p>Now that we know it's there we can create a data bunch for it… Actually I tried it and found out that this is the wrong set (it throws an error for some reason), let's try it their way.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
<span class="n">mnist_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">)</span>
</pre></div>
<pre class="example">
http://files.fast.ai/data/examples/mnist_sample
/home/athena/.fastai/data/mnist_sample
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.309
･ CPU:          0          1      3,070 MB |
･ GPU:          0          0      1,706 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.379
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
</pre>
<p>Let's look at the difference. Here's what I downloaded.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">mnist_path_original</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{path}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>/home/athena/data/datasets/images/mnist_png/testing</li>
<li>/home/athena/data/datasets/images/mnist_png/README.org</li>
<li>/home/athena/data/datasets/images/mnist_png/training</li>
</ul>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.026 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB | ･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.071 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB |</p>
<p>And here's what they downloaded.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">mnist_path</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" - </span><span class="si">{path}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li><i>home/athena</i>.fastai/data/mnist_sample/labels.csv</li>
<li><i>home/athena</i>.fastai/data/mnist_sample/train</li>
<li><i>home/athena</i>.fastai/data/mnist_sample/valid</li>
<li><i>home/athena</i>.fastai/data/mnist_sample/models</li>
</ul>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.043 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB | ･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.090 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB |</p>
<p>Maybe you need a <code>labels.csv</code> file… I guess that's the point of this being in the "other formats" section.</p>
<div class="highlight">
<pre><span></span><span class="n">transforms</span> <span class="o">=</span> <span class="n">get_transforms</span><span class="p">(</span><span class="n">do_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
</pre></div>
<p>I don't know why the size is 26 in this case.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
<div class="figure">
<p><img alt="mnist_batch.png" src="/posts/fastai/dog-and-cat-breed-classification/mnist_batch.png"></p>
</div>
<p>Now to fit the model. This uses a smaller version of the resnet (18 layers) and the <code>accuracy</code> metric.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 19:15:13.568995
Ended: 2019-04-21 19:15:44.806330
Elapsed: 0:00:31.237335
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:31.239
･ CPU:          0          0      3,075 MB |
･ GPU:         46      1,379      1,733 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:31.297
･ CPU:          0          0      3,075 MB |
･ GPU:         46      1,379      1,733 MB |
</pre>
<p>So, since the labels are so important, maybe we should look at them.</p>
<div class="highlight">
<pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">mnist_path</span><span class="o">/</span><span class="s1">'labels.csv'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">name</th>
<th class="org-right" scope="col">label</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">train/3/7463.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/21102.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/31559.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/46882.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/26209.png</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>
<p>Well, that's not realy revelatory.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">28</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">classes</span><span class="p">)</span>
</pre></div>
<pre class="example">
[0, 1]
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001
･ CPU:          0          0      3,080 MB |
･ GPU:          0          0      1,733 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.047
･ CPU:          0          0      3,080 MB |
･ GPU:          0          0      1,733 MB |
</pre>
<p>So there are only two classes, presumably meaning that they are <code>3</code> and <code>7</code>.</p>
<p>There's more examples of… something in the notebook, but they don't explain it so I'm just going to skip over the rest of it.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf79e0ba">
<h2 id="orgf79e0ba">Return</h2>
<div class="outline-text-2" id="text-orgf79e0ba">
<p>This last bit just let's me run the whole notebook and get a message when it's over.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"The Dog and cat breed classification buffer is done. Come check it out."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 10:43:46.858157
Ended: 2019-04-21 10:43:46.858197
Elapsed: 0:00:00.000040
</pre></div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/cnn/" rel="tag">cnn</a></li>
<li><a class="tag p-category" href="/categories/deep-learning/" rel="tag">deep learning</a></li>
<li><a class="tag p-category" href="/categories/fastai/" rel="tag">fastai</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/pytorch/pytorch-60-minute-blitz/" rel="prev" title="Pytorch 60 Minute Blitz">Previous post</a></li>
<li class="next"><a href="/posts/fastai/building-an-image-dataset/" rel="next" title="Building an image dataset">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
