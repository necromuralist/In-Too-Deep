<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Implementing Locality Sensitive Hashing for the English to French Translation" name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Locality-Sensitive Hashing (LSH) for Machine Translation | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/machine-translation-with-locality-sensitive-hashing/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../machine-translation-k-nearest-neighbors/" rel="prev" title="Implementing k-Nearest Neighbors for Machine Translation" type="text/html">
<link href="../autocorrect-building-the-vocabulary/" rel="next" title="Autocorrect: Building the Vocabulary" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Locality-Sensitive Hashing (LSH) for Machine Translation" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/machine-translation-with-locality-sensitive-hashing/" property="og:url">
<meta content="Implementing Locality Sensitive Hashing for the English to French Translation" property="og:description">
<meta content="article" property="og:type">
<meta content="2020-10-22T17:43:58-07:00" property="article:published_time">
<meta content="assignment" property="article:tag">
<meta content="machine translation" property="article:tag">
<meta content="nlp" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Locality-Sensitive Hashing (LSH) for Machine Translation</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2020-10-22T17:43:58-07:00" itemprop="datePublished" title="2020-10-22 17:43">2020-10-22 17:43</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org395cecd">Beginning</a>
<ul>
<li><a href="#org91f69e8">Imports</a></li>
<li><a href="#orge0f4a54">Set Up</a></li>
</ul>
</li>
<li><a href="#orgea1bb6e">Middle</a>
<ul>
<li><a href="#orge53e588">Locality-Sensitive Hashing (LSH)</a></li>
<li><a href="#orge514985">Bundling It Up</a></li>
<li><a href="#org27f639c">Testing the Classes</a></li>
<li><a href="#orgbdc7ab2">The Data</a></li>
</ul>
</li>
<li><a href="#orgf3372ed">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org395cecd">
<h2 id="org395cecd">Beginning</h2>
<div class="outline-text-2" id="text-org395cecd">
<p>This is a continuation of the post in which we implemented <a href="../machine-translation-k-nearest-neighbors/">k-Nearest Neighbors</a>. It's part of a series of posts on building an English to French translator whose links are gathered in the <a href="../machine-translation/">this post</a>.</p>
</div>
<div class="outline-3" id="outline-container-org91f69e8">
<h3 id="org91f69e8">Imports</h3>
<div class="outline-text-3" id="text-org91f69e8">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># my code</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.word_embeddings.embeddings</span> <span class="kn">import</span> <span class="n">EmbeddingsLoader</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge0f4a54">
<h3 id="orge0f4a54">Set Up</h3>
<div class="outline-text-3" id="text-orge0f4a54"></div>
<div class="outline-4" id="outline-container-org1dee823">
<h4 id="org1dee823">The Timer</h4>
<div class="outline-text-4" id="text-org1dee823">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc209a4c">
<h4 id="orgc209a4c">The Environment</h4>
<div class="outline-text-4" id="text-orgc209a4c">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8d95141">
<h4 id="org8d95141">The Tweets</h4>
<div class="outline-text-4" id="text-org8d95141">
<div class="highlight">
<pre><span></span><span class="n">positive_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"positive_tweets.json"</span><span class="p">)</span>
<span class="n">negative_tweets</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"negative_tweets.json"</span><span class="p">)</span>
<span class="n">tweets</span> <span class="o">=</span> <span class="n">positive_tweets</span> <span class="o">+</span> <span class="n">negative_tweets</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6dcbff7">
<h4 id="org6dcbff7">The Twitter Processor</h4>
<div class="outline-text-4" id="text-org6dcbff7">
<div class="highlight">
<pre><span></span><span class="n">process_tweet</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge5b48c4">
<h4 id="orge5b48c4">The Embeddings Loader</h4>
<div class="outline-text-4" id="text-orge5b48c4">
<div class="highlight">
<pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">EmbeddingsLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgea1bb6e">
<h2 id="orgea1bb6e">Middle</h2>
<div class="outline-text-2" id="text-orgea1bb6e"></div>
<div class="outline-3" id="outline-container-orge53e588">
<h3 id="orge53e588">Locality-Sensitive Hashing (LSH)</h3>
<div class="outline-text-3" id="text-orge53e588">
<p>In this part of the assignment, you will implement a more efficient version of k-nearest neighbors using locality sensitive hashing. You will then apply this to document search.</p>
<ul class="org-ul">
<li>Process the tweets and represent each tweet as a vector (represent a document with a vector embedding).</li>
<li>Use locality sensitive hashing and k nearest neighbors to find tweets that are similar to a given tweet.</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org207412b">
<h4 id="org207412b">3.1 Getting the document embeddings</h4>
<div class="outline-text-4" id="text-org207412b"></div>
<ul class="org-ul">
<li><a id="orged6e054"></a>Bag-of-words (BOW) document models<br>
<div class="outline-text-5" id="text-orged6e054">
<p>Text documents are sequences of words.</p>
<ul class="org-ul">
<li>The ordering of words makes a difference. For example, sentences "Apple pie is better than pepperoni pizza." and "Pepperoni pizza is better than apple pie" have opposite meanings due to the word ordering.</li>
<li>However, for some applications, ignoring the order of words can allow us to train an efficient and still effective model.</li>
<li>This approach is called Bag-of-words document model.</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org8e87426">
<h4 id="org8e87426">Document embeddings</h4>
<div class="outline-text-4" id="text-org8e87426">
<ul class="org-ul">
<li><i>Document embedding</i> is created by summing up the embeddings of all words in the document.</li>
<li>If we don't know the embedding of some word, we can ignore that word.</li>
</ul>
<p><b>Exercise 07</b>: Complete the <code>get_document_embedding()</code> function.</p>
<ul class="org-ul">
<li>The function <code>get_document_embedding()</code> encodes entire document as a "document" embedding.</li>
<li>It takes in a document (as a string) and a dictionary, <code>en_embeddings</code></li>
<li>It processes the document, and looks up the corresponding embedding of each word.
<ul class="org-ul">
<li>It then sums them up and returns the sum of all word vectors of that processed tweet.</li>
</ul>
</li>
</ul>
</div>
<ul class="org-ul">
<li><a id="orgb5a3d6c"></a>Hints<br>
<div class="outline-text-5" id="text-orgb5a3d6c">
<ul class="org-ul">
<li>You can handle missing words easier by using the <code>get()</code> method of the python dictionary instead of the bracket notation (i.e. "[ ]"). See more about it <a href="https://stackoverflow.com/a/11041421/12816433%22">here</a></li>
<li>The default value for missing word should be the zero vector. Numpy will <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcast</a> simple 0 scalar into a vector of zeros during the summation.</li>
<li>Alternatively, skip the addition if a word is not in the dictonary.</li>
<li>You can use your <code>process_tweet()</code> function which allows you to process the tweet. The function just takes in a tweet and returns a list of words.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="c1"># UNQ_C12 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span>
<span class="k">def</span> <span class="nf">get_document_embedding</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">en_embeddings</span><span class="p">):</span> 
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">       - tweet: a string</span>
<span class="sd">       - en_embeddings: a dictionary of word embeddings</span>
<span class="sd">    Output:</span>
<span class="sd">       - doc_embedding: sum of all word embeddings in the tweet</span>
<span class="sd">    '''</span>
    <span class="n">doc_embedding</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>

    <span class="c1">### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###</span>
    <span class="c1"># process the document into a list of words (process the tweet)</span>
    <span class="n">processed_doc</span> <span class="o">=</span> <span class="n">process_tweet</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">processed_doc</span><span class="p">:</span>
        <span class="c1"># add the word embedding to the running total for the document embedding</span>
        <span class="n">doc_embedding</span> <span class="o">=</span> <span class="n">doc_embedding</span> <span class="o">+</span> <span class="n">en_embeddings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###</span>
    <span class="k">return</span> <span class="n">doc_embedding</span>
</pre></div>
<p>You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything</p>
<div class="highlight">
<pre><span></span><span class="c1"># testing your function</span>
<span class="n">custom_tweet</span> <span class="o">=</span> <span class="s2">"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np"</span>
<span class="c1">#tweet_embedding = get_document_embedding(custom_tweet, en_embeddings_subset)</span>
<span class="n">tweet_embedding</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">custom_tweet</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">english_subset</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">tweet_embedding</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.00268555</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15378189</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.55761719</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07216644</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32263184</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
</pre></div>
<pre class="example">
[-0.00268555 -0.15378189 -0.55761719 -0.07216644 -0.32263184]
</pre></div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orga348d01">
<h4 id="orga348d01">Exercise 08</h4>
<div class="outline-text-4" id="text-orga348d01"></div>
<ul class="org-ul">
<li><a id="orgb720d09"></a>Store all document vectors into a dictionary<br>
<div class="outline-text-5" id="text-orgb720d09">
<p>Now, let's store all the tweet embeddings into a dictionary. Implement <code>get_document_vecs()</code>.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_document_vecs</span><span class="p">(</span><span class="n">all_docs</span><span class="p">,</span> <span class="n">en_embeddings</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Input:</span>
<span class="sd">       - all_docs: list of strings - all tweets in our dataset.</span>
<span class="sd">       - en_embeddings: dictionary with words as the keys and their embeddings as the values.</span>
<span class="sd">    Output:</span>
<span class="sd">       - document_vec_matrix: matrix of tweet embeddings.</span>
<span class="sd">       - ind2Doc_dict: dictionary with indices of tweets in vecs as keys and their embeddings as the values.</span>
<span class="sd">    '''</span>

    <span class="c1"># the dictionary's key is an index (integer) that identifies a specific tweet</span>
    <span class="c1"># the value is the document embedding for that document</span>
    <span class="n">ind2Doc_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># this is list that will store the document vectors</span>
    <span class="n">document_vec_l</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_docs</span><span class="p">):</span>

        <span class="c1">### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###</span>
        <span class="c1"># get the document embedding of the tweet</span>
        <span class="n">doc_embedding</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">en_embeddings</span><span class="p">)</span>

        <span class="c1"># save the document embedding into the ind2Tweet dictionary at index i</span>
        <span class="n">ind2Doc_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">doc_embedding</span>

        <span class="c1"># append the document embedding to the list of document vectors</span>
        <span class="n">document_vec_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc_embedding</span><span class="p">)</span>

        <span class="c1">### END CODE HERE ###</span>

    <span class="c1"># convert the list of document vectors into a 2D array (each row is a document vector)</span>
    <span class="n">document_vec_matrix</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">document_vec_l</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">document_vec_matrix</span><span class="p">,</span> <span class="n">ind2Doc_dict</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">ind2Tweet</span> <span class="o">=</span> <span class="n">get_document_vecs</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">english_subset</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">dict_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind2Tweet</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">dict_length</span> <span class="o">==</span> <span class="n">expected</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"length of dictionary </span><span class="si">{</span><span class="n">dict_length</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">document_vecs</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"shape of document_vecs (</span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">rows</span> <span class="o">==</span> <span class="n">expected</span>
<span class="k">assert</span> <span class="n">columns</span> <span class="o">==</span> <span class="mi">300</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgf556eab">
<h4 id="orgf556eab">3.2 Looking up the tweets</h4>
<div class="outline-text-4" id="text-orgf556eab">
<p>Now you have a vector of dimension (m,d) where <code>m</code> is the number of tweets (10,000) and <code>d</code> is the dimension of the embeddings (300). Now you will input a tweet, and use cosine similarity to see which tweet in our corpus is similar to your tweet.</p>
<div class="highlight">
<pre><span></span><span class="n">my_tweet</span> <span class="o">=</span> <span class="s1">'i am sad'</span>
<span class="n">process_tweet</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">)</span>
<span class="n">tweet_embedding</span> <span class="o">=</span> <span class="n">get_document_embedding</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">english_subset</span><span class="p">)</span>
</pre></div>
<p>This gives you a tweet similar to your input.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">vector_1</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">vector_2</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""Calculates the similarity between two vectors</span>

<span class="sd">    Args:</span>
<span class="sd">     vector_1: array to compare</span>
<span class="sd">     vector_2: array to compare to vector_1</span>

<span class="sd">    Returns:</span>
<span class="sd">     cosine similarity between the two vectors</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vector_1</span><span class="p">,</span> <span class="n">vector_2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vector_1</span><span class="p">)</span> <span class="o">*</span>
                                          <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vector_2</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">tweet_embedding</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdfadcaf">
<h4 id="orgdfadcaf">3.3 Finding the most similar tweets with LSH</h4>
<div class="outline-text-4" id="text-orgdfadcaf">
<p>You will now implement locality sensitive hashing (LSH) to identify the most similar tweet. Instead of looking at all 10,000 vectors, you can just search a subset to find its nearest neighbors.</p>
<p>Let's say you have a set of data points, You can divide the vector space into regions and search within one region for nearest neighbors of a given vector.</p>
<div class="highlight">
<pre><span></span><span class="n">N_VECS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>       <span class="c1"># This many vectors.</span>
<span class="n">N_DIMS</span> <span class="o">=</span> <span class="n">document_vecs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>     <span class="c1"># Vector dimensionality.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"There are </span><span class="si">{</span><span class="n">N_VECS</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> vectors and each has </span><span class="si">{</span><span class="n">N_DIMS</span><span class="si">}</span><span class="s2"> dimensions."</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbba8c90">
<h4 id="orgbba8c90">Choosing the number of planes</h4>
<div class="outline-text-4" id="text-orgbba8c90">
<ul class="org-ul">
<li>Each plane divides the space to <i>2</i> parts.</li>
<li>So <i>n</i> planes divide the space into \(2^{n}\) hash buckets.</li>
<li>We want to organize 10,000 document vectors into buckets so that every bucket has about <i>~16</i> vectors.</li>
<li>For that we need \(\frac{10000}{16}=625\) buckets.</li>
<li>We're interested in <i>n</i>, number of planes, so that \(2^{n}= 625\). Now, we can calculate \(n=\log_{2}625 = 9.29 \approx 10\).</li>
</ul>
<p>We use \(\log_2(625)\) as the number of planes to have ~16 vectors/bucket.</p>
<div class="highlight">
<pre><span></span><span class="n">buckets</span> <span class="o">=</span> <span class="mi">10000</span><span class="o">/</span><span class="mi">16</span>
<span class="nb">print</span><span class="p">(</span><span class="n">buckets</span><span class="p">)</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">buckets</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
</pre></div>
<pre class="example">
625.0
10
</pre>
<div class="highlight">
<pre><span></span><span class="n">N_PLANES</span> <span class="o">=</span> <span class="n">planes</span>
</pre></div>
<p>Number of times to repeat the hashing to improve the search.</p>
<div class="highlight">
<pre><span></span><span class="n">N_UNIVERSES</span> <span class="o">=</span> <span class="mi">25</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org95fa45f">
<h4 id="org95fa45f">3.4 Getting the hash number for a vector</h4>
<div class="outline-text-4" id="text-org95fa45f">
<p>For each vector, we need to get a unique number associated to that vector in order to assign it to a "hash bucket".</p>
</div>
</div>
<div class="outline-4" id="outline-container-orge514dae">
<h4 id="orge514dae">Hyperlanes in vector spaces</h4>
<div class="outline-text-4" id="text-orge514dae">
<ul class="org-ul">
<li>In <i>3</i>-dimensional vector space, the hyperplane is a regular plane. In <i>2</i> dimensional vector space, the hyperplane is a line.</li>
<li>Generally, the hyperplane is a subspace which has dimension <i>1</i> lower than the original vector space has.</li>
<li>A hyperplane is uniquely defined by its normal vector.</li>
<li>Normal vector <i>n</i> of the plane \(\pi\) is the vector to which all vectors in the plane \(\pi\) are orthogonal (perpendicular in <i>3</i> dimensional case).</li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-orgff71824">
<h4 id="orgff71824">Using Hyperplanes to split the vector space</h4>
<div class="outline-text-4" id="text-orgff71824">
<p>We can use a hyperplane to split the vector space into <i>2</i> parts.</p>
<ul class="org-ul">
<li>All vectors whose dot product with a plane's normal vector is positive are on one side of the plane.</li>
<li>All vectors whose dot product with the plane's normal vector is negative are on the other side of the plane.</li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-orgc74c417">
<h4 id="orgc74c417">Encoding hash buckets</h4>
<div class="outline-text-4" id="text-orgc74c417">
<ul class="org-ul">
<li>For a vector, we can take its dot product with all the planes, then encode this information to assign the vector to a single hash bucket.</li>
<li>When the vector is pointing to the opposite side of the hyperplane than normal, encode it by 0.</li>
<li>Otherwise, if the vector is on the same side as the normal vector, encode it by 1.</li>
<li>If you calculate the dot product with each plane in the same order for every vector, you've encoded each vector's unique hash ID as a binary number, like [0, 1, 1, … 0].</li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-orgeeb44cc">
<h4 id="orgeeb44cc">Exercise 09: Implementing hash buckets</h4>
<div class="outline-text-4" id="text-orgeeb44cc">
<p>We've initialized hash table <code>hashes</code> for you. It is list of <code>N_UNIVERSES</code> matrices, each describes its own hash table. Each matrix has <code>N_DIMS</code> rows and <code>N_PLANES</code> columns. Every column of that matrix is a <code>N_DIMS</code>-dimensional normal vector for each of <code>N_PLANES</code> hyperplanes which are used for creating buckets of the particular hash table.</p>
<p><b>Exercise</b>: Your task is to complete the function <code>hash_value_of_vector</code> which places vector <code>v</code> in the correct hash bucket.</p>
<ul class="org-ul">
<li>First multiply your vector <i>v</i>, with a corresponding plane. This will give you a vector of dimension \((1,\text{N_planes})\).</li>
<li>You will then convert every element in that vector to 0 or 1.</li>
<li>You create a hash vector by doing the following: if the element is negative, it becomes a 0, otherwise you change it to a 1.</li>
<li>You then compute the unique number for the vector by iterating over <code>N_PLANES</code></li>
<li>Then you multiply \(2^i\) times the corresponding bit (0 or 1).</li>
<li>You will then store that sum in the variable <code>hash_value</code>.</li>
</ul>
<p><b>Intructions:</b> Create a hash for the vector in the function below. Use this formula:</p>
<p>\[ hash = \sum_{i=0}^{N-1} \left( 2^{i} \times h_{i} \right) \]</p>
</div>
<ul class="org-ul">
<li><a id="org0877eb0"></a>Create the sets of planes<br>
<div class="outline-text-5" id="text-org0877eb0">
<ul class="org-ul">
<li>Create multiple (25) sets of planes (the planes that divide up the region).</li>
<li>You can think of these as 25 separate ways of dividing up the vector space with a different set of planes.</li>
<li>Each element of this list contains a matrix with 300 rows (the word vectors have 300 dimensions), and 10 columns (there are 10 planes in each "universe").</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">planes_l</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N_DIMS</span><span class="p">,</span> <span class="n">N_PLANES</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_UNIVERSES</span><span class="p">)]</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org8107305"></a>Hints<br>
<div class="outline-text-6" id="text-org8107305">
<ul class="org-ul">
<li><code>numpy.squeeze()</code> removes unused dimensions from an array; for instance, it converts a (10,1) 2D array into a (10,) 1D array</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">hash_value_of_vector</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">planes</span><span class="p">):</span>
    <span class="sd">"""Create a hash for a vector; hash_id says which random hash to use.</span>

<span class="sd">    Input:</span>
<span class="sd">       - v:  vector of tweet. It's dimension is (1, N_DIMS)</span>
<span class="sd">       - planes: matrix of dimension (N_DIMS, N_PLANES) - the set of planes that divide up the region</span>
<span class="sd">    Output:</span>
<span class="sd">       - res: a number which is used as a hash for your vector</span>

<span class="sd">    """</span>
    <span class="c1">### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###</span>
    <span class="c1"># for the set of planes,</span>
    <span class="c1"># calculate the dot product between the vector and the matrix containing the planes</span>
    <span class="c1"># remember that planes has shape (300, 10)</span>
    <span class="c1"># The dot product will have the shape (1,10)</span>
    <span class="k">assert</span> <span class="n">planes</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">dot_product</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dot_product</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># get the sign of the dot product (1,10) shaped vector</span>
    <span class="n">sign_of_dot_product</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">dot_product</span><span class="p">)</span>

    <span class="c1"># set h to be false (equivalent to 0 when used in operations) if the sign is negative,</span>
    <span class="c1"># and true (equivalent to 1) if the sign is positive (1,10) shaped vector</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">sign_of_dot_product</span> <span class="o">&gt;=</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="c1"># remove extra un-used dimensions (convert this from a 2D to a 1D array)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="c1"># initialize the hash value to 0</span>
    <span class="n">hash_value</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">n_planes</span> <span class="o">=</span> <span class="n">planes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_planes</span><span class="p">):</span>
        <span class="c1"># increment the hash value by 2^i * h_i</span>
        <span class="n">hash_value</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span> <span class="o">*</span> <span class="n">h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="c1">### END CODE HERE ###</span>

    <span class="c1"># cast hash_value as an integer</span>
    <span class="n">hash_value</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hash_value</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">hash_value</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># get one 'universe' of planes to test the function</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="mi">768</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">hash_value_of_vector</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">expected</span> <span class="o">==</span> <span class="n">actual</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" The hash value for this vector,"</span><span class="p">,</span>
      <span class="sa">f</span><span class="s2">"and the set of planes at index </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">,"</span><span class="p">,</span>
      <span class="sa">f</span><span class="s2">"is </span><span class="si">{</span><span class="n">actual</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org5babc9d">
<h4 id="org5babc9d">3.5 Creating a hash table</h4>
</div>
<div class="outline-4" id="outline-container-org32adfa4">
<h4 id="org32adfa4">Exercise 10</h4>
<div class="outline-text-4" id="text-org32adfa4">
<p>Given that you have a unique number for each vector (or tweet), You now want to create a hash table. You need a hash table, so that given a hash_id, you can quickly look up the corresponding vectors. This allows you to reduce your search by a significant amount of time.</p>
<p>We have given you the <code>make_hash_table</code> function, which maps the tweet vectors to a bucket and stores the vector there. It returns the <code>hash_table</code> and the <code>id_table</code>. The <code>id_table</code> tells you which vector in a certain bucket corresponds to what tweet.</p>
</div>
<ul class="org-ul">
<li><a id="orgfde0a98"></a>Hints<br>
<div class="outline-text-5" id="text-orgfde0a98">
<ul class="org-ul">
<li>a dictionary comprehension, similar to a list comprehension, looks like this: `{i:0 for i in range(10)}`, where the key is 'i' and the value is zero for all key-value pairs.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">make_hash_table</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">planes</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Input:</span>
<span class="sd">       - vecs: list of vectors to be hashed.</span>
<span class="sd">       - planes: the matrix of planes in a single "universe", with shape (embedding dimensions, number of planes).</span>
<span class="sd">    Output:</span>
<span class="sd">       - hash_table: dictionary - keys are hashes, values are lists of vectors (hash buckets)</span>
<span class="sd">       - id_table: dictionary - keys are hashes, values are list of vectors id's</span>
<span class="sd">                           (it's used to know which tweet corresponds to the hashed vector)</span>
<span class="sd">    """</span>
    <span class="c1">### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###</span>

    <span class="c1"># number of planes is the number of columns in the planes matrix</span>
    <span class="n">num_of_planes</span> <span class="o">=</span> <span class="n">planes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># number of buckets is 2^(number of planes)</span>
    <span class="n">num_buckets</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">num_of_planes</span>

    <span class="c1"># create the hash table as a dictionary.</span>
    <span class="c1"># Keys are integers (0,1,2.. number of buckets)</span>
    <span class="c1"># Values are empty lists</span>
    <span class="n">hash_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">)}</span>

    <span class="c1"># create the id table as a dictionary.</span>
    <span class="c1"># Keys are integers (0,1,2... number of buckets)</span>
    <span class="c1"># Values are empty lists</span>
    <span class="n">id_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_buckets</span><span class="p">)}</span>

    <span class="c1"># for each vector in 'vecs'</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vecs</span><span class="p">):</span>
        <span class="c1"># calculate the hash value for the vector</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">hash_value_of_vector</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span> <span class="n">planes</span><span class="p">)</span>

        <span class="c1"># store the vector into hash_table at key h,</span>
        <span class="c1"># by appending the vector v to the list at key h</span>
        <span class="n">hash_table</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="c1"># store the vector's index 'i' (each document is given a unique integer 0,1,2...)</span>
        <span class="c1"># the key is the h, and the 'i' is appended to the list at key h</span>
        <span class="n">id_table</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="c1">### END CODE HERE ###</span>

    <span class="k">return</span> <span class="n">hash_table</span><span class="p">,</span> <span class="n">id_table</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># get one 'universe' of planes to test the function</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">tmp_hash_table</span><span class="p">,</span> <span class="n">tmp_id_table</span> <span class="o">=</span> <span class="n">make_hash_table</span><span class="p">(</span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
<span class="c1"># tmp_hash_table, tmp_id_table = make_hash_table(vec.reshape(1, 300), planes)</span>

<span class="n">index</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The hash table at key </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tmp_hash_table</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="si">}</span><span class="s2"> document vectors"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The id table at key </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tmp_id_table</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The first 5 document indices stored at key </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> of are </span><span class="si">{</span><span class="n">tmp_id_table</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<p>Expected output</p>
<p>#+RESULTS The hash table at key 0 has 3 document vectors The id table at key 0 has 3 The first 5 document indices stored at key 0 of are [3276, 3281, 3282]</p>
<p>I get a hash of 2 for document 3276, not 1…</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org24e41f9">
<h4 id="org24e41f9">3.6 Creating all hash tables</h4>
<div class="outline-text-4" id="text-org24e41f9">
<p>You can now hash your vectors and store them in a hash table that would allow you to quickly look up and search for similar vectors. Run the cell below to create the hashes. By doing so, you end up having several tables which have all the vectors. Given a vector, you then identify the buckets in all the tables. You can then iterate over the buckets and consider much fewer vectors. The more buckets you use, the more accurate your lookup will be, but also the longer it will take.</p>
</div>
<ul class="org-ul">
<li><a id="org53ae585"></a>Creating the hashtables<br>
<div class="outline-text-5" id="text-org53ae585">
<div class="highlight">
<pre><span></span><span class="n">hash_tables</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">id_tables</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">universe_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_UNIVERSES</span><span class="p">):</span>  <span class="c1"># there are 25 hashes</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'working on hash universe #:'</span><span class="p">,</span> <span class="n">universe_id</span><span class="p">)</span>
        <span class="n">planes</span> <span class="o">=</span> <span class="n">planes_l</span><span class="p">[</span><span class="n">universe_id</span><span class="p">]</span>
        <span class="n">hash_table</span><span class="p">,</span> <span class="n">id_table</span> <span class="o">=</span> <span class="n">make_hash_table</span><span class="p">(</span><span class="n">document_vecs</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
        <span class="n">hash_tables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hash_table</span><span class="p">)</span>
        <span class="n">id_tables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">id_table</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orge514985">
<h3 id="orge514985">Bundling It Up</h3>
<div class="outline-text-3" id="text-orge514985">
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">planes</span><span class="o">-</span><span class="n">universe</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">planes</span><span class="o">-</span><span class="n">plane</span><span class="o">-</span><span class="n">count</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">planes</span><span class="o">-</span><span class="n">planes</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">documents</span><span class="o">-</span><span class="n">embeddings</span><span class="o">-</span><span class="n">builder</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">document</span><span class="o">-</span><span class="n">embedding</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">documents</span><span class="o">-</span><span class="n">embeddings</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">document</span><span class="o">-</span><span class="n">index</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">embedding</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">table</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">value</span><span class="o">-</span><span class="n">of</span><span class="o">-</span><span class="n">vector</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">hashes</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">table</span><span class="o">-</span><span class="n">table</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">index</span><span class="o">-</span><span class="n">table</span><span class="o">&gt;&gt;</span>



<span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">tables</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">tables</span><span class="o">-</span><span class="nb">hash</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="nb">hash</span><span class="o">-</span><span class="n">tables</span><span class="o">-</span><span class="n">index</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org15d4311">
<h4 id="org15d4311">Imports</h4>
<div class="outline-text-4" id="text-org15d4311">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5b5828a">
<h4 id="org5b5828a">Planes Universe</h4>
<div class="outline-text-4" id="text-org5b5828a">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">PlanesUniverse</span><span class="p">:</span>
    <span class="sd">"""Creates set of planes with a random mormal distribution of points</span>


<span class="sd">    Args:</span>
<span class="sd">     vector_count: number of vectors that will be hashed</span>
<span class="sd">     dimensions: number of columns per vector</span>
<span class="sd">     universes: number of universes to create</span>
<span class="sd">     vectors_per_bucket: how many vectors we want in each</span>
<span class="sd">     random_seed: value to seed the random number generator</span>
<span class="sd">    """</span>
    <span class="n">vector_count</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">dimensions</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">universes</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">vectors_per_bucket</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">random_seed</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">_plane_count</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_planes</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orgc317fde"></a>Plane Count<br>
<div class="outline-text-5" id="text-orgc317fde">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">plane_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""The number of planes to create</span>

<span class="sd">    Uses the number of vectors and desired vectors per bucket</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plane_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">buckets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vector_count</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">vectors_per_bucket</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plane_count</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">buckets</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plane_count</span>
</pre></div>
</div>
</li>
<li><a id="orgc4d6298"></a>Planes<br>
<div class="outline-text-5" id="text-orgc4d6298">
<p>The list of planes.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">planes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""The list of planes"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_planes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_planes</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimensions</span><span class="p">,</span>
                                                  <span class="bp">self</span><span class="o">.</span><span class="n">plane_count</span><span class="p">))</span>
                        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">universes</span><span class="p">)]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_planes</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgde2357d">
<h4 id="orgde2357d">Documents Embeddings Builder</h4>
<div class="outline-text-4" id="text-orgde2357d">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">DocumentsEmbeddings</span><span class="p">:</span>
    <span class="sd">"""Builds embeddings for documents from their words</span>

<span class="sd">    Args:</span>
<span class="sd">     embeddings: word-embeddings for the documents</span>
<span class="sd">     process: callable to pre-process documents</span>
<span class="sd">     documents: documents (strings) to hash</span>
<span class="sd">    """</span>
    <span class="n">embeddings</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="n">process</span><span class="p">:</span> <span class="nb">object</span>
    <span class="n">documents</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">_documents_embeddings</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_document_index_to_embedding</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orgc900605"></a>Getting the Document Embeddings<br>
<div class="outline-text-5" id="text-orgc900605">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">document_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">document</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span> 
    <span class="sd">"""sums the embeddings for words in the document</span>

<span class="sd">    Args:</span>
<span class="sd">      - document: string to tokenize and build embedding for</span>

<span class="sd">    Returns:</span>
<span class="sd">      - embedding: sum of all word embeddings in the document</span>
<span class="sd">    """</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
    <span class="c1"># adding the zeros means you always return an array, not just the number 0</span>
    <span class="c1"># if none of the words in the document are in the embeddings</span>
    <span class="k">return</span> <span class="n">embedding</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><a id="orgcce2d68"></a>Documents Embeddings<br>
<div class="outline-text-5" id="text-orgcce2d68">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">documents_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""array of embeddings for each document in documents"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_documents_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_documents_embeddings</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">document_embedding</span><span class="p">(</span><span class="n">document</span><span class="p">)</span> <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">documents</span><span class="p">])</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_documents_embeddings</span>
</pre></div>
</div>
</li>
<li><a id="org33b7275"></a>Document Index to Embeddings<br>
<div class="outline-text-5" id="text-org33b7275">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">document_index_to_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""maps document index (from self.documents) to embedding"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_document_index_to_embedding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_document_index_to_embedding</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">index</span><span class="p">:</span> <span class="n">embedding</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">documents_embeddings</span><span class="p">)}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_document_index_to_embedding</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgee3013f">
<h4 id="orgee3013f">Hash Table Builder</h4>
<div class="outline-text-4" id="text-orgee3013f">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HashTable</span><span class="p">:</span>
    <span class="sd">"""Builds the hash-table for embeddings</span>

<span class="sd">    Args:</span>
<span class="sd">     planes: matrix of planes to divide into hash table</span>
<span class="sd">     vectors: vectors to be hashed</span>
<span class="sd">    """</span>
    <span class="n">planes</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">_hashes</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_hash_table</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_index_table</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orge9aee87"></a>Vector Hash Value<br>
<div class="outline-text-5" id="text-orge9aee87">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">hash_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vector</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Create a hash for a vector</span>

<span class="sd">    Args:</span>
<span class="sd">     - vector:  vector of tweet. It's dimension is (1, N_DIMS)</span>

<span class="sd">    Returns:</span>
<span class="sd">      - res: a number which is used as a hash for your vector</span>
<span class="sd">    """</span>
    <span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># assert vector.shape == (1, rows), vector.shape</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="p">)</span>
    <span class="c1">#assert dot_product.shape == (1, columns), dot_product.shape</span>

    <span class="n">sign_of_dot_product</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">dot_product</span><span class="p">)</span>
    <span class="n">hashes</span> <span class="o">=</span> <span class="n">sign_of_dot_product</span> <span class="o">&gt;=</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">hashes</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dot_product</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># remove extra un-used dimensions (convert this from a 2D to a 1D array)</span>
    <span class="n">hashes</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">hashes</span><span class="p">)</span>
    <span class="n">hash_value</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">columns</span><span class="p">):</span>
        <span class="n">hash_value</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">**</span><span class="n">column</span> <span class="o">*</span> <span class="n">hashes</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">hash_value</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="org99a7f03"></a>Hashes<br>
<div class="outline-text-5" id="text-org99a7f03">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">hashes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Vector hashes"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hashes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hashes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_value</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span> <span class="k">for</span> <span class="n">vector</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hashes</span>
</pre></div>
</div>
</li>
<li><a id="org404ac19"></a>Hash Table Build<br>
<div class="outline-text-5" id="text-org404ac19">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">hash_table</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""Hash table of vectors</span>

<span class="sd">    Returns:</span>
<span class="sd">      hash_table: dictionary - keys are hashes, values are lists of vectors (hash buckets)</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash_table</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">number_of_planes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">number_of_buckets</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">number_of_planes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_hash_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_buckets</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">hash_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hashes</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hash_table</span><span class="p">[</span><span class="n">hash_</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash_table</span>
</pre></div>
</div>
</li>
<li><a id="org4b11395"></a>Index Table<br>
<div class="outline-text-5" id="text-org4b11395">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">index_table</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""Tabel of document hash to index"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_table</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">number_of_planes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">number_of_buckets</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">number_of_planes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_index_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_buckets</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">hash_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hashes</span><span class="p">):</span>            
            <span class="bp">self</span><span class="o">.</span><span class="n">_index_table</span><span class="p">[</span><span class="n">hash_</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_table</span>
</pre></div>
</div>
</li>
<li><a id="orge870113"></a>Build The Tables<br>
<div class="outline-text-5" id="text-orge870113">
<p>The code that uses the tables doesn't actually pull them at the same time, so I'm going to keep them separate.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">build_tables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Builds the hash and index table properties"""</span>
    <span class="n">number_of_planes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">number_of_buckets</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">number_of_planes</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_hash_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_buckets</span><span class="p">)}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_index_table</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_buckets</span><span class="p">)}</span>

    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">hash_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hashes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hash_table</span><span class="p">[</span><span class="n">hash_</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_index_table</span><span class="p">[</span><span class="n">hash_</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org63a8471">
<h4 id="org63a8471">Hash Tables</h4>
<div class="outline-text-4" id="text-org63a8471">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HashTables</span><span class="p">:</span>
    <span class="sd">"""Builds the universes of hash tables</span>

<span class="sd">    Args:</span>
<span class="sd">     universes: how many universes</span>
<span class="sd">     planes: planes to hash vectors into</span>
<span class="sd">     vectors: vectors to hash</span>
<span class="sd">    """</span>
    <span class="n">universes</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">planes</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">_hash_tables</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_id_tables</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org7481b60"></a>Hash Tables<br>
<div class="outline-text-5" id="text-org7481b60">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">hash_tables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Builds the list of hash tables"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash_tables</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">_hash_tables</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">HashTable</span><span class="p">(</span><span class="n">vectors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span>
                      <span class="n">planes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="p">[</span><span class="n">universe</span><span class="p">])</span><span class="o">.</span><span class="n">hash_table</span>
            <span class="k">for</span> <span class="n">universe</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">universes</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash_tables</span>
</pre></div>
</div>
</li>
<li><a id="org1a2988d"></a>ID Tables<br>
<div class="outline-text-5" id="text-org1a2988d">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">id_tables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Builds the list of id tables"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id_tables</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">_id_tables</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">HashTable</span><span class="p">(</span><span class="n">vectors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span>
                      <span class="n">planes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">planes</span><span class="p">[</span><span class="n">universe</span><span class="p">])</span><span class="o">.</span><span class="n">index_table</span>
            <span class="k">for</span> <span class="n">universe</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">universes</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id_tables</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org27f639c">
<h3 id="org27f639c">Testing the Classes</h3>
<div class="outline-text-3" id="text-org27f639c"></div>
<div class="outline-4" id="outline-container-orgbf9d2c9">
<h4 id="orgbf9d2c9">PlanesUniverse</h4>
<div class="outline-text-4" id="text-orgbf9d2c9">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.word_embeddings.hashing</span> <span class="kn">import</span> <span class="n">PlanesUniverse</span>
<span class="n">universes</span> <span class="o">=</span> <span class="n">PlanesUniverse</span><span class="p">(</span><span class="n">vector_count</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">),</span>
                        <span class="n">dimensions</span><span class="o">=</span><span class="n">N_DIMS</span><span class="p">,</span>
                        <span class="n">universes</span><span class="o">=</span><span class="n">N_UNIVERSES</span><span class="p">,</span>
                        <span class="n">vectors_per_bucket</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">universes</span><span class="o">.</span><span class="n">plane_count</span><span class="o">==</span><span class="mi">10</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org679babc">
<h4 id="org679babc">Documents Embeddings Builder</h4>
<div class="outline-text-4" id="text-org679babc">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.word_embeddings.hashing</span> <span class="kn">import</span> <span class="n">DocumentsEmbeddings</span>

<span class="n">table</span> <span class="o">=</span> <span class="n">DocumentsEmbeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="o">.</span><span class="n">english_subset</span><span class="p">,</span>
                            <span class="n">process</span><span class="o">=</span><span class="n">process_tweet</span><span class="p">,</span> <span class="n">documents</span><span class="o">=</span><span class="n">tweets</span><span class="p">)</span>

<span class="n">custom_tweet</span> <span class="o">=</span> <span class="s2">"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np"</span>

<span class="n">tweet_embedding</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">document_embedding</span><span class="p">(</span><span class="n">custom_tweet</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">tweet_embedding</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.00268555</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15378189</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.55761719</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07216644</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32263184</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>

<span class="n">dict_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">table</span><span class="o">.</span><span class="n">document_index_to_embedding</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tweets</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">dict_length</span> <span class="o">==</span> <span class="n">expected</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"length of dictionary </span><span class="si">{</span><span class="n">dict_length</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">documents_embeddings</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"shape of document_vecs (</span><span class="si">{</span><span class="n">rows</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">columns</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">rows</span> <span class="o">==</span> <span class="n">expected</span>
<span class="k">assert</span> <span class="n">columns</span> <span class="o">==</span> <span class="mi">300</span>

<span class="n">my_tweet</span> <span class="o">=</span> <span class="s1">'i am sad'</span>
<span class="n">tweet_embedding</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">document_embedding</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">)</span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">table</span><span class="o">.</span><span class="n">documents_embeddings</span><span class="p">,</span> <span class="n">tweet_embedding</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tweets</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</pre></div>
<pre class="example">
[-0.00268555 -0.15378189 -0.55761719 -0.07216644 -0.32263184]
length of dictionary 10,000
shape of document_vecs (10,000, 300)
@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6501871">
<h4 id="org6501871">Hash Table Builder</h4>
<div class="outline-text-4" id="text-org6501871">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.word_embeddings.hashing</span> <span class="kn">import</span> <span class="n">HashTable</span>

<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">universes</span><span class="o">.</span><span class="n">planes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># get one 'universe' of planes to test the function</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="mi">768</span>

<span class="n">hasher</span> <span class="o">=</span> <span class="n">HashTable</span><span class="p">(</span><span class="n">planes</span><span class="o">=</span><span class="n">planes</span><span class="p">,</span> <span class="n">vectors</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">hash_value</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">expected</span> <span class="o">==</span> <span class="n">actual</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"expected: </span><span class="si">{</span><span class="n">expected</span><span class="si">}</span><span class="s2">, Actual: </span><span class="si">{</span><span class="n">actual</span><span class="si">}</span><span class="s2">"</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" The hash value for this vector,"</span><span class="p">,</span>
      <span class="sa">f</span><span class="s2">"and the set of planes at index </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">,"</span><span class="p">,</span>
      <span class="sa">f</span><span class="s2">"is </span><span class="si">{</span><span class="n">actual</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The hash value for this vector, and the set of planes at index 0, is 768
</pre>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">planes</span> <span class="o">=</span> <span class="n">universes</span><span class="o">.</span><span class="n">planes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># get one 'universe' of planes to test the function</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>

<span class="n">hasher</span> <span class="o">=</span> <span class="n">HashTable</span><span class="p">(</span><span class="n">planes</span><span class="o">=</span><span class="n">planes</span><span class="p">,</span> <span class="n">vectors</span><span class="o">=</span><span class="n">document_vecs</span><span class="p">)</span>

<span class="n">tmp_hash_table</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">hash_table</span>
<span class="n">tmp_id_table</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">index_table</span>

<span class="n">index</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The hash table at key </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tmp_hash_table</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="si">}</span><span class="s2"> document vectors"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The id table at key </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tmp_id_table</span><span class="p">[</span><span class="n">index</span><span class="p">])</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The first 5 document indices stored at key </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2"> of are </span><span class="si">{</span><span class="n">tmp_id_table</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The hash table at key 2 has 21 document vectors
The id table at key 2 has 21
The first 5 document indices stored at key 2 of are [356, 529, 976, 1754, 1779]
</pre></div>
</div>
<div class="outline-4" id="outline-container-org8e45f7f">
<h4 id="org8e45f7f">Hash Tables</h4>
<div class="outline-text-4" id="text-org8e45f7f">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.word_embeddings.hashing</span> <span class="kn">import</span> <span class="n">HashTables</span>
<span class="n">tables</span> <span class="o">=</span> <span class="n">HashTables</span><span class="p">(</span><span class="n">universes</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">planes</span><span class="o">=</span><span class="n">universes</span><span class="o">.</span><span class="n">planes</span><span class="p">,</span> <span class="n">vectors</span><span class="o">=</span><span class="n">table</span><span class="o">.</span><span class="n">documents_embeddings</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>    
    <span class="n">hash_tables_2</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">hash_tables</span>
    <span class="n">id_tables_2</span> <span class="o">=</span> <span class="n">tables</span><span class="o">.</span><span class="n">id_tables</span>
</pre></div>
<pre class="example">
2020-10-29 19:06:32,191 graeae.timers.timer start: Started: 2020-10-29 19:06:32.191271
2020-10-29 19:06:56,635 graeae.timers.timer end: Ended: 2020-10-29 19:06:56.635738
2020-10-29 19:06:56,637 graeae.timers.timer end: Elapsed: 0:00:24.444467
</pre>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">hash_tables_2</span><span class="p">)</span> <span class="o">==</span> <span class="n">universes</span><span class="o">.</span><span class="n">universes</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">id_tables_2</span><span class="p">)</span> <span class="o">==</span> <span class="n">universes</span><span class="o">.</span><span class="n">universes</span>

<span class="n">id_tables_</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">id_tables</span><span class="p">,</span> <span class="n">id_tables_2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">table</span><span class="p">,</span> <span class="n">table_2</span> <span class="ow">in</span> <span class="n">id_tables_</span><span class="p">:</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">table_2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="o">**</span><span class="n">universes</span><span class="o">.</span><span class="n">plane_count</span>
    <span class="k">for</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">table</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">ids</span> <span class="o">==</span> <span class="n">table_2</span><span class="p">[</span><span class="n">bucket</span><span class="p">],</span> <span class="s2">"[</span><span class="si">{bucket}</span><span class="s2">]: </span><span class="si">{ids}</span><span class="s2">, </span><span class="si">{table_2[bucket]}</span><span class="s2">"</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3bec87a">
<h4 id="org3bec87a">Testing Objects</h4>
<div class="outline-text-4" id="text-org3bec87a">
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Variable</th>
<th class="org-left" scope="col">Class</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">embeddings</td>
<td class="org-left">EmbeddingsLoader</td>
</tr>
<tr>
<td class="org-left">process_tweet</td>
<td class="org-left">TwitterProcessor</td>
</tr>
<tr>
<td class="org-left">table</td>
<td class="org-left">DocumentsEmbeddings</td>
</tr>
<tr>
<td class="org-left">hasher</td>
<td class="org-left">HashTable</td>
</tr>
<tr>
<td class="org-left">tables</td>
<td class="org-left">HashTables</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgbdc7ab2">
<h3 id="orgbdc7ab2">The Data</h3>
<div class="outline-text-3" id="text-orgbdc7ab2">
<p>This is a summary of the data that was loaded since this was such a long post and I can't remember what's what without looking around.</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Variable</th>
<th class="org-left" scope="col">Type</th>
<th class="org-left" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">tweets</td>
<td class="org-left">list of strings</td>
<td class="org-left">All the tweets (10,000)</td>
</tr>
<tr>
<td class="org-left">document_vecs</td>
<td class="org-left">numpy.ndarray</td>
<td class="org-left">Document embeddings for the tweets (10,000, 300)</td>
</tr>
<tr>
<td class="org-left">ind2Tweet</td>
<td class="org-left">dict</td>
<td class="org-left">Map index of tweet (in tweets or document_vecs) to document embedding</td>
</tr>
<tr>
<td class="org-left">planes_l</td>
<td class="org-left">List of arrays</td>
<td class="org-left">List of random planes for hashing (each is 300 x 10, 25 total)</td>
</tr>
<tr>
<td class="org-left">hash_tables</td>
<td class="org-left">List</td>
<td class="org-left">List of bucket-index to document embeddings maps (One for each plane, each with 1,024 buckets (2^number of planes))</td>
</tr>
<tr>
<td class="org-left">id_tables</td>
<td class="org-left">List</td>
<td class="org-left">List of bucket index: document index maps (one for each plane, each with 1,024)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf3372ed">
<h2 id="orgf3372ed">End</h2>
<div class="outline-text-2" id="text-orgf3372ed">
<p>The next step is to use this to implement <a href="../machine-translation-with-approximate-knn/">approximate k-Nearest Neighbors</a> to compelete our application.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/assignment/" rel="tag">assignment</a></li>
<li><a class="tag p-category" href="../../../categories/machine-translation/" rel="tag">machine translation</a></li>
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../machine-translation-k-nearest-neighbors/" rel="prev" title="Implementing k-Nearest Neighbors for Machine Translation">Previous post</a></li>
<li class="next"><a href="../autocorrect-building-the-vocabulary/" rel="next" title="Autocorrect: Building the Vocabulary">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
