#+BEGIN_COMMENT
.. title: Siamese Networks: The Data Generator
.. slug: siamese-networks-the-data-generator
.. date: 2021-01-25 19:35:05 UTC-08:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT
* Raw
#+begin_example python
# ### 1.3 Understanding the iterator 
# 
# Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. If you were to use stochastic gradient descent with one example at a time, it will take you forever to build a model. In this example, we show you how you can build a data generator that takes in $Q1$ and $Q2$ and returns a batch of size `batch_size`  in the following format $([q1_1, q1_2, q1_3, ...]$, $[q2_1, q2_2,q2_3, ...])$. The tuple consists of two arrays and each array has `batch_size` questions. Again, $q1_i$ and $q2_i$ are duplicates, but they are not duplicates with any other elements in the batch. 
# 
# <br>
# 
# The command ```next(data_generator)```returns the next batch. This iterator returns the data in a format that you could directly use in your model when computing the feed-forward of your algorithm. This iterator returns a pair of arrays of questions. 
# 
# <a name='ex01'></a>
# ### Exercise 01
# 
# **Instructions:**  
# Implement the data generator below. Here are some things you will need. 
# 
# - While true loop.
# - if `index >= len_Q1`, set the `idx` to $0$.
# - The generator should return shuffled batches of data. To achieve this without modifying the actual question lists, a list containing the indexes of the questions is created. This list can be shuffled and used to get random batches everytime the index is reset.
# - Append elements of $Q1$ and $Q2$ to `input1` and `input2` respectively.
# - if `len(input1) == batch_size`, determine `max_len` as the longest question in `input1` and `input2`. Ceil `max_len` to a power of $2$ (for computation purposes) using the following command:  `max_len = 2**int(np.ceil(np.log2(max_len)))`.
# - Pad every question by `vocab['<PAD>']` until you get the length `max_len`.
# - Use yield to return `input1, input2`. 
# - Don't forget to reset `input1, input2`  to empty arrays at the end (data generator resumes from where it last left).

# In[ ]:


# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: data_generator
def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):
    """Generator function that yields batches of data

    Args:
        Q1 (list): List of transformed (to tensor) questions.
        Q2 (list): List of transformed (to tensor) questions.
        batch_size (int): Number of elements per batch.
        pad (int, optional): Pad character from the vocab. Defaults to 1.
        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.
    Yields:
        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)
        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates
              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates
    """

    input1 = []
    input2 = []
    idx = 0
    len_q = len(Q1)
    question_indexes = [*range(len_q)]
    
    if shuffle:
        rnd.shuffle(question_indexes)
    
    ### START CODE HERE (Replace instances of 'None' with your code) ###
    while True:
        if idx >= len_q:
            # if idx is greater than or equal to len_q, set idx accordingly 
            # (Hint: look at the instructions above)
            idx = None
            # shuffle to get random batches if shuffle is set to True
            if shuffle:
                rnd.shuffle(question_indexes)
        
        # get questions at the `question_indexes[idx]` position in Q1 and Q2
        q1 = None
        q2 = None
        
        # increment idx by 1
        idx += None
        # append q1
        input1.append(None)
        # append q2
        input2.append(None)
        if len(input1) == batch_size:
            # determine max_len as the longest question in input1 & input 2
            # Hint: use the `max` function. 
            # take max of input1 & input2 and then max out of the two of them.
            max_len = None
            # pad to power-of-2 (Hint: look at the instructions above)
            max_len = None
            b1 = []
            b2 = []
            for q1, q2 in zip(input1, input2):
                # add [pad] to q1 until it reaches max_len
                q1 = None
                # add [pad] to q2 until it reaches max_len
                q2 = None
                # append q1
                b1.append(None)
                # append q2
                b2.append(None)
            # use b1 and b2
            yield np.array(None), np.array(None)
    ### END CODE HERE ###
            # reset the batches
            input1, input2 = [], []  # reset the batches


# In[ ]:


batch_size = 2
res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))
print("First questions  : ",'\n', res1, '\n')
print("Second questions : ",'\n', res2)


# **Note**: The following expected output is valid only if you run the above test cell **_once_** (first time). The output will change on each execution.
# 
# If you think your implementation is correct and it is not matching the output, make sure to restart the kernel and run all the cells from the top again. 
# 
# **Expected Output:**
# ```CPP
# First questions  :  
#  [[  30   87   78  134 2132 1981   28   78  594   21    1    1    1    1
#      1    1]
#  [  30   55   78 3541 1460   28   56  253   21    1    1    1    1    1
#      1    1]] 
# 
# Second questions :  
#  [[  30  156   78  134 2132 9508   21    1    1    1    1    1    1    1
#      1    1]
#  [  30  156   78 3541 1460  131   56  253   21    1    1    1    1    1
#      1    1]]
# ```
# Now that you have your generator, you can just call it and it will return tensors which correspond to your questions in the Quora data set.<br>Now you can go ahead and start building your neural network. 
# 
# 

#+end_example  
