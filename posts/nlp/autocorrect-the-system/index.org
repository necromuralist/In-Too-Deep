#+BEGIN_COMMENT
.. title: Autocorrect: The System
.. slug: autocorrect-the-system
.. date: 2020-11-05 18:17:54 UTC-08:00
.. tags: nlp,autocorrect
.. category: NLP
.. link: 
.. description: Building an autocorrect system.
.. type: text
.. has_math: True
#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 2

#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-6db97024-c8c7-4320-bce4-02bca75093d4-ssh.json

#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC

* The Posts In the Series
 - {{% lancelot title="Data Preprocessing" %}}autocorrect-system-data-preprocessing{{% /lancelot %}}
 - {{% lancelot title="Edits" %}}autocorrect-system-edits{{% /lancelot %}}
 - {{% lancelot title="Combining the Edits" %}}autocorrect-system-combining-the-edits{{% /lancelot %}}
 - {{% lancelot title="Finding the Closest Candidate" %}}autocorrect-minimum-edit-distance{{% /lancelot %}}
 - {{% lancelot title="Finding the Shortest Path" %}}autocorrect-minimum-edit-distance-backtrace{{% /lancelot %}}

* Edit Distance
 In this series of posts we'll implement models that correct words that are 1 and 2 edit distances away. 
 - We say two words are /n/ edit distance away from each other when we need /n/ edits to change one word into another. 

 An edit could consist of one of the following options: 
 
 - Delete (remove a letter): ‘hat’ => ‘at, ha, ht’
 - Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’
 - Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’
 - Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’
 
We'll be using the four methods above to implement an Auto-correct system by computing the probabilities that a certain word is correct given an input word.
 
This auto-correct system was first created by [[https://en.wikipedia.org/wiki/Peter_Norvig][Peter Norvig]] in 2007 in [[https://norvig.com/spell-correct.html][this article]].

The goal of our spell check model is to compute the following probability:

\[
P(c|w) = \frac{P(w|c)\times P(c)}{P(w)} \tag{Equation 1}
\]

The equation above is [[https://en.wikipedia.org/wiki/Bayes%27_theorem][Bayes Rule]], and it is saying that the probability of a word being correct \(P(c|w)\) is equal to the probability of having a certain word /w/, given that it is correct \(P(w|c)\), multiplied by the probability of being correct in general \(P(C)\) divided by the probability of that word /w/ appearing \(P(w)\) in general.
