#+BEGIN_COMMENT
.. title: Deep N-Grams: Creating the Model
.. slug: deep-n-grams-creating-the-model
.. date: 2021-01-05 16:48:01 UTC-08:00
.. tags: nlp,n-grams,rnn,gru
.. category: NLP
.. link: 
.. description: Creating a GRU model.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-a24596d0-64a2-492f-addb-06954c445c65-ssh.json
#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC

* Defining the GRU Model
  - {{% lancelot title="First Post" %}}deep-n-grams{{% /lancelot %}}
  - {{% lancelot title="Previous Post" %}}deep-n-grams-loading-the-data{{% /lancelot %}}
  - {{% lancelot title="Next Post" %}}deep-n-grams-training-the-model{{% /lancelot %}}

We're going to build a =GRU= model using trax.

 - [[https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial][=Serial=]]: Combinator that applies layers serially (by function composition). 
    + You can pass in the layers as arguments to =Serial=, separated by commas. 
    + For example: =tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))=
 - [[https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight][=ShiftRight]]: Allows the model to go right in the feed forward. 
    + =ShiftRight(n_shifts=1, mode='train')= layer to shift the tensor to the right n_shift times
    + Here in the exercise you only need to specify the mode and not worry about n_shifts
 - [[https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding][=Embedding=]]: Initializes the embedding. In this case it is the size of the vocabulary by the dimension of the model.
    + =tl.Embedding(vocab_size, d_feature)=.
    + =vocab_size= is the number of unique words in the given vocabulary.
    + =d_feature= is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).
 -  [[https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.GRU][=GRU=]]: =Trax= GRU layer.
    + =GRU(n_units)= Builds a traditional GRU of n_cells with dense internal transformations.
    + =GRU= paper: [[https://arxiv.org/abs/1412.3555][Empirical Evaluation of Gated Neural Networks On Sequence Modeling]]
 -  [[https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense][=Dense=]]: A dense layer.
    + =tl.Dense(n_units)=: The parameter =n_units= is the number of units chosen for this dense layer.
 -  [[https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax][=LogSoftmax=]]: Log of the output probabilities.
    + Here, you don't need to set any parameters for =LogSoftMax()=.
** Imports
#+begin_src python :results none
# pypi
from trax import layers

# this project
from neurotic.nlp.deep_rnn import DataLoader, DataGenerator
#+end_src

** Set Up
#+begin_src python :results none
loader = DataLoader()
#+end_src   
* Middle
** The GRU Model
#+begin_src python :results none
def GRULM(vocab_size: int=256, d_model: int=512, n_layers: int=2, mode:str='train') -> layers.Serial:
    """Returns a GRU language model.

    Args:
        vocab_size (int, optional): Size of the vocabulary. Defaults to 256.
        d_model (int, optional): Depth of embedding (n_units in the GRU cell). Defaults to 512.
        n_layers (int, optional): Number of GRU layers. Defaults to 2.
        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to "train".

    Returns:
        trax.layers.combinators.Serial: A GRU language model as a layer that maps from a tensor of tokens to activations over a vocab set.
    """
    ### START CODE HERE (Replace instances of 'None' with your code) ###
    model = layers.Serial(
        # the ``n_shifts`` argument seems to have changed to ``n_positions``,
        # don't use it remain be backwards compatible
        layers.ShiftRight(1, mode="train"),
        layers.Embedding(vocab_size, d_model),
        *[layers.GRU(d_model) for unit in range(n_layers)],
        layers.Dense(vocab_size),
        layers.LogSoftmax()
    )
    ### END CODE HERE ###
    return model
#+end_src
** Will It Build?
#+begin_src python :results output :exports both
model = GRULM()
print(model)
#+end_src

#+RESULTS:
: Serial[
:   Serial[
:     ShiftRight(1)
:   ]
:   Embedding_256_512
:   GRU_512
:   GRU_512
:   Dense_256
:   LogSoftmax
: ]
