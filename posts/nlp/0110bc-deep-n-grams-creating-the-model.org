#+BEGIN_COMMENT
.. title: Deep N-Grams: Creating the Model
.. slug: deep-n-grams-creating-the-model
.. date: 2021-01-05 16:48:01 UTC-08:00
.. tags: nlp,n-grams,rnn,gru
.. category: NLP
.. link: 
.. description: Creating a GRU model.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/
#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC

* Creating The Model
  - {{% lancelot title="First Post" %}}deep-n-grams{{% /lancelot %}}
  - {{% lancelot title="Previous Post" %}}deep-n-grams-loading-the-data{{% /lancelot %}}
  - {{% lancelot title="Next Post" %}}deep-n-grams-training-the-model{{% /lancelot %}}
#+begin_example python    
# # Part 2: Defining the GRU model
# 
# Now that you have the input and output tensors, you will go ahead and initialize your model. You will be implementing the `GRULM`, gated recurrent unit model. To implement this model, you will be using google's `trax` package. Instead of making you implement the `GRU` from scratch, we will give you the necessary methods from a build in package. You can use the following packages when constructing the model: 
# 
# 
# - `tl.Serial`: Combinator that applies layers serially (by function composition). [docs](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial) / [source code](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/combinators.py#L26)
#     - You can pass in the layers as arguments to `Serial`, separated by commas. 
#     - For example: `tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))`
# 
# ___
# 
# - `tl.ShiftRight`: Allows the model to go right in the feed forward. [docs](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight) / [source code](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/attention.py#L297)
#     - `ShiftRight(n_shifts=1, mode='train')` layer to shift the tensor to the right n_shift times
#     - Here in the exercise you only need to specify the mode and not worry about n_shifts
# 
# ___
# 
# - `tl.Embedding`: Initializes the embedding. In this case it is the size of the vocabulary by the dimension of the model. [docs](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding) / [source code](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113) 
#     - `tl.Embedding(vocab_size, d_feature)`.
#     - `vocab_size` is the number of unique words in the given vocabulary.
#     - `d_feature` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).
# ___
# 
# - `tl.GRU`: `Trax` GRU layer. [docs](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.GRU) / [source code](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/rnn.py#L143)
#     - `GRU(n_units)` Builds a traditional GRU of n_cells with dense internal transformations.
#     - `GRU` paper: https://arxiv.org/abs/1412.3555
# ___
# 
# - `tl.Dense`: A dense layer. [docs](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) / [source code](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L28)
#     - `tl.Dense(n_units)`: The parameter `n_units` is the number of units chosen for this dense layer.
# ___
# 
# - `tl.LogSoftmax`: Log of the output probabilities. [docs](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) / [source code](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L242)
#     - Here, you don't need to set any parameters for `LogSoftMax()`.
# ___
# 
# <a name='ex03'></a>
# ### Exercise 03
# **Instructions:** Implement the `GRULM` class below. You should be using all the methods explained above.
# 

# In[ ]:


# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: GRULM
def GRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):
    """Returns a GRU language model.

    Args:
        vocab_size (int, optional): Size of the vocabulary. Defaults to 256.
        d_model (int, optional): Depth of embedding (n_units in the GRU cell). Defaults to 512.
        n_layers (int, optional): Number of GRU layers. Defaults to 2.
        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to "train".

    Returns:
        trax.layers.combinators.Serial: A GRU language model as a layer that maps from a tensor of tokens to activations over a vocab set.
    """
    ### START CODE HERE (Replace instances of 'None' with your code) ###
    model = tl.Serial(
      None, # Stack the ShiftRight layer
      None, # Stack the embedding layer
      None, # Stack GRU layers of d_model units keeping n_layer parameter in mind (use list comprehension syntax)
      None, # Dense layer
      None # Log Softmax
    )
    ### END CODE HERE ###
    return model


# In[ ]:


# testing your model
model = GRULM()
print(model)


# ##### Expected output
# 
# ```CPP
# Serial[
#   ShiftRight(1)
#   Embedding_256_512
#   GRU_512
#   GRU_512
#   Dense_256
#   LogSoftmax
# ]
# ```

# <a name='3'></a>
#+end_example
