#+BEGIN_COMMENT
.. title: Autocorrect: Finding Candidates Using Edits
.. slug: autocorrect-finding-candidates-using-edits
.. date: 2020-11-05 17:30:56 UTC-08:00
.. tags: nlp,autocorrect
.. category: NLP
.. link: 
.. description: Finding autocorrect candidates using the edits.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 2

#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-0a461a03-03f9-459f-8c9e-7ee319ef1e4e-ssh.json

#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC
* Beginning
* Middle
** Our Data
   This is the word we are going to autocorrect.
#+begin_src python :results none
word = "dearz"
#+end_src
** Splits
   This finds all the splits in our word.

#+begin_src python :results output :exports both
splits = [(word[:index], word[index:]) for index in range(len(word) + 1)]
for split in splits:
    print(split)
#+end_src

#+RESULTS:
: ('', 'dearz')
: ('d', 'earz')
: ('de', 'arz')
: ('dea', 'rz')
: ('dear', 'z')
: ('dearz', '')
** Delete
   Starting with the splits, delete the first letter of the second element of each tuple. This means that each letter gets deleted exactly once.
#+begin_src python :results output :exports both
deletes = [left + right[1:] for left, right in splits if right]
for deleted in deletes:
    print(f" - {deleted}")
#+end_src

#+RESULTS:
:  - earz
:  - darz
:  - derz
:  - deaz
:  - dear

These are now the candidates to use for the correction.
** Filter Out
   Since not all the candidates are real words you need to filter out all but the real candidates using a pre-defined vocabulary.
#+begin_src python :results output :exports both
vocabulary = ['dean','deer','dear','fries','and','coke']
candidates = set(vocabulary).intersection(set(deletes))
print(candidates)
#+end_src

#+RESULTS:
: {'dear'}

* End
This doesn't demonstrate all the edits (nor the use of edit distance) but the remaining types of edits are done in a similar manner to these two.
