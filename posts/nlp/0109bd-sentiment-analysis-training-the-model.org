#+BEGIN_COMMENT
.. title: Sentiment Analysis: Training the Model
.. slug: sentiment-analysis-training-the-model
.. date: 2020-12-23 15:49:53 UTC-08:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT
* Beginning
  In the {{% lancelot title="previous post" %}}sentiment-analysis-defining-the-model{{% /lancelot %}} we defined our Deep Learning model for Sentiment Analysis. Now we'll turn to training it on our data.
* End
  Now that we have a trained model, in the {{% lancelot title="next post" %}}sentiment-analysis-testing-the-model{{% /lancelot %}} we'll test how well it did.
* Raw
#+begin_example
# # Part 4:  Training
# 
# To train a model on a task, Trax defines an abstraction [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) which packages the train data, loss and optimizer (among other things) together into an object.
# 
# Similarly to evaluate a model, Trax defines an abstraction [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) which packages the eval data and metrics (among other things) into another object.
# 
# The final piece tying things together is the [`trax.supervised.training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) abstraction that is a very simple and flexible way to put everything together and train the model, all the while evaluating it and saving checkpoints.
# Using `Loop` will save you a lot of code compared to always writing the training loop by hand, like you did in courses 1 and 2. More importantly, you are less likely to have a bug in that code that would ruin your training.

# In[ ]:



# View documentation for trax.supervised.training.TrainTask
help(trax.supervised.training.TrainTask)


# In[ ]:


# View documentation for trax.supervised.training.EvalTask
help(trax.supervised.training.EvalTask)


# In[ ]:


# View documentation for trax.supervised.training.Loop
help(trax.supervised.training.Loop)


# In[ ]:


# View optimizers that you could choose from
help(trax.optimizers)


# Notice some available optimizers include:
# ```CPP
#     adafactor
#     adam
#     momentum
#     rms_prop
#     sm3
# ```

# <a name="4.1"></a>
# ## 4.1  Training the model
# 
# Now you are going to train your model. 
# 
# Let's define the `TrainTask`, `EvalTask` and `Loop` in preparation to train the model.

# In[ ]:


from trax.supervised import training

batch_size = 16
rnd.seed(271)

train_task = training.TrainTask(
    labeled_data=train_generator(batch_size=batch_size, shuffle=True),
    loss_layer=tl.CrossEntropyLoss(),
    optimizer=trax.optimizers.Adam(0.01),
    n_steps_per_checkpoint=10,
)

eval_task = training.EvalTask(
    labeled_data=val_generator(batch_size=batch_size, shuffle=True),
    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],
)

model = classifier()


# This defines a model trained using [`tl.CrossEntropyLoss`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss) optimized with the [`trax.optimizers.Adam`](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam) optimizer, all the while tracking the accuracy using [`tl.Accuracy`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy) metric. We also track `tl.CrossEntropyLoss` on the validation set.

# Now let's make an output directory and train the model.

# In[ ]:


output_dir = '~/model/'
output_dir_expand = os.path.expanduser(output_dir)
print(output_dir_expand)


# <a name="ex06"></a>
# ### Exercise 06
# **Instructions:** Implement `train_model` to train the model (`classifier` that you wrote earlier) for the given number of training steps (`n_steps`) using `TrainTask`, `EvalTask` and `Loop`.

# In[ ]:


# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: train_model
def train_model(classifier, train_task, eval_task, n_steps, output_dir):
    '''
    Input: 
        classifier - the model you are building
        train_task - Training task
        eval_task - Evaluation task
        n_steps - the evaluation steps
        output_dir - folder to save your files
    Output:
        trainer -  trax trainer
    '''
### START CODE HERE (Replace instances of 'None' with your code) ###
    training_loop = training.Loop(
                                None, # The learning model
                                None, # The training task
                                eval_task = None, # The evaluation task
                                output_dir = None) # The output directory

    training_loop.run(n_steps = None)
### END CODE HERE ###

    # Return the training_loop, since it has the model.
    return training_loop


# In[ ]:


training_loop = train_model(model, train_task, eval_task, 100, output_dir_expand)


# ##### Expected output (Approximately)
# ```CPP
# Step      1: train CrossEntropyLoss |  0.88939196
# Step      1: eval  CrossEntropyLoss |  0.68833977
# Step      1: eval          Accuracy |  0.50000000
# Step     10: train CrossEntropyLoss |  0.61036736
# Step     10: eval  CrossEntropyLoss |  0.52182281
# Step     10: eval          Accuracy |  0.68750000
# Step     20: train CrossEntropyLoss |  0.34137666
# Step     20: eval  CrossEntropyLoss |  0.20654774
# Step     20: eval          Accuracy |  1.00000000
# Step     30: train CrossEntropyLoss |  0.20208922
# Step     30: eval  CrossEntropyLoss |  0.21594886
# Step     30: eval          Accuracy |  0.93750000
# Step     40: train CrossEntropyLoss |  0.19611198
# Step     40: eval  CrossEntropyLoss |  0.17582777
# Step     40: eval          Accuracy |  1.00000000
# Step     50: train CrossEntropyLoss |  0.11203773
# Step     50: eval  CrossEntropyLoss |  0.07589275
# Step     50: eval          Accuracy |  1.00000000
# Step     60: train CrossEntropyLoss |  0.09375446
# Step     60: eval  CrossEntropyLoss |  0.09290724
# Step     60: eval          Accuracy |  1.00000000
# Step     70: train CrossEntropyLoss |  0.08785903
# Step     70: eval  CrossEntropyLoss |  0.09610598
# Step     70: eval          Accuracy |  1.00000000
# Step     80: train CrossEntropyLoss |  0.08858261
# Step     80: eval  CrossEntropyLoss |  0.02319432
# Step     80: eval          Accuracy |  1.00000000
# Step     90: train CrossEntropyLoss |  0.05699894
# Step     90: eval  CrossEntropyLoss |  0.01778970
# Step     90: eval          Accuracy |  1.00000000
# Step    100: train CrossEntropyLoss |  0.03663783
# Step    100: eval  CrossEntropyLoss |  0.00210550
# Step    100: eval          Accuracy |  1.00000000
# ```

# <a name="4.2"></a>
# ## 4.2  Practice Making a prediction
# 
# Now that you have trained a model, you can access it as `training_loop.model` object. We will actually use `training_loop.eval_model` and in the next weeks you will learn why we sometimes use a different model for evaluation, e.g., one without dropout. For now, make predictions with your model.
# 
# Use the training data just to see how the prediction process works.  
# - Later, you will use validation data to evaluate your model's performance.
# 

# In[ ]:


# Create a generator object
tmp_train_generator = train_generator(16)

# get one batch
tmp_batch = next(tmp_train_generator)

# Position 0 has the model inputs (tweets as tensors)
# position 1 has the targets (the actual labels)
tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch

print(f"The batch is a tuple of length {len(tmp_batch)} because position 0 contains the tweets, and position 1 contains the targets.") 
print(f"The shape of the tweet tensors is {tmp_inputs.shape} (num of examples, length of tweet tensors)")
print(f"The shape of the labels is {tmp_targets.shape}, which is the batch size.")
print(f"The shape of the example_weights is {tmp_example_weights.shape}, which is the same as inputs/targets size.")


# In[ ]:


# feed the tweet tensors into the model to get a prediction
tmp_pred = training_loop.eval_model(tmp_inputs)
print(f"The prediction shape is {tmp_pred.shape}, num of tensor_tweets as rows")
print("Column 0 is the probability of a negative sentiment (class 0)")
print("Column 1 is the probability of a positive sentiment (class 1)")
print()
print("View the prediction array")
tmp_pred


# To turn these probabilities into categories (negative or positive sentiment prediction), for each row:
# - Compare the probabilities in each column.
# - If column 1 has a value greater than column 0, classify that as a positive tweet.
# - Otherwise if column 1 is less than or equal to column 0, classify that example as a negative tweet.

# In[ ]:


# turn probabilites into category predictions
tmp_is_positive = tmp_pred[:,1] > tmp_pred[:,0]
for i, p in enumerate(tmp_is_positive):
    print(f"Neg log prob {tmp_pred[i,0]:.4f}\tPos log prob {tmp_pred[i,1]:.4f}\t is positive? {p}\t actual {tmp_targets[i]}")


# Notice that since you are making a prediction using a training batch, it's more likely that the model's predictions match the actual targets (labels).  
# - Every prediction that the tweet is positive is also matching the actual target of 1 (positive sentiment).
# - Similarly, all predictions that the sentiment is not positive matches the actual target of 0 (negative sentiment)

# One more useful thing to know is how to compare if the prediction is matching the actual target (label).  
# - The result of calculation `is_positive` is a boolean.
# - The target is a type trax.fastmath.numpy.int32
# - If you expect to be doing division, you may prefer to work with decimal numbers with the data type type trax.fastmath.numpy.int32

# In[ ]:


# View the array of booleans
print("Array of booleans")
display(tmp_is_positive)

# convert boolean to type int32
# True is converted to 1
# False is converted to 0
tmp_is_positive_int = tmp_is_positive.astype(np.int32)


# View the array of integers
print("Array of integers")
display(tmp_is_positive_int)

# convert boolean to type float32
tmp_is_positive_float = tmp_is_positive.astype(np.float32)

# View the array of floats
print("Array of floats")
display(tmp_is_positive_float)


# In[ ]:


tmp_pred.shape


# Note that Python usually does type conversion for you when you compare a boolean to an integer
# - True compared to 1 is True, otherwise any other integer is False.
# - False compared to 0 is True, otherwise any ohter integer is False.

# In[ ]:


print(f"True == 1: {True == 1}")
print(f"True == 2: {True == 2}")
print(f"False == 0: {False == 0}")
print(f"False == 2: {False == 2}")


# However, we recommend that you keep track of the data type of your variables to avoid unexpected outcomes.  So it helps to convert the booleans into integers
# - Compare 1 to 1 rather than comparing True to 1.

# Hopefully you are now familiar with what kinds of inputs and outputs the model uses when making a prediction.
# - This will help you implement a function that estimates the accuracy of the model's predictions.

# <a name="5"></a>
# # Part 5:  Evaluation  
# 
# <a name="5.1"></a>
# ## 5.1  Computing the accuracy on a batch
# 
# You will now write a function that evaluates your model on the validation set and returns the accuracy. 
# - `preds` contains the predictions.
#     - Its dimensions are `(batch_size, output_dim)`.  `output_dim` is two in this case.  Column 0 contains the probability that the tweet belongs to class 0 (negative sentiment). Column 1 contains probability that it belongs to class 1 (positive sentiment).
#     - If the probability in column 1 is greater than the probability in column 0, then interpret this as the model's prediction that the example has label 1 (positive sentiment).  
#     - Otherwise, if the probabilities are equal or the probability in column 0 is higher, the model's prediction is 0 (negative sentiment).
# - `y` contains the actual labels.
# - `y_weights` contains the weights to give to predictions.

# <a name="ex07"></a>
# ### Exercise 07
# Implement `compute_accuracy`.

# In[ ]:


# UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: compute_accuracy
def compute_accuracy(preds, y, y_weights):
    """
    Input: 
        preds: a tensor of shape (dim_batch, output_dim) 
        y: a tensor of shape (dim_batch,) with the true labels
        y_weights: a n.ndarray with the a weight for each example
    Output: 
        accuracy: a float between 0-1 
        weighted_num_correct (np.float32): Sum of the weighted correct predictions
        sum_weights (np.float32): Sum of the weights
    """
    ### START CODE HERE (Replace instances of 'None' with your code) ###
    # Create an array of booleans, 
    # True if the probability of positive sentiment is greater than
    # the probability of negative sentiment
    # else False
    is_pos =  None

    # convert the array of booleans into an array of np.int32
    is_pos_int = None
    
    # compare the array of predictions (as int32) with the target (labels) of type int32
    correct = None

    # Count the sum of the weights.
    sum_weights = None
    
    # convert the array of correct predictions (boolean) into an arrayof np.float32
    correct_float = None
    
    # Multiply each prediction with its corresponding weight.
    weighted_correct_float = None

    # Sum up the weighted correct predictions (of type np.float32), to go in the
    # denominator.
    weighted_num_correct = None
 
    # Divide the number of weighted correct predictions by the sum of the
    # weights.
    accuracy = None

    ### END CODE HERE ###
    return accuracy, weighted_num_correct, sum_weights


# In[ ]:


# test your function
tmp_val_generator = val_generator(64)

# get one batch
tmp_batch = next(tmp_val_generator)

# Position 0 has the model inputs (tweets as tensors)
# position 1 has the targets (the actual labels)
tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch

# feed the tweet tensors into the model to get a prediction
tmp_pred = training_loop.eval_model(tmp_inputs)

tmp_acc, tmp_num_correct, tmp_num_predictions = compute_accuracy(preds=tmp_pred, y=tmp_targets, y_weights=tmp_example_weights)

print(f"Model's prediction accuracy on a single training batch is: {100 * tmp_acc}%")
print(f"Weighted number of correct predictions {tmp_num_correct}; weighted number of total observations predicted {tmp_num_predictions}")

# ##### Expected output (Approximately)
# 
# ```
# Model's prediction accuracy on a single training batch is: 100.0%
# Weighted number of correct predictions 64.0; weighted number of total observations predicted 64
# ```
#+end_example
