<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Generating sentences with our GRU model." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Deep N-Grams: Generating Sentences | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/deep-n-grams-generating-sentences/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../deep-n-grams-evaluating-the-model/" rel="prev" title="Deep N-Grams: Evaluating the Model" type="text/html">
<link href="../deep-n-grams-batch-generation/" rel="next" title="Deep N-Grams: Batch Generation" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Deep N-Grams: Generating Sentences" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/deep-n-grams-generating-sentences/" property="og:url">
<meta content="Generating sentences with our GRU model." property="og:description">
<meta content="article" property="og:type">
<meta content="2021-01-05T16:49:26-08:00" property="article:published_time">
<meta content="gru" property="article:tag">
<meta content="n-grams" property="article:tag">
<meta content="nlp" property="article:tag">
<meta content="rnn" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Deep N-Grams: Generating Sentences</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2021-01-05T16:49:26-08:00" itemprop="datePublished" title="2021-01-05 16:49">2021-01-05 16:49</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgaec32e3">Generating New Sentences</a>
<ul>
<li><a href="#org16eebf2">Imports</a></li>
<li><a href="#org935d244">Set Up</a></li>
</ul>
</li>
<li><a href="#orgba3abb9">Middle</a>
<ul>
<li><a href="#org1690989">The Gumbel Sample</a></li>
<li><a href="#org4653cab">A Predictor</a></li>
<li><a href="#org0e0bc78">Some Predictions</a></li>
</ul>
</li>
<li><a href="#org8f78caf">On statistical methods</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgaec32e3">
<h2 id="orgaec32e3">Generating New Sentences</h2>
<div class="outline-text-2" id="text-orgaec32e3">
<ul class="org-ul">
<li><a href="../deep-n-grams/">First Post</a></li>
<li><a href="../deep-n-grams-evaluating-the-model/">Previous Post</a></li>
</ul>
<p>Now we'll use the language model to generate new sentences for that we need to make draws from a <a href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumble distribution</a>.</p>
<p>The Gumbel Probability Density Function (PDF) is defined as: \[ f(z) = {1\over{\beta}}e^{\left(-z+e^{(-z)}\right)} \]</p>
<p>Where: \[ z = {(x - \mu)\over{\beta}} \]</p>
<p>The maximum value is what we choose as the prediction in the last step of a Recursive Neural Network <code>RNN</code> we are using for text generation. A sample of a random variable from an exponential distribution approaches the Gumbel distribution when the sample increases asymptotically. For that reason, the Gumbel distribution is used to sample from a categorical distribution.</p>
</div>
<div class="outline-3" id="outline-container-org16eebf2">
<h3 id="org16eebf2">Imports</h3>
<div class="outline-text-3" id="text-org16eebf2">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.deep_rnn</span> <span class="kn">import</span> <span class="n">GRUModel</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org935d244">
<h3 id="org935d244">Set Up</h3>
<div class="outline-text-3" id="text-org935d244">
<div class="highlight">
<pre><span></span><span class="n">gru</span> <span class="o">=</span> <span class="n">GRUModel</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gru</span><span class="o">.</span><span class="n">model</span>
<span class="n">ours</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/models/gru-shakespeare-model/model.pkl.gz"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">init_from_file</span><span class="p">(</span><span class="n">ours</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgba3abb9">
<h2 id="orgba3abb9">Middle</h2>
<div class="outline-text-2" id="text-orgba3abb9"></div>
<div class="outline-3" id="outline-container-org1690989">
<h3 id="org1690989">The Gumbel Sample</h3>
<div class="outline-text-3" id="text-org1690989">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">gumbel_sample</span><span class="p">(</span><span class="n">log_probabilities</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">,</span>
                  <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""Gumbel sampling from a categorical distribution</span>

<span class="sd">    Args:</span>
<span class="sd">     log_probabilities: model predictions for a given input</span>
<span class="sd">     temperature: fudge</span>

<span class="sd">    Returns:</span>
<span class="sd">     the maximum sample</span>
<span class="sd">    """</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">-</span> <span class="mf">1e-6</span><span class="p">,</span>
                             <span class="n">size</span><span class="o">=</span><span class="n">log_probabilities</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">log_probabilities</span> <span class="o">+</span> <span class="n">g</span> <span class="o">*</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4653cab">
<h3 id="org4653cab">A Predictor</h3>
<div class="outline-text-3" id="text-org4653cab">
<div class="highlight">
<pre><span></span><span class="n">END_OF_SENTENCE</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">number_of_characters</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">break_on</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">END_OF_SENTENCE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">"""Predicts characters</span>

<span class="sd">    Args:</span>
<span class="sd">     number_of_characters: how many characters to predict</span>
<span class="sd">     prefix: character to prompt the predictions</span>
<span class="sd">     break_on: identifier for character to prematurely stop on</span>

<span class="sd">    Returns:</span>
<span class="sd">     prefix followed by predicted characters</span>
<span class="sd">    """</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">ord</span><span class="p">(</span><span class="n">character</span><span class="p">)</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">prefix</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
    <span class="n">maximum_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">+</span> <span class="n">number_of_characters</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_characters</span><span class="p">):</span>
        <span class="n">current_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">inputs</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">maximum_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">current_inputs</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>  <span class="c1"># Add batch dim.</span>
        <span class="n">next_character</span> <span class="o">=</span> <span class="n">gumbel_sample</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)])</span>
        <span class="n">inputs</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">next_character</span><span class="p">)]</span>

        <span class="k">if</span> <span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">break_on</span><span class="p">:</span>
            <span class="k">break</span>  <span class="c1"># EOS</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">chr</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">next_character</span><span class="p">)))</span>

    <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0e0bc78">
<h3 id="org0e0bc78">Some Predictions</h3>
<div class="outline-text-3" id="text-org0e0bc78">
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="s2">""</span><span class="p">))</span>
</pre></div>
<pre class="example">
you would not live at essenomed 
</pre>
<p>Yes, but I don't know anyone who would. Note that we are using a random sample, so repeatedly making predictions won't necessarily get you the same result.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="s2">""</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="s2">""</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="s2">""</span><span class="p">))</span>
</pre></div>
<pre class="example">
[exeunt]
katharine       yes, you are like the 
le beau where's some of my prett
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="s2">"falstaff"</span><span class="p">))</span>
</pre></div>
<pre class="example">
falstaff        yea, marry, lady, she hath bianced three months.
</pre>
<p><i>bianced</i>?</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="s2">"beast"</span><span class="p">))</span>
</pre></div>
<pre class="example">
beastly, and god forbid, sir! our revenue's cannon,
</pre>
<div class="highlight">
<pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="s2">"finger"</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
</pre></div>
<pre class="example">
finger, iago, an
finger, iago, and ask.
finger, iago, and ask.
finger, iago, and ask.
finger, iago, and ask.
</pre>
<p>So, if you feed it enough text, it becomes more deterministic.</p>
<div class="highlight">
<pre><span></span><span class="n">SPACE</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">" "</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="s2">"iago"</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">start</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">start</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">output</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">start</span><span class="si">}</span><span class="s2">"</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>    
</pre></div>
<pre class="example">
iago your husband if there never for you need no never
</pre>
<p>In the generated text above, you can see that the model generates text that makes sense capturing dependencies between words and without any input. A simple n-gram model would have not been able to capture all of that in one sentence.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8f78caf">
<h2 id="org8f78caf">On statistical methods</h2>
<div class="outline-text-2" id="text-org8f78caf">
<p>Using a statistical method will not give you results that are as good. The model would not be able to encode information seen previously in the data set and as a result, the perplexity will increase. The higher the perplexity, the worse your model is. Furthermore, statistical N-Gram models take up too much space and memory. As a result, it would be inefficient and too slow. Conversely, with deep neural networks, you can get a better perplexity. Note though, that learning about n-gram language models is still important and leads to a better understanding of deep neural networks.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/gru/" rel="tag">gru</a></li>
<li><a class="tag p-category" href="../../../categories/n-grams/" rel="tag">n-grams</a></li>
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/rnn/" rel="tag">rnn</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../deep-n-grams-evaluating-the-model/" rel="prev" title="Deep N-Grams: Evaluating the Model">Previous post</a></li>
<li class="next"><a href="../deep-n-grams-batch-generation/" rel="next" title="Deep N-Grams: Batch Generation">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
