#+BEGIN_COMMENT
.. title: Siamese Networks: New Questions
.. slug: siamese-networks-new-questions
.. date: 2021-01-25 19:40:55 UTC-08:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT
* Raw
#+begin_example python
# # Part 5: Testing with your own questions
# 
# In this section you will test the model with your own questions. You will write a function `predict` which takes two questions as input and returns $1$ or $0$ depending on whether the question pair is a duplicate or not.   
# 
# But first, we build a reverse vocabulary that allows to map encoded questions back to words: 

# Write a function `predict`that takes in two questions, the model, and the vocabulary and returns whether the questions are duplicates ($1$) or not duplicates ($0$) given a similarity threshold. 
# 
# <a name='ex06'></a>
# ### Exercise 06
# 
# 
# **Instructions:** 
# - Tokenize your question using `nltk.word_tokenize` 
# - Create Q1,Q2 by encoding your questions as a list of numbers using vocab
# - pad Q1,Q2 with next(data_generator([Q1], [Q2],1,vocab['<PAD>']))
# - use model() to create v1, v2
# - compute the cosine similarity (dot product) of v1, v2
# - compute res by comparing d to the threshold
# 

# In[ ]:


# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: predict
def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):
    """Function for predicting if two questions are duplicates.

    Args:
        question1 (str): First question.
        question2 (str): Second question.
        threshold (float): Desired threshold.
        model (trax.layers.combinators.Parallel): The Siamese model.
        vocab (collections.defaultdict): The vocabulary used.
        data_generator (function): Data generator function. Defaults to data_generator.
        verbose (bool, optional): If the results should be printed out. Defaults to False.

    Returns:
        bool: True if the questions are duplicates, False otherwise.
    """
    ### START CODE HERE (Replace instances of 'None' with your code) ###
    # use `nltk` word tokenize function to tokenize
    q1 = None  # tokenize
    q2 = None  # tokenize
    Q1, Q2 = [], []
    for word in q1:  # encode q1
        # increment by checking the 'word' index in `vocab`
        Q1 += None
    for word in q2:  # encode q2
        # increment by checking the 'word' index in `vocab`
        Q2 += None
        
    # Call the data generator (built in Ex 01) using next()
    # pass [Q1] & [Q2] as Q1 & Q2 arguments of the data generator. Set batch size as 1
    # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator
    Q1, Q2 = None
    # Call the model
    v1, v2 = None
    # take dot product to compute cos similarity of each pair of entries, v1, v2
    # don't forget to transpose the second argument
    d = None
    # is d greater than the threshold?
    res = None
    
    ### END CODE HERE ###
    
    if(verbose):
        print("Q1  = ", Q1, "\nQ2  = ", Q2)
        print("d   = ", d)
        print("res = ", res)

    return res


# In[ ]:


# Feel free to try with your own questions
question1 = "When will I see you?"
question2 = "When can I see you again?"
# 1 means it is duplicated, 0 otherwise
predict(question1 , question2, 0.7, model, vocab, verbose = True)


# ##### Expected Output
# If input is:
# ```CPP
# question1 = "When will I see you?"
# question2 = "When can I see you again?"
# ```
# 
# Output is (d may vary a bit):
# ```CPP
# Q1  =  [[585  76   4  46  53  21   1   1]] 
# Q2  =  [[ 585   33    4   46   53 7280   21    1]]
# d   =  0.88113236
# res =  True
# True
# ```

# In[ ]:


# Feel free to try with your own questions
question1 = "Do they enjoy eating the dessert?"
question2 = "Do they like hiking in the desert?"
# 1 means it is duplicated, 0 otherwise
predict(question1 , question2, 0.7, model, vocab, verbose=True)


# ##### Expected output
# 
# If input is:
# ```CPP
# question1 = "Do they enjoy eating the dessert?"
# question2 = "Do they like hiking in the desert?"
# ```
# 
# Output  (d may vary a bit):
# 
# ```CPP
# Q1  =  [[  443  1145  3159  1169    78 29017    21     1]] 
# Q2  =  [[  443  1145    60 15302    28    78  7431    21]]
# d   =  0.477536
# res =  False
# False
# ```

# You can see that the Siamese network is capable of catching complicated structures. Concretely it can identify question duplicates although the questions do not have many words in common. 
#  

# <a name='6'></a>
# 
# ###  <span style="color:blue"> On Siamese networks </span>
# 
# Siamese networks are important and useful. Many times there are several questions that are already asked in quora, or other platforms and you can use Siamese networks to avoid question duplicates. 
# 
# Congratulations, you have now built a powerful system that can recognize question duplicates. In the next course we will use transformers for machine translation, summarization, question answering, and chatbots. 
#+end_example  
