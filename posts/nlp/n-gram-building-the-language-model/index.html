<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Building the language model for N-Grams." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>N-Gram: Building the Language Model | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/n-gram-building-the-language-model/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../n-gram-pre-processing/" rel="prev" title="N-Gram Pre-Processing" type="text/html">
<link href="../n-grams-out-of-vocabulary-words/" rel="next" title="N-Grams: Out-of-Vocabulary Words" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="N-Gram: Building the Language Model" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/n-gram-building-the-language-model/" property="og:url">
<meta content="Building the language model for N-Grams." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-12-02T19:12:55-08:00" property="article:published_time">
<meta content="n-grams" property="article:tag">
<meta content="nlp" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">N-Gram: Building the Language Model</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2020-12-02T19:12:55-08:00" itemprop="datePublished" title="2020-12-02 19:12">2020-12-02 19:12</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgf76d107">Building the Language Model</a>
<ul>
<li><a href="#org8b47c99">Imports</a></li>
<li><a href="#org4e213b6">Set Up</a></li>
</ul>
</li>
<li><a href="#orgb4d1667">Middle</a>
<ul>
<li><a href="#org9231251">The Count Matrix</a></li>
<li><a href="#org1a9bf61">Single-Pass Trigram Count Matrix</a></li>
<li><a href="#org3d5fd82">The Probability Matrix</a>
<ul>
<li><a href="#orgff30883">Create the Probability Matrix from the Count Matrix</a></li>
<li><a href="#org404b63f">Divide Each Row By Its Sum</a></li>
<li><a href="#orgb4aafe4">Find the Probability of a Trigram</a></li>
</ul>
</li>
<li><a href="#org61ab2e1">List all the words in the vocabulary starting with a given prefix</a></li>
<li><a href="#orgedc7b9e">Building Training, Validation, and Testing Sets</a>
<ul>
<li><a href="#orga13b841">Check the Sets</a></li>
</ul>
</li>
<li><a href="#org7b73272">Perplexity</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgf76d107">
<h2 id="orgf76d107">Building the Language Model</h2>
<div class="outline-text-2" id="text-orgf76d107"></div>
<div class="outline-3" id="outline-container-org8b47c99">
<h3 id="org8b47c99">Imports</h3>
<div class="outline-text-3" id="text-org8b47c99">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4e213b6">
<h3 id="org4e213b6">Set Up</h3>
<div class="outline-text-3" id="text-org4e213b6">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb4d1667">
<h2 id="orgb4d1667">Middle</h2>
<div class="outline-text-2" id="text-orgb4d1667"></div>
<div class="outline-3" id="outline-container-org9231251">
<h3 id="org9231251">The Count Matrix</h3>
<div class="outline-text-3" id="text-org9231251">
<p>To calculate the n-gram probability, you will need to count frequencies of n-grams and n-gram prefixes in the training dataset. In some of the code assignment exercises, you will store the n-gram frequencies in a dictionary.</p>
<p>In other parts of the assignment, you will build a count matrix that keeps counts of (n-1)-gram prefix followed by all possible last words in the vocabulary.</p>
<p>The following code shows how to check, retrieve and update counts of n-grams in the word count dictionary.</p>
<div class="highlight">
<pre><span></span><span class="n">n_gram_counts</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">):</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">(</span><span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">,</span> <span class="s1">'because'</span><span class="p">):</span> <span class="mi">1</span><span class="p">}</span>

<span class="c1"># get count for an n-gram tuple</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"count of n-gram </span><span class="si">{</span><span class="p">(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">)</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">n_gram_counts</span><span class="p">[(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
count of n-gram ('i', 'am', 'happy'): 2
</pre>
<div class="highlight">
<pre><span></span><span class="c1"># check if n-gram is present in the dictionary</span>
<span class="n">n_gram</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'learning'</span><span class="p">)</span>
<span class="n">status</span> <span class="o">=</span> <span class="s2">"found"</span> <span class="k">if</span> <span class="n">n_gram</span> <span class="ow">in</span> <span class="n">n_gram_counts</span> <span class="k">else</span> <span class="s2">"missing"</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"n-gram </span><span class="si">{</span><span class="n">n_gram</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
n-gram ('i', 'am', 'learning') missing
</pre>
<div class="highlight">
<pre><span></span><span class="c1"># update the count in the word count dictionary</span>
<span class="n">n_gram_counts</span><span class="p">[</span><span class="n">n_gram</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">status</span> <span class="o">=</span> <span class="s2">"found"</span> <span class="k">if</span> <span class="p">(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'learning'</span><span class="p">)</span> <span class="ow">in</span> <span class="n">n_gram_counts</span> <span class="k">else</span> <span class="s2">"missing"</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"n-gram </span><span class="si">{</span><span class="n">n_gram</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
n-gram ('i', 'am', 'learning') found
</pre>
<p>The next code snippet shows how to merge two tuples in Python. That will be handy when creating the n-gram from the prefix and the last word.</p>
<p>concatenate tuple for prefix and tuple with the last word to create the n_gram</p>
<div class="highlight">
<pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">)</span>
<span class="n">word</span> <span class="o">=</span> <span class="s1">'because'</span>

<span class="c1"># note here the syntax for creating a tuple for a single word</span>
<span class="n">n_gram</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="p">(</span><span class="n">word</span><span class="p">,)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n_gram</span><span class="p">)</span>
</pre></div>
<pre class="example">
('i', 'am', 'happy', 'because')
</pre></div>
</div>
<div class="outline-3" id="outline-container-org1a9bf61">
<h3 id="org1a9bf61">Single-Pass Trigram Count Matrix</h3>
<div class="outline-text-3" id="text-org1a9bf61">
<p>In the lecture, you've seen that the count matrix could be made in a single pass through the corpus. Here is one approach to do that.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">single_pass_trigram_count_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Creates the trigram count matrix from the input corpus in a single pass through the corpus.</span>

<span class="sd">    Args:</span>
<span class="sd">       corpus: Pre-processed and tokenized corpus. </span>

<span class="sd">    Returns:</span>
<span class="sd">       bigrams: list of all bigram prefixes, row index</span>
<span class="sd">       vocabulary: list of all found words, the column index</span>
<span class="sd">       count_matrix: pandas dataframe with bigram prefixes as rows, </span>
<span class="sd">                     vocabulary words as columns </span>
<span class="sd">                     and the counts of the bigram/word combinations (i.e. trigrams) as values</span>
<span class="sd">    """</span>
    <span class="n">bigrams</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">vocabulary</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">count_matrix_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>

    <span class="c1"># go through the corpus once with a sliding window</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># the sliding window starts at position i and contains 3 words</span>
        <span class="n">trigram</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">3</span><span class="p">])</span>

        <span class="n">bigram</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">bigram</span> <span class="ow">in</span> <span class="n">bigrams</span><span class="p">:</span>
            <span class="n">bigrams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bigram</span><span class="p">)</span>        

        <span class="n">last_word</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">last_word</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">:</span>
            <span class="n">vocabulary</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">last_word</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">bigram</span><span class="p">,</span><span class="n">last_word</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">count_matrix_dict</span><span class="p">:</span>
            <span class="n">count_matrix_dict</span><span class="p">[</span><span class="n">bigram</span><span class="p">,</span><span class="n">last_word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">count_matrix_dict</span><span class="p">[</span><span class="n">bigram</span><span class="p">,</span><span class="n">last_word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># convert the count_matrix to numpy.array to fill in the blanks</span>
    <span class="n">count_matrix</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">bigrams</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">trigram_key</span><span class="p">,</span> <span class="n">trigam_count</span> <span class="ow">in</span> <span class="n">count_matrix_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">count_matrix</span><span class="p">[</span><span class="n">bigrams</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">trigram_key</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                     <span class="n">vocabulary</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">trigram_key</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="n">trigam_count</span>

    <span class="c1"># numpy.array to pandas dataframe conversion</span>
    <span class="n">count_matrix</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">count_matrix</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">bigrams</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bigrams</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">count_matrix</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">,</span> <span class="s1">'because'</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'learning'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]</span>

<span class="n">bigrams</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">,</span> <span class="n">count_matrix</span> <span class="o">=</span> <span class="n">single_pass_trigram_count_matrix</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">count_matrix</span><span class="p">))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">&nbsp;</th>
<th class="org-right" scope="col">happy</th>
<th class="org-right" scope="col">because</th>
<th class="org-right" scope="col">i</th>
<th class="org-right" scope="col">am</th>
<th class="org-right" scope="col">learning</th>
<th class="org-right" scope="col">.</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">('i', 'am')</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('am', 'happy')</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('happy', 'because')</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('because', 'i')</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('am', 'learning')</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="outline-3" id="outline-container-org3d5fd82">
<h3 id="org3d5fd82">The Probability Matrix</h3>
<div class="outline-text-3" id="text-org3d5fd82">
<p>The next step is to build a probability matrix from the count matrix. You can use an object dataframe from library pandas and its methods <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html?highlight=sum#pandas.DataFrame.sum">sum</a> and <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.div.html">div</a> to normalize the cell counts with the sum of the respective rows.</p>
</div>
<div class="outline-4" id="outline-container-orgff30883">
<h4 id="orgff30883">Create the Probability Matrix from the Count Matrix</h4>
<div class="outline-text-4" id="text-orgff30883">
<div class="highlight">
<pre><span></span><span class="n">row_sums</span> <span class="o">=</span> <span class="n">count_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org404b63f">
<h4 id="org404b63f">Divide Each Row By Its Sum</h4>
<div class="outline-text-4" id="text-org404b63f">
<div class="highlight">
<pre><span></span><span class="n">prob_matrix</span> <span class="o">=</span> <span class="n">count_matrix</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">row_sums</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"rows"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">prob_matrix</span><span class="p">))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">&nbsp;</th>
<th class="org-right" scope="col">happy</th>
<th class="org-right" scope="col">because</th>
<th class="org-right" scope="col">i</th>
<th class="org-right" scope="col">am</th>
<th class="org-right" scope="col">learning</th>
<th class="org-right" scope="col">.</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">('i', 'am')</td>
<td class="org-right">0.5</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0.5</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('am', 'happy')</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('happy', 'because')</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('because', 'i')</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">('am', 'learning')</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="outline-4" id="outline-container-orgb4aafe4">
<h4 id="orgb4aafe4">Find the Probability of a Trigram</h4>
<div class="outline-text-4" id="text-orgb4aafe4">
<p>Since the columns of the probability matrix are the suffix-words and the index is made up of the bigram-prefix we'll need to unpack those to look up our probability.</p>
<div class="highlight">
<pre><span></span><span class="n">trigram</span> <span class="o">=</span> <span class="p">(</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">)</span>

<span class="n">bigram</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'prefix-bigram: </span><span class="si">{</span><span class="n">bigram</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
prefix-bigram: ('i', 'am')
</pre>
<div class="highlight">
<pre><span></span><span class="n">word</span> <span class="o">=</span> <span class="n">trigram</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"last word of the trigram: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
last word of the trigram: happy
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"trigram probability: </span><span class="si">{</span><span class="n">prob_matrix</span><span class="p">[</span><span class="n">word</span><span class="p">][</span><span class="n">bigram</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
trigram probability: 0.5
</pre>
<p>Which if you look at our corpus or count matrix, is the correct value ("i am" appears twice and one of those times it's "i am happy").</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org61ab2e1">
<h3 id="org61ab2e1">List all the words in the vocabulary starting with a given prefix</h3>
<div class="outline-text-3" id="text-org61ab2e1">
<p>This is just a demonstration of checking the prefix of a string in python.</p>
<div class="highlight">
<pre><span></span><span class="n">vocabulary</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'am'</span><span class="p">,</span> <span class="s1">'happy'</span><span class="p">,</span> <span class="s1">'because'</span><span class="p">,</span> <span class="s1">'learning'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">,</span> <span class="s1">'have'</span><span class="p">,</span> <span class="s1">'you'</span><span class="p">,</span> <span class="s1">'seen'</span><span class="p">,</span><span class="s1">'it'</span><span class="p">,</span> <span class="s1">'?'</span><span class="p">]</span>
<span class="n">starts_with</span> <span class="o">=</span> <span class="s1">'ha'</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'words in vocabulary starting with prefix: </span><span class="si">{</span><span class="n">starts_with</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">(</span><span class="n">candidate</span> <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">vocabulary</span>
             <span class="k">if</span> <span class="n">candidate</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">starts_with</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</pre></div>
<pre class="example">
words in vocabulary starting with prefix: ha

happy
have
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgedc7b9e">
<h3 id="orgedc7b9e">Building Training, Validation, and Testing Sets</h3>
<div class="outline-text-3" id="text-orgedc7b9e">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train_validation_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">train_percent</span><span class="p">,</span> <span class="n">validation_percent</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Splits the input data to  train/validation/test according to the percentage provided</span>

<span class="sd">    Args:</span>
<span class="sd">       data: Pre-processed and tokenized corpus, i.e. list of sentences.</span>
<span class="sd">       train_percent: integer 0-100, defines the portion of input corpus allocated for training</span>
<span class="sd">       validation_percent: integer 0-100, defines the portion of input corpus allocated for validation</span>

<span class="sd">       Note: train_percent + validation_percent need to be &lt;=100</span>
<span class="sd">             the reminder to 100 is allocated for the test set</span>

<span class="sd">    Returns:</span>
<span class="sd">       train_data: list of sentences, the training part of the corpus</span>
<span class="sd">       validation_data: list of sentences, the validation part of the corpus</span>
<span class="sd">       test_data: list of sentences, the test part of the corpus</span>
<span class="sd">    """</span>
    <span class="c1"># fixed seed here for reproducibility</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">87</span><span class="p">)</span>

    <span class="c1"># reshuffle all input sentences</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_percent</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">train_size</span><span class="p">]</span>

    <span class="n">validation_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">validation_percent</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">validation_size</span><span class="p">]</span>

    <span class="n">test_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">validation_size</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga13b841">
<h4 id="orga13b841">Check the Sets</h4>
<div class="outline-text-4" id="text-orga13b841">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_validation_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"split 80/10/10:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="sa">f</span><span class="s2">"train data:</span><span class="si">{</span><span class="n">train_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"validation data:</span><span class="si">{</span><span class="n">validation_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> 
      <span class="sa">f</span><span class="s2">"test data:</span><span class="si">{</span><span class="n">test_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_validation_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">98</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"split 98/1/1:</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="sa">f</span><span class="s2">"train data:</span><span class="si">{</span><span class="n">train_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"validation data:</span><span class="si">{</span><span class="n">validation_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> 
      <span class="sa">f</span><span class="s2">"test data:</span><span class="si">{</span><span class="n">test_data</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
split 80/10/10:
 train data:[28, 76, 5, 0, 62, 29, 54, 95, 88, 58, 4, 22, 92, 14, 50, 77, 47, 33, 75, 68, 56, 74, 43, 80, 83, 84, 73, 93, 66, 87, 9, 91, 64, 79, 20, 51, 17, 27, 12, 31, 67, 81, 7, 34, 45, 72, 38, 30, 16, 60, 40, 86, 48, 21, 70, 59, 6, 19, 2, 99, 37, 36, 52, 61, 97, 44, 26, 57, 89, 55, 53, 85, 3, 39, 10, 71, 23, 32, 25, 8]
 validation data:[78, 65, 63, 11, 49, 98, 1, 46, 15, 41]
 test data:[90, 96, 82, 42, 35, 13, 69, 24, 94, 18]

split 98/1/1:
 train data:[66, 23, 29, 28, 52, 87, 70, 13, 15, 2, 62, 43, 82, 50, 40, 32, 30, 79, 71, 89, 6, 10, 34, 78, 11, 49, 39, 42, 26, 46, 58, 96, 97, 8, 56, 86, 33, 93, 92, 91, 57, 65, 95, 20, 72, 3, 12, 9, 47, 37, 67, 1, 16, 74, 53, 99, 54, 68, 5, 18, 27, 17, 48, 36, 24, 45, 73, 19, 41, 59, 21, 98, 0, 31, 4, 85, 80, 64, 84, 88, 25, 44, 61, 22, 60, 94, 76, 38, 77, 81, 90, 69, 63, 7, 51, 14, 55, 83]
 validation data:[35]
 test data:[75]

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7b73272">
<h3 id="org7b73272">Perplexity</h3>
<div class="outline-text-3" id="text-org7b73272">
<p>In order to implement the <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> formula, you'll need to know how to implement m-th order root of a variable.</p>
\begin{equation*} PP(W)=\sqrt[M]{\prod_{i=1}^{m}{\frac{1}{P(w_i|w_{i-1})}}} \end{equation*}
<p>Remember from calculus:</p>
\begin{equation*} \sqrt[M]{\frac{1}{x}} = x^{-\frac{1}{M}} \end{equation*}
<p>Here is some code that will help you with the formula.</p>
<div class="highlight">
<pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">250</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">100</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"perplexity = </span><span class="si">{</span><span class="n">p</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">M</span><span class="p">)</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
perplexity = 316.228
</pre></div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/n-grams/" rel="tag">n-grams</a></li>
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../n-gram-pre-processing/" rel="prev" title="N-Gram Pre-Processing">Previous post</a></li>
<li class="next"><a href="../n-grams-out-of-vocabulary-words/" rel="next" title="N-Grams: Out-of-Vocabulary Words">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
