<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Adding counts to the twitter auto-complete data for the n-gram model." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Auto-Complete: Pre-Process the Data II | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/auto-complete-pre-process-the-data-ii/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../auto-complete-pre-process-the-data-i/" rel="prev" title="Auto-Complete: Pre-Process the Data I" type="text/html">
<link href="../auto-complete-the-n-gram-model/" rel="next" title="Auto-Complete: the N-Gram Model" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Auto-Complete: Pre-Process the Data II" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/auto-complete-pre-process-the-data-ii/" property="og:url">
<meta content="Adding counts to the twitter auto-complete data for the n-gram model." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-12-04T15:12:52-08:00" property="article:published_time">
<meta content="auto-complete" property="article:tag">
<meta content="n-gram" property="article:tag">
<meta content="nlp" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Auto-Complete: Pre-Process the Data II</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2020-12-04T15:12:52-08:00" itemprop="datePublished" title="2020-12-04 15:12">2020-12-04 15:12</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org99d2147">Beginning</a>
<ul>
<li><a href="#org8246821">Imports</a></li>
<li><a href="#org377723b">Set Up</a>
<ul>
<li><a href="#orgfe348b0">The Environment</a></li>
<li><a href="#org031ebee">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org7ea00f4">Middle</a>
<ul>
<li><a href="#orgf8f79aa">Count Words</a></li>
<li><a href="#org70be809">Test the Code</a></li>
<li><a href="#orgcf2c47c">Out-Of-Vocabulary Words</a>
<ul>
<li><a href="#org66edf81">Test The Code</a></li>
</ul>
</li>
<li><a href="#org69fc0ac">Parts Unknown</a>
<ul>
<li><a href="#org7472703">Test It</a></li>
</ul>
</li>
<li><a href="#orgeade33c">Combine Them</a></li>
<li><a href="#orgd41a5d8">Preprocess the Real Data</a></li>
<li><a href="#orgde11fc8">Put It All Together</a>
<ul>
<li><a href="#org6f5c091">The Imports</a></li>
<li><a href="#org38df027">The Processor</a></li>
<li><a href="#org69b2ff9">Test It Out</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org543c8b6">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org99d2147">
<h2 id="org99d2147">Beginning</h2>
<div class="outline-text-2" id="text-org99d2147">
<p>This is the third post in a series that begins with <a href="../auto-complete/">Auto-Complete</a>. In the <a href="../auto-complete-pre-process-the-data-i/">previous entry</a> we did some basic preprocessing to transform the raw tweet data into a form closer to what we wanted. In this post we'll add some counts to the data so that we can use it to build our model.</p>
</div>
<div class="outline-3" id="outline-container-org8246821">
<h3 id="org8246821">Imports</h3>
<div class="outline-text-3" id="text-org8246821">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">contain_exactly</span><span class="p">,</span>
    <span class="n">contain_only</span><span class="p">,</span>
    <span class="n">equal</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">have_keys</span><span class="p">)</span>

<span class="c1"># this series</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.autocomplete</span> <span class="kn">import</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">TrainTestSplit</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org377723b">
<h3 id="org377723b">Set Up</h3>
<div class="outline-text-3" id="text-org377723b"></div>
<div class="outline-4" id="outline-container-orgfe348b0">
<h4 id="orgfe348b0">The Environment</h4>
<div class="outline-text-4" id="text-orgfe348b0">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org031ebee">
<h4 id="org031ebee">The Data</h4>
<div class="outline-text-4" id="text-org031ebee">
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_AUTOCOMPLETE"</span><span class="p">]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">splitter</span> <span class="o">=</span> <span class="n">TrainTestSplit</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenized</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">splitter</span><span class="o">.</span><span class="n">training</span><span class="p">,</span> <span class="n">splitter</span><span class="o">.</span><span class="n">testing</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7ea00f4">
<h2 id="org7ea00f4">Middle</h2>
<div class="outline-text-2" id="text-org7ea00f4"></div>
<div class="outline-3" id="outline-container-orgf8f79aa">
<h3 id="orgf8f79aa">Count Words</h3>
<div class="outline-text-3" id="text-orgf8f79aa">
<div class="highlight">
<pre><span></span><span class="c1"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span>
<span class="c1">### GRADED_FUNCTION: count_words ###</span>
<span class="k">def</span> <span class="nf">count_words</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Count the number of word appearence in the tokenized sentences</span>

<span class="sd">    Args:</span>
<span class="sd">       tokenized_sentences: List of lists of strings</span>

<span class="sd">    Returns:</span>
<span class="sd">       dict that maps word (str) to the frequency (int)</span>
<span class="sd">    """</span>

    <span class="n">word_counts</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

    <span class="c1"># Loop through each sentence</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">tokenized_sentences</span><span class="p">:</span> <span class="c1"># complete this line</span>

        <span class="c1"># Go through each token in the sentence</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span> <span class="c1"># complete this line</span>

            <span class="c1"># If the token is not in the dictionary yet, set the count to 1</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="p">:</span> <span class="c1"># complete this line</span>
                <span class="n">word_counts</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># If the token is already in the dictionary, increment the count by 1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">word_counts</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1">### END CODE HERE ###</span>

    <span class="k">return</span> <span class="n">word_counts</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org70be809">
<h3 id="org70be809">Test the Code</h3>
<div class="outline-text-3" id="text-org70be809">
<div class="highlight">
<pre><span></span><span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'sky'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
                       <span class="p">[</span><span class="s1">'leaves'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
                       <span class="p">[</span><span class="s1">'roses'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]]</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">count_words</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">)</span>

<span class="n">expected</span> <span class="o">=</span>  <span class="p">{</span><span class="s1">'sky'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'is'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'blue'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'.'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
             <span class="s1">'leaves'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'are'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
             <span class="s1">'green'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'roses'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'red'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

<span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">have_keys</span><span class="p">(</span><span class="o">**</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcf2c47c">
<h3 id="orgcf2c47c">Out-Of-Vocabulary Words</h3>
<div class="outline-text-3" id="text-orgcf2c47c">
<p>If your model is performing autocomplete, but encounters a word that it never saw during training, it won't have an input word to help it determine the next word to suggest. The model will not be able to predict the next word because there are no counts for the current word.</p>
<ul class="org-ul">
<li>This 'new' word is called an 'unknown word', or &lt;b&gt;out of vocabulary (OOV)&lt;/b&gt; words.</li>
<li>The percentage of unknown words in the test set is called the &lt;b&gt; OOV &lt;/b&gt; rate.</li>
</ul>
<p>To handle unknown words during prediction, use a special token to represent all unknown words 'unk'.</p>
<ul class="org-ul">
<li>Modify the training data so that it has some 'unknown' words to train on.</li>
<li>Words to convert into "unknown" words are those that do not occur very frequently in the training set.</li>
<li>Create a list of the most frequent words in the training set, called the &lt;b&gt; closed vocabulary &lt;/b&gt;.</li>
<li>Convert all the other words that are not part of the closed vocabulary to the token 'unk'.</li>
</ul>
<p>Create a function that takes in a text document and a threshold `count_threshold`.</p>
<ul class="org-ul">
<li>Any word whose count is greater than or equal to the threshold `count_threshold` is kept in the closed vocabulary.</li>
<li>Returns the word closed vocabulary list.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="c1"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span>
<span class="c1">### GRADED_FUNCTION: get_words_with_nplus_frequency ###</span>
<span class="k">def</span> <span class="nf">get_words_with_nplus_frequency</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">count_threshold</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Find the words that appear N times or more</span>

<span class="sd">    Args:</span>
<span class="sd">       tokenized_sentences: List of lists of sentences</span>
<span class="sd">       count_threshold: minimum number of occurrences for a word to be in the closed vocabulary.</span>

<span class="sd">    Returns:</span>
<span class="sd">       List of words that appear N times or more</span>
<span class="sd">    """</span>
    <span class="c1"># Initialize an empty list to contain the words that</span>
    <span class="c1"># appear at least 'minimum_freq' times.</span>
    <span class="n">closed_vocab</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Get the word couts of the tokenized sentences</span>
    <span class="c1"># Use the function that you defined earlier to count the words</span>
    <span class="n">word_counts</span> <span class="o">=</span> <span class="n">count_words</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">)</span>

    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

    <span class="c1"># for each word and its count</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">cnt</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> <span class="c1"># complete this line</span>

        <span class="c1"># check that the word's count</span>
        <span class="c1"># is at least as great as the minimum count</span>
        <span class="k">if</span> <span class="n">cnt</span> <span class="o">&gt;=</span> <span class="n">count_threshold</span><span class="p">:</span>

            <span class="c1"># append the word to the list</span>
            <span class="n">closed_vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###</span>

    <span class="k">return</span> <span class="n">closed_vocab</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org66edf81">
<h4 id="org66edf81">Test The Code</h4>
<div class="outline-text-4" id="text-org66edf81">
<div class="highlight">
<pre><span></span><span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'sky'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
                       <span class="p">[</span><span class="s1">'leaves'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
                       <span class="p">[</span><span class="s1">'roses'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]]</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">get_words_with_nplus_frequency</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">,</span> <span class="n">count_threshold</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Closed vocabulary:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'.'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">]</span>
<span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
<pre class="example">
Closed vocabulary:
['.', 'are']
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org69fc0ac">
<h3 id="org69fc0ac">Parts Unknown</h3>
<div class="outline-text-3" id="text-org69fc0ac">
<p>The words that appear `count_threshold` times or more are in the closed vocabulary.</p>
<ul class="org-ul">
<li>All other words are regarded as `unknown`.</li>
<li>Replace words not in the closed vocabulary with the token `&lt;unk&gt;`.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="c1"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span>
<span class="c1">### GRADED_FUNCTION: replace_oov_words_by_unk ###</span>
<span class="k">def</span> <span class="nf">replace_oov_words_by_unk</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
                             <span class="n">vocabulary</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
                             <span class="n">unknown_token</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"&lt;unk&gt;"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Replace words not in the given vocabulary with '&lt;unk&gt;' token.</span>

<span class="sd">    Args:</span>
<span class="sd">       tokenized_sentences: List of lists of strings</span>
<span class="sd">       vocabulary: List of strings that we will use</span>
<span class="sd">       unknown_token: A string representing unknown (out-of-vocabulary) words</span>

<span class="sd">    Returns:</span>
<span class="sd">       List of lists of strings, with words not in the vocabulary replaced</span>
<span class="sd">    """</span>

    <span class="c1"># Place vocabulary into a set for faster search</span>
    <span class="n">vocabulary</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>

    <span class="c1"># Initialize a list that will hold the sentences</span>
    <span class="c1"># after less frequent words are replaced by the unknown token</span>
    <span class="n">replaced_tokenized_sentences</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Go through each sentence</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">tokenized_sentences</span><span class="p">:</span>

        <span class="c1"># Initialize the list that will contain</span>
        <span class="c1"># a single sentence with "unknown_token" replacements</span>
        <span class="n">replaced_sentence</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

        <span class="c1"># for each token in the sentence</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span> <span class="c1"># complete this line</span>

            <span class="c1"># Check if the token is in the closed vocabulary</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">:</span> <span class="c1"># complete this line</span>
                <span class="c1"># If so, append the word to the replaced_sentence</span>
                <span class="n">replaced_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># otherwise, append the unknown token instead</span>
                <span class="n">replaced_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unknown_token</span><span class="p">)</span>
        <span class="c1">### END CODE HERE ###</span>

        <span class="c1"># Append the list of tokens to the list of lists</span>
        <span class="n">replaced_tokenized_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">replaced_sentence</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">replaced_tokenized_sentences</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org7472703">
<h4 id="org7472703">Test It</h4>
<div class="outline-text-4" id="text-org7472703">
<div class="highlight">
<pre><span></span><span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"dogs"</span><span class="p">,</span> <span class="s2">"run"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"cats"</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">]]</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"dogs"</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">]</span>
<span class="n">tmp_replaced_tokenized_sentences</span> <span class="o">=</span> <span class="n">replace_oov_words_by_unk</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original sentence:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">)</span>
<span class="n">expecteds</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'dogs'</span><span class="p">,</span> <span class="s1">'run'</span><span class="p">],</span> <span class="p">[</span><span class="s1">'cats'</span><span class="p">,</span> <span class="s1">'sleep'</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">,</span> <span class="n">expecteds</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"tokenized_sentences with less frequent words converted to '&lt;unk&gt;':"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tmp_replaced_tokenized_sentences</span><span class="p">)</span>
<span class="n">expecteds</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'dogs'</span><span class="p">,</span> <span class="s1">'&lt;unk&gt;'</span><span class="p">],</span> <span class="p">[</span><span class="s1">'&lt;unk&gt;'</span><span class="p">,</span> <span class="s1">'sleep'</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">actual</span><span class="p">,</span><span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tmp_replaced_tokenized_sentences</span><span class="p">,</span> <span class="n">expecteds</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
<pre class="example">
Original sentence:
[['dogs', 'run'], ['cats', 'sleep']]
tokenized_sentences with less frequent words converted to '&lt;unk&gt;':
[['dogs', '&lt;unk&gt;'], ['&lt;unk&gt;', 'sleep']]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgeade33c">
<h3 id="orgeade33c">Combine Them</h3>
<div class="outline-text-3" id="text-orgeade33c">
<div class="highlight">
<pre><span></span><span class="c1"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span>
<span class="c1">### GRADED_FUNCTION: preprocess_data ###</span>
<span class="k">def</span> <span class="nf">preprocess_data</span><span class="p">(</span><span class="n">train_data</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">count_threshold</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Preprocess data, i.e.,</span>
<span class="sd">       - Find tokens that appear at least N times in the training data.</span>
<span class="sd">       - Replace tokens that appear less than N times by "&lt;unk&gt;" both for training and test data.        </span>
<span class="sd">    Args:</span>
<span class="sd">       train_data, test_data: List of lists of strings.</span>
<span class="sd">       count_threshold: Words whose count is less than this are </span>
<span class="sd">                     treated as unknown.</span>

<span class="sd">    Returns:</span>
<span class="sd">       Tuple of</span>
<span class="sd">       - training data with low frequent words replaced by "&lt;unk&gt;"</span>
<span class="sd">       - test data with low frequent words replaced by "&lt;unk&gt;"</span>
<span class="sd">       - vocabulary of words that appear n times or more in the training data</span>
<span class="sd">    """</span>
    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

    <span class="c1"># Get the closed vocabulary using the train data</span>
    <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">get_words_with_nplus_frequency</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">count_threshold</span><span class="p">)</span>

    <span class="c1"># For the train data, replace less common words with "&lt;unk&gt;"</span>
    <span class="n">train_data_replaced</span> <span class="o">=</span> <span class="n">replace_oov_words_by_unk</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">)</span>

    <span class="c1"># For the test data, replace less common words with "&lt;unk&gt;"</span>
    <span class="n">test_data_replaced</span> <span class="o">=</span>  <span class="n">replace_oov_words_by_unk</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">vocabulary</span><span class="p">)</span>

    <span class="c1">### END CODE HERE ###</span>
    <span class="k">return</span> <span class="n">train_data_replaced</span><span class="p">,</span> <span class="n">test_data_replaced</span><span class="p">,</span> <span class="n">vocabulary</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">tmp_train</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'sky'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
     <span class="p">[</span><span class="s1">'leaves'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">]]</span>
<span class="n">tmp_test</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'roses'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]]</span>

<span class="n">tmp_train_repl</span><span class="p">,</span> <span class="n">tmp_test_repl</span><span class="p">,</span> <span class="n">tmp_vocab</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">tmp_train</span><span class="p">,</span> 
                                                           <span class="n">tmp_test</span><span class="p">,</span> 
                                                           <span class="n">count_threshold</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"tmp_train_repl"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tmp_train_repl</span><span class="p">)</span>
<span class="n">expecteds</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'sky'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span> <span class="p">[</span><span class="s1">'leaves'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tmp_train_repl</span><span class="p">,</span> <span class="n">expecteds</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tmp_test_repl"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tmp_test_repl</span><span class="p">)</span>

<span class="n">expecteds</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'&lt;unk&gt;'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'&lt;unk&gt;'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]]</span>

<span class="k">for</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tmp_test_repl</span><span class="p">,</span> <span class="n">expecteds</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"tmp_vocab"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tmp_vocab</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sky'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">,</span> <span class="s1">'leaves'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">]</span>
<span class="n">expect</span><span class="p">(</span><span class="n">tmp_vocab</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
<pre class="example">
tmp_train_repl
[['sky', 'is', 'blue', '.'], ['leaves', 'are', 'green']]

tmp_test_repl
[['&lt;unk&gt;', 'are', '&lt;unk&gt;', '.']]

tmp_vocab
['sky', 'is', 'blue', '.', 'leaves', 'are', 'green']
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgd41a5d8">
<h3 id="orgd41a5d8">Preprocess the Real Data</h3>
<div class="outline-text-3" id="text-orgd41a5d8">
<div class="highlight">
<pre><span></span><span class="n">minimum_freq</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">train_data_processed</span><span class="p">,</span> <span class="n">test_data_processed</span><span class="p">,</span> <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> 
                                                                        <span class="n">test_data</span><span class="p">,</span> 
                                                                        <span class="n">minimum_freq</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"last preprocessed testing sample:"</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">test_data_processed</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'personally'</span><span class="p">,</span> <span class="s1">'would'</span><span class="p">,</span> <span class="s1">'like'</span><span class="p">,</span> <span class="s1">'as'</span><span class="p">,</span> <span class="s1">'our'</span><span class="p">,</span> <span class="s1">'official'</span><span class="p">,</span> <span class="s1">'glove'</span><span class="p">,</span> <span class="s1">'of'</span><span class="p">,</span> <span class="s1">'the'</span><span class="p">,</span> <span class="s1">'team'</span><span class="p">,</span> <span class="s1">'local'</span><span class="p">,</span> <span class="s1">'company'</span><span class="p">,</span> <span class="s1">'and'</span><span class="p">,</span> <span class="s1">'quality'</span><span class="p">,</span> <span class="s1">'production'</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"preprocessed training sample:"</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">train_data_processed</span><span class="p">[</span><span class="mi">9592</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'that'</span><span class="p">,</span> <span class="s1">'picture'</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="s1">'just'</span><span class="p">,</span> <span class="s1">'seen'</span><span class="p">,</span> <span class="s1">'whoa'</span><span class="p">,</span> <span class="s1">'dere'</span><span class="p">,</span> <span class="s1">'!'</span><span class="p">,</span> <span class="s1">'!'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">,</span> <span class="s1">'&gt;'</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"First 10 vocabulary:"</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'i'</span><span class="p">,</span> <span class="s1">'personally'</span><span class="p">,</span> <span class="s1">'would'</span><span class="p">,</span> <span class="s1">'like'</span><span class="p">,</span> <span class="s1">'as'</span><span class="p">,</span> <span class="s1">'our'</span><span class="p">,</span> <span class="s1">'official'</span><span class="p">,</span> <span class="s1">'glove'</span><span class="p">,</span> <span class="s1">'of'</span><span class="p">,</span> <span class="s1">'the'</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
<span class="c1">#expect(actual).to(contain_exactly(*expected))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">actual</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Size of vocabulary: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="mi">14821</span>
<span class="c1">#expect(actual).to(equal(expected))</span>
</pre></div>
<pre class="example">
last preprocessed testing sample:
['i', 'personally', 'would', 'like', 'as', 'our', 'official', 'glove', 'of', 'the', 'team', 'local', 'company', 'and', 'quality', 'production']

preprocessed training sample:
['that', 'picture', 'i', 'just', 'seen', 'whoa', 'dere', '!', '!', '&gt;', '&gt;', '&gt;', '&gt;', '&gt;', '&gt;', '&gt;']

First 10 vocabulary:
['d', '&amp;', 's', 'is', 'covering', 'the', 'event', 'with', 'thomas', ',']

Size of vocabulary: 14,679
</pre>
<p><b>Note:</b> My shuffling is different from theirs, even though I'm setting the seed, so it seems to come out differently.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgde11fc8">
<h3 id="orgde11fc8">Put It All Together</h3>
<div class="outline-text-3" id="text-orgde11fc8"></div>
<div class="outline-4" id="outline-container-org6f5c091">
<h4 id="org6f5c091">The Imports</h4>
<div class="outline-text-4" id="text-org6f5c091">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>

<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org38df027">
<h4 id="org38df027">The Processor</h4>
<div class="outline-text-4" id="text-org38df027">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CountProcessor</span><span class="p">:</span>
    <span class="sd">"""Processes the data to have unknowns</span>

<span class="sd">    Args:</span>
<span class="sd">     training: the tokenized training data (list of lists)</span>
<span class="sd">     testing: the tokenized testing data</span>
<span class="sd">     count_threshold: minimum number of times token needs to appear</span>
<span class="sd">     unknown_token: string to use for words below threshold</span>
<span class="sd">    """</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">testing</span><span class="p">:</span> <span class="nb">list</span>
    <span class="n">count_threshold</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span>
    <span class="n">unknown_token</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"&lt;unk&gt;"</span>
    <span class="n">_counts</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vocabulary</span><span class="p">:</span> <span class="nb">set</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_train_unknown</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_test_unknown</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orga340241"></a>Counts<br>
<div class="outline-text-5" id="text-orga340241">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">counts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Counter</span><span class="p">:</span>
    <span class="sd">"""Count of each word in the training data"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span>
</pre></div>
</div>
</li>
<li><a id="org956c994"></a>The Vocabulary<br>
<div class="outline-text-5" id="text-org956c994">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">:</span>
    <span class="sd">"""The tokens in training that appear at least ``count_threshold`` times"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="o">=</span> <span class="nb">set</span><span class="p">((</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_threshold</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span>
</pre></div>
</div>
</li>
<li><a id="orgdeb34fd"></a>Train Unknown<br>
<div class="outline-text-5" id="text-orgdeb34fd">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">train_unknown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Training data with words below threshold replaced"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_unknown</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_unknown</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parts_unknown</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_unknown</span>
</pre></div>
</div>
</li>
<li><a id="org115cdf1"></a>Test Unknown<br>
<div class="outline-text-5" id="text-org115cdf1">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">test_unknown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Testing data with words below threshold replaced"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_unknown</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_unknown</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parts_unknown</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">testing</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_unknown</span>
</pre></div>
</div>
</li>
<li><a id="org524db89"></a>Parts Unknown<br>
<div class="outline-text-5" id="text-org524db89">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">parts_unknown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""Replaces tokens in source that aren't in vocabulary</span>

<span class="sd">    Args:</span>
<span class="sd">     source: nested list of lists with tokens to check</span>

<span class="sd">    Returns: source with unknown words replaced by unknown_token</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">token</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">unknown_token</span>
             <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">source</span>
    <span class="p">]</span>    
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org69b2ff9">
<h4 id="org69b2ff9">Test It Out</h4>
<div class="outline-text-4" id="text-org69b2ff9">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.autocomplete</span> <span class="kn">import</span> <span class="n">CountProcessor</span>

<span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'sky'</span><span class="p">,</span> <span class="s1">'is'</span><span class="p">,</span> <span class="s1">'blue'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
                       <span class="p">[</span><span class="s1">'leaves'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'green'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">],</span>
                       <span class="p">[</span><span class="s1">'roses'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]]</span>

<span class="n">testing</span> <span class="o">=</span> <span class="p">[[]]</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">CountProcessor</span><span class="p">(</span><span class="n">tokenized_sentences</span><span class="p">,</span> <span class="n">testing</span><span class="p">)</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">counts</span>

<span class="n">expected</span> <span class="o">=</span>  <span class="p">{</span><span class="s1">'sky'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'is'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'blue'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'.'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
             <span class="s1">'leaves'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'are'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
             <span class="s1">'green'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'roses'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">'red'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>

<span class="c1"># note to future self: if you pass key=value to have_keys it checks both</span>
<span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">have_keys</span><span class="p">(</span><span class="o">**</span><span class="n">expected</span><span class="p">))</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'.'</span><span class="p">,</span> <span class="s1">'are'</span><span class="p">]</span>
<span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_only</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"dogs"</span><span class="p">,</span> <span class="s2">"run"</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"cats"</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">,</span> <span class="s2">"dogs"</span><span class="p">]]</span>

<span class="n">testing</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"cows"</span><span class="p">,</span> <span class="s2">"dogs"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"pigs"</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">]]</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">CountProcessor</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="n">tokenized_sentences</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">)</span>

<span class="n">actuals</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">train_unknown</span>

<span class="n">UNKNOWN</span> <span class="o">=</span> <span class="s2">"&lt;unk&gt;"</span>
<span class="n">expecteds</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"dogs"</span><span class="p">,</span> <span class="n">UNKNOWN</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">],</span> <span class="p">[</span><span class="n">UNKNOWN</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">,</span> <span class="s2">"dogs"</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">actual</span><span class="p">,</span><span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span> <span class="n">expecteds</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>

<span class="n">actuals</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">test_unknown</span>
<span class="n">expecteds</span> <span class="o">=</span> <span class="p">[[</span><span class="n">UNKNOWN</span><span class="p">,</span> <span class="s2">"dogs"</span><span class="p">],</span> <span class="p">[</span><span class="n">UNKNOWN</span><span class="p">,</span> <span class="s2">"sleep"</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">actual</span><span class="p">,</span><span class="n">expected</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">actuals</span><span class="p">,</span> <span class="n">expecteds</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">expected</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org543c8b6">
<h2 id="org543c8b6">End</h2>
<div class="outline-text-2" id="text-org543c8b6">
<p>Now that we have the data in the basic form we want we'll move on to building the <a href="../auto-complete-the-n-gram-model/">N-Gram Language Model</a>.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/auto-complete/" rel="tag">auto-complete</a></li>
<li><a class="tag p-category" href="../../../categories/n-gram/" rel="tag">n-gram</a></li>
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../auto-complete-pre-process-the-data-i/" rel="prev" title="Auto-Complete: Pre-Process the Data I">Previous post</a></li>
<li class="next"><a href="../auto-complete-the-n-gram-model/" rel="next" title="Auto-Complete: the N-Gram Model">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
