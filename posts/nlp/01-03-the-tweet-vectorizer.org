#+BEGIN_COMMENT
.. title: The Tweet Vectorizer
.. slug: the-tweet-vectorizer
.. date: 2020-07-24 16:51:53 UTC-07:00
.. tags: twitter,nlp
.. category: NLP
.. link: 
.. description: Transforming Tweets into count vectors.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 2
#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-9a4aeb7b-e200-4c23-b9f5-244f9fc113c9.json

#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC
* Beginning
  We are going to be classifying [[https://help.twitter.com/en/using-twitter/how-to-tweet][tweets]] by positive or negative sentiment, but tweets are free-form text (and images, but we're ignoring those) and we want tabular numbers so in order to be able to work with the tweets we'll have to convert them somehow. That's what we'll be doing here.
** Set Up
   This is some preliminary stuff so we have python ready to go.
*** Imports
#+begin_src python :results none
# python
from argparse import Namespace
from functools import partial

# pypi
from nltk.corpus import twitter_samples
import holoviews
import hvplot.pandas
import pandas

# some helper stuff
from graeae import EmbedHoloviews
#+end_src
*** The Data
*** For Plotting
    These are some helpers for the plotting that I'll do later on.

#+begin_src python :results none
SLUG = "the-tweet-vectorizer"
Embed = partial(EmbedHoloviews,
                folder_path=f"files/posts/nlp/{SLUG}")

Plot = Namespace(
    width=990,
    height=780,
    tan="#ddb377",
    blue="#4687b7",
    red="#ce7b6d",
    font_scale=2,
    color_cycle = holoviews.Cycle(["#4687b7", "#ce7b6d"])
)
#+end_src
* Middle
** The Tweet Vectors
   In an earlier post we built a dictionary-like set to count the number of times each token was in a positive tweet and in a negative tweet. To represent a tweet as a vector for training and using the model we're going to sum the total counts for the tokens in the tweet when they are positive and when they are positive. 

Come again?

Lets say you have a tweet ="a b c"= which tokenizes to =a, b, c=. Looking up the positive and negative tweet counts for each token we get these counts and totals in the bottom row for the tweet.

| Token | Positive | Negative |
|-------+----------+----------|
| a     |        1 |        4 |
| b     |        2 |        5 |
| c     |        3 |        6 |
|-------+----------+----------|
| Total |        6 | 15       |

So to represent this tweet you would create a vector of the form:

\begin{align}
\hat{v} &= \langle bias, positive, negative \rangle\\
&= \langle 1, 6, 15\rangle\\
\end{align}

**Note:** The bias is always one (it just is).


** The Tweet Vectorizer
   This is going to be a class to convert the tokenized tweets for us into vectors.
*** The Testing
    We'll start with some vaguely BDD-ish testing. First tghe tangles.

#+begin_src feature :tangle ../../tests/features/twitter/tweet_vectorizer.feature
Feature: A Tweet Count Vectorizer

<<extract-features-feature>>

<<get-vectors-feature>>

<<reset-vectors-feature>>

<<check-rep-vectorizer-tweets-feature>>

<<check-rep-vectorizer-counter-feature>>
#+end_src

#+begin_src python :tangle ../../tests/functional/twitter/test_vectorizer.py
# from python
from collections import Counter

import random

# from pypi
from expects import (
    be,
    be_true,
    contain_exactly,
    expect,
    raise_error,
)
from pytest_bdd import (
    given,
    scenarios,
    when,
    then
)

import numpy

# this testing
from fixtures import katamari

# software under test
from neurotic.nlp.twitter.vectorizer import Columns, TweetVectorizer
from neurotic.nlp.twitter.counter import WordCounter

and_also = then
scenarios("../../features/twitter/tweet_vectorizer.feature")

<<test-extract-features>>

<<test-vectors>>

<<test-reset-vectors>>

<<test-vectorizer-tweets-check-rep>>

<<test-vectorizer-counter-check-rep>>
#+end_src

And now we can move on to the tests.
**** Extract Features
     For training and testing I'm going to want to convert them in bulk, but first I'll create a method so that a single tweet can be vectorized.

#+begin_src feature :noweb-ref extract-features-feature
Scenario: A user converts a tweet to a feature-vector

Given a Tweet Vectorizer
When the user converts a tweet to a feature-vector
Then it's the expected feature-vector
#+end_src

#+begin_src python :noweb-ref test-extract-features
# Scenario: A user converts a tweet to a feature-vector


@given("a Tweet Vectorizer")
def setup_tweet_vectorizer(katamari, mocker):
    katamari.bias = random.randrange(100) * random.random()
    TWEETS = 1

    TOKENS = "A B C".split()
    katamari.tweets = [TOKENS for tweet in range(TWEETS)]
    katamari.counter = mocker.MagicMock(spec=WordCounter)
    katamari.counter.processed = katamari.tweets
    katamari.vectorizer = TweetVectorizer(tweets=katamari.tweets,
                                          counter=katamari.counter,
                                          bias=katamari.bias)

    katamari.vectorizer.counter.counts = Counter({('A', 0):1,
                                                  ('B', 1):2,
                                                  ('C', 0):3})
    katamari.vectorizer._process = mocker.MagicMock()
    katamari.vectorizer._process.return_value = "A B C".split()
    return


@when("the user converts a tweet to a feature-vector")
def extract_features(katamari):
    katamari.actual = katamari.vectorizer.extract_features("A B C")
    katamari.actual_array = katamari.vectorizer.extract_features("A B C", as_array=True)
    katamari.expected = [katamari.bias, 2, 4]
    katamari.expected_array = numpy.array(katamari.expected)
    return


@then("it's the expected feature-vector")
def check_feature_vectors(katamari):
    expect(numpy.allclose(katamari.actual_array, katamari.expected_array)).to(be_true)
    expect(katamari.actual).to(contain_exactly(*katamari.expected))

    expect(katamari.actual_array.shape).to(contain_exactly(1, 3))
    return
#+end_src
**** Get the Vectors

#+begin_src feature :noweb-ref get-vectors-feature
Scenario: A user retrieves the count vectors
Given a user sets up the Count Vectorizer with tweets
When the user checks the count vectors
Then the first column is the bias colum
And the positive counts are correct
And the negative counts are correct
#+end_src

#+begin_src python :noweb-ref test-vectors
# Feature: A Tweet Count Vectorizer

# Scenario: A user retrieves the count vectors

@given("a user sets up the Count Vectorizer with tweets")
def setup_vectorizer(katamari, faker, mocker):
    katamari.bias = random.randrange(100) * random.random()
    TWEETS = 3

    TOKENS = "A B C"
    katamari.tweets = [TOKENS for tweet in range(TWEETS)]
    katamari.counter = mocker.MagicMock(spec=WordCounter)

    katamari.vectorizer = TweetVectorizer(tweets=katamari.tweets,
                                          counter=katamari.counter,
                                          bias=katamari.bias)

    katamari.vectorizer._process = mocker.MagicMock()
    katamari.vectorizer._process.return_value = TOKENS.split()
    katamari.vectorizer.counter.counts = Counter({('A', 0):1,
                                                  ('B', 1):2,
                                                  ('C', 0):3})
    katamari.negative = numpy.array([sum([katamari.counter.counts[(token, 0)]
                                      for token in TOKENS])
                                      for row in range(TWEETS)])
    katamari.positive = numpy.array([sum([katamari.counter.counts[(token, 1)]
                                      for token in TOKENS])
                                     for row in range(TWEETS)])
    return


@when("the user checks the count vectors")
def check_count_vectors(katamari):
    # kind of silly, but useful for troubleshooting
    katamari.actual_vectors = katamari.vectorizer.vectors
    return


@then("the first column is the bias colum")
def check_bias(katamari):
    expect(all(katamari.actual_vectors[:, Columns.bias]==katamari.bias)).to(be_true)
    return


@and_also("the positive counts are correct")
def check_positive_counts(katamari):
    positive = katamari.actual_vectors[:, Columns.positive]
    expect(numpy.allclose(positive, katamari.positive)).to(be_true)
    return


@and_also("the negative counts are correct")
def check_negative_counts(katamari):
    negative = katamari.actual_vectors[:, Columns.negative]
    expect(numpy.allclose(negative, katamari.negative)).to(be_true)
    return
#+end_src

**** Reset the Vectors
#+begin_src feature :noweb-ref reset-vectors-feature
Scenario: The vectors are reset
Given a Tweet Vectorizer with the vectors set
When the user calls the reset method
Then the vectors are gone
#+end_src

#+begin_src python :noweb-ref test-reset-vectors
# Scenario: The vectors are reset


@given("a Tweet Vectorizer with the vectors set")
def setup_vectors(katamari, faker, mocker):
    katamari.vectors = mocker.MagicMock()
    katamari.vectorizer = TweetVectorizer(tweets = [faker.sentence()], counter=None)
    katamari.vectorizer._vectors = katamari.vectors
    return


@when("the user calls the reset method")
def call_reset(katamari):
    expect(katamari.vectorizer.vectors).to(be(katamari.vectors))
    katamari.vectorizer.reset()
    return


@then("the vectors are gone")
def check_vectors_gone(katamari):
    expect(katamari.vectorizer._vectors).to(be(None))
    return
#+end_src
**** Check Rep
#+begin_src feature :noweb-ref check-rep-vectorizer-tweets-feature
Scenario: the check-rep is called with bad tweets
Given a Tweet Vectorizer with bad tweets
When check-rep is called
Then it raises an AssertionError
#+end_src

#+begin_src python :noweb-ref test-vectorizer-tweets-check-rep
# Scenario: the check-rep is called with bad tweets


@given("a Tweet Vectorizer with bad tweets")
def setup_bad_tweets(katamari):
    katamari.vectorizer = TweetVectorizer(tweets=[5],
                                          counter=WordCounter(
                                              tweets=None, labels=None))
    return


@when("check-rep is called")
def call_check_rep(katamari):
    def bad_call():
        katamari.vectorizer.check_rep()
    katamari.bad_call = bad_call
    return


@then("it raises an AssertionError")
def check_assertion_error(katamari):
    expect(katamari.bad_call).to(raise_error(AssertionError))
    return
#+end_src

#+begin_src feature :noweb-ref check-rep-vectorizer-counter-feature
Scenario: the check-rep is called with a bad word-counter
Given a Tweet Vectorizer with the wrong counter object
When check-rep is called
Then it raises an AssertionError
#+end_src

#+begin_src python :noweb-ref test-vectorizer-counter-check-rep
# Scenario: the check-rep is called with a bad word-counter


@given("a Tweet Vectorizer with the wrong counter object")
def setup_bad_counter(katamari, mocker):
    katamari.vectorizer = TweetVectorizer(tweets=["apple"], counter=mocker.MagicMock())
    return

# When check-rep is called
# Then it raises an AssertionError
#+end_src
*** The Implementation
    Okay, so here's where we make the class implementation that'll do the vectorizing for us.

#+begin_src python :tangle ../../neurotic/nlp/twitter/vectorizer.py
# python
from argparse import Namespace
from typing import List, Union

# pypi
import numpy
import attr


# this package
from neurotic.nlp.twitter.processor import TwitterProcessor
from neurotic.nlp.twitter.counter import WordCounter

Columns = Namespace(
    bias=0,
    positive=1,
    negative=2
)

TweetClass = Namespace(
    positive=1,
    negative=0
)

# some types
Tweets = List[List[str]]
Vector = Union[numpy.ndarray, list]


@attr.s(auto_attribs=True)
class TweetVectorizer:
    """A tweet vectorizer

    Args:
     tweets: the pre-processed/tokenized tweets to vectorize
     counter: the word counter with the tweet token counts
     bias: constant to use for the bias
    """
    tweets: Tweets
    counter: WordCounter
    bias: float=1
    _process: TwitterProcessor=None
    _vectors: numpy.ndarray=None

    @property
    def process(self) -> TwitterProcessor:
        """Processes tweet strings to tokens"""
        if self._process is None:
            self._process = TwitterProcessor()
        return self._process

    @property
    def vectors(self) -> numpy.ndarray:
        """The vectorized tweet counts"""
        if self._vectors is None:
            rows = [self.extract_features(tweet) for tweet in self.tweets]
            self._vectors = numpy.array(rows)
        return self._vectors

    def extract_features(self, tweet: str, as_array: bool=False) -> Vector:
        """converts a single tweet to an array of counts

        Args:
         tweet: a string tweet to count up
         as_array: whether to match the assignment format or not

        Returns:
         either a list of floats or a 1 x 3 array
        """
        tokens = self.process(tweet)
        vector = [
            self.bias,
            sum((self.counter.counts[(token, TweetClass.positive)]
                 for token in tokens)),
            sum((self.counter.counts[(token, TweetClass.negative)]
                                for token in tokens))
        ]
        vector = numpy.array([vector]) if as_array else vector
        return vector

    def reset(self) -> None:
        """Removes the vectors"""
        self._vectors = None
        return

    def check_rep(self) -> None:
        """Checks that the tweets and word-counter are set

        Raises:
         AssertionError if one of them isn't right
        """
        for tweet in self.tweets:
            assert type(tweet) is str
        assert type(self.counter) is WordCounter
        return
#+end_src
** Plotting The Vectors
   Now that we have a vectorizer, let's see what it looks like when we plot the training set.

#+begin_src python :results output :exports both
sentiment = {
    0: "Negative",
    1:"Positive"
}
data.loc[:, "sentiment"] = data.sentiment.map(sentiment)

print(data.sentiment.value_counts())

#+end_src

#+RESULTS:
: Positive    4000
: Negative    4000
: Name: sentiment, dtype: int64

If you followed the previous post you can probably figure out that this is the training set.

*** The Weights
    Since I saved the weights for our Logistic Regression model we can load it now

#+begin_src python :results output :exports both
weights_path = Path(os.environ["TWITTER_REGRESSION_WEIGHTS"]).expanduser()
assert weights_path.is_file()
theta = pandas.read_csv(weights_path)
print(theta)

# 'weights' is just something to make it easier to remember which column is which
Weights = Namespace(
    bias=0,
    positive=1,
    negative=2
)
#+end_src

#+RESULTS:
:            bias  positive  negative
: 0  6.369479e-08  0.000537 -0.000558



* End
