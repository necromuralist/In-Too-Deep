<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Finding the probability matrices for the Viterbi Algorithm." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Parts-of-Speech: Viterbi Algorithm | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/parts-of-speech-viterbi-algorithm/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../parts-of-speech-tagging-hidden-markov-model/" rel="prev" title="Parts-of-Speech Tagging: Hidden Markov Model" type="text/html">
<link href="../pos-tagging-accuracy-of-model/" rel="next" title="POS Tagging: Accuracy of Model" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Parts-of-Speech: Viterbi Algorithm" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/parts-of-speech-viterbi-algorithm/" property="og:url">
<meta content="Finding the probability matrices for the Viterbi Algorithm." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-11-21T18:21:58-08:00" property="article:published_time">
<meta content="nlp" property="article:tag">
<meta content="pos tagging" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Parts-of-Speech: Viterbi Algorithm</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2020-11-21T18:21:58-08:00" itemprop="datePublished" title="2020-11-21 18:21">2020-11-21 18:21</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org7ba4893">Beginning</a>
<ul>
<li><a href="#orga0cc9c0">Imports</a></li>
<li><a href="#org628b5ba">Set Up</a>
<ul>
<li><a href="#org74769b3">The Timer</a></li>
<li><a href="#org8b3c4a3">The Matrices</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org917b6f8">Middle</a>
<ul>
<li><a href="#orgd9fd747">Initialization</a></li>
<li><a href="#org1ec4357">Viterby Forward</a></li>
<li><a href="#org7b30acf">Viterbi Backward</a></li>
</ul>
</li>
<li><a href="#org4eef1f1">End</a>
<ul>
<li><a href="#orga5ec293">Imports</a></li>
<li><a href="#orge715a3d">An Exception</a></li>
<li><a href="#org4afc603">The Model Class</a>
<ul>
<li><a href="#org5890049">The States List</a></li>
<li><a href="#orge6d1ef8">The Tag Counts</a></li>
<li><a href="#org2b70cc3">Tag Count</a></li>
<li><a href="#org403f065">Transition Matrix (A)</a></li>
<li><a href="#org10c627e">Emission Matrix (B)</a></li>
<li><a href="#orgcf942ed">Test Words</a></li>
<li><a href="#org2ea023d">Test Word Count</a></li>
<li><a href="#orgb789061">Vocabulary</a></li>
<li><a href="#orgfc24a19">Start Token Index</a></li>
<li><a href="#org439c123">Negative Infinity</a></li>
<li><a href="#orgfb18472">Initialize the Matrices</a></li>
<li><a href="#orgb33a566">Virterbi Forward</a></li>
<li><a href="#org5b864e7">Viterbi Backward</a></li>
<li><a href="#orga3ad0da">Call It</a></li>
</ul>
</li>
<li><a href="#org90f79db">Test it out</a>
<ul>
<li><a href="#org9d3d154">Run The Methods In the correct order with a call</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org7ba4893">
<h2 id="org7ba4893">Beginning</h2>
<div class="outline-text-2" id="text-org7ba4893"></div>
<div class="outline-3" id="outline-container-orga0cc9c0">
<h3 id="orga0cc9c0">Imports</h3>
<div class="outline-text-3" id="text-orga0cc9c0">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">call</span><span class="p">,</span> <span class="n">MagicMock</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span><span class="n">equal</span><span class="p">,</span> <span class="n">expect</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="n">np</span> <span class="o">=</span> <span class="n">numpy</span>

<span class="c1"># this stuff</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.parts_of_speech</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Matrices</span><span class="p">,</span> <span class="n">TheTrainer</span>

<span class="c1"># my other stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org628b5ba">
<h3 id="org628b5ba">Set Up</h3>
<div class="outline-text-3" id="text-org628b5ba"></div>
<div class="outline-4" id="outline-container-org74769b3">
<h4 id="org74769b3">The Timer</h4>
<div class="outline-text-4" id="text-org74769b3">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8b3c4a3">
<h4 id="org8b3c4a3">The Matrices</h4>
<div class="outline-text-4" id="text-org8b3c4a3">
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">TheTrainer</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">processed_training</span><span class="p">)</span>
<span class="n">matrices</span> <span class="o">=</span> <span class="n">Matrices</span><span class="p">(</span><span class="n">transition_counts</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">transition_counts</span><span class="p">,</span>
                    <span class="n">emission_counts</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">emission_counts</span><span class="p">,</span>
                    <span class="n">words</span><span class="o">=</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary_words</span><span class="p">,</span>
                    <span class="n">tag_counts</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">tag_counts</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</pre></div>
<p>These classes were defined in other posts:</p>
<ul class="org-ul">
<li><a href="../parts-of-speech-tagging-the-data/">DataLoader</a></li>
<li><a href="../parts-of-speech-tagging-training/">TheTrainer</a></li>
<li><a href="../parts-of-speech-tagging-hidden-markov-model/">Matrices</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org917b6f8">
<h2 id="org917b6f8">Middle</h2>
<div class="outline-text-2" id="text-org917b6f8"></div>
<div class="outline-3" id="outline-container-orgd9fd747">
<h3 id="orgd9fd747">Initialization</h3>
<div class="outline-text-3" id="text-orgd9fd747">
<p>Write a program below that initializes the <code>best_probs</code> and the <code>best_paths</code> matrix.</p>
<p>Both matrices will be initialized to zero except for column zero of <code>best_probs</code>.</p>
<ul class="org-ul">
<li>Column zero of <code>best_probs</code> is initialized with the assumption that the first word of the corpus was preceded by a start token ("–s–").</li>
<li>This allows you to reference the <b>A</b> matrix for the transition probability</li>
</ul>
<p>Here is how to initialize column 0 of <code>best_probs</code>:</p>
<ul class="org-ul">
<li>The probability of the best path going from the start index to a given POS tag indexed by integer <i>i</i> is denoted by \(\textrm{best_probs}[s_{idx}, i]\).</li>
<li>This is estimated as the probability that the start tag transitions to the POS denoted by index <i>i</i>: \(\mathbf{A}[s_{idx}, i]\) AND that the POS tag denoted by <i>i</i> emits the first word of the given corpus, which is \(\mathbf{B}[i, vocab[corpus[0]]]\).</li>
<li>Note that vocab[corpus[0]] refers to the first word of the corpus (the word at position 0 of the corpus).</li>
<li><b>vocab</b> is a dictionary that returns the unique integer that refers to that particular word.</li>
</ul>
<p>Conceptually, it looks like this:</p>
<p>\[ \textrm{best_probs}[s_{idx}, i] = \mathbf{A}[s_{idx}, i] \times \mathbf{B}[i, corpus[0] ] \]</p>
<p>In order to avoid multiplying and storing small values on the computer, we'll take the log of the product, which becomes the sum of two logs:</p>
<p>\[ best\_probs[i,0] = log(A[s_{idx}, i]) + log(B[i, vocab[corpus[0]] \]</p>
<p>Also, to avoid taking the log of 0 (which is defined as negative infinity), the code itself will just set \(best\_probs[i,0] = float('-inf')\) when \(A[s_{idx}, i] == 0\).</p>
<p>So the implementation to initialize <code>best_probs</code> looks like this:</p>
<p>\[ if A[s_{idx}, i] &lt;&gt; 0 : best\_probs[i,0] = log(A[s_{idx}, i]) + log(B[i, vocab[corpus[0]]]) \]</p>
<p>\[ if A[s_{idx}, i] == 0 : best\_probs[i,0] = float('-inf') \]</p>
<p>Please use <a href="https://docs.python.org/3/library/math.html">math.log</a> to compute the natural logarithm.</p>
<p>Represent infinity and negative infinity like this:</p>
<pre class="example">
float('inf')
float('-inf')
</pre>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">tag_counts</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
    <span class="sd">"""Initializes the ``best_probs`` and ``best_paths`` matrices</span>

<span class="sd">    Args: </span>
<span class="sd">       states: a list of all possible parts-of-speech</span>
<span class="sd">       tag_counts: a dictionary mapping each tag to its respective count</span>
<span class="sd">       A: Transition Matrix of dimension (num_tags, num_tags)</span>
<span class="sd">       B: Emission Matrix of dimension (num_tags, len(vocab))</span>
<span class="sd">       corpus: a sequence of words whose POS is to be identified in a list </span>
<span class="sd">       vocab: a dictionary where keys are words in vocabulary and value is an index</span>

<span class="sd">    Returns:</span>
<span class="sd">       best_probs: matrix of dimension (num_tags, len(corpus)) of floats</span>
<span class="sd">       best_paths: matrix of dimension (num_tags, len(corpus)) of integers</span>
<span class="sd">    """</span>
    <span class="c1"># Get the total number of unique POS tags</span>
    <span class="n">num_tags</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_counts</span><span class="p">)</span>

    <span class="c1"># Initialize best_probs matrix </span>
    <span class="c1"># POS tags in the rows, number of words in the corpus as the columns</span>
    <span class="n">best_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_tags</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)))</span>

    <span class="c1"># Initialize best_paths matrix</span>
    <span class="c1"># POS tags in the rows, number of words in the corpus as columns</span>
    <span class="n">best_paths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_tags</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Define the start token</span>
    <span class="n">s_idx</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">"--s--"</span><span class="p">)</span>
    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>

    <span class="c1"># Go through each of the POS tags</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)):</span> <span class="c1"># complete this line</span>
        <span class="c1"># Handle the special case when the transition from start token to POS tag i is zero</span>
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># complete this line</span>

            <span class="c1"># Initialize best_probs at POS tag 'i', column 0, to negative infinity</span>
            <span class="n">best_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"-inf"</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: negitive infinity"</span><span class="p">)</span>

        <span class="c1"># For all other cases when transition from start token to POS tag i is non-zero:</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Initialize best_probs at POS tag 'i', column 0</span>
            <span class="c1"># Check the formula in the instructions above</span>
            <span class="n">best_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="n">corpus</span><span class="p">[</span><span class="mi">0</span><span class="p">]]])</span>
    <span class="c1">### END CODE HERE ### </span>
    <span class="k">return</span> <span class="n">best_probs</span><span class="p">,</span> <span class="n">best_paths</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">states</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">tags</span>
<span class="n">tag_counts</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">tag_counts</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">transition</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">emission</span>
<span class="n">prep</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">test_words</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span>
<span class="n">best_probs</span><span class="p">,</span> <span class="n">best_paths</span> <span class="o">=</span> <span class="n">initialize</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">tag_counts</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">prep</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
</pre></div>
<p>Test the function</p>
<div class="highlight">
<pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="n">best_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="o">-</span><span class="mf">22.6098</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"best_probs[0,0]: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">),</span> <span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">best_paths</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="mf">0.0000</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"best_paths[2,3]: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
</pre></div>
<pre class="example">
best_probs[0,0]: -22.6099
best_paths[2,3]: 0.0000
</pre></div>
</div>
<div class="outline-3" id="outline-container-org1ec4357">
<h3 id="org1ec4357">Viterby Forward</h3>
<div class="outline-text-3" id="text-org1ec4357">
<p>In this part of the assignment, you will implement the <code>viterbi_forward</code> segment. In other words, you will populate your <code>best_probs</code> and <code>best_paths</code> matrices.</p>
<ul class="org-ul">
<li>Walk forward through the corpus.</li>
<li>For each word, compute a probability for each possible tag.</li>
<li>Unlike the previous algorithm <code>predict_pos</code> (the 'warm-up' exercise), this will include the path up to that (word,tag) combination.</li>
</ul>
<p>Here is an example with a three-word corpus "Loss tracks upward":</p>
<ul class="org-ul">
<li>Note, in this example, only a subset of states (POS tags) are shown in the diagram below, for easier reading.</li>
<li>In the diagram below, the first word "Loss" is already initialized.</li>
<li>The algorithm will compute a probability for each of the potential tags in the second and future words.</li>
</ul>
<p>Compute the probability that the tag of the second work ('tracks') is a verb, 3rd person singular present (VBZ).</p>
<ul class="org-ul">
<li>In the <code>best_probs</code> matrix, go to the column of the second word ('tracks'), and row 40 (VBZ), this cell is highlighted in light orange in the diagram below.</li>
<li>Examine each of the paths from the tags of the first word ('Loss') and choose the most likely path.</li>
<li>An example of the calculation for <b>one</b> of those paths is the path from ('Loss', NN) to ('tracks', VBZ).</li>
<li>The log of the probability of the path up to and including the first word 'Loss' having POS tag NN is <i>-14.32</i>. The <code>best_probs</code> matrix contains this value -14.32 in the column for 'Loss' and row for 'NN'.</li>
<li>Find the probability that NN transitions to VBZ. To find this probability, go to the <code>A</code> transition matrix, and go to the row for 'NN' and the column for 'VBZ'. The value is <i>4.37e-02</i>, which is circled in the diagram, so add \(-14.32 + \log(4.37e-02)\).</li>
<li>Find the log of the probability that the tag VBS would 'emit' the word 'tracks'. To find this, look at the 'B' emission matrix in row 'VBZ' and the column for the word 'tracks'. The value <i>4.61e-04</i> is circled in the diagram below. So add \(-14.32 + \log(4.37e-02) + \log(4.61e-04)\).</li>
<li>The sum of \(-14.32 + \log(4.37e-02) + \log(4.61e-04)\) is <i>-25.13</i>. Store <i>-25.13</i> in the <code>best_probs</code> matrix at row 'VBZ' and column 'tracks' (as seen in the cell that is highlighted in light orange in the diagram).</li>
<li>All other paths in best_probs are calculated. Notice that <i>-25.13</i> is greater than all of the other values in column 'tracks' of matrix <code>best_probs</code>, and so the most likely path to 'VBZ' is from 'NN'. 'NN' is in row 20 of the <code>best_probs</code> matrix, so <i>20</i> is the most likely path.</li>
<li>Store the most likely path <i>20</i> in the <code>best_paths</code> table. This is highlighted in light orange in the diagram below.</li>
</ul>
<p>The formula to compute the probability and path for the \(i^{th}\) word in the <i>corpus</i>, the prior word <i>i-1</i> in the corpus, current POS tag <i>j</i>, and previous POS tag <i>k</i> is:</p>
<p>\[ \mathrm{prob} = \mathbf{best\_prob}_{k, i-1} + \mathrm{log}(\mathbf{A}_{k, j}) + \mathrm{log}(\mathbf{B}_{j, vocab(corpus_{i})}) \]</p>
<p>where \(corpus_{i}\) is the word in the corpus at index <i>i</i>, and <i>vocab</i> is the dictionary that gets the unique integer that represents a given word.</p>
<p>\[ \mathrm{path} = k \]</p>
<p>where <i>k</i> is the integer representing the previous POS tag.</p>
<p>Implement the `viterbi_forward` algorithm and store the best_path and best_prob for every possible tag for each word in the matrices `best_probs` and `best_tags` using the pseudo code below.</p>
<pre class="example">

for each word in the corpus

    for each POS tag type that this word may be

        for POS tag type that the previous word could be

            compute the probability that the previous word had a given POS tag, that the current word has a given POS tag, and that the POS tag would emit this current word.

            retain the highest probability computed for the current word

            set best_probs to this highest probability

            set best_paths to the index 'k', representing the POS tag of the previous word which produced the highest probability `

</pre>
<p>Please use <a href="https://docs.python.org/3/library/math.html">math.log</a> to compute the natural logarithm.</p>
<ul class="org-ul">
<li>Remember that when accessing emission matrix B, the column index is the unique integer ID associated with the word. It can be accessed by using the 'vocab' dictionary, where the key is the word, and the value is the unique integer ID for that word.</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">viterbi_forward</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">test_corpus</span><span class="p">,</span> <span class="n">best_probs</span><span class="p">,</span> <span class="n">best_paths</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
    <span class="sd">"""The forward training pass</span>

<span class="sd">    Args: </span>
<span class="sd">       A, B: The transition and emission matrices respectively</span>
<span class="sd">       test_corpus: a list containing a preprocessed corpus</span>
<span class="sd">       best_probs: an initilized matrix of dimension (num_tags, len(corpus))</span>
<span class="sd">       best_paths: an initilized matrix of dimension (num_tags, len(corpus))</span>
<span class="sd">       vocab: a dictionary where keys are words in vocabulary and value is an index </span>
<span class="sd">    Returns: </span>
<span class="sd">       best_probs: a completed matrix of dimension (num_tags, len(corpus))</span>
<span class="sd">       best_paths: a completed matrix of dimension (num_tags, len(corpus))</span>
<span class="sd">    """</span>
    <span class="c1"># Get the number of unique POS tags (which is the num of rows in best_probs)</span>
    <span class="n">num_tags</span> <span class="o">=</span> <span class="n">best_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Go through every word in the corpus starting from word 1</span>
    <span class="c1"># Recall that word 0 was initialized in `initialize()`</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_corpus</span><span class="p">)):</span> 

        <span class="c1"># Print number of words processed, every 5000 words</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Words processed: </span><span class="si">{:&gt;8}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

        <span class="c1">### START CODE HERE (Replace instances of 'None' with your code EXCEPT the first 'best_path_i = None') ###</span>
        <span class="c1"># For each unique POS tag that the current word can be</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tags</span><span class="p">):</span> <span class="c1"># complete this line</span>

            <span class="c1"># Initialize best_prob for word i to negative infinity</span>
            <span class="n">best_prob_i</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"-inf"</span><span class="p">)</span>

            <span class="c1"># Initialize best_path for current word i to None</span>
            <span class="n">best_path_i</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># For each POS tag that the previous word can be:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tags</span><span class="p">):</span> <span class="c1"># complete this line</span>

                <span class="c1"># Calculate the probability = </span>
                <span class="c1"># best probs of POS tag k, previous word i-1 + </span>
                <span class="c1"># log(prob of transition from POS k to POS j) + </span>
                <span class="c1"># log(prob that emission of POS j is word i)</span>
                <span class="n">prob</span> <span class="o">=</span> <span class="n">best_probs</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="n">test_corpus</span><span class="p">[</span><span class="n">i</span><span class="p">]]])</span>

                <span class="c1"># check if this path's probability is greater than</span>
                <span class="c1"># the best probability up to and before this point</span>
                <span class="k">if</span> <span class="n">prob</span> <span class="o">&gt;</span> <span class="n">best_prob_i</span><span class="p">:</span> <span class="c1"># complete this line</span>

                    <span class="c1"># Keep track of the best probability</span>
                    <span class="n">best_prob_i</span> <span class="o">=</span> <span class="n">prob</span>

                    <span class="c1"># keep track of the POS tag of the previous word</span>
                    <span class="c1"># that is part of the best path.  </span>
                    <span class="c1"># Save the index (integer) associated with </span>
                    <span class="c1"># that previous word's POS tag</span>
                    <span class="n">best_path_i</span> <span class="o">=</span> <span class="n">k</span>

            <span class="c1"># Save the best probability for the </span>
            <span class="c1"># given current word's POS tag</span>
            <span class="c1"># and the position of the current word inside the corpus</span>
            <span class="n">best_probs</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_prob_i</span>

            <span class="c1"># Save the unique integer ID of the previous POS tag</span>
            <span class="c1"># into best_paths matrix, for the POS tag of the current word</span>
            <span class="c1"># and the position of the current word inside the corpus.</span>
            <span class="n">best_paths</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_path_i</span>

        <span class="c1">### END CODE HERE ###</span>
    <span class="k">return</span> <span class="n">best_probs</span><span class="p">,</span> <span class="n">best_paths</span>
</pre></div>
<p>Run the <code>viterbi_forward</code> function to fill in the <code>best_probs</code> and <code>best_paths</code> matrices.</p>
<p><b>Note</b> that this will take a few minutes to run. There are about 30,000 words to process.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">best_probs</span><span class="p">,</span> <span class="n">best_paths</span> <span class="o">=</span> <span class="n">viterbi_forward</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span>
                                             <span class="n">prep</span><span class="p">,</span>
                                             <span class="n">best_probs</span><span class="p">,</span>
                                             <span class="n">best_paths</span><span class="p">,</span>
                                             <span class="n">vocab</span><span class="p">)</span>
</pre></div>
<pre class="example">
2020-11-30 19:35:42,383 graeae.timers.timer start: Started: 2020-11-30 19:35:42.383922
Words processed:     5000
Words processed:    10000
Words processed:    15000
Words processed:    20000
Words processed:    25000
Words processed:    30000
2020-11-30 19:37:56,143 graeae.timers.timer end: Ended: 2020-11-30 19:37:56.143551
2020-11-30 19:37:56,144 graeae.timers.timer end: Elapsed: 0:02:13.759629
</pre>
<div class="highlight">
<pre><span></span><span class="n">expected</span> <span class="o">=</span> <span class="o">-</span><span class="mf">24.7822</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">best_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"best_probs[0,1]: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">best_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="o">-</span><span class="mf">49.5601</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"best_probs[0,4]: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</pre></div>
<pre class="example">
best_probs[0,1]: -24.7822
best_probs[0,4]: -49.5602
</pre></div>
</div>
<div class="outline-3" id="outline-container-org7b30acf">
<h3 id="org7b30acf">Viterbi Backward</h3>
<div class="outline-text-3" id="text-org7b30acf">
<p>Now you will implement the Viterbi backward algorithm.</p>
<ul class="org-ul">
<li>The Viterbi backward algorithm gets the predictions of the POS tags for each word in the corpus using the <code>best_paths</code> and the <code>best_probs</code> matrices.</li>
</ul>
<p>The example below shows how to walk backwards through the best_paths matrix to get the POS tags of each word in the corpus. Recall that this example corpus has three words: "Loss tracks upward".</p>
<p>POS tag for 'upward' is <code>RB</code></p>
<ul class="org-ul">
<li>Select the the most likely POS tag for the last word in the corpus, 'upward' in the <code>best_prob</code> table.</li>
<li>Look for the row in the column for 'upward' that has the largest probability.</li>
<li>Notice that in row 28 of <code>best_probs</code>, the estimated probability is -34.99, which is larger than the other values in the column. So the most likely POS tag for 'upward' is <code>RB</code> an adverb, at row 28 of <code>best_prob</code>.</li>
<li>The variable <code>z</code> is an array that stores the unique integer ID of the predicted POS tags for each word in the corpus. In array z, at position 2, store the value 28 to indicate that the word 'upward' (at index 2 in the corpus), most likely has the POS tag associated with unique ID 28 (which is <code>RB</code>).</li>
<li>The variable <code>pred</code> contains the POS tags in string form. So <code>pred</code> at index 2 stores the string <code>RB</code>.</li>
</ul>
<p>POS tag for 'tracks' is <code>VBZ</code></p>
<ul class="org-ul">
<li>The next step is to go backward one word in the corpus ('tracks'). Since the most likely POS tag for 'upward' is <code>RB</code>, which is uniquely identified by integer ID 28, go to the <code>best_paths</code> matrix in column 2, row 28. The value stored in <code>best_paths</code>, column 2, row 28 indicates the unique ID of the POS tag of the previous word. In this case, the value stored here is 40, which is the unique ID for POS tag <code>VBZ</code> (verb, 3rd person singular present).</li>
<li>So the previous word at index 1 of the corpus ('tracks'), most likely has the POS tag with unique ID 40, which is <code>VBZ</code>.</li>
<li>In array <code>z</code>, store the value 40 at position 1, and for array <code>pred</code>, store the string <code>VBZ</code> to indicate that the word 'tracks' most likely has POS tag <code>VBZ</code>.</li>
</ul>
<p>POS tag for 'Loss' is <code>NN</code></p>
<ul class="org-ul">
<li>In <code>best_paths</code> at column 1, the unique ID stored at row 40 is 20. 20 is the unique ID for POS tag <code>NN</code>.</li>
<li>In array <code>z</code> at position 0, store 20. In array <code>pred</code> at position 0, store <code>NN</code>.</li>
</ul>
<p>Implement the <code>viterbi_backward</code> algorithm, which returns a list of predicted POS tags for each word in the corpus.</p>
<ul class="org-ul">
<li>Note that the numbering of the index positions starts at 0 and not 1.</li>
<li><code>m</code> is the number of words in the corpus.
<ul class="org-ul">
<li>So the indexing into the corpus goes from <code>0</code> to <code>m - 1</code>.</li>
<li>Also, the columns in <code>best_probs</code> and <code>best_paths</code> are indexed from <code>0</code> to <code>m - 1</code></li>
</ul>
</li>
</ul>
<p><b>In Step 1:</b> Loop through all the rows (POS tags) in the last entry of `best_probs` and find the row (POS tag) with the maximum value. Convert the unique integer ID to a tag (a string representation) using the list `states`.</p>
<p>Referring to the three-word corpus described above:</p>
<ul class="org-ul">
<li>`z[2] = 28`: For the word 'upward' at position 2 in the corpus, the POS tag ID is 28. Store 28 in `z` at position 2.</li>
<li>`states[28]` is 'RB': The POS tag ID 28 refers to the POS tag 'RB'.</li>
<li>`pred[2] = 'RB'`: In array `pred`, store the POS tag for the word 'upward'.</li>
</ul>
<p><b>In Step 2:</b></p>
<ul class="org-ul">
<li>Starting at the last column of best_paths, use `best_probs` to find the most likely POS tag for the last word in the corpus.</li>
<li>Then use `best_paths` to find the most likely POS tag for the previous word.</li>
<li>Update the POS tag for each word in `z` and in `preds`.</li>
</ul>
<p>Referring to the three-word example from above, read best_paths at column 2 and fill in z at position 1. `z[1] = best_paths[z[2],2]`</p>
<p>The small test following the routine prints the last few words of the corpus and their states to aid in debug.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">viterbi_backward</span><span class="p">(</span><span class="n">best_probs</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                     <span class="n">best_paths</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                     <span class="n">corpus</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
                     <span class="n">states</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    This function returns the best path.</span>
<span class="sd">    """</span>
    <span class="c1"># Get the number of words in the corpus</span>
    <span class="c1"># which is also the number of columns in best_probs, best_paths</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">best_paths</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> 

    <span class="c1"># Initialize array z, same length as the corpus</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span>

    <span class="c1"># Get the number of unique POS tags</span>
    <span class="n">num_tags</span> <span class="o">=</span> <span class="n">best_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Initialize the best probability for the last word</span>
    <span class="n">best_prob_for_last_word</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">)</span>

    <span class="c1"># Initialize pred array, same length as corpus</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span>

    <span class="c1">### START CODE HERE (Replace instances of 'None' with your code) ###</span>
    <span class="c1">## Step 1 ##</span>

    <span class="c1"># Go through each POS tag for the last word (last column of best_probs)</span>
    <span class="c1"># in order to find the row (POS tag integer ID) </span>
    <span class="c1"># with highest probability for the last word</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_tags</span><span class="p">):</span> <span class="c1"># complete this line</span>

        <span class="c1"># If the probability of POS tag at row k </span>
        <span class="c1"># is better than the previously best probability for the last word:</span>
        <span class="k">if</span> <span class="n">best_probs</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">best_prob_for_last_word</span><span class="p">:</span> <span class="c1"># complete this line</span>

            <span class="c1"># Store the new best probability for the lsat word</span>
            <span class="n">best_prob_for_last_word</span> <span class="o">=</span> <span class="n">best_probs</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Store the unique integer ID of the POS tag</span>
            <span class="c1"># which is also the row number in best_probs</span>
            <span class="n">z</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span>

    <span class="c1"># Convert the last word's predicted POS tag</span>
    <span class="c1"># from its unique integer ID into the string representation</span>
    <span class="c1"># using the 'states' dictionary</span>
    <span class="c1"># store this in the 'pred' array for the last word</span>
    <span class="n">pred</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="n">z</span><span class="p">[</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>

    <span class="c1">## Step 2 ##</span>
    <span class="c1"># Find the best POS tags by walking backward through the best_paths</span>
    <span class="c1"># From the last word in the corpus to the 0th word in the corpus</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># complete this line</span>

        <span class="c1"># Retrieve the unique integer ID of</span>
        <span class="c1"># the POS tag for the word at position 'i' in the corpus</span>
        <span class="n">pos_tag_for_word_i</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># In best_paths, go to the row representing the POS tag of word i</span>
        <span class="c1"># and the column representing the word's position in the corpus</span>
        <span class="c1"># to retrieve the predicted POS for the word at position i-1 in the corpus</span>
        <span class="n">z</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_paths</span><span class="p">[</span><span class="n">pos_tag_for_word_i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>

        <span class="c1"># Get the previous word's POS tag in string form</span>
        <span class="c1"># Use the 'states' dictionary, </span>
        <span class="c1"># where the key is the unique integer ID of the POS tag,</span>
        <span class="c1"># and the value is the string representation of that POS tag</span>
        <span class="n">pred</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="n">z</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>

     <span class="c1">### END CODE HERE ###</span>
    <span class="k">return</span> <span class="n">pred</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">states</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">tags</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">viterbi_backward</span><span class="p">(</span><span class="n">best_probs</span><span class="p">,</span> <span class="n">best_paths</span><span class="p">,</span> <span class="n">corpus</span><span class="o">=</span><span class="n">prep</span><span class="p">,</span> <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>
<span class="n">m</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="n">actual_prep</span> <span class="o">=</span> <span class="n">prep</span><span class="p">[</span><span class="o">-</span><span class="mi">7</span><span class="p">:</span><span class="n">m</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">actual_pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="o">-</span><span class="mi">7</span><span class="p">:</span><span class="n">m</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">expected_prep</span> <span class="o">=</span>  <span class="p">[</span><span class="s1">'see'</span><span class="p">,</span> <span class="s1">'them'</span><span class="p">,</span> <span class="s1">'here'</span><span class="p">,</span> <span class="s1">'with'</span><span class="p">,</span> <span class="s1">'us'</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">]</span>  
<span class="nb">print</span><span class="p">(</span><span class="s1">'The prediction for pred[-7:m-1] is: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">actual_prep</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">actual_pred</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'The prediction for pred[0:7] is: </span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">],</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">prep</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">])</span>
</pre></div>
<pre class="example">
The prediction for pred[-7:m-1] is: 
 ['them', 'here', 'with', 'us', '.', '--n--'] 
 ['PRP', 'RB', 'IN', 'PRP', '.', '--s--'] 

The prediction for pred[0:8] is: 
 ['DT', 'NN', 'POS', 'NN', 'MD', 'VB', 'VBN'] 
 ['The', 'economy', "'s", 'temperature', 'will', 'be', 'taken']
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org4eef1f1">
<h2 id="org4eef1f1">End</h2>
<div class="outline-text-2" id="text-org4eef1f1">
<p>Bundle it up.</p>
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">hidden</span><span class="o">-</span><span class="n">markov</span><span class="o">-</span><span class="n">imports</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">exception</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">hidden</span><span class="o">-</span><span class="n">markov</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">states</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">tag</span><span class="o">-</span><span class="n">counts</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">tag</span><span class="o">-</span><span class="n">count</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">transition</span><span class="o">-</span><span class="n">matrix</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">emission</span><span class="o">-</span><span class="n">matrix</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">words</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">word</span><span class="o">-</span><span class="n">count</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">vocabulary</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">start</span><span class="o">-</span><span class="n">token</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">negative</span><span class="o">-</span><span class="n">infinity</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">initialize</span><span class="o">-</span><span class="n">matrices</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">viterbi</span><span class="o">-</span><span class="n">forward</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">viterbi</span><span class="o">-</span><span class="n">backward</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">call</span><span class="o">-</span><span class="n">it</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orga5ec293">
<h3 id="orga5ec293">Imports</h3>
<div class="outline-text-3" id="text-orga5ec293">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.preprocessing</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Empty</span>
<span class="kn">from</span> <span class="nn">.training</span> <span class="kn">import</span> <span class="n">TheTrainer</span>
<span class="kn">from</span> <span class="nn">.matrices</span> <span class="kn">import</span> <span class="n">Matrices</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge715a3d">
<h3 id="orge715a3d">An Exception</h3>
<div class="outline-text-3" id="text-orge715a3d">
<p>This is so that if the viterbi is called out of order things will break.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">AlgorithmError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="sd">"""Called when the methods are called out of order"""</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4afc603">
<h3 id="org4afc603">The Model Class</h3>
<div class="outline-text-3" id="text-org4afc603">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">HiddenMarkov</span><span class="p">:</span>
    <span class="sd">"""A Hidden Markov Model Class</span>

<span class="sd">    Args:</span>
<span class="sd">     loader: a DataLoader</span>
<span class="sd">     trainer: A TheTrainer object</span>
<span class="sd">     matrices: A Matrices object</span>
<span class="sd">    """</span>
    <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span>
    <span class="n">trainer</span><span class="p">:</span> <span class="n">TheTrainer</span>
    <span class="n">matrices</span><span class="p">:</span> <span class="n">Matrices</span>
    <span class="n">best_probabilities</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">best_paths</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_states</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tag_counts</span><span class="p">:</span> <span class="n">Counter</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_tag_count</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_transition_matrix</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_emission_matrix</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_test_words</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_test_word_count</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vocabulary</span><span class="p">:</span> <span class="nb">dict</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_start_token_index</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_negative_infinity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org5890049">
<h4 id="org5890049">The States List</h4>
<div class="outline-text-4" id="text-org5890049">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">states</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""POS Tags representing nodes in the HMM graph</span>

<span class="sd">    Returns:</span>
<span class="sd">     list of POS tags found in the training set</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="o">.</span><span class="n">tags</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_states</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge6d1ef8">
<h4 id="orge6d1ef8">The Tag Counts</h4>
<div class="outline-text-4" id="text-orge6d1ef8">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tag_counts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Counter</span><span class="p">:</span>
    <span class="sd">"""The number of times a POS tag was in the training set</span>

<span class="sd">    Returns:</span>
<span class="sd">     dict-like of POS: Count</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tag_counts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tag_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">tag_counts</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tag_counts</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2b70cc3">
<h4 id="org2b70cc3">Tag Count</h4>
<div class="outline-text-4" id="text-org2b70cc3">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">tag_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""The Number of tags in the corpus"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tag_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tag_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_counts</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tag_count</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org403f065">
<h4 id="org403f065">Transition Matrix (A)</h4>
<div class="outline-text-4" id="text-org403f065">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">transition_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""The 'A' Matrix with the transitions"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transition_matrix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transition_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="o">.</span><span class="n">transition</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transition_matrix</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org10c627e">
<h4 id="org10c627e">Emission Matrix (B)</h4>
<div class="outline-text-4" id="text-org10c627e">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">emission_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""The Emission matrix (B)"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emission_matrix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_emission_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrices</span><span class="o">.</span><span class="n">emission</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emission_matrix</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcf942ed">
<h4 id="orgcf942ed">Test Words</h4>
<div class="outline-text-4" id="text-orgcf942ed">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">test_words</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
    <span class="sd">"""The preprocessed test-words"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_words</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="n">test_words</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_words</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2ea023d">
<h4 id="org2ea023d">Test Word Count</h4>
<div class="outline-text-4" id="text-org2ea023d">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">test_word_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Number of words in the test set"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_word_count</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_word_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_words</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_word_count</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb789061">
<h4 id="orgb789061">Vocabulary</h4>
<div class="outline-text-4" id="text-orgb789061">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""Training tokens mapped to index in the training corpus"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfc24a19">
<h4 id="orgfc24a19">Start Token Index</h4>
<div class="outline-text-4" id="text-orgfc24a19">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">start_token_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""The index of the start token in the graph states"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_token_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_start_token_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">Empty</span><span class="o">.</span><span class="n">tag</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_token_index</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org439c123">
<h4 id="org439c123">Negative Infinity</h4>
<div class="outline-text-4" id="text-org439c123">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">negative_infinity</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""a value for no probability"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_negative_infinity</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_negative_infinity</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"-inf"</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_negative_infinity</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfb18472">
<h4 id="orgfb18472">Initialize the Matrices</h4>
<div class="outline-text-4" id="text-orgfb18472">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">initialize_matrices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Initializes the ``best_probs`` and ``best_paths`` matrices</span>

<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_count</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_word_count</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_paths</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_count</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_word_count</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">pos_tag</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">)):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_token_index</span><span class="p">,</span> <span class="n">pos_tag</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="n">pos_tag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_infinity</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="n">pos_tag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_token_index</span><span class="p">,</span> <span class="n">pos_tag</span><span class="p">])</span>
                <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emission_matrix</span><span class="p">[</span>
                    <span class="n">pos_tag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">test_words</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb33a566">
<h4 id="orgb33a566">Virterbi Forward</h4>
<div class="outline-text-4" id="text-orgb33a566">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">viterbi_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""The forward training pass</span>

<span class="sd">    Raises:</span>
<span class="sd">      AlgorithmError: initalize_matrices wasn't run before this method</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">AlgorithmError</span><span class="p">(</span><span class="s2">"initialize_matrices must be called before viterbi_forward"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_word_count</span><span class="p">):</span> 
        <span class="k">for</span> <span class="n">pos_tag</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_count</span><span class="p">):</span>
            <span class="n">best_probability_for_this_tag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_infinity</span>
            <span class="n">best_path_for_this_tag</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">previous_possible_tag</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_count</span><span class="p">):</span>

                <span class="n">probability</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="n">previous_possible_tag</span><span class="p">,</span> <span class="n">word</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">[</span><span class="n">previous_possible_tag</span><span class="p">,</span> <span class="n">pos_tag</span><span class="p">])</span>
                    <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emission_matrix</span><span class="p">[</span>
                        <span class="n">pos_tag</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">test_words</span><span class="p">[</span><span class="n">word</span><span class="p">]]]))</span>

                <span class="k">if</span> <span class="n">probability</span> <span class="o">&gt;</span> <span class="n">best_probability_for_this_tag</span><span class="p">:</span>
                    <span class="n">best_probability_for_this_tag</span> <span class="o">=</span> <span class="n">probability</span>
                    <span class="n">best_path_for_this_tag</span> <span class="o">=</span> <span class="n">previous_possible_tag</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="n">pos_tag</span><span class="p">,</span> <span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_probability_for_this_tag</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_paths</span><span class="p">[</span><span class="n">pos_tag</span><span class="p">,</span> <span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_path_for_this_tag</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5b864e7">
<h4 id="org5b864e7">Viterbi Backward</h4>
<div class="outline-text-4" id="text-org5b864e7">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">viterbi_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    This function creates the best path.</span>

<span class="sd">    Raises:</span>
<span class="sd">     AlgorithmError: initialize or forward-pass not done</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">AlgorithmError</span><span class="p">(</span><span class="s2">"initialize and forward-pass not run"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">AlgorithmError</span><span class="p">(</span><span class="s2">"forward-pass not run"</span><span class="p">)</span>

    <span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_word_count</span>

    <span class="n">best_probability_for_last_word</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_infinity</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_word_count</span>
    <span class="n">last_column</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_word_count</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">pos_tag</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tag_count</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="n">pos_tag</span><span class="p">,</span> <span class="n">last_column</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">best_probability_for_last_word</span><span class="p">:</span>
            <span class="n">best_probability_for_last_word</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="n">pos_tag</span><span class="p">,</span> <span class="n">last_column</span><span class="p">]</span>
            <span class="n">z</span><span class="p">[</span><span class="n">last_column</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_tag</span>
    <span class="n">prediction</span><span class="p">[</span><span class="n">last_column</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">z</span><span class="p">[</span><span class="n">last_column</span><span class="p">]]</span>

    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">last_column</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">previous_word</span> <span class="o">=</span> <span class="n">word</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">pos_tag_for_word</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">z</span><span class="p">[</span><span class="n">previous_word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_paths</span><span class="p">[</span><span class="n">pos_tag_for_word</span><span class="p">,</span> <span class="n">word</span><span class="p">]</span>
        <span class="n">prediction</span><span class="p">[</span><span class="n">previous_word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">z</span><span class="p">[</span><span class="n">previous_word</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">prediction</span>    
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga3ad0da">
<h4 id="orga3ad0da">Call It</h4>
<div class="outline-text-4" id="text-orga3ad0da">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Calls the methods in order"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initialize_matrices</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">viterbi_forward</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">viterbi_backward</span><span class="p">()</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org90f79db">
<h3 id="org90f79db">Test it out</h3>
<div class="outline-text-3" id="text-org90f79db">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.parts_of_speech</span> <span class="kn">import</span> <span class="n">HiddenMarkov</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">HiddenMarkov</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">matrices</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">original</span> <span class="o">==</span> <span class="n">other</span> <span class="k">for</span> <span class="n">original</span><span class="p">,</span> <span class="n">other</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">states</span><span class="p">))</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">value</span> <span class="o">==</span> <span class="n">model</span><span class="o">.</span><span class="n">tag_counts</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tag_counts</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
<span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">emission_matrix</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">original</span> <span class="o">==</span> <span class="n">new</span> <span class="k">for</span> <span class="n">original</span><span class="p">,</span> <span class="n">new</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prep</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">test_words</span><span class="p">))</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">value</span> <span class="o">==</span> <span class="n">model</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">initialize_matrices</span><span class="p">()</span>

<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">best_probabilities</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">best_probs</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">best_paths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">best_paths</span><span class="o">.</span><span class="n">shape</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="o">-</span><span class="mf">22.6098</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">),</span> <span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_paths</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="mf">0.0000</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">viterbi_forward</span><span class="p">()</span>
<span class="n">expected</span> <span class="o">=</span> <span class="o">-</span><span class="mf">24.7822</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">best_probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="o">-</span><span class="mf">49.5601</span>
<span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">abs_tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">viterbi_backward</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'DT'</span><span class="p">,</span> <span class="s1">'NN'</span><span class="p">,</span> <span class="s1">'POS'</span><span class="p">,</span> <span class="s1">'NN'</span><span class="p">,</span> <span class="s1">'MD'</span><span class="p">,</span> <span class="s1">'VB'</span><span class="p">,</span> <span class="s1">'VBN'</span><span class="p">]</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">((</span><span class="n">a</span><span class="o">==</span><span class="n">e</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span><span class="n">e</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">)))</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org9d3d154">
<h4 id="org9d3d154">Run The Methods In the correct order with a call</h4>
<div class="outline-text-4" id="text-org9d3d154">
<div class="highlight">
<pre><span></span><span class="n">mock</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
<span class="n">step_1</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
<span class="n">step_2</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
<span class="n">step_3</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>

<span class="n">mock</span><span class="o">.</span><span class="n">initialize</span> <span class="o">=</span> <span class="n">step_1</span>
<span class="n">mock</span><span class="o">.</span><span class="n">viterbi_forward</span> <span class="o">=</span> <span class="n">step_2</span>
<span class="n">mock</span><span class="o">.</span><span class="n">viterbi_backward</span> <span class="o">=</span> <span class="n">step_3</span>

<span class="n">HiddenMarkov</span><span class="o">.</span><span class="n">initialize_matrices</span> <span class="o">=</span> <span class="n">step_1</span>
<span class="n">HiddenMarkov</span><span class="o">.</span><span class="n">viterbi_forward</span> <span class="o">=</span> <span class="n">step_2</span>
<span class="n">HiddenMarkov</span><span class="o">.</span><span class="n">viterbi_backward</span> <span class="o">=</span> <span class="n">step_3</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">HiddenMarkov</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">matrices</span><span class="p">)</span>
<span class="n">model</span><span class="p">()</span>
<span class="n">expect</span><span class="p">(</span><span class="n">mock</span><span class="o">.</span><span class="n">mock_calls</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">([</span><span class="n">call</span><span class="o">.</span><span class="n">initialize</span><span class="p">(),</span>
                                  <span class="n">call</span><span class="o">.</span><span class="n">viterbi_forward</span><span class="p">(),</span>
                                  <span class="n">call</span><span class="o">.</span><span class="n">viterbi_backward</span><span class="p">()]))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/pos-tagging/" rel="tag">pos tagging</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../parts-of-speech-tagging-hidden-markov-model/" rel="prev" title="Parts-of-Speech Tagging: Hidden Markov Model">Previous post</a></li>
<li class="next"><a href="../pos-tagging-accuracy-of-model/" rel="next" title="POS Tagging: Accuracy of Model">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
