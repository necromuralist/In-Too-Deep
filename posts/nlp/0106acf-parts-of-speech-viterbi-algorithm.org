#+BEGIN_COMMENT
.. title: Parts-of-Speech: Viterbi Algorithm
.. slug: parts-of-speech-viterbi-algorithm
.. date: 2020-11-21 18:21:58 UTC-08:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3

#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-36a8b624-64ee-4fb4-abec-0e4e5f8fbc72-ssh.json

#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC
* Beginning
* Middle
* End
* Raw
#+begin_example
# # Part 3: Viterbi Algorithm and Dynamic Programming
# 
# In this part of the assignment you will implement the Viterbi algorithm which makes use of dynamic programming. Specifically, you will use your two matrices, `A` and `B` to compute the Viterbi algorithm. We have decomposed this process into three main steps for you. 
# 
# * **Initialization** - In this part you initialize the `best_paths` and `best_probabilities` matrices that you will be populating in `feed_forward`.
# * **Feed forward** - At each step, you calculate the probability of each path happening and the best paths up to that point. 
# * **Feed backward**: This allows you to find the best path with the highest probabilities. 
# 
# <a name='3.1'></a>
# ## Part 3.1:  Initialization 
# 
# You will start by initializing two matrices of the same dimension. 
# 
# - best_probs: Each cell contains the probability of going from one POS tag to a word in the corpus.
# 
# - best_paths: A matrix that helps you trace through the best possible path in the corpus. 

# <a name='ex-05'></a>
# ### Exercise 05
# **Instructions**: 
# Write a program below that initializes the `best_probs` and the `best_paths` matrix. 
# 
# Both matrices will be initialized to zero except for column zero of `best_probs`.  
# - Column zero of `best_probs` is initialized with the assumption that the first word of the corpus was preceded by a start token ("--s--"). 
# - This allows you to reference the **A** matrix for the transition probability
# 
# Here is how to initialize column 0 of `best_probs`:
# - The probability of the best path going from the start index to a given POS tag indexed by integer $i$ is denoted by $\textrm{best_probs}[s_{idx}, i]$.
# - This is estimated as the probability that the start tag transitions to the POS denoted by index $i$: $\mathbf{A}[s_{idx}, i]$ AND that the POS tag denoted by $i$ emits the first word of the given corpus, which is $\mathbf{B}[i, vocab[corpus[0]]]$.
# - Note that vocab[corpus[0]] refers to the first word of the corpus (the word at position 0 of the corpus). 
# - **vocab** is a dictionary that returns the unique integer that refers to that particular word.
# 
# Conceptually, it looks like this:
# $\textrm{best_probs}[s_{idx}, i] = \mathbf{A}[s_{idx}, i] \times \mathbf{B}[i, corpus[0] ]$
# 
# 
# In order to avoid multiplying and storing small values on the computer, we'll take the log of the product, which becomes the sum of two logs:
# 
# $best\_probs[i,0] = log(A[s_{idx}, i]) + log(B[i, vocab[corpus[0]]$
# 
# Also, to avoid taking the log of 0 (which is defined as negative infinity), the code itself will just set $best\_probs[i,0] = float('-inf')$ when $A[s_{idx}, i] == 0$
# 
# 
# So the implementation to initialize $best\_probs$ looks like this:
# 
# $ if A[s_{idx}, i] <> 0 : best\_probs[i,0] = log(A[s_{idx}, i]) + log(B[i, vocab[corpus[0]]])$
# 
# $ if A[s_{idx}, i] == 0 : best\_probs[i,0] = float('-inf')$
# 
# Please use [math.log](https://docs.python.org/3/library/math.html) to compute the natural logarithm.

# The example below shows the initialization assuming the corpus starts with the phrase "Loss tracks upward".
# 
# <img src = "Initialize4.PNG"/>

# Represent infinity and negative infinity like this:
# 
# ```CPP
# float('inf')
# float('-inf')
# ```

# In[ ]:


# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION: initialize
def initialize(states, tag_counts, A, B, corpus, vocab):
    '''
    Input: 
        states: a list of all possible parts-of-speech
        tag_counts: a dictionary mapping each tag to its respective count
        A: Transition Matrix of dimension (num_tags, num_tags)
        B: Emission Matrix of dimension (num_tags, len(vocab))
        corpus: a sequence of words whose POS is to be identified in a list 
        vocab: a dictionary where keys are words in vocabulary and value is an index
    Output:
        best_probs: matrix of dimension (num_tags, len(corpus)) of floats
        best_paths: matrix of dimension (num_tags, len(corpus)) of integers
    '''
    # Get the total number of unique POS tags
    num_tags = len(tag_counts)
    
    # Initialize best_probs matrix 
    # POS tags in the rows, number of words in the corpus as the columns
    best_probs = np.zeros((num_tags, len(corpus)))
    
    # Initialize best_paths matrix
    # POS tags in the rows, number of words in the corpus as columns
    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)
    
    # Define the start token
    s_idx = states.index("--s--")
    ### START CODE HERE (Replace instances of 'None' with your code) ###
    
    # Go through each of the POS tags
    for i in None: # complete this line
        
        # Handle the special case when the transition from start token to POS tag i is zero
        if None: # complete this line
            
            # Initialize best_probs at POS tag 'i', column 0, to negative infinity
            best_probs[i,0] = None
        
        # For all other cases when transition from start token to POS tag i is non-zero:
        else:
            
            # Initialize best_probs at POS tag 'i', column 0
            # Check the formula in the instructions above
            best_probs[i,0] = None
                        
    ### END CODE HERE ### 
    return best_probs, best_paths


# In[ ]:


best_probs, best_paths = initialize(states, tag_counts, A, B, prep, vocab)


# In[ ]:


# Test the function
print(f"best_probs[0,0]: {best_probs[0,0]:.4f}") 
print(f"best_paths[2,3]: {best_paths[2,3]:.4f}")


# ##### Expected Output
# 
# ```CPP
# best_probs[0,0]: -22.6098
# best_paths[2,3]: 0.0000
# ```
# 

#+end_example
