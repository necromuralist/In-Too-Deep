<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Looking at Recurrent Neural Networks with and without GRUs." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Vanilla RNNs and GRUs | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/vanilla-rnns-and-grus/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../jax-numpy-and-perplexity/" rel="prev" title="Jax, Numpy, and Perplexity" type="text/html">
<link href="../trax-gru-model/" rel="next" title="Trax GRU Model" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Vanilla RNNs and GRUs" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/vanilla-rnns-and-grus/" property="og:url">
<meta content="Looking at Recurrent Neural Networks with and without GRUs." property="og:description">
<meta content="article" property="og:type">
<meta content="2021-01-01T20:21:58-08:00" property="article:published_time">
<meta content="nlp" property="article:tag">
<meta content="rnns" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Vanilla RNNs and GRUs</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2021-01-01T20:21:58-08:00" itemprop="datePublished" title="2021-01-01 20:21">2021-01-01 20:21</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgf401a12">Vanilla RNNs, GRUs and the <code>scan</code> function</a>
<ul>
<li><a href="#orgd653534">Imports</a></li>
<li><a href="#org474947f">Set Up</a>
<ul>
<li><a href="#org34d51d4">The Sigmoid Function</a></li>
<li><a href="#org8e89224">Collections</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org48aa67b">Middle</a>
<ul>
<li><a href="#orga0a86ac">The Forward Method For Vanilla RNNs and GRUs</a>
<ul>
<li><a href="#orgfb5eae0">The Forward Method For Vanilla RNNs</a></li>
<li><a href="#org04f6d8b">The Forward Method For GRUs</a></li>
</ul>
</li>
<li><a href="#org31a1c91">Part 2: Implementation of the <code>scan</code> function</a></li>
<li><a href="#org45cadf3">Comparing Vanilla RNNs and GRUs</a>
<ul>
<li><a href="#org4a1997f">Vanilla RNNs</a></li>
<li><a href="#orgabe5c0c">GRUs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgf401a12">
<h2 id="orgf401a12">Vanilla RNNs, GRUs and the <code>scan</code> function</h2>
<div class="outline-text-2" id="text-orgf401a12"></div>
<div class="outline-3" id="outline-container-orgd653534">
<h3 id="orgd653534">Imports</h3>
<div class="outline-text-3" id="text-orgd653534">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">perf_counter</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="n">be_true</span><span class="p">,</span> <span class="n">expect</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">random</span>

<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org474947f">
<h3 id="org474947f">Set Up</h3>
<div class="outline-text-3" id="text-org474947f"></div>
<div class="outline-4" id="outline-container-org34d51d4">
<h4 id="org34d51d4">The Sigmoid Function</h4>
<div class="outline-text-4" id="text-org34d51d4">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Calculates the sigmoid of x</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the array (or float) to get the sigmoid for</span>

<span class="sd">    Returns:</span>
<span class="sd">     the sigmoid of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8e89224">
<h4 id="org8e89224">Collections</h4>
<div class="outline-text-4" id="text-org8e89224">
<p>These are going to hold the arrays that we are using for calculation.</p>
<div class="highlight">
<pre><span></span><span class="n">Weights</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Weights"</span><span class="p">,</span> <span class="s2">"w1 w2 w3 b1 b2 b3"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">Inputs</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Inputs"</span><span class="p">,</span> <span class="s2">"X hidden_state"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org48aa67b">
<h2 id="org48aa67b">Middle</h2>
<div class="outline-text-2" id="text-org48aa67b"></div>
<div class="outline-3" id="outline-container-orga0a86ac">
<h3 id="orga0a86ac">The Forward Method For Vanilla RNNs and GRUs</h3>
<div class="outline-text-3" id="text-orga0a86ac">
<p>In this part of the notebook, we'll look at the implementation of the forward method for a vanilla RNN and implement that same method for a GRU. For this excercise we'll use a set of random weights and variables with the following dimensions:</p>
<ul class="org-ul">
<li>Embedding size (<code>emb</code>) : 128</li>
<li>Hidden state size (<code>h_dim</code>) : (16,1)</li>
</ul>
<p>The weights <code>w_</code> and biases <code>b_</code> are initialized with dimensions (<code>h_dim</code>, <code>emb + h_dim</code>) and (<code>h_dim</code>, 1). We expect the hidden state <code>h_t</code> to be a column vector with size (<code>h_dim</code>,1) and the initial hidden state <code>h_0</code> is a vector of zeros.</p>
<p>Now we'll set up the variables for the dimensions.</p>
<div class="highlight">
<pre><span></span><span class="n">Dimension</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">embedding</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">hidden_variables</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">hidden_state</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>    
<span class="p">)</span>
</pre></div>
<p>Now we'll initialize the various arrays.</p>
<div class="highlight">
<pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">Weights</span><span class="p">(</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span>
        <span class="p">(</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span>
         <span class="n">Dimension</span><span class="o">.</span><span class="n">embedding</span> <span class="o">+</span> <span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">)),</span>
    <span class="n">w2</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span>
        <span class="p">(</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span>
         <span class="n">Dimension</span><span class="o">.</span><span class="n">embedding</span> <span class="o">+</span> <span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">)),</span>
    <span class="n">w3</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span>
        <span class="p">(</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span>
         <span class="n">Dimension</span><span class="o">.</span><span class="n">embedding</span> <span class="o">+</span> <span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">)),</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  
<span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">Inputs</span><span class="p">(</span>
    <span class="n">hidden_state</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">Dimension</span><span class="o">.</span><span class="n">hidden_variables</span><span class="p">,</span> <span class="n">Dimension</span><span class="o">.</span><span class="n">embedding</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgfb5eae0">
<h4 id="orgfb5eae0">The Forward Method For Vanilla RNNs</h4>
<div class="outline-text-4" id="text-orgfb5eae0">
<p>The vanilla RNN cell is quite straight forward.</p>
<p>The computations made in a vanilla RNN cell are equivalent to the following equations:</p>
\begin{equation} h^{\langle t \rangle}=g(W_{h}[h^{\langle t-1 \rangle},x^{\langle t \rangle}] + b_h) \label{eq: htRNN} \end{equation} \begin{equation} \hat{y}^{\langle t \rangle}=g(W_{yh}h^{\langle t \rangle} + b_y) \label{eq: ytRNN} \end{equation}
<p>Where \([h^{\langle t-1 \rangle},x^{\langle t \rangle}]\) means that \(h^{\langle t-1 \rangle}\) and \(x^{\langle t \rangle}\) are concatenated together.</p>
<p>Here's the implementation of the forward method for a vanilla RNN.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">forward_vanilla_RNN</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Forward propagation for a a single vanilla RNN cell</span>

<span class="sd">    Args:</span>
<span class="sd">     inputs: collection of x and the hidden state</span>
<span class="sd">     weights: collections of weights and biases</span>

<span class="sd">    Returns:</span>
<span class="sd">     hidden state twice (so we don't have to implement y for the scan)</span>
<span class="sd">    """</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="n">w1</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="n">h_t</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span>
                    <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">hidden_state</span><span class="p">,</span>
                                       <span class="n">x</span><span class="p">]))</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">h_t</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">h_t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">h_t</span><span class="p">,</span> <span class="n">h_t</span>
</pre></div>
<p>As you can see, we omitted the computation of \(\hat{y}^{\langle t \rangle}\). This was done for the sake of simplicity, so you can focus on the way that hidden states are updated here and in the GRU cell.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org04f6d8b">
<h4 id="org04f6d8b">The Forward Method For GRUs</h4>
<div class="outline-text-4" id="text-org04f6d8b">
<p>A GRU cell has more computations than the ones that vanilla RNNs have.</p>
<p>GRUs have relevance \(\Gamma_r\) and update \(\Gamma_u\) gates that control how the hidden state \(h^{\langle t \rangle}\) is updated on every time step. With these gates, GRUs are capable of keeping relevant information in the hidden state even for long sequences. The equations needed for the forward method in GRUs are:</p>
\begin{equation} \Gamma_r=\sigma{(W_r[h^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_r)} \end{equation} \begin{equation} \Gamma_u=\sigma{(W_u[h^{\langle t-1\rangle}, x^{\langle t\rangle}]+b_u)} \end{equation} \begin{equation} c^{\langle t\rangle}=\tanh{(W_h[\Gamma_r*h^{\langle t-1\rangle},x^{\langle t\rangle}]+b_h)} \end{equation} \begin{equation} h^{\langle t\rangle}=\Gamma_u*c^{\langle t\rangle}+(1-\Gamma_u)*h^{\langle t-1\rangle} \end{equation}
<p>In the next cell, we'll implement the forward method for a GRU cell by computing the update <code>u</code> and relevance <code>r</code> gates, and the candidate hidden state <code>c</code>.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">forward_GRU</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Namespace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Forward propagation for a single GRU cell</span>

<span class="sd">    Args: </span>
<span class="sd">     inputs: collection of (x, h_t)</span>
<span class="sd">     weights: tuple of weights</span>

<span class="sd">    Returns:</span>
<span class="sd">     updated hidden weights twice</span>
<span class="sd">    """</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">h_t</span> <span class="o">=</span> <span class="n">inputs</span>

    <span class="c1"># weights.</span>
    <span class="n">wu</span><span class="p">,</span> <span class="n">wr</span><span class="p">,</span> <span class="n">wc</span><span class="p">,</span> <span class="n">bu</span><span class="p">,</span> <span class="n">br</span><span class="p">,</span> <span class="n">bc</span> <span class="o">=</span> <span class="n">weights</span>

    <span class="c1"># Update gate</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wu</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">h_t</span><span class="p">,</span> <span class="n">x</span><span class="p">]))</span> <span class="o">+</span> <span class="n">bu</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

    <span class="c1"># Relevance gate</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wr</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">h_t</span><span class="p">,</span> <span class="n">x</span><span class="p">]))</span> <span class="o">+</span> <span class="n">br</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

    <span class="c1"># Candidate hidden state </span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wc</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">r</span> <span class="o">*</span> <span class="n">h_t</span><span class="p">,</span> <span class="n">x</span><span class="p">]))</span> <span class="o">+</span> <span class="n">bc</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

    <span class="c1"># New Hidden state h_t</span>
    <span class="n">h_t</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">c</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span> <span class="o">*</span> <span class="n">h_t</span>
    <span class="k">return</span> <span class="n">h_t</span><span class="p">,</span> <span class="n">h_t</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orgfdecc67"></a>A Check<br>
<div class="outline-text-5" id="text-orgfdecc67">
<div class="highlight">
<pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="n">forward_GRU</span><span class="p">([</span><span class="n">inputs</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inputs</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">],</span> <span class="n">weights</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>

<span class="n">expected</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">9.77779014e-01</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">9.97986240e-01</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">5.19958083e-01</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">9.99999886e-01</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">9.99707004e-01</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">3.02197037e-04</span><span class="p">],</span>
                        <span class="p">[</span><span class="o">-</span><span class="mf">9.58733503e-01</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">2.10804828e-02</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">9.77365398e-05</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">9.99833090e-01</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">1.63200940e-08</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">8.51874303e-01</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">5.21399924e-02</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">2.15495959e-02</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">9.99878828e-01</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">9.77165472e-01</span><span class="p">]])</span>
<span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
</pre></div>
<pre class="example" id="org90dbf88">
[[ 9.77779014e-01]
 [-9.97986240e-01]
 [-5.19958083e-01]
 [-9.99999886e-01]
 [-9.99707004e-01]
 [-3.02197037e-04]
 [-9.58733503e-01]
 [ 2.10804828e-02]
 [ 9.77365398e-05]
 [ 9.99833090e-01]
 [ 1.63200940e-08]
 [ 8.51874303e-01]
 [ 5.21399924e-02]
 [ 2.15495959e-02]
 [ 9.99878828e-01]
 [ 9.77165472e-01]]
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org31a1c91">
<h3 id="org31a1c91">Part 2: Implementation of the <code>scan</code> function</h3>
<div class="outline-text-3" id="text-org31a1c91">
<p>The <code>scan</code> function is used for forward propagation in RNNs. It takes as inputs:</p>
<ul class="org-ul">
<li><code>fn</code> : the function to be called recurrently (i.e. <code>forward_GRU</code>)</li>
<li><code>elems</code> : the list of inputs for each time step (<code>X</code>)</li>
<li><code>weights</code> : the parameters needed to compute <code>fn</code></li>
<li><code>h_0</code> : the initial hidden state</li>
</ul>
<p><code>scan</code> goes through all the elements <code>x</code> in <code>elems</code>, calls the function <code>fn</code> with arguments ([=x=, <code>h_t=],=weights</code>), stores the computed hidden state <code>h_t</code> and appends the result to a list <code>ys</code>. Complete the following cell by calling <code>fn</code> with arguments ([=x=, <code>h_t=],=weights</code>).</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">scan</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">elems</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">h_0</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Forward propagation for RNNs</span>

<span class="sd">    Args:</span>
<span class="sd">     function: callable that updates the hidden state</span>
<span class="sd">      elems: input (x)</span>
<span class="sd">      weights: collection of weights</span>
<span class="sd">      h_0: the initial hidden weights</span>
<span class="sd">    """</span>
    <span class="n">h_t</span> <span class="o">=</span> <span class="n">h_0</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">elems</span><span class="p">:</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">h_t</span> <span class="o">=</span> <span class="n">fn</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">h_t</span><span class="p">],</span> <span class="n">weights</span><span class="p">)</span>
        <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ys</span><span class="p">,</span> <span class="n">h_t</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org45cadf3">
<h3 id="org45cadf3">Comparing Vanilla RNNs and GRUs</h3>
<div class="outline-text-3" id="text-org45cadf3">
<p>You have already seen how forward propagation is computed for vanilla RNNs and GRUs. As a quick recap, you need to have a forward method for the recurrent cell and a function like <code>scan</code> to go through all the elements from a sequence using a forward method. You saw that GRUs performed more computations than vanilla RNNs, and you can check that they have 3 times more parameters. In the next two cells, we compute forward propagation for a sequence with 256 time steps (<code>T</code>) for an RNN and a GRU with the same hidden state <code>h_t</code> size (=h_dim==16).</p>
</div>
<div class="outline-4" id="outline-container-org4a1997f">
<h4 id="org4a1997f">Vanilla RNNs</h4>
<div class="outline-text-4" id="text-org4a1997f">
<p>We'll train the RNN and also time it.</p>
<div class="highlight">
<pre><span></span><span class="n">tick</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">ys</span><span class="p">,</span> <span class="n">h_T</span> <span class="o">=</span> <span class="n">scan</span><span class="p">(</span><span class="n">forward_vanilla_RNN</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">)</span>
<span class="n">tock</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">RNN_time</span><span class="o">=</span><span class="p">(</span><span class="n">tock</span><span class="o">-</span><span class="n">tick</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">"It took </span><span class="si">{</span><span class="n">RNN_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms to run the forward method for the vanilla RNN."</span><span class="p">)</span>
</pre></div>
<pre class="example">
It took 2.03ms to run the forward method for the vanilla RNN.
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgabe5c0c">
<h4 id="orgabe5c0c">GRUs</h4>
<div class="outline-text-4" id="text-orgabe5c0c">
<div class="highlight">
<pre><span></span><span class="n">tick</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">ys</span><span class="p">,</span> <span class="n">h_T</span> <span class="o">=</span> <span class="n">scan</span><span class="p">(</span><span class="n">forward_GRU</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">hidden_state</span><span class="p">)</span>
<span class="n">tock</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">GRU_time</span><span class="o">=</span><span class="p">(</span><span class="n">tock</span> <span class="o">-</span> <span class="n">tick</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">"It took </span><span class="si">{</span><span class="n">GRU_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms to run the forward method for the GRU."</span><span class="p">)</span>
</pre></div>
<pre class="example">
It took 5.48ms to run the forward method for the GRU.
</pre>
<p>GRUs take more time to compute. This means that training and prediction would take more time for a GRU than for a vanilla RNN. However, GRUs allow you to propagate relevant information even for long sequences, so when selecting an architecture for NLP we should assess the tradeoff between computational time and performance.</p>
</div>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/rnns/" rel="tag">rnns</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../jax-numpy-and-perplexity/" rel="prev" title="Jax, Numpy, and Perplexity">Previous post</a></li>
<li class="next"><a href="../trax-gru-model/" rel="next" title="Trax GRU Model">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
