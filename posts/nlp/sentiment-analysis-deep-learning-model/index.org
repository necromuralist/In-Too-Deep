#+BEGIN_COMMENT
.. title: Sentiment Analysis: Deep Learning Model
.. slug: sentiment-analysis-deep-learning-model
.. date: 2020-12-23 15:14:07 UTC-08:00
.. tags: nlp,sentiment analysis,deep learning
.. category: NLP
.. link: 
.. description: Sentiment Analysis using a Deep Neural Network.
.. type: text
.. has_math: True
#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+PROPERTY: header-args :session ~/.local/share/jupyter/runtime/kernel-e0274818-4f82-48c6-9b0f-931b217316f3-ssh.json
#+BEGIN_SRC python :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC
* Beginning
Previously we created sentiment analysis models using the Logistic Regression and Naive Bayes algorithms. However if we were to give those models an example like:

#+begin_quote
This movie was almost good.
#+end_quote

The model would have predicted a positive sentiment for that review. That sentence, however, is expressing the negative sentiment that the movie was not good. To solve those kinds of misclassifications we will write a program that uses deep neural networks to identify sentiment in text. 

This model will follow a similar structure to the Continuous Bag of Words Model ({{% doc %}}introducing-the-cbow-model{{% /doc %}}) that we looked at previously - indeed most of the deep nets have a similar structure. The only thing that changes is the model architecture, the inputs, and the outputs. Although we looked at [[https://github.com/google/trax][Trax]] and [[https://jax.readthedocs.io/en/latest/index.html][JAX]] in a previous post ({{% doc %}}introducing-trax{{% /doc %}}) we'll start off with a review of some of their features and then in future posts we'll implement the actual model. These are the other posts.

 - {{% lancelot title="Loading the Data" %}}sentiment-analysis-pre-processing-the-data{{% /lancelot %}}
 - {{% lancelot title="Defining the Model" %}}sentiment-analysis-defining-the-model{{% /lancelot %}}
 - {{% lancelot title="Training the Model" %}}sentiment-analysis-training-the-model{{% /lancelot %}}
 - {{% lancelot title="Testing the Model" %}}sentiment-analysis-testing-the-model{{% /lancelot %}}

** Imports
#+begin_src python :results none
# from python
import os
import random

# from pypi
from trax import layers
import trax
import trax.fastmath.numpy as numpy
#+end_src
** Set Up
*** The Random Seed
#+begin_src python :results none
trax.supervised.trainer_lib.init_random_number_generators(31)
#+end_src
* Middle
** Trax Review
*** JAX Arrays
   First, the JAX reimplementation of numpy (from [[https://trax-ml.readthedocs.io/en/latest/trax.fastmath.html][Trax.fastmath]]).
   
#+begin_src python :results output :exports both
an_array = numpy.array(5.0)
display(an_array)
print(type(an_array))
#+end_src   

#+RESULTS:
:RESULTS:
: DeviceArray(5., dtype=float32)
: <class 'jax.interpreters.xla._DeviceArray'>
:END:

**Note:** the trax library is strict about the typing so =5= won't work, it has to be a float.
*** Squaring
Now we'll create a function to square the array.

#+begin_src python :results none
def square(x) :
    return x**2
#+end_src

#+begin_src python :results output :exports both
print(f"f({an_array}) -> {square(an_array)}")
#+end_src

#+RESULTS:
: f(5.0) -> 25.0
*** Gradients
 The gradient (derivative) of function =f= with respect to its input =x= is the derivative of \(x^2\).
 - The derivative of \(x^2\) is \(2x\).  
 - When /x/ is /5/, then /2x=10/.

 You can calculate the gradient of a function by using ~trax.fastmath.grad(fun=)~ and passing in the name of the function.
 - In this case the function you want to take the gradient of is =square=.
 - The object returned (saved in =square_gradient= in this example) is a function that can calculate the gradient of =square= for a given =trax.fastmath.numpy= array.

 Use =trax.fastmath.grad= to calculate the gradient (derivative) of the function.

#+begin_src python :results output :exports both
square_gradient = trax.fastmath.grad(fun=square)

print(type(square_gradient))
#+end_src 

#+RESULTS:
: <class 'function'>

Call the newly created function and pass in a value for x (the DeviceArray stored in 'a')

#+begin_src python :results output :exports both
gradient_calculation = square_gradient(an_array)
display(gradient_calculation)
#+end_src

#+RESULTS:
: DeviceArray(10., dtype=float32)


The function returned by =trax.fastmath.grad= takes in /x=5/ and calculates the gradient of =square=, which is /2x/, which equals /10/. The value is also stored as a DeviceArray from the jax library.
* End
  Now that we've had a brief review of Trax let's move on to {{% lancelot title="loading the data" %}}sentiment-analysis-pre-processing-the-data{{% /lancelot %}}.
