<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Implementing Logistic Regression for twitter sentiment analysis." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Implementing Logistic Regression for Tweet Classification | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/implementing-twitter-logistic-regression/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="../twitter-logistic-regression/" rel="prev" title="Twitter Logistic Regression Visualization" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Implementing Logistic Regression for Tweet Classification" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/implementing-twitter-logistic-regression/" property="og:url">
<meta content="Implementing Logistic Regression for twitter sentiment analysis." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-07-14T16:16:22-07:00" property="article:published_time">
<meta content="logistic regression" property="article:tag">
<meta content="nlp" property="article:tag">
<meta content="sentiment analysis" property="article:tag">
<meta content="twitter" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Implementing Logistic Regression for Tweet Classification</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2020-07-14T16:16:22-07:00" itemprop="datePublished" title="2020-07-14 16:16">2020-07-14 16:16</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org3362661">Beginning</a>
<ul>
<li><a href="#org62e3246">Set Up</a></li>
</ul>
</li>
<li><a href="#org7789908">Middle</a>
<ul>
<li><a href="#org08ed8ce">The Tweet Vectorizer</a></li>
<li><a href="#orga26b293">Setup the Training and Testing Sets</a></li>
<li><a href="#orgfe17386">Logistic Regression</a></li>
<li><a href="#orgd8bb421">Train the Model</a></li>
<li><a href="#orge7292ca">Test the Model</a></li>
<li><a href="#org418194b">The Wrong Stuff</a></li>
<li><a href="#orgde4c76b">Some Fresh Tweets</a></li>
<li><a href="#orgc732053">Compare to SKLearn</a></li>
</ul>
</li>
<li><a href="#org8da45c0">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org3362661">
<h2 id="org3362661">Beginning</h2>
<div class="outline-text-2" id="text-org3362661">
<p>This will implement a Logistic Regression model to train on our word counts to classify tweets by sentiment.</p>
</div>
<div class="outline-3" id="outline-container-org62e3246">
<h3 id="org62e3246">Set Up</h3>
<div class="outline-text-3" id="text-org62e3246"></div>
<div class="outline-4" id="outline-container-orgb9a704e">
<h4 id="orgb9a704e">Imports</h4>
<div class="outline-text-4" id="text-orgb9a704e">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">equal</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># this package</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.sentiment</span> <span class="kn">import</span> <span class="n">TweetSentiment</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>

<span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org923c61b">
<h4 id="org923c61b">The Data</h4>
<div class="outline-text-4" id="text-org923c61b">
<p>Download the data (if it hasn't been downloaded before).</p>
<div class="highlight">
<pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"twitter_samples"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">positive</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"positive_tweets.json"</span><span class="p">)</span>
<span class="n">negative</span> <span class="o">=</span> <span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="s2">"negative_tweets.json"</span><span class="p">)</span>

<span class="n">Sentiment</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">positive_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">positive</span><span class="p">)</span>
<span class="n">negative_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org27edbb9">
<h4 id="org27edbb9">For Plotting</h4>
<div class="outline-text-4" id="text-org27edbb9">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"implementing-twitter-logistic-regression"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">990</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">780</span><span class="p">,</span>
    <span class="n">tan</span><span class="o">=</span><span class="s2">"#ddb377"</span><span class="p">,</span>
    <span class="n">blue</span><span class="o">=</span><span class="s2">"#4687b7"</span><span class="p">,</span>
    <span class="n">red</span><span class="o">=</span><span class="s2">"#ce7b6d"</span><span class="p">,</span>
    <span class="n">font_scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">color_cycle</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Cycle</span><span class="p">([</span><span class="s2">"#4687b7"</span><span class="p">,</span> <span class="s2">"#ce7b6d"</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org272f149">
<h4 id="org272f149">Types</h4>
<div class="outline-text-4" id="text-org272f149">
<p>Some stuff for type hinting.</p>
<div class="highlight">
<pre><span></span><span class="n">Tweet</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
<span class="n">PositiveProbability</span> <span class="o">=</span> <span class="n">Tweet</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7789908">
<h2 id="org7789908">Middle</h2>
<div class="outline-text-2" id="text-org7789908"></div>
<div class="outline-3" id="outline-container-org08ed8ce">
<h3 id="org08ed8ce">The Tweet Vectorizer</h3>
<div class="outline-text-3" id="text-org08ed8ce"></div>
<div class="outline-4" id="outline-container-orgcdacc5e">
<h4 id="orgcdacc5e">The Testing</h4>
<div class="outline-text-4" id="text-orgcdacc5e">
<div class="highlight">
<pre><span></span>Feature: A Tweet Count Vectorizer

&lt;&lt;extract-features-feature&gt;&gt;

&lt;&lt;get-vectors-feature&gt;&gt;

&lt;&lt;reset-vectors-feature&gt;&gt;

&lt;&lt;check-rep-vectorizer-tweets-feature&gt;&gt;

&lt;&lt;check-rep-vectorizer-counter-feature&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be</span><span class="p">,</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">contain_exactly</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">raise_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">when</span><span class="p">,</span>
    <span class="n">then</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this testing</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">Columns</span><span class="p">,</span> <span class="n">TweetVectorizer</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="n">and_also</span> <span class="o">=</span> <span class="n">then</span>
<span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/tweet_vectorizer.feature"</span><span class="p">)</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">extract</span><span class="o">-</span><span class="n">features</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectors</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">reset</span><span class="o">-</span><span class="n">vectors</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectorizer</span><span class="o">-</span><span class="n">tweets</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">rep</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectorizer</span><span class="o">-</span><span class="n">counter</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">rep</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org7dd0b8b"></a>Extract Features<br>
<div class="outline-text-5" id="text-org7dd0b8b">
<p>I don't really like the way the coursera people code - but to get a method closer to what's in the assignment I'm going to add this method and call in it the vectors property.</p>
<div class="highlight">
<pre><span></span>Scenario: A user converts a tweet to a feature-vector

Given a Tweet Vectorizer
When the user converts a tweet to a feature-vector
Then it's the expected feature-vector
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: A user converts a tweet to a feature-vector</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_tweet_vectorizer</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">TWEETS</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">TOKENS</span> <span class="o">=</span> <span class="s2">"A B C"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKENS</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">processed</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                          <span class="n">counter</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'B'</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">2</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">3</span><span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="s2">"A B C"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user converts a tweet to a feature-vector"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"A B C"</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"A B C"</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected_array</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it's the expected feature-vector"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_feature_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">expected_array</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span>

    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org517d514"></a>Get the Vectors<br>
<div class="outline-text-5" id="text-org517d514">
<div class="highlight">
<pre><span></span>Scenario: A user retrieves the count vectors
Given a user sets up the Count Vectorizer with tweets
When the user checks the count vectors
Then the first column is the bias colum
And the positive counts are correct
And the negative counts are correct
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Feature: A Tweet Count Vectorizer</span>

<span class="c1"># Scenario: A user retrieves the count vectors</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a user sets up the Count Vectorizer with tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_vectorizer</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">TWEETS</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">TOKENS</span> <span class="o">=</span> <span class="s2">"A B C"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKENS</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                          <span class="n">counter</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'B'</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">2</span><span class="p">,</span>
                                                  <span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">3</span><span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">negative</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
                                      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">TOKENS</span><span class="p">])</span>
                                      <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)])</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">positive</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
                                      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">TOKENS</span><span class="p">])</span>
                                     <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)])</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the count vectors"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_count_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="c1"># kind of silly, but useful for troubleshooting</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the first column is the bias colum"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_bias</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">bias</span><span class="p">]</span><span class="o">==</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@and_also</span><span class="p">(</span><span class="s2">"the positive counts are correct"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_positive_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">positive</span><span class="p">]</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">positive</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@and_also</span><span class="p">(</span><span class="s2">"the negative counts are correct"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_negative_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">negative</span><span class="p">]</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">negative</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">negative</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org6c4f036"></a>Reset the Vectors<br>
<div class="outline-text-5" id="text-org6c4f036">
<div class="highlight">
<pre><span></span>Scenario: The vectors are reset
Given a Tweet Vectorizer with the vectors set
When the user calls the reset method
Then the vectors are gone
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The vectors are reset</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with the vectors set"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()],</span> <span class="n">counter</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user calls the reset method"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_reset</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span><span class="p">))</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the vectors are gone"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_vectors_gone</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org4e1bacf"></a>Check Rep<br>
<div class="outline-text-5" id="text-org4e1bacf">
<div class="highlight">
<pre><span></span>Scenario: the check-rep is called with bad tweets
Given a Tweet Vectorizer with bad tweets
When check-rep is called
Then it raises an AssertionError
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: the check-rep is called with bad tweets</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with bad tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_bad_tweets</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                                          <span class="n">counter</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">(</span>
                                              <span class="n">tweets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"check-rep is called"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_check_rep</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">bad_call</span><span class="p">():</span>
        <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">check_rep</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bad_call</span> <span class="o">=</span> <span class="n">bad_call</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it raises an AssertionError"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_assertion_error</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">bad_call</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">raise_error</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span>Scenario: the check-rep is called with a bad word-counter
Given a Tweet Vectorizer with the wrong counter object
When check-rep is called
Then it raises an AssertionError
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: the check-rep is called with a bad word-counter</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with the wrong counter object"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_bad_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[</span><span class="s2">"apple"</span><span class="p">],</span> <span class="n">counter</span><span class="o">=</span><span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">())</span>
    <span class="k">return</span>

<span class="c1"># When check-rep is called</span>
<span class="c1"># Then it raises an AssertionError</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org6c1d3f6">
<h4 id="org6c1d3f6">The Implementation</h4>
<div class="outline-text-4" id="text-org6c1d3f6">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">attr</span>


<span class="c1"># this package</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="n">Columns</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">bias</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">TweetClass</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># some types</span>
<span class="n">Tweets</span> <span class="o">=</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
<span class="n">Vector</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TweetVectorizer</span><span class="p">:</span>
    <span class="sd">"""A tweet vectorizer</span>

<span class="sd">    Args:</span>
<span class="sd">     tweets: the pre-processed/tokenized tweets to vectorize</span>
<span class="sd">     counter: the word counter with the tweet token counts</span>
<span class="sd">     bias: constant to use for the bias</span>
<span class="sd">    """</span>
    <span class="n">tweets</span><span class="p">:</span> <span class="n">Tweets</span>
    <span class="n">counter</span><span class="p">:</span> <span class="n">WordCounter</span>
    <span class="n">bias</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">1</span>
    <span class="n">_process</span><span class="p">:</span> <span class="n">TwitterProcessor</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TwitterProcessor</span><span class="p">:</span>
        <span class="sd">"""Processes tweet strings to tokens"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">"""The vectorized tweet counts"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span>

    <span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">as_array</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Vector</span><span class="p">:</span>
        <span class="sd">"""converts a single tweet to an array of counts</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: a string tweet to count up</span>
<span class="sd">        as_array: whether to match the assignment format or not</span>

<span class="sd">       Returns:</span>
<span class="sd">        either a list of floats or a 1 x 3 array</span>
<span class="sd">       """</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
            <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">TweetClass</span><span class="o">.</span><span class="n">positive</span><span class="p">)]</span>
                 <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)),</span>
            <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">TweetClass</span><span class="o">.</span><span class="n">negative</span><span class="p">)]</span>
                                <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vector</span><span class="p">])</span> <span class="k">if</span> <span class="n">as_array</span> <span class="k">else</span> <span class="n">vector</span>
        <span class="k">return</span> <span class="n">vector</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Removes the vectors"""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">check_rep</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Checks that the tweets and word-counter are set</span>

<span class="sd">       Raises:</span>
<span class="sd">        AssertionError if one of them isn't right</span>
<span class="sd">       """</span>
        <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span>
        <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="p">)</span> <span class="ow">is</span> <span class="n">WordCounter</span>
        <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orga26b293">
<h3 id="orga26b293">Setup the Training and Testing Sets</h3>
<div class="outline-text-3" id="text-orga26b293">
<p>This is a new step in the process. In the previous explorations we used the entire tweet sets but since we're going to train a model we need to split it into training and testing sets.</p>
<div class="highlight">
<pre><span></span><span class="n">TRAINING_SIZE</span> <span class="o">=</span> <span class="mi">4000</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">20200714</span>
<span class="n">positive_x_train</span><span class="p">,</span> <span class="n">positive_x_test</span><span class="p">,</span> <span class="n">positive_y_train</span><span class="p">,</span> <span class="n">positive_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">positive</span><span class="p">,</span> <span class="n">positive_labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">TRAINING_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">negative_x_train</span><span class="p">,</span> <span class="n">negative_x_test</span><span class="p">,</span> <span class="n">negative_y_train</span><span class="p">,</span> <span class="n">negative_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">negative</span><span class="p">,</span> <span class="n">negative_labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="n">TRAINING_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">positive_x_train</span> <span class="o">+</span> <span class="n">negative_x_train</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">positive_x_test</span> <span class="o">+</span> <span class="n">negative_x_test</span>

<span class="c1"># the initial code I wrote assumes that we're using lists for the tweets and labels</span>
<span class="c1"># so later on convert the y-data to arrays, but keep them al lists for now</span>
<span class="n">SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">positive_y_train</span> <span class="o">+</span> <span class="n">negative_y_train</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">positive_y_test</span> <span class="o">+</span> <span class="n">negative_y_test</span>

<span class="n">x_check</span> <span class="o">=</span> <span class="n">positive</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span> <span class="o">+</span> <span class="n">negative</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span>
<span class="n">y_check</span> <span class="o">=</span> <span class="n">positive_labels</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span> <span class="o">+</span> <span class="n">negative_labels</span><span class="p">[:</span><span class="n">TRAINING_SIZE</span><span class="p">]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">TRAIN_SIZE</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">TRAINING_SIZE</span>
<span class="n">TEST_SIZE</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">positive</span><span class="p">)</span> <span class="o">-</span> <span class="n">TRAIN_SIZE</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">))</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TEST_SIZE</span><span class="p">))</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TRAIN_SIZE</span><span class="p">))</span>
<span class="n">expect</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">TEST_SIZE</span><span class="p">))</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6904bc0">
<h4 id="org6904bc0">Build the Counts</h4>
<div class="outline-text-4" id="text-org6904bc0">
<p>Now we'll build the counts for the training set.</p>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span> 

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
11,443
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
<pre class="example">
[((':(', 0), 3670)]
</pre>
<p>So, as a reminder, the <code>counts</code> is a dictionary-like object that holds <code>(token, sentiment)</code> pairs as keys mapped to the number of tweets that had the token and were classified as having that sentiment. So in the sample given, the token is <code>:(</code> and it was in 3,661 negative tweets (because 0 indicates a negative tweet).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org3cf69d4">
<h4 id="org3cf69d4">Try the Vectorizer</h4>
<div class="outline-text-4" id="text-org3cf69d4">
<p><b>Note:</b> I changed the regular expression tweet cleaner to only remove URIs up to a whitespace, because it was wiping out emoticons that came after them so my numbers no longer match the Coursera numbers exactly.</p>
<div class="highlight">
<pre><span></span><span class="n">check_counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">x_check</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_check</span><span class="p">)</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">x_check</span><span class="p">,</span> <span class="n">counter</span><span class="o">=</span><span class="n">check_counter</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First Tweet: </span><span class="si">{</span><span class="n">x_check</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"First count vector: </span><span class="si">{</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">actual</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"nunya noa agar"</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">expected</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
</pre></div>
<pre class="example">
First Tweet: #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)
First count vector: [   1 3133   61]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgfe17386">
<h3 id="orgfe17386">Logistic Regression</h3>
<div class="outline-text-3" id="text-orgfe17386">
<p>Now that we have the data it's time to implement the <a href="https://www.wikiwand.com/en/Logistic_regression">Logistic Regression</a> model to classify tweets as positive or negative.</p>
</div>
<div class="outline-4" id="outline-container-org6c72dc7">
<h4 id="org6c72dc7">The Sigmoid</h4>
<div class="outline-text-4" id="text-org6c72dc7">
<p>Logistic Regression uses a version of <a href="https://www.wikiwand.com/en/Sigmoid_function">the Sigmoid Function</a> called the Standard <a href="https://www.wikiwand.com/en/Logistic_function">Logistic Function</a> to measure whether an entry has passed the threshold for classification. This is the mathematical definition:</p>
<p>\[ \sigma(z) = \frac{1}{1 + e^{-x \cdot \theta}} \]</p>
<p>The numerator (1) determines the maximum value for the function, so in this case the range is from 0 to 1 and we can interpret \(\sigma(z)\) as the probability that a tweet (<i>z</i>) is positive (<i>1</i>). The interpretation of \(\sigma(z)\) is it's the probability that <i>z</i> (a vector representation of a tweet times the weights) is classified as 1 (having a positive sentiment). So we could re-write this as:</p>
<p>\[ P(Y=1 | z) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2)}} \]</p>
<p>Where \(x_1\) is the sum of the positive tweet counts for the tokens in \(x\) and \(x_2\) is the sum of the negative tweet counts for the tokens. \(\beta_0\) is our bias and \(\beta_1\) and \(\beta_2\) are the weights that we're going to find by training our model.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">:</span> <span class="n">Tweet</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PositiveProbability</span><span class="p">:</span>
    <span class="sd">"""Calculates the logistic function value</span>

<span class="sd">    Args:</span>
<span class="sd">     z: input to the logistic function (float or array)</span>

<span class="sd">    Returns:</span>
<span class="sd">     calculated sigmoid for z</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org55a15cf"></a>A Little Test<br>
<div class="outline-text-5" id="text-org55a15cf">
<p>We have a couple of given values to test that our sigmoid is correct.</p>
<div class="highlight">
<pre><span></span><span class="n">expect</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">4.92</span><span class="p">),</span> <span class="mf">0.9927537604041685</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>

<span class="n">expected</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9927537604041685</span><span class="p">])</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">4.92</span><span class="p">]))</span>

<span class="n">expect</span><span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="orga375565"></a>Plotting It<br>
<div class="outline-text-5" id="text-orga375565">
<p>Let's see what the output looks like.</p>
<div class="highlight">
<pre><span></span><span class="n">min_x</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
<span class="n">max_x</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">halfway</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plot_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">curve</span> <span class="o">=</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">)</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Curve</span><span class="p">([(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">halfway</span><span class="p">),</span> <span class="p">(</span><span class="n">max_x</span><span class="p">,</span> <span class="n">halfway</span><span class="p">)],</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">curve</span> <span class="o">*</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Sigmoid"</span><span class="p">,</span>
    <span class="n">show_grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">embedded</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sigmoid_function"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">embedded</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="sigmoid_function.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Looking at the plot you can see that the probability that a tweet is positive is 0.5 when the input is 0, becomes more likely the more positive the input is, and is less likely the more negative an input is. Next we'll need to look at how to train our model.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org297ed42">
<h4 id="org297ed42">The Loss Function</h4>
<div class="outline-text-4" id="text-org297ed42">
<p>To train our model we need a way to measure how well (or in this case poorly) it's doing. For this we'll use the <a href="http://wiki.fast.ai/index.php/Log_Loss">Log Loss</a> function which is the negative logarithm of our probability - so for each tweet, we'll calculate \(\sigma\) (which is the probability that it's positive) and take the negative logarithm of it to get the log-loss.</p>
<p>The formula for loss:</p>
<p>\[ Loss = - \left( y\log (p) + (1-y)\log (1-p) \right) \]</p>
<p>\(y\) is the classification of the tweet (1 or 0) so when the tweet is classified 1 (positive) the right term becomes 0 and when the tweet is classified 0 (negative) the left term becomes 0 so this is the equivalent of:</p>
<div class="highlight">
<pre><span></span><span class="k">if</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
<p>Where \(p\) is the probability that the tweet is positive and \(1 - p\) is the probability that it isn't (so it's negative since that's the only alternative). We take the negative of the logarithm because \(log(p)\) is negative (all the values of \(p\) are between 0 and 1) so negating it makes the output positive.</p>
<p>We can fill it in to make it match what we're going to actually calculate - for the \(i^{th}\) item in our dataset \(p = \sigma(z^i \cdot \theta)\) and the equation becomes:</p>
<p>\[ Loss = - \left( y^{(i)}\log (\sigma(z^{(i)} \cdot \theta)) + (1-y^{(i)})\log (1-\sigma(z^{(i)} \cdot \theta)) \right) \]</p>
<div class="highlight">
<pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"p"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
    <span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span> 
<span class="p">})</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"p"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Log-Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Loss (Y=1)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"log_loss_example"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="log_loss_example.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So what is this telling us? This is for the case where a tweet is labeled positive and at the far left, near 0 (<code>log(0)</code> is undefined so you can use a really small probability but not 0) our model is saying that it probably isn't a positive tweet, so the log-loss is fairly high, then as we move along the x-axis our model is saying that it is more and more likely that the tweet is positive so our log-loss goes down, until we reach the point where our model says that it's 100% guaranteed to be a positive tweet, at which point our log-loss drops to zero. Fairly intuitive.</p>
<p>Let's look at the case where the tweet is actually negative (<i>y=0</i>). Since <i>p</i> is the probability that it's positive, when the label is 0 we need to take the log of <i>1-p</i> to see what the model thinks the probability is that it's negative.</p>
<div class="highlight">
<pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">probabilities</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"p"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
    <span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span> 
<span class="p">})</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"p"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Log-Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Loss (Y=0)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"log_loss_y_0_example"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="log_loss_y_0_example.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So now we have basically the opposite loss. In this case the tweet is not positive so when the model puts a low likelihood that the tweet is positive the log-loss is small, but as you move along the x-axis the model is giving more probability to the notion that the tweet is positive so the log-loss gets larger.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org7478e13">
<h4 id="org7478e13">Training the Model</h4>
<div class="outline-text-4" id="text-org7478e13">
<p>To train the model we're going to use <a href="https://www.wikiwand.com/en/Gradient_descent">Gradient Descent</a>. What this means is that we're going to use the <i>gradient</i> of our loss function to figure out how to update our weights. The <i>gradient</i> is just the slope of the loss-function (but generalized to multiple dimensions).</p>
<p>How do we do this? First we calculate our model's estimate of the input being positive, then we calculate the gradient of its loss. If you remember from calculus the slope of a line is the derivative of its function so instead of calculating the loss, we'll calculate the derivative of the loss-function which is given as:</p>
<p>\[ \nabla_{\theta}L_{\theta} = \left [ \sigma(x \cdot \theta) - y \right] x_j \]</p>
<p>The rightmost term \(x_j\) represents one term in the input vector, the one that matches the weight - this has to be repeated for each \(\beta\) in \(\theta\) so in our case it will be repeated three times, with \(x\) being 1 for the bias term.</p>
<p>It's called stochastic gradient descent because the inputs are chosen randomly from our training set. This turns out to not give you a smooth descent so we're going to do <b>batch training</b> which changes our gradient a little.</p>
<p>\[ \nabla_{\theta_j}L_{\theta} = \frac{1}{m} \sum_{i=1}^m(\sigma(x \cdot \theta)-y)x_j \]</p>
<p>Our gradient is now the average of the gradients for each of the inputs in our training set. We update the weights by subtracting a fraction of the difference between the current weights and the gradient. The fraction \(\eta\) is called the <i>learning rate</i> and it controls how much the weights change, representng how fast our model will learn. If it is too large we can miss the minimum and if it's too large it will take too long to train the model, so we need to choose the right value for it to reach the minima within a feasible time.</p>
<p>Here's the algorithm in the rough.</p>
<ul class="org-ul">
<li><i>L</i>: Loss Function</li>
<li>\(\sigma\): probability function parameterized by \(\theta\)</li>
<li><i>x</i>: set of training inputs</li>
<li><i>y</i>: set of training labels</li>
</ul>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<pre id="gradientdescent" style="display:hidden">
\begin{algorithm}
\caption{Stochastic Gradient Descent}
\begin{algorithmic}
\STATE $\theta \gets 0$
\WHILE{not done}

 \FOR{each $(x^{(i)},y^{(i)})$ in training data}
  \State $\hat{y} \gets \sigma(x^{(i)}; \theta)$
  \State $loss \gets L(\hat{y}^{(i)}, y^{(i)})$
  \State $g \gets \nabla_{\theta} L(\hat{y}^{(i)}, y^{(i)})$
  \State $\theta \gets \theta - \eta g$
 \ENDFOR

\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre>
<p>We can translate this a little more.</p>
<pre id="gradientdescentengrish" style="display:hidden">
\begin{algorithm}
\caption{Stochastic Gradient Descent}
\begin{algorithmic}
\STATE Initialize the weights
\WHILE{the loss is still too high}

 \FOR{each $(x^{(i)},y^{(i)})$ in training data}
  \State What is our probability that the input is positive?
  \State How far off are we?
  \State What direction would we need to head to maximize the error?
  \State Let's go in the opposite direction.
 \ENDFOR

\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescent"));
    pseudocode.renderElement(document.getElementById("gradientdescentengrish"));
</script>
<p>Note that the losses aren't needed for the algorithm to train the model, just for assessing how well the model did.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orge8e6763">
<h4 id="orge8e6763">Implement It</h4>
<div class="outline-text-4" id="text-orge8e6763"></div>
<ul class="org-ul">
<li><a id="org7d77d33"></a>The Function<br>
<div class="outline-text-5" id="text-org7d77d33">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                     <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                     <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Finds the weights for the model</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the tweet vectors</span>
<span class="sd">     y: the positive/negative labels</span>
<span class="sd">     weights: the regression weights</span>
<span class="sd">     learning_rate: (eta) how much to update the weights</span>
<span class="sd">     iterations: the number of times to repeat training</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">learning_rate</span> <span class="o">/=</span> <span class="n">rows</span>
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
        <span class="c1"># average loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)))</span> <span class="o">+</span>
                               <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">))))</span><span class="o">/</span><span class="n">rows</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
<p>If you look at the implementation you can see that there are some changes made to it from what I wrote earlier. This is because the algorithm I wrote in pseudocode came from a book while the implementation that I made came from a Coursera assignment. The main differences being that we use a set number of iterations to train the model and the learning rate is divided by the number of training examples. Of course, you could just divide the learning rate before passing it in to the function so it doesn't really change it that much. I also had to take into account the fact that you can't just take a dot product of two matrices if their shapes aren't compatible - the rows of the left hand matrix has to match the columns of the right hand matrix) so there's some transposing of matrices being done. Our actual implementation might be more like this.</p>
<pre id="gradientdescentimplementation" style="display:hidden">
\begin{algorithm}
\caption{Stochastic Gradient Descent Implemented}
\begin{algorithmic}
\STATE $\theta \gets 0$
\STATE $m \gets rows(X)$
\FOR{$iteration \in$ \{0 $\ldots iterations-1$ \}}
  \STATE $\hat{Y} \gets \sigma(X \cdot \theta)$
  \STATE $loss \gets -\frac{1}{m}(Y^T \cdot \ln \hat{Y}) + (1 - Y)^T \cdot (\ln 1 - \hat{Y})$
  \STATE $\nabla \gets \sum (\hat{Y} - Y)^T \cdot x$
  \STATE $\theta \gets \theta - \frac{\eta}{m} \nabla^T$
 \ENDFOR
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescentimplementation"));
</script></div>
</li>
<li><a id="orga31ed2d"></a>Test It<br>
<div class="outline-text-5" id="text-orga31ed2d">
<p>First we'll make a fake (random) input set.</p>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2000</span>
<span class="n">fake_tweet_vectors</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">fake</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>Now, the fake labels - we'll make around 35% of them negative and the rest positive.</p>
<div class="highlight">
<pre><span></span><span class="n">fake_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.35</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="org1ed8c98"></a>Do the Descent<br>
<div class="outline-text-5" id="text-org1ed8c98">
<p>So now we can pass our test data into the gradient descent function and see what happens.</p>
<div class="highlight">
<pre><span></span><span class="n">fake_weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">fake_loss</span><span class="p">,</span> <span class="n">fake_weights</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">fake_tweet_vectors</span><span class="p">,</span>
                                           <span class="n">y</span><span class="o">=</span><span class="n">fake_labels</span><span class="p">,</span> 
                                           <span class="n">weights</span><span class="o">=</span><span class="n">fake_weights</span><span class="p">,</span>
                                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                                           <span class="n">iterations</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">fake_loss</span><span class="p">,</span> <span class="mf">0.67094970</span><span class="p">,</span> <span class="n">rel_tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The log-loss after training is </span><span class="si">{</span><span class="n">fake_loss</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The trained weights are </span><span class="si">{</span><span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">fake_weights</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The log-loss after training is 0.67094970.
The trained weights are [4.1e-07, 0.00035658, 7.309e-05]
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgd8bb421">
<h3 id="orgd8bb421">Train the Model</h3>
<div class="outline-text-3" id="text-orgd8bb421">
<p>Now that we have our parts let's actually train the model using the real training data. At this point we need everything to be numpy arrays so I'll convert the y-sets (the vectorizer already does this for the x-sets).</p>
<div class="highlight">
<pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">train_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">counter</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">final_loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The log-loss after training is </span><span class="si">{</span><span class="n">final_loss</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The resulting vector of weights is </span><span class="si">{</span><span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weights</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The log-loss after training is 0.22361758.
The resulting vector of weights is [6e-08, 0.00053882, -0.00055969]
</pre>
<div class="highlight">
<pre><span></span><span class="n">plot_losses</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span><span class="p">})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">plot_losses</span><span class="o">.</span><span class="n">hvplot</span><span class="p">()</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Training Losses"</span><span class="p">,</span>
                            <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                            <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                            <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                            <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span>
                            <span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"training_loss"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="training_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>As you can see, the losses are still on the decline, but we'll stop here to see how it's doing.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orge7292ca">
<h3 id="orge7292ca">Test the Model</h3>
<div class="outline-text-3" id="text-orge7292ca">
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TweetSentiment</span><span class="p">:</span>
    <span class="sd">"""Predicts the sentiment of a tweet</span>

<span class="sd">    Args:</span>
<span class="sd">     vectorizer: something to vectorize tweets</span>
<span class="sd">     theta: vector of weights for the logistic regression model</span>
<span class="sd">    """</span>
    <span class="n">vectorizer</span><span class="p">:</span> <span class="n">TweetVectorizer</span>
    <span class="n">theta</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>

    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">"""the logistic function</span>

<span class="sd">       Args:</span>
<span class="sd">        vectors: a matrix of bias, positive, negative counts</span>

<span class="sd">       Returns:</span>
<span class="sd">        array of probabilities that the tweets are positive</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">vectors</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">probability_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">"""Calculates the probability of the tweet being positive</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: a tweet to classify</span>

<span class="sd">       Returns:</span>
<span class="sd">        the probability that the tweet is a positive one</span>
<span class="sd">       """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">"""Decides if the tweet was positive or not</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: the tweet message to classify.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">"""Get the sentiments of the vectorized tweets</span>

<span class="sd">       Note:</span>
<span class="sd">        this assumes that the vectorizer passed in has the tweets</span>

<span class="sd">       Returns:</span>
<span class="sd">        array of predicted sentiments (1 for positive 0 for negative)</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">sentiment</span> <span class="o">=</span> <span class="n">TweetSentiment</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'I am happy'</span><span class="p">,</span> <span class="s1">'I am bad'</span><span class="p">,</span> <span class="s1">'this movie should have been great.'</span><span class="p">,</span> <span class="s1">'great'</span><span class="p">,</span> <span class="s1">'great great'</span><span class="p">,</span> <span class="s1">'great great great'</span><span class="p">,</span> <span class="s1">'great great great great'</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">tweet</span><span class="si">}</span><span class="s1"> -&gt; </span><span class="si">{</span><span class="n">sentiment</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
I am happy -&gt; 0.5194180879292754
I am bad -&gt; 0.49324236291188817
this movie should have been great. -&gt; 0.5155519549115258
great -&gt; 0.5159253614387586
great great -&gt; 0.5318184293628917
great great great -&gt; 0.5476472009859494
great great great great -&gt; 0.5633801766216647
</pre>
<p>Strangely very near the center. Probably because the words weren't that commonly used in our training set.</p>
<div class="highlight">
<pre><span></span><span class="n">totals</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Great positive percentage: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="s1">'great'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="o">/</span><span class="n">totals</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> %"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Great negative percentage: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="s1">'great'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="o">/</span><span class="n">totals</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> % "</span><span class="p">)</span>
</pre></div>
<pre class="example">
Great positive percentage: 0.25 %
Great negative percentage: 0.03 % 
</pre>
<p>Now we can see how it did overall.</p>
<div class="highlight">
<pre><span></span><span class="n">y_test</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">test_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">counter</span><span class="p">)</span>
<span class="n">sentiment</span> <span class="o">=</span> <span class="n">TweetSentiment</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">sentiment</span><span class="p">()</span>
<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.9945
</pre>
<p>That does surprisingly well. But what did we get wrong?</p>
</div>
</div>
<div class="outline-3" id="outline-container-org418194b">
<h3 id="org418194b">The Wrong Stuff</h3>
<div class="outline-text-3" id="text-org418194b">
<div class="highlight">
<pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">wrong_places</span> <span class="o">=</span> <span class="n">predictions</span> <span class="o">!=</span> <span class="n">y_test</span>
<span class="n">wrong</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">wrong_places</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wrong</span><span class="p">))</span>
</pre></div>
<pre class="example">
11
</pre>
<div class="highlight">
<pre><span></span><span class="n">wrong_ys</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">wrong_places</span><span class="p">]</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrong</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"*"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tweet: </span><span class="si">{</span><span class="n">tweet</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokens: </span><span class="si">{</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Probability Positive: </span><span class="si">{</span><span class="n">sentiment</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classification: </span><span class="si">{</span><span class="n">wrong_ys</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example">
**********
Tweet: I'm playing Brain Dots : ) #BrainDots
http://t.co/ilDzDRHf9d http://t.co/VTXNFCPFuI
Tokens: ["i'm", 'play', 'brain', 'dot', 'braindot']
Probability Positive: 0.48526803083166703
Classification: 1

**********
Tweet: @ellekagaoan @chinmarquez Catch up once in a while :( &amp;gt;:D&amp;lt; @aditriphosphate @ErinMonzon
Tokens: ['catch', ':(', '&gt;:d']
Probability Positive: 0.11389833615259448
Classification: 1

**********
Tweet: off to the park to get some sunlight : )
Tokens: ['park', 'get', 'sunlight']
Probability Positive: 0.49574440240612333
Classification: 1

**********
Tweet: Google has made @narendramodi really very sad about @ImranKhanPTI not becoming Prime Minister. :p @PTIofficial @pmln_org
Tokens: ['googl', 'made', 'realli', 'sad', 'becom', 'prime', 'minist', ':p']
Probability Positive: 0.49947331811099865
Classification: 1

**********
Tweet: @planetjedward GoodMorning ! What's coming next? =:D =:D
Tokens: ['goodmorn', "what'", 'come', 'next', '=:', '=:']
Probability Positive: 0.49786597951455913
Classification: 1

**********
Tweet: @_sarah_mae omg you can't just tell this and don't say more :p can't wait to know !!!! ❤️
Tokens: ['omg', "can't", 'tell', 'say', ':p', "can't", 'wait', 'know', '❤', '️']
Probability Positive: 0.48000079019523884
Classification: 1

**********
Tweet: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5
Tokens: ["i'm", 'play', 'brain', 'dot', 'braindot']
Probability Positive: 0.48526803083166703
Classification: 1

**********
Tweet: @samayanyan yes thank u!! Oh damn that hella sucks :-( but at least u had a really good time that's all that matters
Tokens: ['ye', 'thank', 'u', 'oh', 'damn', 'hella', 'suck', ':-(', 'least', 'u', 'realli', 'good', 'time', "that'", 'matter']
Probability Positive: 0.5145779186318544
Classification: 0

**********
Tweet: @phenomyoutube u probs had more fun with david than me : (
Tokens: ['u', 'prob', 'fun', 'david']
Probability Positive: 0.5101260021527917
Classification: 0

**********
Tweet: @wtfxmbs AMBS please it's harry's jeans :)):):):(
Tokens: ['amb', 'pleas', "harry'", 'jean', ':)', '):', '):', '):']
Probability Positive: 0.8218858541205992
Classification: 0

**********
Tweet: @hinata_shouyno fuck u Neil u ruined it &amp;gt;:-(
Tokens: ['fuck', 'u', 'neil', 'u', 'ruin', '&gt;:-(']
Probability Positive: 0.5095962377275693
Classification: 0
</pre>
<p>The first thing to notice is that there's a duplicate tweet (the one about "Brain Dots", whatever that is). Another thing to note is that sometimes there are spaces between the characters in the emoticons, which the tokenizer probably can't figure out should be togethter, along with that weird <code>:)):):):(</code> emoticon. I'm not really soure that all of the positive tweets are actually positive, nor is it always obvious what they are about - what does "AMBS please it's harry's jeans" mean?</p>
<p>In at least in one case the NLTK vectorizer seems to mangle an emoticon as well:</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">process</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s2">"=:D"</span><span class="p">))</span>
</pre></div>
<pre class="example">
['=:', 'd']
</pre>
<p>That last one looks really wrong, though, let's take a look at it.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">wrong</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">token</span><span class="si">}</span><span class="s2">: positive=</span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="si">}</span><span class="s2"> negative=</span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
fuck: positive=23 negative=47
u: positive=206 negative=148
neil: positive=2 negative=0
u: positive=206 negative=148
ruin: positive=3 negative=10
&gt;:-(: positive=0 negative=2
</pre>
<p>So the big problem seems to be that the letter "u" is there twice and it's mostly seen as a positive. Why am I allowing single letters? There should probably be a minimum length or something. Anyway, I'm not sure you could get much better.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgde4c76b">
<h3 id="orgde4c76b">Some Fresh Tweets</h3>
<div class="outline-text-3" id="text-orgde4c76b">
<p>First someone reacting to a post about the <a href="https://www.atlasobscura.com/places/clown-motel">Clown Motel</a> in Tonopah, Nevada. The previous link was to Atlas Obscura, but the tweet came from <a href="https://www.thrillist.com/travel/nation/clown-motel-nevada-hame-anand">thrillist</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">sentiments</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">"negative"</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">"positive"</span><span class="p">}</span>
<span class="n">tweet</span> <span class="o">=</span> <span class="s2">"Nah dude. I drove by that at night and it was the creepiest thing ever. The whole town gave me bad vibes. I still shudder when I think about it."</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classified as </span><span class="si">{</span><span class="n">sentiments</span><span class="p">[</span><span class="n">sentiment</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Classified as negative
</pre>
<p>Seems reasonable.</p>
<div class="highlight">
<pre><span></span><span class="n">tweet</span> <span class="o">=</span> <span class="s2">"This is just dope. Quaint! I’d love to have an ironic drive-in wedding in Las Vegas and then stay in a clown motel as newly weds for one night. I bet they have Big Clown Suits for newly weds, haha."</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classified as </span><span class="si">{</span><span class="n">sentiments</span><span class="p">[</span><span class="n">sentiment</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Classified as positive
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgc732053">
<h3 id="orgc732053">Compare to SKLearn</h3>
<div class="outline-text-3" id="text-orgc732053">
<div class="highlight">
<pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">"neg_log_loss"</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.9925
</pre>
<p>So it didn't do quite as well, but pretty much the same just using the default parameters. We could probably do a parameter search but that's okay for now.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8da45c0">
<h2 id="org8da45c0">End</h2>
<div class="outline-text-2" id="text-org8da45c0">
<p>Let's save our weights for later. I was going to just write it to a file, but you seem to lose some precision converting the values to strings. numpy has a function called <a href="https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html">savetxt</a> but it didn't behave exactly like I thought it would and I prefer pandas so I'll save it that way.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_REGRESSION_WEIGHTS"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">weights_frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">weights_frame</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>We should also save the counts because we're going to need that for later.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>

<span class="n">counts</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">counts</span><span class="p">[</span><span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_REGRESSION_DATA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">counts</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p><b>Note:</b> This is a re-working of an exercise from Coursera's Natural Language Processing specialization.</p>
<p>I also referred to this revision in progress:</p>
<ul class="org-ul">
<li>Jurafsky, D. & Martin, J. (2020). Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition. 3rd Edition draft. <a href="https://web.stanford.edu/~jurafsky/slp3/">(URL)</a></li>
</ul>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/logistic-regression/" rel="tag">logistic regression</a></li>
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/sentiment-analysis/" rel="tag">sentiment analysis</a></li>
<li><a class="tag p-category" href="../../../categories/twitter/" rel="tag">twitter</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../twitter-logistic-regression/" rel="prev" title="Twitter Logistic Regression Visualization">Previous post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
