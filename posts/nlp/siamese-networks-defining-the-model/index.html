<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Defining the Siamese Network." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Siamese Networks: Defining the Model | Neurotic Networking</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/siamese-networks-defining-the-model/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<link href="../../../apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="../../../favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="../../../favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="../../../site.webmanifest" rel="manifest">
<meta content="Cloistered Monkey" name="author">
<link href="../siamese-networks-the-data-generator/" rel="prev" title="Siamese Networks: The Data Generator" type="text/html">
<link href="../siamese-networks-hard-negative-mining/" rel="next" title="Siamese Networks: Hard Negative Mining" type="text/html">
<meta content="Neurotic Networking" property="og:site_name">
<meta content="Siamese Networks: Defining the Model" property="og:title">
<meta content="https://necromuralist.github.io/Neurotic-Networking/posts/nlp/siamese-networks-defining-the-model/" property="og:url">
<meta content="Defining the Siamese Network." property="og:description">
<meta content="article" property="og:type">
<meta content="2021-01-25T19:36:23-08:00" property="article:published_time">
<meta content="nlp" property="article:tag">
<meta content="siamese networks" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="../../../"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="../../../archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="../../../categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="../../../rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href=".">Siamese Networks: Defining the Model</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2021-01-25T19:36:23-08:00" itemprop="datePublished" title="2021-01-25 19:36">2021-01-25 19:36</time></a></p>
<p class="sourceline"><a class="sourcelink" href="index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org4d1266c">Understanding the Siamese Network</a>
<ul>
<li><a href="#org810ccd7">Imports</a></li>
<li><a href="#org75914f9">Set Up</a></li>
</ul>
</li>
<li><a href="#orgcabf205">Implementation</a>
<ul>
<li><a href="#org77318ef">Check the Model</a></li>
</ul>
</li>
<li><a href="#org9ae1356">Bundle It Up</a>
<ul>
<li><a href="#org0f22292">Imports</a></li>
<li><a href="#org7b90d49">Constants</a></li>
<li><a href="#org10d3332">Normalize</a></li>
<li><a href="#orgcac7a3d">The Siamese Model</a>
<ul>
<li><a href="#org3155aee">The Processor</a></li>
<li><a href="#org1e4bf1d">The Model</a></li>
</ul>
</li>
<li><a href="#org202660d">Check It Out</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4d1266c">
<h2 id="org4d1266c">Understanding the Siamese Network</h2>
<div class="outline-text-2" id="text-org4d1266c">
<p>A Siamese network is a neural network which uses the same weights while working in tandem on two different input vectors to compute comparable output vectors.</p>
<p>You get the question embedding, run it through an LSTM layer, normalize \(v_1\) and \(v_2\), and finally use a triplet loss (explained below) to get the corresponding cosine similarity for each pair of questions. As usual, you will start by importing the data set. The triplet loss makes use of a baseline (anchor) input that is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized. In math equations, you are trying to maximize the following.</p>
<p>\[ \mathcal{L}(A, P, N)=\max \left(\|\mathrm{f}(A)-\mathrm{f}(P)\|^{2}-\|\mathrm{f}(A)-\mathrm{f}(N)\|^{2}+\alpha, 0\right) \]</p>
<p><i>A</i> is the anchor input, for example \(q1_1\), \(P\) the duplicate input, for example, \(q2_1\), and \(N\) the negative input (the non duplicate question), for example \(q2_2\). \(\alpha\) is a margin; you can think about it as a safety net, or by how much you want to push the duplicates from the non duplicates.</p>
</div>
<div class="outline-3" id="outline-container-org810ccd7">
<h3 id="org810ccd7">Imports</h3>
<div class="outline-text-3" id="text-org810ccd7">
<div class="highlight">
<pre><span></span><span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">trax.fastmath.numpy</span> <span class="k">as</span> <span class="nn">fastnp</span>
<span class="kn">import</span> <span class="nn">trax.layers</span> <span class="k">as</span> <span class="nn">tl</span>
<span class="c1"># This Project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TOKENS</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org75914f9">
<h3 id="org75914f9">Set Up</h3>
<div class="outline-text-3" id="text-org75914f9">
<div class="highlight">
<pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgcabf205">
<h2 id="orgcabf205">Implementation</h2>
<div class="outline-text-2" id="text-orgcabf205">
<p>To implement this model, you will be using `trax`. Concretely, you will be using the following functions.</p>
<ul class="org-ul">
<li><code>tl.Serial</code>: Combinator that applies layers serially (by function composition) allows you set up the overall structure of the feedforward. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/combinators.py#L26">source code</a>
<ul class="org-ul">
<li>You can pass in the layers as arguments to <code>Serial</code>, separated by commas.</li>
<li>For example: <code>tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))</code></li>
</ul>
</li>
<li><code>tl.Embedding</code>: Maps discrete tokens to vectors. It will have shape (vocabulary length X dimension of output vectors). The dimension of output vectors (also called d_feature) is the number of elements in the word embedding. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113">source code</a>
<ul class="org-ul">
<li><code>tl.Embedding(vocab_size, d_feature)</code>.</li>
<li><code>vocab_size</code> is the number of unique words in the given vocabulary.</li>
<li><code>d_feature</code> is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).</li>
</ul>
</li>
<li><code>tl.LSTM</code> The LSTM layer. It leverages another Trax layer called <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTMCell"><code>LSTMCell</code></a>. The number of units should be specified and should match the number of elements in the word embedding. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/rnn.py#L87">source code</a>
<ul class="org-ul">
<li><code>tl.LSTM(n_units)</code> Builds an LSTM layer of n_units.</li>
</ul>
</li>
<li><code>tl.Mean</code>: Computes the mean across a desired axis. Mean uses one tensor axis to form groups of values and replaces each group with the mean value of that group. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean">docs</a> / <a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L276">source code</a>
<ul class="org-ul">
<li><code>tl.Mean(axis=1)</code> mean over columns.</li>
</ul>
</li>
<li><code>tl.Fn</code> Layer with no weights that applies the function f, which should be specified using a lambda syntax. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn">docs</a> / <a href="https://github.com/google/trax/blob/70f5364dcaf6ec11aabbd918e5f5e4b0f5bfb995/trax/layers/base.py#L576">source code</a>
<ul class="org-ul">
<li><i>x</i> -&gt; This is used for cosine similarity.</li>
<li><code>tl.Fn('Normalize', lambda x: normalize(x))</code> Returns a layer with no weights that applies the function <code>f</code></li>
</ul>
</li>
<li><code>tl.parallel</code>: It is a combinator layer (like <code>Serial</code>) that applies a list of layers in parallel to its inputs. <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Parallel">docs</a> / <a href="https://github.com/google/trax/blob/37aba571a89a8ad86be76a569d0ec4a46bdd8642/trax/layers/combinators.py#L152">source code</a></li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">Siamese</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">),</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'train'</span><span class="p">):</span>
    <span class="sd">"""Returns a Siamese model.</span>

<span class="sd">    Args:</span>
<span class="sd">       vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).</span>
<span class="sd">       d_model (int, optional): Depth of the model. Defaults to 128.</span>
<span class="sd">       mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.</span>

<span class="sd">    Returns:</span>
<span class="sd">       trax.layers.combinators.Parallel: A Siamese model. </span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  <span class="c1"># normalizes the vectors to have L2 norm 1</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">fastnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fastnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="n">q_processor</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>  <span class="c1"># Processor will run on Q1 and Q2.</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="c1"># Embedding layer</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">d_model</span><span class="p">),</span> <span class="c1"># LSTM layer</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># Mean over columns</span>
        <span class="n">tl</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span>  <span class="c1"># Apply normalize function</span>
    <span class="p">)</span>  <span class="c1"># Returns one vector of shape [batch_size, d_model].</span>

    <span class="c1"># Run on Q1 and Q2 in parallel.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">q_processor</span><span class="p">,</span> <span class="n">q_processor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org77318ef">
<h3 id="org77318ef">Check the Model</h3>
<div class="outline-text-3" id="text-org77318ef">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Siamese</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgd45ef27">
Parallel_in2_out2[
  Serial[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize
  ]
  Serial[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize
  ]
]
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org9ae1356">
<h2 id="org9ae1356">Bundle It Up</h2>
<div class="outline-text-2" id="text-org9ae1356">
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">constants</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">normalize</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">siamese</span><span class="o">-</span><span class="n">network</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">the</span><span class="o">-</span><span class="n">processor</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">the</span><span class="o">-</span><span class="n">model</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org0f22292">
<h3 id="org0f22292">Imports</h3>
<div class="outline-text-3" id="text-org0f22292">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">trax</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">trax.fastmath</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">fastmath_numpy</span>

<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">trax</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7b90d49">
<h3 id="org7b90d49">Constants</h3>
<div class="outline-text-3" id="text-org7b90d49">
<div class="highlight">
<pre><span></span><span class="n">Axis</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Axis"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"columns"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">])</span>
<span class="n">Constants</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">"Constants"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"model_depth"</span><span class="p">,</span> <span class="s2">"axis"</span><span class="p">])</span>

<span class="n">AXIS</span> <span class="o">=</span> <span class="n">Axis</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">CONSTANTS</span> <span class="o">=</span> <span class="n">Constants</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">AXIS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org10d3332">
<h3 id="org10d3332">Normalize</h3>
<div class="outline-text-3" id="text-org10d3332">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Normalizes the vectors to have L2 norm 1</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the array of vectors to normalize</span>

<span class="sd">    Returns:</span>
<span class="sd">     normalized version of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">/</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fastmath_numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>
                                                    <span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">last</span><span class="p">,</span>
                                                    <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcac7a3d">
<h3 id="orgcac7a3d">The Siamese Model</h3>
<div class="outline-text-3" id="text-orgcac7a3d">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SiameseModel</span><span class="p">:</span>
    <span class="sd">"""The Siamese network model</span>

<span class="sd">    Args:</span>
<span class="sd">     vocabulary_size: number of tokens in the vocabulary</span>
<span class="sd">     model_depth: depth of our embedding layer</span>
<span class="sd">     mode: train|eval|predict</span>
<span class="sd">    """</span>
    <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">model_depth</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">model_depth</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span><span class="o">=</span><span class="s2">"train"</span>
    <span class="n">_processor</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Serial</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_model</span><span class="p">:</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">combinators</span><span class="o">.</span><span class="n">Parallel</span><span class="o">=</span><span class="kc">None</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3155aee">
<h4 id="org3155aee">The Processor</h4>
<div class="outline-text-4" id="text-org3155aee">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">processor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">:</span>
    <span class="sd">"""The Question Processor"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span> 
        <span class="p">)</span> 
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processor</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1e4bf1d">
<h4 id="org1e4bf1d">The Model</h4>
<div class="outline-text-4" id="text-org1e4bf1d">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">trax</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">:</span>
    <span class="sd">"""The Siamese Model"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">processor</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Serial</span><span class="p">(</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_depth</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">CONSTANTS</span><span class="o">.</span><span class="n">axis</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Fn</span><span class="p">(</span><span class="s2">"Normalize"</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span> 
        <span class="p">)</span> 

        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Parallel</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">processor</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org202660d">
<h3 id="org202660d">Check It Out</h3>
<div class="outline-text-3" id="text-org202660d">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.nlp.siamese_networks</span> <span class="kn">import</span> <span class="n">SiameseModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SiameseModel</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example" id="orgcd304f3">
Parallel_in4_out2[
  Serial_in2[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize_in2
  ]
  Serial_in2[
    Embedding_77068_128
    LSTM_128
    Mean
    Normalize_in2
  ]
]
</pre></div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="../../../categories/nlp/" rel="tag">nlp</a></li>
<li><a class="tag p-category" href="../../../categories/siamese-networks/" rel="tag">siamese networks</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="../siamese-networks-the-data-generator/" rel="prev" title="Siamese Networks: The Data Generator">Previous post</a></li>
<li class="next"><a href="../siamese-networks-hard-negative-mining/" rel="next" title="Siamese Networks: Hard Negative Mining">Next post</a></li>
</ul>
</nav>
</aside>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script></article>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="../../../assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
