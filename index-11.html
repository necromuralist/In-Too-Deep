<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking (old posts, page 11) | Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/index-11.html" rel="canonical">
<link href="index-12.html" rel="prev" type="text/html">
<link href="index-10.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="."><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/visualizing-naive-bayes/">Visualizing Naive Bayes</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/visualizing-naive-bayes/" rel="bookmark"><time class="published dt-published" datetime="2020-08-31T06:16:19-07:00" itemprop="datePublished" title="2020-08-31 06:16">2020-08-31 06:16</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/visualizing-naive-bayes/#org902869b">Beginning</a>
<ul>
<li><a href="posts/nlp/visualizing-naive-bayes/#orga48431c">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/visualizing-naive-bayes/#org5b12ace">Middle</a>
<ul>
<li><a href="posts/nlp/visualizing-naive-bayes/#org2723c1e">Log Likelihoods</a></li>
<li><a href="posts/nlp/visualizing-naive-bayes/#org9b626a0">Confidence Ellipses</a></li>
</ul>
</li>
<li><a href="posts/nlp/visualizing-naive-bayes/#org4cc2d20">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org902869b">
<h2 id="org902869b">Beginning</h2>
<div class="outline-text-2" id="text-org902869b">
<p>In the <a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/">previous post</a> I made a class-based version of the Naive Bayes Classifier for tweets. For this post I'm going to plot the model values. It turns out that we need to get at some values that the previous implementations hide so I'm going to re-calculate the likelihoods from scratch rather than alter the previous code.</p>
</div>
<div class="outline-3" id="outline-container-orga48431c">
<h3 id="orga48431c">Set Up</h3>
<div class="outline-text-3" id="text-orga48431c"></div>
<div class="outline-4" id="outline-container-org5dd4b20">
<h4 id="org5dd4b20">Imports</h4>
<div class="outline-text-4" id="text-org5dd4b20">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Ellipse</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">matplotlib.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">seaborn</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="c1"># graeae</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8389ce0">
<h4 id="org8389ce0">The Dotenv</h4>
<div class="outline-text-4" id="text-org8389ce0">
<div class="highlight">
<pre><span></span><span class="n">env_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">env_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
<span class="n">load_dotenv</span><span class="p">(</span><span class="n">env_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org04a4e67">
<h4 id="org04a4e67">Plotting</h4>
<div class="outline-text-4" id="text-org04a4e67">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"visualizing-naive-bayes"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">create_folder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plot_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_PLOT"</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">plot_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
<span class="k">with</span> <span class="n">plot_path</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Plot</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">"whitegrid"</span><span class="p">,</span> <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
<span class="n">FIGURE_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org204143b">
<h4 id="org204143b">The Data</h4>
<div class="outline-text-4" id="text-org204143b">
<div class="highlight">
<pre><span></span><span class="n">train_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>

<span class="n">test_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TEST_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_raw</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_raw</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Training: 8,000
Testing: 2,000
</pre></div>
</div>
<div class="outline-4" id="outline-container-org806bf58">
<h4 id="org806bf58">The Word Counter</h4>
<div class="outline-text-4" id="text-org806bf58">
<p>This is a class to clean and tokenize the tweets and build up a Counter with the word counts.</p>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">train_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcaa7823">
<h4 id="orgcaa7823">Constants</h4>
<div class="outline-text-4" id="text-orgcaa7823">
<div class="highlight">
<pre><span></span><span class="n">Sentiment</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org5b12ace">
<h2 id="org5b12ace">Middle</h2>
<div class="outline-text-2" id="text-org5b12ace"></div>
<div class="outline-3" id="outline-container-org2723c1e">
<h3 id="org2723c1e">Log Likelihoods</h3>
<div class="outline-text-3" id="text-org2723c1e"></div>
<div class="outline-4" id="outline-container-orgf4e4d09">
<h4 id="orgf4e4d09">Calculating the Likelihoods</h4>
<div class="outline-text-4" id="text-orgf4e4d09">
<p>The first thing to plot are the log-likelihoods for positive and negative tweets. When I implemented the Naive Bayes Classifier I took advantage of the fact that we're making a binary classifier and took the odds ratio when making predictions, but for our plot we're going to need to undo the division and plot the numerator against the denominator.</p>
\begin{align} log \frac{P(tweet|pos)}{P(tweet|neg)} &amp;= log(P(tweet|pos)) - log(P(tweet|neg)) \\ positive = log(P(tweet|pos)) &amp;= \sum_{i=0}^{n}{log P(W_i|pos)}\\ negative = log(P(tweet|neg)) &amp;= \sum_{i=0}^{n}{log P(W_i|neg)}\\ \end{align}
<p>So, let's get the log-likelihoods.</p>
<div class="highlight">
<pre><span></span><span class="n">COUNTS</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span>

<span class="n">positive_loglikelihood</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">negative_loglikelihood</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">log_ratio</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">all_positive_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">(</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span><span class="p">)]</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="n">COUNTS</span>
     <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">))</span>
<span class="n">all_negative_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">(</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span><span class="p">)]</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="n">COUNTS</span>
     <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">))</span>

<span class="n">vocabulary</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">COUNTS</span><span class="p">}</span>
<span class="n">vocabulary_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>

<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">:</span>
    <span class="n">this_word_positive_count</span> <span class="o">=</span> <span class="n">COUNTS</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">)]</span>
    <span class="n">this_word_negative_count</span> <span class="o">=</span> <span class="n">COUNTS</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">)]</span>

    <span class="n">probability_word_is_positive</span> <span class="o">=</span> <span class="p">((</span><span class="n">this_word_positive_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span>
                                    <span class="p">(</span><span class="n">all_positive_words</span> <span class="o">+</span> <span class="n">vocabulary_size</span><span class="p">))</span>
    <span class="n">probability_word_is_negative</span> <span class="o">=</span> <span class="p">((</span><span class="n">this_word_negative_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span>
                                    <span class="p">(</span><span class="n">all_negative_words</span> <span class="o">+</span> <span class="n">vocabulary_size</span><span class="p">))</span>
    <span class="n">positive_loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probability_word_is_positive</span><span class="p">)</span>
    <span class="n">negative_loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probability_word_is_negative</span><span class="p">)</span>
    <span class="n">log_ratio</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">positive_loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">-</span> <span class="n">negative_loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
</pre></div>
<p>So now we have our positive and negative log-likelihoods and I'll put them into a pandas DataFrame to make it easier to plot.</p>
<div class="highlight">
<pre><span></span><span class="n">positive_document_likelihood</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">negative_document_likelihood</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sentiment</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">tweet</span><span class="p">)</span>

    <span class="n">positive_document_likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">positive_loglikelihood</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                                            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">))</span>
    <span class="n">negative_document_likelihood</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">negative_loglikelihood</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                                            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">))</span>
    <span class="n">sentiment</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
    <span class="nb">dict</span><span class="p">(</span>
        <span class="n">positive</span> <span class="o">=</span> <span class="n">positive_document_likelihood</span><span class="p">,</span>
        <span class="n">negative</span> <span class="o">=</span> <span class="n">negative_document_likelihood</span><span class="p">,</span>
        <span class="n">sentiment</span><span class="o">=</span><span class="n">sentiment</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
<pre class="example">
     positive   negative  sentiment
0  -26.305672 -33.940649          1
1  -30.909803 -37.634516          1
2  -42.936400 -33.403567          0
3  -15.983546 -25.501140          1
4 -107.899933 -99.191875          0
</pre></div>
</div>
<div class="outline-4" id="outline-container-org36f820a">
<h4 id="org36f820a">Plotting the Likelihoods</h4>
<div class="outline-text-4" id="text-org36f820a">
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span>
                               <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">,</span> <span class="n">fill_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
                                   <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative"</span><span class="p">,</span>
                                   <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                   <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                                   <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                               <span class="p">)</span>

<span class="n">outcome</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_vs_negative_sentiment"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">outcome</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/visualizing-naive-bayes/positive_vs_negative_sentiment.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>It looks like the log likelihoods for the negatives are linearly separable.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9b626a0">
<h3 id="org9b626a0">Confidence Ellipses</h3>
<div class="outline-text-3" id="text-org9b626a0">
<p>Now we're going to plot a <a href="https://www.wikiwand.com/en/Confidence_region">Confidence Region</a>, which is a generalization of a confidence interval to higher dimensions. In this case we're going to create confidence ellipses. I'm not really sure about the details of the math to get them, but matplotlib has <a href="https://matplotlib.org/3.1.1/gallery/statistics/confidence_ellipse.html">a page</a> with a function to create a matplotlib plot for a confidence ellipse that I'm going to adapt.</p>
</div>
<div class="outline-4" id="outline-container-org6766e2b">
<h4 id="org6766e2b">The Ellipse Function</h4>
<div class="outline-text-4" id="text-org6766e2b">
<p>This is taken almost verbatim from matplotlib's page.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">confidence_ellipse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">n_std</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'none'</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Create a plot of the covariance confidence ellipse of `x` and `y`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : array_like, shape (n, )</span>
<span class="sd">       Input data.</span>

<span class="sd">    ax : matplotlib.axes.Axes</span>
<span class="sd">       The axes object to draw the ellipse into.</span>

<span class="sd">    n_std : float</span>
<span class="sd">       The number of standard deviations to determine the ellipse's radiuses.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    matplotlib.patches.Ellipse</span>

<span class="sd">    Other parameters</span>
<span class="sd">    ----------------</span>
<span class="sd">    kwargs : `~matplotlib.patches.Patch` properties</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"x and y must be the same size"</span><span class="p">)</span>

    <span class="n">cov</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">pearson</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="c1"># Using a special case to obtain the eigenvalues of this</span>
    <span class="c1"># two-dimensionl dataset.</span>
    <span class="n">ell_radius_x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">pearson</span><span class="p">)</span>
    <span class="n">ell_radius_y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pearson</span><span class="p">)</span>
    <span class="n">ellipse</span> <span class="o">=</span> <span class="n">Ellipse</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                      <span class="n">width</span><span class="o">=</span><span class="n">ell_radius_x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">height</span><span class="o">=</span><span class="n">ell_radius_y</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="n">facecolor</span><span class="o">=</span><span class="n">facecolor</span><span class="p">,</span>
                      <span class="o">**</span><span class="n">kwargs</span>
                      <span class="p">)</span>

    <span class="c1"># Calculating the stdandard deviation of x from</span>
    <span class="c1"># the squareroot of the variance and multiplying</span>
    <span class="c1"># with the given number of standard deviations.</span>
    <span class="n">scale_x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">n_std</span>
    <span class="n">mean_x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># calculating the stdandard deviation of y ...</span>
    <span class="n">scale_y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">n_std</span>
    <span class="n">mean_y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">transf</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Affine2D</span><span class="p">()</span> \
        <span class="o">.</span><span class="n">rotate_deg</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">scale_x</span><span class="p">,</span> <span class="n">scale_y</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">mean_y</span><span class="p">)</span>

    <span class="n">ellipse</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">transf</span> <span class="o">+</span> <span class="n">ax</span><span class="o">.</span><span class="n">transData</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">ellipse</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">figure</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="n">positives</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">features</span><span class="o">.</span><span class="n">sentiment</span><span class="o">==</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">]</span>
<span class="n">negatives</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">features</span><span class="o">.</span><span class="n">sentiment</span><span class="o">==</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">]</span>

<span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">positives</span><span class="o">.</span><span class="n">positive</span><span class="p">,</span> <span class="n">positives</span><span class="o">.</span><span class="n">negative</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">n_std</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                   <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$2\sigma$'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>
<span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">negatives</span><span class="o">.</span><span class="n">positive</span><span class="p">,</span> <span class="n">negatives</span><span class="o">.</span><span class="n">negative</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">n_std</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>

<span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">positives</span><span class="o">.</span><span class="n">positive</span><span class="p">,</span> <span class="n">positives</span><span class="o">.</span><span class="n">negative</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">n_std</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                   <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">'$3\sigma$'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>
<span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">negatives</span><span class="o">.</span><span class="n">positive</span><span class="p">,</span> <span class="n">negatives</span><span class="o">.</span><span class="n">negative</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">n_std</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span>

<span class="n">SIZE</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">positives</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s2">"none"</span><span class="p">,</span>
                           <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">)</span>
<span class="n">negatives</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">SIZE</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                       <span class="n">label</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>

<span class="n">LIMITS</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">200</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">LIMITS</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">LIMITS</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"Confidence Ellipses"</span><span class="p">)</span>

<span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">"ellipses.png"</span><span class="p">)</span>
</pre></div>
<div class="figure" id="org8f6e0bc">
<p><img alt="ellipses.png" src="posts/nlp/visualizing-naive-bayes/ellipses.png"></p>
</div>
<p>It's a bit squashed looking, since the results are so tight, but you can sort of see that the distributions are "left-skewed", with the points that fall outside of the \(3 \sigma\) range being the cases where the "positive" and "negative" values are both negative.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org4cc2d20">
<h2 id="org4cc2d20">End</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/">Class-Based Naive Bayes Tweet Sentiment Classifier</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/" rel="bookmark"><time class="published dt-published" datetime="2020-08-29T11:01:51-07:00" itemprop="datePublished" title="2020-08-29 11:01">2020-08-29 11:01</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org299ddc9">Beginning</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orgade806c">The Naive Bayes Classifier</a>
<ul>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orgfbca9ec">Imports</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org8fd5ad4">The Sentiment Constants</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org826934d">The Declaration</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org61b7d34">The Counter</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org6d78c25">The Vocabulary</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orga0e3573">The logprior</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orga1475dd">The loglikelihood</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org519b540">Predict Probability</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org1e6feed">Predict Sentiment</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org462b914">Check Rep</a></li>
</ul>
</li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org16d80ac">Testing</a>
<ul>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org111d357">Imports</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org11a7110">Test Setup</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orgd41be2d">Can you construct it?</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org6fc7668">Does it build the counter?</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org35320ac">Does it build the logprior?</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orgc58b4df">Does it build the vocabulary?</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org64cd7da">Does it build the log-likelihood?</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#orgd40fe0f">Does it predict probabilities?</a></li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org6f4f6e5">Does it predict the sentiment?</a></li>
</ul>
</li>
<li><a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/#org3709f56">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org299ddc9">
<h2 id="org299ddc9">Beginning</h2>
<div class="outline-text-2" id="text-org299ddc9">
<p>I <a href="posts/nlp/naive-bayes-twitter-sentiment-classification/">previously implemented</a> a Naive Bayes Classifier for Tweets as separate functions, and while that is useful for learningi I want to re-use it so I'm going to re-implement it as a class-based system.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgade806c">
<h2 id="orgade806c">The Naive Bayes Classifier</h2>
<div class="outline-text-2" id="text-orgade806c"></div>
<div class="outline-3" id="outline-container-orgfbca9ec">
<h3 id="orgfbca9ec">Imports</h3>
<div class="outline-text-3" id="text-orgfbca9ec">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterable</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8fd5ad4">
<h3 id="org8fd5ad4">The Sentiment Constants</h3>
<div class="outline-text-3" id="text-org8fd5ad4">
<div class="highlight">
<pre><span></span><span class="n">Sentiment</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org826934d">
<h3 id="org826934d">The Declaration</h3>
<div class="outline-text-3" id="text-org826934d">
<div class="highlight">
<pre><span></span><span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">NaiveBayes</span><span class="p">:</span>
    <span class="sd">"""Naive Bayes Sentiment Classifier for Tweets</span>

<span class="sd">    Args:</span>
<span class="sd">     tweets: the training tweets</span>
<span class="sd">     labels: the sentiment labels for the training tweets</span>
<span class="sd">    """</span>
    <span class="n">tweets</span><span class="p">:</span> <span class="n">Iterable</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Iterable</span>
    <span class="n">_counter</span><span class="p">:</span> <span class="n">WordCounter</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_vocabulary</span><span class="p">:</span> <span class="nb">set</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_logprior</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_loglikelihood</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org61b7d34">
<h3 id="org61b7d34">The Counter</h3>
<div class="outline-text-3" id="text-org61b7d34">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">counter</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WordCounter</span><span class="p">:</span>
    <span class="sd">"""The word processor/counter"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counter</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6d78c25">
<h3 id="org6d78c25">The Vocabulary</h3>
<div class="outline-text-3" id="text-org6d78c25">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">set</span><span class="p">:</span>
    <span class="sd">"""The unique tokens in the tweets"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vocabulary</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga0e3573">
<h3 id="orga0e3573">The logprior</h3>
<div class="outline-text-3" id="text-orga0e3573">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">logprior</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""the log-odds of the priors"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logprior</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">positive_documents</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">negative_documents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">-</span> <span class="n">positive_documents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logprior</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">positive_documents</span><span class="p">)</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">negative_documents</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logprior</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga1475dd">
<h3 id="orga1475dd">The loglikelihood</h3>
<div class="outline-text-3" id="text-orga1475dd">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">loglikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""The log-likelihoods for words"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loglikelihood</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loglikelihood</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span>        

        <span class="n">all_positive_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">(</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span><span class="p">)]</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="n">counts</span>
             <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">))</span>
        <span class="n">all_negative_words</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">(</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span><span class="p">)]</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="n">counts</span>
             <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">))</span>
        <span class="n">vocabulary_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocabulary</span><span class="p">:</span>
            <span class="n">this_word_positive_count</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">)]</span>
            <span class="n">this_word_negative_count</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">)]</span>

            <span class="n">probability_word_is_positive</span> <span class="o">=</span> <span class="p">((</span><span class="n">this_word_positive_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span>
                                         <span class="p">(</span><span class="n">all_positive_words</span> <span class="o">+</span> <span class="n">vocabulary_size</span><span class="p">))</span>
            <span class="n">probability_word_is_negative</span> <span class="o">=</span> <span class="p">((</span><span class="n">this_word_negative_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span>
                                         <span class="p">(</span><span class="n">all_negative_words</span> <span class="o">+</span> <span class="n">vocabulary_size</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probability_word_is_positive</span><span class="p">)</span> <span class="o">-</span>
                                         <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probability_word_is_negative</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loglikelihood</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org519b540">
<h3 id="org519b540">Predict Probability</h3>
<div class="outline-text-3" id="text-org519b540">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">predict_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""predict the odds-ratio positive/negative</span>

<span class="sd">    Args:</span>
<span class="sd">     tweet: the tweet to predict</span>

<span class="sd">    Returns:</span>
<span class="sd">     log-odds-ratio for tweet (positive/negative)</span>
<span class="sd">    """</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">logprior</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1e6feed">
<h3 id="org1e6feed">Predict Sentiment</h3>
<div class="outline-text-3" id="text-org1e6feed">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">predict_sentiment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Predict whether the tweet's sentiment is positive or negative</span>

<span class="sd">    Args:</span>
<span class="sd">     tweet: the 'document' to analyze</span>

<span class="sd">    Returns:</span>
<span class="sd">     the sentiment (0=negative, 1=positive)</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_ratio</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org462b914">
<h3 id="org462b914">Check Rep</h3>
<div class="outline-text-3" id="text-org462b914">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">check_rep</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">"""Does some basic checks of the input arguments"""</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org16d80ac">
<h2 id="org16d80ac">Testing</h2>
<div class="outline-text-2" id="text-org16d80ac"></div>
<div class="outline-3" id="outline-container-org111d357">
<h3 id="org111d357">Imports</h3>
<div class="outline-text-3" id="text-org111d357">
<div class="highlight">
<pre><span></span><span class="sd">"""NaiveBayes Tweet Sentiment Classifier feature tests."""</span>

<span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be</span><span class="p">,</span>
    <span class="n">be_empty</span><span class="p">,</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">equal</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">then</span><span class="p">,</span>
    <span class="n">when</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">pytest_bdd</span>

<span class="c1"># this test repo</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.naive_bayes</span> <span class="kn">import</span> <span class="n">NaiveBayes</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org11a7110">
<h3 id="org11a7110">Test Setup</h3>
<div class="outline-text-3" id="text-org11a7110">
<div class="highlight">
<pre><span></span><span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/naive_bayes.feature"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd41be2d">
<h3 id="orgd41be2d">Can you construct it?</h3>
<div class="outline-text-3" id="text-orgd41be2d">
<div class="highlight">
<pre><span></span>Feature: NaiveBayes Tweet Sentiment Classifier

Scenario: The user builds the classifier
  Given a Naive Bayes definition
  When the user builds the classifier
  Then it has the expected attributes
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user builds the classifier</span>


<span class="nd">@given</span><span class="p">(</span><span class="s1">'a Naive Bayes definition'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">a_naive_bayes_definition</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">definition</span> <span class="o">=</span> <span class="n">NaiveBayes</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s1">'the user builds the classifier'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">the_user_builds_the_classifier</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="s2">"alfa bravo charley"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">definition</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                              <span class="n">labels</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s1">'it has the expected attributes'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">it_has_the_expected_attributes</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">check_rep</span><span class="p">()</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6fc7668">
<h3 id="org6fc7668">Does it build the counter?</h3>
<div class="outline-text-3" id="text-org6fc7668">
<div class="highlight">
<pre><span></span>Scenario: The user checks the counter
  Given a Naive Bayes classifier
  When the user checks the counter
  Then it is the expected counter
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user checks the counter</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Naive Bayes classifier"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">build_naive_classifier</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">NaiveBayes</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[],</span> <span class="n">labels</span><span class="o">=</span><span class="p">[])</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the counter"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter_definition</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter_definition</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span>
    <span class="n">mocker</span><span class="o">.</span><span class="n">patch</span><span class="p">(</span><span class="s2">"neurotic.nlp.twitter.naive_bayes.WordCounter"</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counter_definition</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_counter</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">counter</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it is the expected counter"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expect_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_counter</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org35320ac">
<h3 id="org35320ac">Does it build the logprior?</h3>
<div class="outline-text-3" id="text-org35320ac">
<div class="highlight">
<pre><span></span>Scenario: The user checks the log-prior
 Given a valid Naive Bayes Classifier
 When the user checks the log-odds prior
 Then it is close enough
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user checks the log-prior</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a valid Naive Bayes Classifier"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_classifier</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"a blowfish"</span><span class="p">,</span> <span class="s2">"b closing"</span><span class="p">,</span> <span class="s2">"c that"</span><span class="p">,</span> <span class="s2">"d plane"</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({</span>
        <span class="p">(</span><span class="s2">"appl"</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">5</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">"b"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">2</span><span class="p">,</span>
        <span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">4</span><span class="p">,</span>

    <span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">NaiveBayes</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                     <span class="n">labels</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the log-odds prior"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_log_odds_prior</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">logprior</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it is close enough"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expect_close_enough</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc58b4df">
<h3 id="orgc58b4df">Does it build the vocabulary?</h3>
<div class="outline-text-3" id="text-orgc58b4df">
<div class="highlight">
<pre><span></span>Scenario: The user checks the vocabulary
  Given a valid Naive Bayes Classifier
  When the user checks the vocabulary
  Then all the words are there
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user checks the vocabulary</span>
<span class="c1">#  Given a valid Naive Bayes Classifier</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the vocabulary"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_vocabulary</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
  <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">vocabulary</span>
  <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"appl"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">}</span>
  <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"all the words are there"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compare_words</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
  <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">^</span> <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_empty</span><span class="p">)</span>
  <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org64cd7da">
<h3 id="org64cd7da">Does it build the log-likelihood?</h3>
<div class="outline-text-3" id="text-org64cd7da">
<div class="highlight">
<pre><span></span>Scenario: The user gets the log-likelihood dictionary
  Given a valid Naive Bayes Classifier
  When the user checks the loglikelihoods
  Then they are close enough
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user gets the log-likelihood dictionary</span>
<span class="c1">#  Given a valid Naive Bayes Classifier</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the loglikelihoods"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_log_likelihoods</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">appl</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">9</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">6</span><span class="o">/</span><span class="mi">8</span><span class="p">),</span>
        <span class="n">b</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">9</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">),</span>
        <span class="n">c</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">5</span><span class="o">/</span><span class="mi">9</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">loglikelihood</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"they are close enough"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expect_close_values</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">loglikelihood</span><span class="p">:</span>
        <span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">[</span><span class="n">word</span><span class="p">],</span>
                            <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">[</span><span class="n">word</span><span class="p">]))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd40fe0f">
<h3 id="orgd40fe0f">Does it predict probabilities?</h3>
<div class="outline-text-3" id="text-orgd40fe0f">
<div class="highlight">
<pre><span></span>Scenario: User predicts tweet positive probability
  Given a valid Naive Bayes Classifier
  When the user makes a tweet prediction
  Then it is the expected probability
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: User predicts tweet positive probability</span>
<span class="c1">#   Given a valid Naive Bayes Classifier</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user makes a tweet prediction"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_prediction</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">logprior</span>
                         <span class="o">+</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">loglikelihood</span><span class="p">[</span><span class="s2">"c"</span><span class="p">]</span>
                         <span class="o">+</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">loglikelihood</span><span class="p">[</span><span class="s2">"b"</span><span class="p">])</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">predict_ratio</span><span class="p">(</span>
        <span class="s2">"c you later b"</span>
    <span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it is the expected probability"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expect_probability</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6f4f6e5">
<h3 id="org6f4f6e5">Does it predict the sentiment?</h3>
<div class="outline-text-3" id="text-org6f4f6e5">
<div class="highlight">
<pre><span></span>Scenario: The user predicts tweet sentiment
  Given a valid Naive Bayes Classifier
  When the user predicts the sentiment of tweets
  Then the sentiments are the expected ones
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The user predicts tweet sentiment</span>
<span class="c1">#   Given a valid Naive Bayes Classifier</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user predicts the sentiment of tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_predict_sentiment</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_1</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">predict_sentiment</span><span class="p">(</span><span class="s2">"c you later b"</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected_1</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_2</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">predict_sentiment</span><span class="p">(</span><span class="s2">"apple banana tart"</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected_2</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the sentiments are the expected ones"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expect_sentiments</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected_1</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected_2</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org3709f56">
<h2 id="org3709f56">End</h2>
<div class="outline-text-2" id="text-org3709f56">
<p>Now that we have the class-based version let's do a little <a href="posts/nlp/visualizing-naive-bayes/">visualization of the model</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/naive-bayes-twitter-sentiment-classification/">Implementing a Naive Bayes Twitter Sentiment Classifier</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/" rel="bookmark"><time class="published dt-published" datetime="2020-08-29T10:16:04-07:00" itemprop="datePublished" title="2020-08-29 10:16">2020-08-29 10:16</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#org05b0ef1">Beginning</a>
<ul>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgd2cdac6">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#org8e67fbe">Middle</a>
<ul>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgb7afd21">Implementing the Model</a></li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgf7405a8">Making Predictions</a></li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgf71408f">Filtering Words</a></li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgb66c7bb">Error Analysis</a></li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgb2fbc1b">Predict Your Own Tweet</a></li>
</ul>
</li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification/#orgd677a8d">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org05b0ef1">
<h2 id="org05b0ef1">Beginning</h2>
<div class="outline-text-2" id="text-org05b0ef1">
<p>In the <a href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/">previous post</a> I went through some of the background of how Naive Bayes works. In this post I'll implement a Naive Bayes Classifier to classify tweets by whether they are positive in sentiment or negative. The Naive Bayes model uses Bayes' rule to make its predictions and it's called "naive" because it makes the assumption that words in the document are independent (in the probability event sense) which allows us to use the multiplication rule to calculate our probabilities. It also uses the \(\textit{Bag of Words}\) assumption that word ordering isn't important.</p>
</div>
<div class="outline-3" id="outline-container-orgd2cdac6">
<h3 id="orgd2cdac6">Set Up</h3>
<div class="outline-text-3" id="text-orgd2cdac6">
<p>This first bit imports the needed dependencies followed by setting up the data and some helpers.</p>
</div>
<div class="outline-4" id="outline-container-org608fd68">
<h4 id="org608fd68">Imports</h4>
<div class="outline-text-4" id="text-org608fd68">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># my stuff</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7fac828">
<h4 id="org7fac828">Tabulate</h4>
<div class="outline-text-4" id="text-org7fac828">
<p>This sets up tabulate to make it a little simpler to display pandas DataFrames in org.</p>
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge1c5a71">
<h4 id="orge1c5a71">The Dotenv</h4>
<div class="outline-text-4" id="text-orge1c5a71">
<p>I put the path to the data files in a .env file so this loads it into the environment.</p>
<div class="highlight">
<pre><span></span><span class="n">env_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">env_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
<span class="n">load_dotenv</span><span class="p">(</span><span class="n">env_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org39c5209">
<h4 id="org39c5209">Load the Twitter Data</h4>
<div class="outline-text-4" id="text-org39c5209">
<p>I split the data <a href="posts/nlp/01-twitter-preprocessing-with-nltk/">previously</a> for the Logistic Regression twitter sentiment classifier so I'll load it here and skip building the sets.</p>
<div class="highlight">
<pre><span></span><span class="n">train_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>

<span class="n">test_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TEST_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_raw</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_raw</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Training: 8,000
Testing: 2,000
</pre>
<p>I'll also re-use the WordCounter from the Logistic Regression. Despite the name it also does tokenizing and cleaning.</p>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">train_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org80aa517">
<h4 id="org80aa517">Constants</h4>
<div class="outline-text-4" id="text-org80aa517">
<p>This was an object I created to store a few constant values.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_SENTIMENT"</span><span class="p">],</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Sentiment</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Sentiment</span><span class="p">)</span>
</pre></div>
<pre class="example">
Namespace(decode={1: 'positive', 0: 'negative'}, encode={'positive': 1, 'negative': 0}, negative=0, positive=1)
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8e67fbe">
<h2 id="org8e67fbe">Middle</h2>
<div class="outline-text-2" id="text-org8e67fbe"></div>
<div class="outline-3" id="outline-container-orgb7afd21">
<h3 id="orgb7afd21">Implementing the Model</h3>
<div class="outline-text-3" id="text-orgb7afd21">
<p>In an <a href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/">earlier post</a> I wrote up a little of the background behind what we're doing and now I'm going to translate the math in that post into code.</p>
</div>
<div class="outline-4" id="outline-container-orge8bfa04">
<h4 id="orge8bfa04">Implementing The Training Function</h4>
<div class="outline-text-4" id="text-orge8bfa04">
<p>The first part of the problem - training the model by building up the probabilities.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train_naive_bayes</span><span class="p">(</span><span class="n">counts</span><span class="p">:</span> <span class="n">Counter</span><span class="p">,</span>
                      <span class="n">train_x</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
                      <span class="n">train_y</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">       counts: Counter from (word, label) to how often the word appears</span>
<span class="sd">       train_x: a list of tweets</span>
<span class="sd">       train_y: a list of labels correponding to the tweets (0,1)</span>

<span class="sd">    Returns:</span>
<span class="sd">       logprior: the log odds ratio</span>
<span class="sd">       loglikelihood: log likelihood dictionary for the Naive bayes equation</span>
<span class="sd">    """</span>
    <span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">logprior</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">vocabulary</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">])</span>
    <span class="n">V</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>

    <span class="c1"># number of positive and negative words in the training set</span>
    <span class="n">N_pos</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span><span class="p">)]</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="n">counts</span>
                 <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">))</span>
    <span class="n">N_neg</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span><span class="p">)]</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="ow">in</span> <span class="n">counts</span>
                 <span class="k">if</span> <span class="n">sentiment</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">))</span>

    <span class="n">D</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>

    <span class="c1"># D_pos is number of positive documents</span>
    <span class="n">D_pos</span> <span class="o">=</span> <span class="n">train_y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># D_neg is the number of negative documents</span>
    <span class="n">D_neg</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">D_pos</span>

    <span class="c1"># the log odds ratio</span>
    <span class="n">logprior</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">D_pos</span><span class="p">)</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">D_neg</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="p">:</span>
        <span class="n">freq_pos</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">)]</span>
        <span class="n">freq_neg</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">)]</span>

        <span class="c1"># the probability that the word is positive, and negative</span>
        <span class="n">p_w_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">freq_pos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">N_pos</span> <span class="o">+</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">p_w_neg</span> <span class="o">=</span> <span class="p">(</span><span class="n">freq_neg</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">N_neg</span> <span class="o">+</span> <span class="n">V</span><span class="p">)</span>

        <span class="n">loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_w_pos</span><span class="p">)</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_w_neg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span>
</pre></div>
<p>Now we can see what we get when we train our model.</p>
<div class="highlight">
<pre><span></span><span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">train_naive_bayes</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Log Prior: </span><span class="si">{</span><span class="n">logprior</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Words in Log Likelihood: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loglikelihood</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Log Prior: -0.006500022885560952
Words in Log Likelihood: 9,172
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Positive Tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_raw</span><span class="p">[</span><span class="n">train_raw</span><span class="o">.</span><span class="n">label</span><span class="o">==</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">])</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Negative Tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_raw</span><span class="p">[</span><span class="n">train_raw</span><span class="o">.</span><span class="n">label</span><span class="o">==</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">])</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Positive Tweets: 3,987
Negative Tweets: 4,013
</pre>
<p>We get a negative value for the <code>logprior</code> because we have more negative tweets than positive tweets in the training set and the negative count is the second term when we calculate the difference for the <code>logprior</code>. If we evened it out it would drop to 0.</p>
<div class="highlight">
<pre><span></span><span class="n">all_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train_raw</span><span class="p">,</span> <span class="n">test_raw</span><span class="p">])</span>
<span class="n">check</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">all_raw</span><span class="p">[</span><span class="n">all_raw</span><span class="o">.</span><span class="n">label</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">4000</span><span class="p">],</span> <span class="n">all_raw</span><span class="p">[</span><span class="n">all_raw</span><span class="o">.</span><span class="n">label</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">4000</span><span class="p">]])</span>
<span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">train_naive_bayes</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="n">check</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">check</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Log Prior: </span><span class="si">{</span><span class="n">logprior</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Log Likelihood: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">loglikelihood</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Log Prior: 0.0
Log Likelihood: 9172
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf7405a8">
<h3 id="orgf7405a8">Making Predictions</h3>
<div class="outline-text-3" id="text-orgf7405a8">
<p>Now that we have the model we can use it to make some predictions.</p>
<p>\[ p = logprior + \sum_i^N (loglikelihood_i) \]</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">naive_bayes_predict</span><span class="p">(</span><span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">logprior</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">       tweet: a tweet to classify</span>
<span class="sd">       logprior: the log odds ratio of prior probabilities</span>
<span class="sd">       loglikelihood: a dictionary of words mapped to their log likelihood ratios</span>

<span class="sd">    Returns:</span>
<span class="sd">       p: sum of the log-odds ratio for the tweet</span>
<span class="sd">    """</span>
    <span class="c1"># process the tweet to get a list of words</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logprior</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">loglikelihood</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span>
</pre></div>
<p>Now test it with a tweet.</p>
<div class="highlight">
<pre><span></span><span class="n">my_tweet</span> <span class="o">=</span> <span class="s1">'She smiled.'</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'The positive to negative ratio is </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">.'</span><span class="p">)</span>
</pre></div>
<pre class="example">
The positive to negative ratio is 1.44.
</pre>
<p>Since the ratio is greater than 0, we're predicting that the tweet has a positive sentiment.</p>
</div>
<div class="outline-4" id="outline-container-org9c01e53">
<h4 id="org9c01e53">Test The Model</h4>
<div class="outline-text-4" id="text-org9c01e53">
<p>Now we'll calculate the accuracy of the model against the test set.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test_naive_bayes</span><span class="p">(</span><span class="n">test_x</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">test_y</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
                     <span class="n">logprior</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">       test_x: tweets to classify</span>
<span class="sd">       test_y: labels for test_x</span>
<span class="sd">       logprior: the logprior for the training set</span>
<span class="sd">       loglikelihood: a dictionary with the loglikelihoods for each word</span>

<span class="sd">    Returns:</span>
<span class="sd">       accuracy: (# of tweets classified correctly)/(total # of tweets)</span>
<span class="sd">    """</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">y_hats</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
              <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">test_x</span><span class="p">])</span>

    <span class="c1"># error is the average of the absolute values of the differences between y_hats and test_y</span>
    <span class="c1"># error = number wrong/number of tweets</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_hats</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># Accuracy is 1 minus the error</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">error</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Naive Bayes accuracy = </span><span class="si">%0.4f</span><span class="s2">"</span> <span class="o">%</span>
      <span class="p">(</span><span class="n">test_naive_bayes</span><span class="p">(</span><span class="n">test_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">test_raw</span><span class="o">.</span><span class="n">label</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)))</span>
</pre></div>
<pre class="example">
Naive Bayes accuracy = 0.9955
</pre>
<p>Which looks good, but it might actually be overfitting - it looks too good. Now here's some example tweets to check.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'I am happy'</span><span class="p">,</span> <span class="s1">'I am bad'</span><span class="p">,</span> <span class="s1">'this movie should have been great.'</span><span class="p">,</span>
              <span class="s1">'great'</span><span class="p">,</span> <span class="s1">'great great'</span><span class="p">,</span> <span class="s1">'great great great'</span><span class="p">,</span> <span class="s1">'great great great great'</span><span class="p">]:</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">tweet</span><span class="si">}</span><span class="s1"> -&gt; </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
I am happy -&gt; 1.89
I am bad -&gt; -1.63
this movie should have been great. -&gt; 2.05
great -&gt; 2.06
great great -&gt; 4.13
great great great -&gt; 6.19
great great great great -&gt; 8.25
</pre>
<p>It looks like the word "great" throws off the third sentence which hints at being negative. What if we pass in a neutral (nonsensical) tweet?</p>
<div class="highlight">
<pre><span></span><span class="n">my_tweet</span> <span class="o">=</span> <span class="s2">"the answer is nicht in the umwelt"</span>
<span class="nb">print</span><span class="p">(</span><span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">))</span>
</pre></div>
<pre class="example">
-0.41441957689474407
</pre>
<p>I don't know which of those words triggered the negative value…</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="s2">"the answer is nicht in the umwelt"</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s2">:</span><span class="se">\t</span><span class="si">{</span><span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
the:    0.00
answer: -0.41
is:     0.00
nicht:  0.00
in:     0.00
the:    0.00
umwelt: 0.00
</pre>
<p>It only got one word, <code>answer</code> and that's negative for some reason. Go figure.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf71408f">
<h3 id="orgf71408f">Filtering Words</h3>
<div class="outline-text-3" id="text-orgf71408f">
<p>This is sort of an aside, but one way to quickly filter tweets based on how positive or negative they are is to use the ratio of positive to negative counts and setting a threshold that has to be met to be included in the output.</p>
<p>\[ ratio = \frac{\text{pos_words} + 1}{\text{neg_words} + 1} \]</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Words</th>
<th class="org-right" scope="col">Positive word count</th>
<th class="org-right" scope="col">Negative Word Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">glad</td>
<td class="org-right">41</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">arriv</td>
<td class="org-right">57</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">:(</td>
<td class="org-right">1</td>
<td class="org-right">3663</td>
</tr>
<tr>
<td class="org-left">:-(</td>
<td class="org-right">0</td>
<td class="org-right">378</td>
</tr>
</tbody>
</table>
</div>
<div class="outline-4" id="outline-container-orgc55c1be">
<h4 id="orgc55c1be">Get The Ratio</h4>
<div class="outline-text-4" id="text-orgc55c1be">
<p>As an intermediate step we'll create a function named <code>get_ratio</code> that looks up a word and calculates the positive to negative ratio.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_ratio</span><span class="p">(</span><span class="n">freqs</span><span class="p">:</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">       freqs: Counter with (word, sentiment) : count</span>
<span class="sd">       word: string to lookup</span>

<span class="sd">    Returns: </span>
<span class="sd">     dictionary with keys 'positive', 'negative', and 'ratio'.</span>
<span class="sd">       Example: {'positive': 10, 'negative': 20, 'ratio': 0.5}</span>
<span class="sd">    """</span>
    <span class="n">pos_neg_ratio</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">positive</span> <span class="o">=</span> <span class="n">freqs</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">)],</span>
        <span class="n">negative</span> <span class="o">=</span> <span class="n">freqs</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">)],</span>
    <span class="p">)</span>

    <span class="c1"># calculate the ratio of positive to negative counts for the word</span>
    <span class="n">pos_neg_ratio</span><span class="p">[</span><span class="s1">'ratio'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_neg_ratio</span><span class="p">[</span><span class="s2">"positive"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span>
        <span class="n">pos_neg_ratio</span><span class="p">[</span><span class="s2">"negative"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pos_neg_ratio</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">get_ratio</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="s1">'happi'</span><span class="p">))</span>
</pre></div>
<pre class="example">
{'positive': 160, 'negative': 23, 'ratio': 6.708333333333333}
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga96d2a2">
<h4 id="orga96d2a2">Get Words By Threshold</h4>
<div class="outline-text-4" id="text-orga96d2a2">
<p>Now we'll create the filter function. To make it simpler we'll assume that if we're filtering on the positive label then the ratio for a word to be included has to be equal to or greater than the given threshold while if the label is negative then a word has to be less than or equal to the threshold. Doing this means we're filtering to get words that are further toward the extremes of positive or negative (further from 0).</p>
<p>An example key-value pair would have this structure:</p>
<div class="highlight">
<pre><span></span><span class="p">{</span><span class="s1">'happi'</span><span class="p">:</span>
     <span class="p">{</span><span class="s1">'positive'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">'negative'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">'ratio'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
 <span class="p">}</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_words_by_threshold</span><span class="p">(</span><span class="n">freqs</span><span class="p">:</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">       freqs: Counter of (word, sentiment): word count</span>
<span class="sd">       label: 1 for positive, 0 for negative</span>
<span class="sd">       threshold: ratio that will be used as the cutoff for including a word in the returned dictionary</span>

<span class="sd">    Returns:</span>
<span class="sd">       words: dictionary containing the word and information on its positive count, negative count, and ratio of positive to negative counts.</span>
<span class="sd">       example of a key value pair:</span>
<span class="sd">       {'happi':</span>
<span class="sd">           {'positive': 10, 'negative': 20, 'ratio': 0.5}</span>
<span class="sd">       }</span>
<span class="sd">    """</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">freqs</span><span class="p">:</span>
        <span class="n">pos_neg_ratio</span> <span class="o">=</span> <span class="n">get_ratio</span><span class="p">(</span><span class="n">freqs</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">((</span><span class="n">label</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span> <span class="ow">and</span> <span class="n">pos_neg_ratio</span><span class="p">[</span><span class="s2">"ratio"</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span> <span class="ow">or</span>
            <span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span> <span class="ow">and</span> <span class="n">pos_neg_ratio</span><span class="p">[</span><span class="s2">"ratio"</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">)):</span>
            <span class="n">words</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_neg_ratio</span>

    <span class="k">return</span> <span class="n">words</span>
</pre></div>
<p>Here's an example where we'll filter on negative sentiment so all the tweets should be negative and have a positive to negative ration less that the threshold.</p>
<div class="highlight">
<pre><span></span><span class="n">passed</span> <span class="o">=</span> <span class="n">get_words_by_threshold</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">negative</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">passed</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="se">\t</span><span class="s2">word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">info</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
<pre class="example" id="orgd7e73de">
1       word: :(        {'positive': 1, 'negative': 3705, 'ratio': 0.0005396654074473826}
2       word: :-(       {'positive': 0, 'negative': 407, 'ratio': 0.0024509803921568627}
3       word: ♛ {'positive': 0, 'negative': 162, 'ratio': 0.006134969325153374}
4       word: 》 {'positive': 0, 'negative': 162, 'ratio': 0.006134969325153374}
5       word: beli̇ev   {'positive': 0, 'negative': 27, 'ratio': 0.03571428571428571}
6       word: wi̇ll     {'positive': 0, 'negative': 27, 'ratio': 0.03571428571428571}
7       word: justi̇n   {'positive': 0, 'negative': 27, 'ratio': 0.03571428571428571}
8       word: ｓｅｅ       {'positive': 0, 'negative': 27, 'ratio': 0.03571428571428571}
9       word: ｍｅ        {'positive': 0, 'negative': 27, 'ratio': 0.03571428571428571}
10      word: sad       {'positive': 3, 'negative': 100, 'ratio': 0.039603960396039604}
11      word: &gt;:(    {'positive': 0, 'negative': 36, 'ratio': 0.02702702702702703}
</pre>
<p>So our threshold gives us the eleven most negative words.</p>
<p>Now, what about filtering on the most positive words?</p>
<div class="highlight">
<pre><span></span><span class="n">passed</span> <span class="o">=</span> <span class="n">get_words_by_threshold</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">positive</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">passed</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="se">\t</span><span class="s2">word: </span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">info</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
<pre class="example" id="orgcc41277">
1       word: :)        {'positive': 2967, 'negative': 1, 'ratio': 1484.0}
2       word: :-)       {'positive': 547, 'negative': 0, 'ratio': 548.0}
3       word: :D        {'positive': 537, 'negative': 0, 'ratio': 538.0}
4       word: :p        {'positive': 113, 'negative': 0, 'ratio': 114.0}
5       word: fback     {'positive': 22, 'negative': 0, 'ratio': 23.0}
6       word: blog      {'positive': 29, 'negative': 2, 'ratio': 10.0}
7       word: followfriday      {'positive': 19, 'negative': 0, 'ratio': 20.0}
8       word: recent    {'positive': 9, 'negative': 0, 'ratio': 10.0}
9       word: stat      {'positive': 52, 'negative': 0, 'ratio': 53.0}
10      word: arriv     {'positive': 57, 'negative': 4, 'ratio': 11.6}
11      word: thx       {'positive': 11, 'negative': 0, 'ratio': 12.0}
12      word: here'     {'positive': 19, 'negative': 0, 'ratio': 20.0}
13      word: influenc  {'positive': 16, 'negative': 0, 'ratio': 17.0}
14      word: bam       {'positive': 34, 'negative': 0, 'ratio': 35.0}
15      word: warsaw    {'positive': 34, 'negative': 0, 'ratio': 35.0}
16      word: welcom    {'positive': 58, 'negative': 4, 'ratio': 11.8}
17      word: vid       {'positive': 9, 'negative': 0, 'ratio': 10.0}
18      word: ceo       {'positive': 9, 'negative': 0, 'ratio': 10.0}
19      word: 1month    {'positive': 9, 'negative': 0, 'ratio': 10.0}
20      word: flipkartfashionfriday     {'positive': 14, 'negative': 0, 'ratio': 15.0}
21      word: inde      {'positive': 10, 'negative': 0, 'ratio': 11.0}
22      word: glad      {'positive': 35, 'negative': 2, 'ratio': 12.0}
23      word: braindot  {'positive': 9, 'negative': 0, 'ratio': 10.0}
24      word: ;)        {'positive': 21, 'negative': 0, 'ratio': 22.0}
25      word: goodnight {'positive': 19, 'negative': 1, 'ratio': 10.0}
26      word: youth     {'positive': 10, 'negative': 0, 'ratio': 11.0}
27      word: shout     {'positive': 9, 'negative': 0, 'ratio': 10.0}
28      word: fantast   {'positive': 10, 'negative': 0, 'ratio': 11.0}
</pre>
<p>The first four make sense, but after that maybe not so much. "fback"?</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb66c7bb">
<h3 id="orgb66c7bb">Error Analysis</h3>
<div class="outline-text-3" id="text-orgb66c7bb">
<p>Now let's look at some tweets that we got wrong. We're going to use <a href="https://numpy.org/doc/stable/reference/generated/numpy.sign.html">numpy.sign</a> which reduces numbers to <code>-1</code>, <code>0</code>, or <code>1</code>.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Truth Predicted Tweet'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">test_raw</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">row</span><span class="o">.</span><span class="n">label</span> <span class="o">!=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">row</span><span class="o">.</span><span class="n">label</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">numpy</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="se">\t</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">tweet</span><span class="p">))</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">'ascii'</span><span class="p">,</span> <span class="s1">'ignore'</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Truth Predicted Tweet
0       1       b'whatev stil l young &gt;:-('
1       0       b'look fun kik va 642 kik kikgirl french model orgasm hannib phonesex :)'
0       1       b'great news thank let us know :( hope good weekend'
0       1       b"amb pleas harry' jean :) ): ): ):"
0       1       b'srsli fuck u unfollow hope ur futur child unpar u &gt;:-('
1       0       b'ate last cooki shir 0 &gt;:d'
1       0       b'snapchat jennyjean 22 snapchat kikmeboy model french kikchat sabadodeganarseguidor sexysasunday :)'
1       0       b'add kik ughtm 545 kik kikmeguy kissm nude likeforfollow musicbiz sexysasunday :)'
0       1       b'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'
</pre>
<p>For some reason it misses the <code>&gt;:-(</code> emoji and the <code>:)</code> - maybe they didn't occur in the training set. I think these woud be hard for a human to get too, unless you were well versed in tweets and emojis and maybe even then it would be hard…</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgb2fbc1b">
<h3 id="orgb2fbc1b">Predict Your Own Tweet</h3>
<div class="outline-text-3" id="text-orgb2fbc1b">
<p>Let's try a random tweet not in the given training or test sets.</p>
<div class="highlight">
<pre><span></span><span class="n">my_tweet</span> <span class="o">=</span> <span class="s1">'my balls itch'</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">naive_bayes_predict</span><span class="p">(</span><span class="n">my_tweet</span><span class="p">,</span> <span class="n">logprior</span><span class="p">,</span> <span class="n">loglikelihood</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">my_tweet</span><span class="si">}</span><span class="s2"> is a positive tweet: </span><span class="si">{</span><span class="n">numpy</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
my balls itch is a positive tweet: True
</pre>
<p>Hmmm. Maybe…</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd677a8d">
<h2 id="orgd677a8d">End</h2>
<div class="outline-text-2" id="text-orgd677a8d">
<p>I want to do more work with the Naive Bayes Classifier but this post is getting too long so I'm going to move on to other posts, the next being a <a href="posts/nlp/class-based-naive-bayes-tweet-sentiment-classifier/">class-based implementation</a> of the model.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/">Using Naive Bayes to Classify Tweets by Sentiment</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/" rel="bookmark"><time class="published dt-published" datetime="2020-08-28T09:25:00-07:00" itemprop="datePublished" title="2020-08-28 09:25">2020-08-28 09:25</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/#org2511f7e">Beginning</a></li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/#orgb554ea9">Middle</a></li>
<li><a href="posts/nlp/naive-bayes-twitter-sentiment-classification-background/#org17208f9">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org2511f7e">
<h2 id="org2511f7e">Beginning</h2>
<div class="outline-text-2" id="text-org2511f7e">
<p>In a <a href="posts/nlp/implementing-twitter-logistic-regression/">previous post</a> I implemented a Logistic Regression model to classify twitter tweets as having a positive or negative sentiment. This time I'll be using the same data set (from <a href="http://www.nltk.org/">NLTK</a>) but implementing it with a <a href="https://www.wikiwand.com/en/Naive_Bayes_classifier">Naive Bayes</a> model. This post will look at some of the math behind it and the next one will translate the math into code.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgb554ea9">
<h2 id="orgb554ea9">Middle</h2>
<div class="outline-text-2" id="text-orgb554ea9"></div>
<div class="outline-4" id="outline-container-orge552ee9">
<h4 id="orge552ee9">Bayesian Inference</h4>
<div class="outline-text-4" id="text-orge552ee9">
<p>What we want is to take a document (<i>D</i>) - which is a tweet in this case - and guess its classification \(\hat{c}\). We do this by calculating the probability for both of our classifications (<i>positive</i> and <i>negative</i>) using Bayes' Rule and then choosing the classification with the higher probability.</p>
\begin{align} \hat{c} &amp;= \underset{c \in C}{\mathrm{argmax}} P(c|d)\\ &amp;= \underset{c \in C}{\mathrm{argmax}} P(D|c)P(c)\\ \end{align}
<p>So our guess as to what class the document belongs to is the classification with the highest probability given the document - and "the probability of the classification given the document", when translated using Bayes' Rule, becomes the probability of the document given the classification (the <i>likelihood</i> of the document) times the prior probability of any document belonging to the class. But then you might wonder - if there's only one of each document then won't the probability always be \(\frac{1}{c}\)? It would, so we use the words within the document to calculate the probability for the document. How? Well, I mentioned earlier that we make two assumptions - that the documents can be represented as a bag of words and that they are independent. The independent assumption allows us to figure out the total probability using the Multiplication Rule:</p>
<p>\[ P(A \cap B) = P(A)P(B) \]</p>
<p>The probability of A and B is the product of their probabilities. In this case we are calculating the probability of the document as the product of the conditional probabilities of the words given the class:</p>
<p>\[ P(D|c) = \prod_{i=1}^{n}P(w_i | c) \]</p>
<p>Where the <i>n</i> refers to the number of words in the document. Given this we could re-write the previous equation like this.</p>
\begin{align} \hat{c} &amp;= \underset{c \in C}{\textrm{argmax}} P(c) \prod_{i}^{n} P(w_i | c)\\ \end{align}
<p>But it turns out this form isn't really ideal. Among other things you're multiplying values that range from 0 to 1, with most values being less than 1, so the more classes you have, the smaller this number will get and you could end up with really small numbers leading to <a href="https://www.wikiwand.com/en/Arithmetic_underflow">underflow</a>. So we're going to do a log transform of the equation which will also simplify the computation a little (although nowadays I don't know that that's so much of a consideration).</p>
<p>\[ \hat{c} = \underset{c \in C}{\textrm{argmax}} \log{P(c)} + \sum_{i=1}^n \log{P(w_i|c)} \]</p>
<p>This is what we'll use to classify tweets after training the model by building up the probabilities.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org0a3f68a">
<h4 id="org0a3f68a">Ratios</h4>
<div class="outline-text-4" id="text-org0a3f68a">
<p>While I wrote out the general case where you take the class with the highest probability, in this case we only have two classes, <i>positive</i> and <i>negative</i> so we can take advantage of this and make our classification using the ratio of the conditional probabilities for each class (the log <a href="https://www.wikiwand.com/en/Odds_ratio">odds ratio</a>). We're going to use the ratio of positive to negative.</p>
<p>\[ \log{\frac{P(positive|D)}{P(negative | D)}} = \log{\frac{P(positive)}{P(negative)}} + \sum_{i=1}^n \log{\frac{P(w_i|positive)}{P(w_i|negative)}} \]</p>
<p>Since <i>positive</i> is the numerator, and the log of values less than one are negative, this ratio will be positive when the review is likely positive and negative otherwise, so we can use the sign of this ratio to classify tweets.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgf226b90">
<h4 id="orgf226b90">Priors and Log Priors</h4>
<div class="outline-text-4" id="text-orgf226b90">
<p>Now we can start picking apart our ratio. The prior probabilities are just the fraction of our training set that matches a variable. So the prior probabilities of the document classifications can be described like this:</p>
\begin{align} P(D_{positive}) &amp;= \frac{\textit{number of positive tweets}}{\textit{total number of tweets}}\\ &amp;= \frac{D_{pos}}{D}\\ \end{align} \begin{align} P(D_{negative}) &amp;= \frac{\textit{number of negative tweets}}{\textit{total number of tweets}}\\ &amp;= \frac{D_{neg}}{D}\\ \end{align}
<p>But as I noted above we are going to use the ratio of the prior probabilities \(\frac{P(D_{pos})}{P(D_{neg})}\) and if you look at them, they have the same denominator (<i>D</i>) so taking the ratio of the probabilities means the denominator cancels out and we end up with the ratio of the positive to negative documents.</p>
\begin{align} \frac{P(D_{pos})}{P(D_{neg})} &amp;= \frac{\frac{D_{pos}}{D}}{\frac{D_{neg}}{D}}\\ &amp;= \frac{\left( \frac{D_{pos}}{\cancel{D}}\right) \left(\frac{\cancel{D}}{D_{neg}}\right) }{ \cancel{\left(\frac{D_{neg}}{D}\right)} \cancel{\left(\frac{D}{D_{neg}}\right)} }\\ &amp;= \frac{D_{pos}}{D_{neg}}\\ \end{align}
<p>And as I noted above, we'll be using a log transform so our ratio (which will be called <i>logprior</i>) needs to be transformed as well.</p>
\begin{align} \text{logprior} &amp;= log \left( \frac{P(D_{pos})}{P(D_{neg})} \right) \\ &amp;= log \left( \frac{D_{pos}}{D_{neg}} \right)\\ \end{align}
<p>Note that \(log(\frac{A}{B})\) is the same as \(log(A) - log(B)\). So the logprior can also be calculated as the difference between two logs:</p>
\begin{align} \text{logprior} &amp;= \log (P(D_{pos})) - \log (P(D_{neg})) \\ &amp;= \log (D_{pos}) - \log (D_{neg})\\ \end{align}
<p>I don't know that this helps any with computation, but it makes it clearer (to me) that the ratio will be positive when the tweet's sentiment is positive and negative when the sentiment is negative.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgcd03beb">
<h4 id="orgcd03beb">Positive and Negative Word Probabilities</h4>
<div class="outline-text-4" id="text-orgcd03beb">
<p>Now for the second part of our equation. To compute the positive probability and the negative probability for a specific word in the vocabulary, we'll use the following inputs:</p>
<ul class="org-ul">
<li>\(freq_{pos} =\) the number of times the word is counted in a document with a label of 1</li>
<li>\(freq_{neg} =\) the number of times the word is counted in a document with a label of 0</li>
<li>\(N_{pos} = \) the number of words in all the positive documents</li>
<li>\(N_{neg} = \) the number of words in all the negative documents</li>
<li><i>V</i> is the number of unique words in the entire set of documents</li>
<li><i>W</i> is a word in a document</li>
</ul>
<p>So now we can re-write our numerator and denominator for the second term.</p>
\begin{align} P(W|positive) &amp;= P(W_{pos})\\ &amp;= \frac{freq_{pos}}{N_{pos}}\\ \end{align} \begin{align} P(W | negative ) &amp;= P(W_{neg})\\ &amp;= \frac{freq_{neg}}{N_{neg}}\\ \end{align}
<p>Meaning that the likelihood of the word given the class is the number of times the word shows up in documents of that class divided by a count of all the unique words in the corpus. One thing to notice, though, is that our numerators have the count for a word within documents labeled with the classification, but it's not guaranteed that all of the words will show up in both classes (the word "horrible" might only show up in the negative tweets, for instance) so if a word shows up in one class but not the other, we might end up with a zero in the numerator or denominator and not only is division by zero not defined, but neither is the logarithm of zero. The solution is to add 1 to the numerator and the size of the vocabulary to the denominator (adding 1 for each word). Besides fixing our arithmetic problem there's some other more mathy reasons for doing this that are explained in this <a href="https://en.wikipedia.org/wiki/Additive_smoothing">wikipedia article</a>.</p>
<p>With those changes we now have:</p>
\begin{align} P(W_{pos}) &amp;= \frac{freq_{pos} + 1}{N_{pos} + V}\\ \end{align} \begin{align} P(W_{neg}) &amp;= \frac{freq_{neg} + 1}{N_{neg} + V}\\ \end{align}
<p>And the log-likelihood term becomes:</p>
\begin{align} \text{loglikelihood} &amp;= \log \left(\frac{P(W_{pos})}{P(W_{neg})} \right)\\ &amp;= \log P(W_{pos}) - \log P(W_{neg})\\ &amp;= \log \frac{freq_{pos} + 1}{N_{pos} + V} - \log \frac{freq_{neg} + 1}{N_{neg} + V} \end{align}</div>
</div>
</div>
<div class="outline-2" id="outline-container-org17208f9">
<h2 id="org17208f9">End</h2>
<div class="outline-text-2" id="text-org17208f9">
<p>Now that we have the math I'm going to implement the model using python in <a href="posts/nlp/naive-bayes-twitter-sentiment-classification/">this post</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/bibliographies/text-data-management-and-analysis/">Text Data Management and Analysis</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/bibliographies/text-data-management-and-analysis/" rel="bookmark"><time class="published dt-published" datetime="2020-07-30T13:23:23-07:00" itemprop="datePublished" title="2020-07-30 13:23">2020-07-30 13:23</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div class="outline-2" id="outline-container-org8e39464">
<h2 id="org8e39464">Bibliography</h2>
<div class="outline-text-2" id="text-org8e39464">
<ul class="org-ul">
<li>Zhai C, Massung S. Text data management and analysis: a practical introduction to information retrieval and text mining. First edition. New York: Association for Computing Machinery; 2016. 510 p. (ACM books).</li>
</ul>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/bibliographies/sentiment-analysis-in-social-networks/">Sentiment Analysis In Social Networks</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/bibliographies/sentiment-analysis-in-social-networks/" rel="bookmark"><time class="published dt-published" datetime="2020-07-30T13:05:58-07:00" itemprop="datePublished" title="2020-07-30 13:05">2020-07-30 13:05</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div class="outline-2" id="outline-container-orga25a545">
<h2 id="orga25a545">Bibliography</h2>
<div class="outline-text-2" id="text-orga25a545">
<ul class="org-ul">
<li>Pozzi FA, Fersini E, Messina E, Liu B, editors. Sentiment analysis in social networks. Elsevier Inc.: 2017. 263 p.</li>
</ul>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/bibliographies/bib-speech-and-language-processing-jurafsky-martin/">Speech and Language Processing</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/bibliographies/bib-speech-and-language-processing-jurafsky-martin/" rel="bookmark"><time class="published dt-published" datetime="2020-07-27T20:53:07-07:00" itemprop="datePublished" title="2020-07-27 20:53">2020-07-27 20:53</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div class="outline-2" id="outline-container-orgce84119">
<h2 id="orgce84119">Citation</h2>
<div class="outline-text-2" id="text-orgce84119">
<p>Jurafsky, D. & Martin, J. (2020). Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition. 3rd Edition draft. <a href="https://web.stanford.edu/~jurafsky/slp3/">(URL)</a></p>
</div>
</div>
<div class="outline-2" id="outline-container-org9693712">
<h2 id="org9693712">Notes</h2>
<div class="outline-text-2" id="text-org9693712">
<p>Online and PDF version of a (work in progress) revision to this text about text processing.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/the-tweet-vectorizer/">The Tweet Vectorizer</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/the-tweet-vectorizer/" rel="bookmark"><time class="published dt-published" datetime="2020-07-24T16:51:53-07:00" itemprop="datePublished" title="2020-07-24 16:51">2020-07-24 16:51</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/the-tweet-vectorizer/#org86a841a">Beginning</a>
<ul>
<li><a href="posts/nlp/the-tweet-vectorizer/#org41592c3">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/the-tweet-vectorizer/#org1c2d112">Middle</a>
<ul>
<li><a href="posts/nlp/the-tweet-vectorizer/#orgbb24631">The Tweet Vectors</a></li>
<li><a href="posts/nlp/the-tweet-vectorizer/#org565f830">The Tweet Vectorizer</a></li>
<li><a href="posts/nlp/the-tweet-vectorizer/#orgf28907a">Plotting The Vectors</a></li>
</ul>
</li>
<li><a href="posts/nlp/the-tweet-vectorizer/#org5a5d3c4">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org86a841a">
<h2 id="org86a841a">Beginning</h2>
<div class="outline-text-2" id="text-org86a841a">
<p>In the previous post (<a href="posts/nlp/twitter-word-frequencies/">Twitter Word Frequencies</a>) I built up a word-counter now we're going to use it to create word-counters for our tweets.</p>
<p>We are going to be classifying <a href="https://help.twitter.com/en/using-twitter/how-to-tweet">tweets</a> by positive or negative sentiment, but tweets are free-form text (and images, but we're ignoring them) and we want numbers in a table form so in order to be able to work with the tweets we'll have to convert them somehow. That's what we'll be doing here.</p>
</div>
<div class="outline-3" id="outline-container-org41592c3">
<h3 id="org41592c3">Set Up</h3>
<div class="outline-text-3" id="text-org41592c3">
<p>This is some preliminary stuff so we have python ready to go.</p>
</div>
<div class="outline-4" id="outline-container-org4aadbeb">
<h4 id="org4aadbeb">Imports</h4>
<div class="outline-text-4" id="text-org4aadbeb">
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">bokeh.models.tools</span> <span class="kn">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># the vectorizer</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>

<span class="c1"># some helper stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf7f94fa">
<h4 id="orgf7f94fa">The Environment</h4>
<div class="outline-text-4" id="text-orgf7f94fa">
<p>I'm using environment variables (well, in this case a <code>.env</code> file) to keep track of where I save files so this loads the paths into the environment.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8785df6">
<h4 id="org8785df6">The Data</h4>
<div class="outline-text-4" id="text-org8785df6">
<div class="highlight">
<pre><span></span><span class="n">training</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_PROCESSED"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>

<span class="n">train_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>

<span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_SENTIMENT"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Sentiment</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
<p>The <code>training</code> frame has the cleaned, stemmed, and tokenized version of the tweets.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
tweet    [park, get, sunlight, :)]
label                            1
Name: 0, dtype: object
</pre>
<p>This is what we need for when things are working. The <code>train_raw</code> frame has the tweets as they come from NLTK.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_raw</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
tweet    off to the park to get some sunlight : )
label                                           1
Name: 0, dtype: object
</pre>
<p>This is just for double-checking if things aren't working the way we expect.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orga65e897">
<h4 id="orga65e897">For Plotting</h4>
<div class="outline-text-4" id="text-orga65e897">
<p>These are some helpers for the plotting that I'll do later on.</p>
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"the-tweet-vectorizer"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_PLOT"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Plot</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org34c314b">
<h4 id="org34c314b">The Token Counter</h4>
<div class="outline-text-4" id="text-org34c314b">
<p>I made the counts in a previous post (<a href="posts/nlp/twitter-word-frequencies/">Twitter Word Frequencies</a>) so I'll just load it here.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_COUNTER"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1c2d112">
<h2 id="org1c2d112">Middle</h2>
<div class="outline-text-2" id="text-org1c2d112"></div>
<div class="outline-3" id="outline-container-orgbb24631">
<h3 id="orgbb24631">The Tweet Vectors</h3>
<div class="outline-text-3" id="text-orgbb24631">
<p>In an earlier post we built a dictionary-like set to count the number of times each token was in a positive tweet and the number of times it was in a negative tweet. To represent a tweet as a vector we're going to sum the total counts for the tokens in the tweet when they are positive and when they are positive.</p>
<p>Come again?</p>
<p>Lets say you have a tweet <code>"a b c"</code> which tokenizes to <code>a, b, c</code> and you look up the positive and negative tweet counts for each token so you add them up, getting this:</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-right" scope="col">Positive</th>
<th class="org-right" scope="col">Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">a</td>
<td class="org-right">1</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">b</td>
<td class="org-right">2</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">c</td>
<td class="org-right">3</td>
<td class="org-right">6</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">Total</td>
<td class="org-right">6</td>
<td class="org-right">15</td>
</tr>
</tbody>
</table>
<p>The bottom row (<code>total</code>) has the values for our vector for any tweet containing the tokens <i>a, b,</i> and <i>c</i>. So to represent this tweet you would create a vector of the form:</p>
\begin{align} \hat{v} &amp;= \langle bias, positive, negative \rangle\\ &amp;= \langle 1, 6, 15\rangle\\ \end{align}
<p><b>Note:</b> The bias is always one (it just is).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org565f830">
<h3 id="org565f830">The Tweet Vectorizer</h3>
<div class="outline-text-3" id="text-org565f830">
<p>Here's where I'll create the class to create the vectors.</p>
</div>
<div class="outline-4" id="outline-container-orgd6eb232">
<h4 id="orgd6eb232">The Testing</h4>
<div class="outline-text-4" id="text-orgd6eb232">
<p>We'll start with some vaguely BDD-ish testing. First the tangles.</p>
<div class="highlight">
<pre><span></span>Feature: A Tweet Count Vectorizer

&lt;&lt;extract-features-feature&gt;&gt;

&lt;&lt;get-vectors-feature&gt;&gt;

&lt;&lt;reset-vectors-feature&gt;&gt;

&lt;&lt;check-rep-vectorizer-tweets-feature&gt;&gt;

&lt;&lt;check-rep-vectorizer-counter-feature&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be</span><span class="p">,</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">contain_exactly</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">raise_error</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">when</span><span class="p">,</span>
    <span class="n">then</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this testing</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">Columns</span><span class="p">,</span> <span class="n">TweetVectorizer</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="n">and_also</span> <span class="o">=</span> <span class="n">then</span>
<span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/tweet_vectorizer.feature"</span><span class="p">)</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">extract</span><span class="o">-</span><span class="n">features</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectors</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">reset</span><span class="o">-</span><span class="n">vectors</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectorizer</span><span class="o">-</span><span class="n">tweets</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">rep</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">vectorizer</span><span class="o">-</span><span class="n">counter</span><span class="o">-</span><span class="n">check</span><span class="o">-</span><span class="n">rep</span><span class="o">&gt;&gt;</span>
</pre></div>
<p>And now we can move on to the tests.</p>
</div>
<ul class="org-ul">
<li><a id="org2a4e15e"></a>Extract Features<br>
<div class="outline-text-5" id="text-org2a4e15e">
<p>For training and testing I'm going to want to convert them in bulk, but first I'll create a method so that a single tweet can be vectorized.</p>
<div class="highlight">
<pre><span></span>Scenario: A user converts a tweet to a feature-vector

Given a Tweet Vectorizer
When the user converts a tweet to a feature-vector
Then it's the expected feature-vector
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: A user converts a tweet to a feature-vector</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_tweet_vectorizer</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">TWEETS</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">TOKENS</span> <span class="o">=</span> <span class="s2">"A B C"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKENS</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                               <span class="p">(</span><span class="s1">'B'</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">2</span><span class="p">,</span>
                               <span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">3</span><span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">processed</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                          <span class="n">counts</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="s2">"A B C"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user converts a tweet to a feature-vector"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"A B C"</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="s2">"A B C"</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected_array</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it's the expected feature-vector"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_feature_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">expected_array</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="o">*</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">))</span>

    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">contain_exactly</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org615fe34"></a>Get the Vectors<br>
<div class="outline-text-5" id="text-org615fe34">
<div class="highlight">
<pre><span></span>Scenario: A user retrieves the count vectors
Given a user sets up the Count Vectorizer with tweets
When the user checks the count vectors
Then the first column is the bias colum
And the positive counts are correct
And the negative counts are correct
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Feature: A Tweet Count Vectorizer</span>

<span class="c1"># Scenario: A user retrieves the count vectors</span>

<span class="nd">@given</span><span class="p">(</span><span class="s2">"a user sets up the Count Vectorizer with tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_vectorizer</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
    <span class="n">TWEETS</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">TOKENS</span> <span class="o">=</span> <span class="s2">"A B C"</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">TOKENS</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">spec</span><span class="o">=</span><span class="n">WordCounter</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">({(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                                       <span class="p">(</span><span class="s1">'B'</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">2</span><span class="p">,</span>
                                       <span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span><span class="mi">3</span><span class="p">})</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                          <span class="n">counts</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_process</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">TOKENS</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">negative</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
                                      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">TOKENS</span><span class="p">])</span>
                                      <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)])</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">positive</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">([</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
                                      <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">TOKENS</span><span class="p">])</span>
                                     <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TWEETS</span><span class="p">)])</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user checks the count vectors"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_count_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="c1"># kind of silly, but useful for troubleshooting</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the first column is the bias colum"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_bias</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">bias</span><span class="p">]</span><span class="o">==</span><span class="n">katamari</span><span class="o">.</span><span class="n">bias</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@and_also</span><span class="p">(</span><span class="s2">"the positive counts are correct"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_positive_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">positive</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">positive</span><span class="p">]</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">positive</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>


<span class="nd">@and_also</span><span class="p">(</span><span class="s2">"the negative counts are correct"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_negative_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">negative</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">actual_vectors</span><span class="p">[:,</span> <span class="n">Columns</span><span class="o">.</span><span class="n">negative</span><span class="p">]</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">negative</span><span class="p">,</span> <span class="n">katamari</span><span class="o">.</span><span class="n">negative</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="orgc7d1d44"></a>Reset the Vectors<br>
<div class="outline-text-5" id="text-orgc7d1d44">
<div class="highlight">
<pre><span></span>Scenario: The vectors are reset
Given a Tweet Vectorizer with the vectors set
When the user calls the reset method
Then the vectors are gone
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The vectors are reset</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with the vectors set"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_vectors</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="n">faker</span><span class="o">.</span><span class="n">sentence</span><span class="p">()],</span> <span class="n">counts</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the user calls the reset method"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_reset</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectors</span><span class="p">))</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the vectors are gone"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_vectors_gone</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="org857de4f"></a>Check Rep<br>
<div class="outline-text-5" id="text-org857de4f">
<div class="highlight">
<pre><span></span>Scenario: the check-rep is called with bad tweets
Given a Tweet Vectorizer with bad tweets
When check-rep is called
Then it raises an AssertionError
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: the check-rep is called with bad tweets</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with bad tweets"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_bad_tweets</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                                          <span class="n">counts</span><span class="o">=</span><span class="n">Counter</span><span class="p">())</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"check-rep is called"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_check_rep</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">bad_call</span><span class="p">():</span>
        <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">check_rep</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">bad_call</span> <span class="o">=</span> <span class="n">bad_call</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it raises an AssertionError"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_assertion_error</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">bad_call</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">raise_error</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span>Scenario: the check-rep is called with a bad word-counter
Given a Tweet Vectorizer with the wrong counter object
When check-rep is called
Then it raises an AssertionError
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: the check-rep is called with a bad word-counter</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a Tweet Vectorizer with the wrong counter object"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_bad_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="p">[</span><span class="s2">"apple"</span><span class="p">],</span> <span class="n">counts</span><span class="o">=</span><span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">())</span>
    <span class="k">return</span>

<span class="c1"># When check-rep is called</span>
<span class="c1"># Then it raises an AssertionError</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgc49237b">
<h4 id="orgc49237b">The Implementation</h4>
<div class="outline-text-4" id="text-orgc49237b">
<p>Okay, so now for the actual class.</p>
<div class="highlight">
<pre><span></span><span class="c1"># python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">attr</span>


<span class="c1"># this package</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="n">Columns</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">bias</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">TweetClass</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">positive</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">negative</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># some types</span>
<span class="n">Tweets</span> <span class="o">=</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span>
<span class="n">Vector</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TweetVectorizer</span><span class="p">:</span>
    <span class="sd">"""A tweet vectorizer</span>

<span class="sd">    Args:</span>
<span class="sd">     tweets: the pre-processed/tokenized tweets to vectorize</span>
<span class="sd">     counts: the counter with the tweet token counts</span>
<span class="sd">     processed: to not process the bulk tweets</span>
<span class="sd">     bias: constant to use for the bias</span>
<span class="sd">    """</span>
    <span class="n">tweets</span><span class="p">:</span> <span class="n">Tweets</span>
    <span class="n">counts</span><span class="p">:</span> <span class="n">Counter</span>
    <span class="n">processed</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">bias</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">1</span>
    <span class="n">_process</span><span class="p">:</span> <span class="n">TwitterProcessor</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">_vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TwitterProcessor</span><span class="p">:</span>
        <span class="sd">"""Processes tweet strings to tokens"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">"""The vectorized tweet counts"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rows</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span>

    <span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">as_array</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Vector</span><span class="p">:</span>
        <span class="sd">"""converts a single tweet to an array of counts</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: a string tweet to count up</span>
<span class="sd">        as_array: whether to return an array instead of a list</span>

<span class="sd">       Returns:</span>
<span class="sd">        either a list of floats or a 1 x 3 array</span>
<span class="sd">       """</span>
        <span class="c1"># this is a hack to make this work both in bulk and one tweet at a time</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tweet</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
            <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">TweetClass</span><span class="o">.</span><span class="n">positive</span><span class="p">)]</span>
                 <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)),</span>
            <span class="nb">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="n">TweetClass</span><span class="o">.</span><span class="n">negative</span><span class="p">)]</span>
                                <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vector</span><span class="p">])</span> <span class="k">if</span> <span class="n">as_array</span> <span class="k">else</span> <span class="n">vector</span>
        <span class="k">return</span> <span class="n">vector</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Removes the vectors"""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_vectors</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">check_rep</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Checks that the tweets and word-counter are set</span>

<span class="sd">       Raises:</span>
<span class="sd">        AssertionError if one of them isn't right</span>
<span class="sd">       """</span>
        <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span>
        <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">)</span> <span class="ow">is</span> <span class="n">Counter</span>
        <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf28907a">
<h3 id="orgf28907a">Plotting The Vectors</h3>
<div class="outline-text-3" id="text-orgf28907a">
<p>Now that we have a vectorizer definition, let's see what it looks like when we plot the training set. First, we'll have to convert the training set tweets to the vectors.</p>
<div class="highlight">
<pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">training</span><span class="o">.</span><span class="n">tweet</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">counts</span><span class="o">=</span><span class="n">counter</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span>
                        <span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="n">data</span><span class="p">[</span><span class="s2">"Sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">decode</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">tweet</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
['park' 'get' 'sunlight' ':)']
bias                1
positive         3139
negative          208
Sentiment    positive
Name: 0, dtype: object
</pre>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_raw</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tweet</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">training</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tweet</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">token</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">token</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
off to the park to get some sunlight : )
park    6
park    7
get     165
get     200
sunlight        1
sunlight        0
:)      2967
:)      1
</pre>
<p>So a smiley face seems to overwhelm other tokens.</p>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
<pre class="example">
negative    4013
positive    3987
Name: Sentiment, dtype: int64
</pre>
<p>If you followed the previous post you can probably figure out that this is the training set. Weird but I hadn't noticed that they aren't exactly balanced… Anyway, now the plot.</p>
<div class="highlight">
<pre><span></span><span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span>
    <span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">"Positive"</span><span class="p">,</span> <span class="s2">"@positive{0,0}"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Negative"</span><span class="p">,</span> <span class="s2">"@negative{0,0}"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="s2">"@Sentiment"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="n">fill_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                           <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">])</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
                               <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                               <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                               <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                               <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative Tweet Sentiment"</span><span class="p">,</span>
                           <span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_scatter"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/the-tweet-vectorizer/positive_negative_scatter.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So, each point is a tweet and the color is what the tweet was classified as. I don't know why they seem to group in bunches, but you can sort of see that by using the token counts we've made them separable. This becomes even more obvious if we change the scale to a logarithmic one.</p>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"Sentiment"</span><span class="p">,</span>
                           <span class="n">loglog</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">fill_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                           <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">])</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
                               <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                               <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                               <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                               <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                               <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                               <span class="n">apply_ranges</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative Tweet Sentiment (log-log)"</span><span class="p">,</span>
                           <span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_scatter_log"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/the-tweet-vectorizer/positive_negative_scatter_log.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>I don't know why but the <code>xlim</code> and <code>ylim</code> arguments don't seem to work when you use a logarithmic scale, but if you zoom out using the <code>wheel zoom</code> tool (third icon from the top of the toolbar on the right) you'll see that there's a pretty good separation between the sentiment classifications.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org5a5d3c4">
<h2 id="org5a5d3c4">End</h2>
<div class="outline-text-2" id="text-org5a5d3c4">
<p>So, that's it for vectorizing tweets I'll save the values so I don't have to re-do them again when I actually fit the model. Since I changed some values to make it better for plotting I'll change them back first.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"Sentiment"</span><span class="p">:</span> <span class="s2">"sentiment"</span><span class="p">})</span>
<span class="n">data</span><span class="p">[</span><span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">Sentiment</span><span class="o">.</span><span class="n">encode</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">to_feather</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAIN_VECTORS"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
</pre></div>
<p>To make it consistent I'm going to convert the test set too.</p>
<div class="highlight">
<pre><span></span><span class="n">test</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TEST_PROCESSED"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="n">test_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">test</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">counter</span><span class="o">=</span><span class="n">counter</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span>
                             <span class="n">columns</span><span class="o">=</span><span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">test_data</span><span class="p">[</span><span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">label</span>

<span class="n">test_data</span><span class="o">.</span><span class="n">to_feather</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TEST_VECTORS"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
</pre></div>
<p>We also need to use the vectorizers to vectorize future tweets so I'll pickle them too.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_VECTORIZER"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
<p>Next up in the series: <a href="posts/nlp/implementing-twitter-logistic-regression/">Implementing Logistic Regression for Tweet Sentiment Analysis</a>.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/implementing-twitter-logistic-regression/">Implementing Logistic Regression for Tweet Sentiment Analysis</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/implementing-twitter-logistic-regression/" rel="bookmark"><time class="published dt-published" datetime="2020-07-14T16:16:22-07:00" itemprop="datePublished" title="2020-07-14 16:16">2020-07-14 16:16</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org009c5a0">Beginning</a>
<ul>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org1f7875c">Set Up</a></li>
</ul>
</li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orge84087c">Middle</a>
<ul>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org67f7d63">Logistic Regression</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org116f605">Train the Model</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org8a91205">Test the Model</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orgb06b6eb">The Wrong Stuff</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org257c064">Some Fresh Tweets</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#orgb77eaa8">Compare to SKLearn</a></li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org0a19b15">Vizualizing the Model</a></li>
</ul>
</li>
<li><a href="posts/nlp/implementing-twitter-logistic-regression/#org2b5bb45">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org009c5a0">
<h2 id="org009c5a0">Beginning</h2>
<div class="outline-text-2" id="text-org009c5a0">
<p>In the previous post in this series (<a href="posts/nlp/the-tweet-vectorizer/">The Tweet Vectorizer</a>) I transformed some tweet data to vectors based on the sums of the positive and negative tokens in each tweet. This post will implement a Logistic Regression model to train on those vectors to classify tweets by sentiment.</p>
</div>
<div class="outline-3" id="outline-container-org1f7875c">
<h3 id="org1f7875c">Set Up</h3>
<div class="outline-text-3" id="text-org1f7875c"></div>
<div class="outline-4" id="outline-container-orga5d967d">
<h4 id="orga5d967d">Imports</h4>
<div class="outline-text-4" id="text-orga5d967d">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">bokeh.models.tools</span> <span class="kn">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be_true</span><span class="p">,</span>
    <span class="n">expect</span><span class="p">,</span>
    <span class="n">equal</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># this package</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.sentiment</span> <span class="kn">import</span> <span class="n">TweetSentiment</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>

<span class="c1"># for plotting</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org62f7aa2">
<h4 id="org62f7aa2">The Timer</h4>
<div class="outline-text-4" id="text-org62f7aa2">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4db725a">
<h4 id="org4db725a">The Dotenv</h4>
<div class="outline-text-4" id="text-org4db725a">
<p>This loads the locations of previous data and object saves I made.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org60cfd68">
<h4 id="org60cfd68">The Data</h4>
<div class="outline-text-4" id="text-org60cfd68">
<p>I made vectors earlier but to process new tweets I need the Twitter Vectorizer anyway, so I'm going to reprocess everything here.</p>
<div class="highlight">
<pre><span></span><span class="n">train_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>

<span class="n">test_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TEST_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_raw</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_raw</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Training: 8,000
Testing: 2,000
</pre>
<div class="highlight">
<pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">train_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
<span class="n">train_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">train_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="n">processed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_vectorizer</span> <span class="o">=</span> <span class="n">TweetVectorizer</span><span class="p">(</span><span class="n">test_raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">,</span> <span class="n">processed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>But it's easier to work with the DataFrame when exploring and I've been going back and fiddling with different parts of the pipeline and not all the data-files are up to date so it's safer to start from the raw files again.</p>
<div class="highlight">
<pre><span></span><span class="n">training</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">testing</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="n">training</span><span class="p">[</span><span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_raw</span><span class="o">.</span><span class="n">label</span>
<span class="n">testing</span><span class="p">[</span><span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_raw</span><span class="o">.</span><span class="n">label</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">training</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">testing</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Training: 8,000
Testing: 2,000
</pre></div>
</div>
<div class="outline-4" id="outline-container-org3fa9f9c">
<h4 id="org3fa9f9c">For Plotting</h4>
<div class="outline-text-4" id="text-org3fa9f9c">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"implementing-twitter-logistic-regression"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_PLOT"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Plot</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5de65c9">
<h4 id="org5de65c9">Types</h4>
<div class="outline-text-4" id="text-org5de65c9">
<p>Some stuff for type hinting.</p>
<div class="highlight">
<pre><span></span><span class="n">Tweet</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
<span class="n">PositiveProbability</span> <span class="o">=</span> <span class="n">Tweet</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge84087c">
<h2 id="orge84087c">Middle</h2>
<div class="outline-text-2" id="text-orge84087c"></div>
<div class="outline-3" id="outline-container-org67f7d63">
<h3 id="org67f7d63">Logistic Regression</h3>
<div class="outline-text-3" id="text-org67f7d63">
<p>Now that we have the data it's time to implement the <a href="https://www.wikiwand.com/en/Logistic_regression">Logistic Regression</a> model to classify tweets as positive or negative.</p>
</div>
<div class="outline-4" id="outline-container-org1de115c">
<h4 id="org1de115c">The Sigmoid Function</h4>
<div class="outline-text-4" id="text-org1de115c">
<p>Logistic Regression uses a version of <a href="https://www.wikiwand.com/en/Sigmoid_function">the Sigmoid Function</a> called the Standard <a href="https://www.wikiwand.com/en/Logistic_function">Logistic Function</a> to measure whether an entry has passed the threshold for classification. This is the mathematical definition:</p>
<p>\[ \sigma(z) = \frac{1}{1 + e^{-x \cdot \theta}} \]</p>
<p>The numerator (1) determines the maximum value for the function, so in this case the range is from 0 to 1 and we can interpret \(\sigma(z)\) as the probability that a tweet (<i>z</i>) is positive (<i>1</i>). The interpretation of \(\sigma(z)\) is it's the probability that <i>z</i> (a vector representation of a tweet times the weights) is classified as 1 (having a positive sentiment). So we could re-write this as:</p>
<p>\[ P(Y=1 | z) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2)}} \]</p>
<p>Where \(x_1\) is the sum of the positive tweet counts for the tokens in \(x\) and \(x_2\) is the sum of the negative tweet counts for the tokens. \(\beta_0\) is our bias and \(\beta_1\) and \(\beta_2\) are the weights that we're going to find by training our model.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">:</span> <span class="n">Tweet</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PositiveProbability</span><span class="p">:</span>
    <span class="sd">"""Calculates the logistic function value</span>

<span class="sd">    Args:</span>
<span class="sd">     z: input to the logistic function (float or array)</span>

<span class="sd">    Returns:</span>
<span class="sd">     calculated sigmoid for z</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="orgd2a5e40"></a>A Little Test<br>
<div class="outline-text-5" id="text-orgd2a5e40">
<p>We have a couple of given values to test that our sigmoid is correct.</p>
<div class="highlight">
<pre><span></span><span class="n">expect</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>

<span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">4.92</span><span class="p">),</span> <span class="mf">0.9927537604041685</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>

<span class="n">expected</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9927537604041685</span><span class="p">])</span>
<span class="n">actual</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">4.92</span><span class="p">]))</span>

<span class="n">expect</span><span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">actual</span><span class="o">==</span><span class="n">expected</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="orgd9aa355"></a>Plotting It<br>
<div class="outline-text-5" id="text-orgd9aa355">
<p>Let's see what the output looks like.</p>
<div class="highlight">
<pre><span></span><span class="n">min_x</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
<span class="n">max_x</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">halfway</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plot_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">curve</span> <span class="o">=</span> <span class="n">plot_data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">)</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Curve</span><span class="p">([(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">halfway</span><span class="p">),</span> <span class="p">(</span><span class="n">max_x</span><span class="p">,</span> <span class="n">halfway</span><span class="p">)],</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">curve</span> <span class="o">*</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Sigmoid"</span><span class="p">,</span>
    <span class="n">show_grid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">embedded</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sigmoid_function"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">embedded</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/sigmoid_function.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Looking at the plot you can see that the probability that a tweet is positive is 0.5 when the input is 0, becomes more likely the more positive the input is, and is less likely the more negative an input is. Next we'll need to look at how to train our model.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orge56ffe5">
<h4 id="orge56ffe5">The Loss Function</h4>
<div class="outline-text-4" id="text-orge56ffe5">
<p>To train our model we need a way to measure how well (or in this case poorly) it's doing. For this we'll use the <a href="http://wiki.fast.ai/index.php/Log_Loss">Log Loss</a> function which is the negative logarithm of our probability - so for each tweet, we'll calculate \(\sigma\) (which is the probability that it's positive) and take the negative logarithm of it to get the log-loss.</p>
<p>The formula for loss:</p>
<p>\[ Loss = - \left( y\log (p) + (1-y)\log (1-p) \right) \]</p>
<p>\(y\) is the classification of the tweet (1 or 0) so when the tweet is classified 1 (positive) the right term becomes 0 and when the tweet is classified 0 (negative) the left term becomes 0 so this is the equivalent of:</p>
<div class="highlight">
<pre><span></span><span class="k">if</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
<p>Where \(p\) is the probability that the tweet is positive and \(1 - p\) is the probability that it isn't (so it's negative since that's the only alternative). We take the negative of the logarithm because \(log(p)\) is negative (all the values of \(p\) are between 0 and 1) so negating it makes the output positive.</p>
<p>We can fill it in to make it match what we're going to actually calculate - for the \(i^{th}\) item in our dataset \(p = \sigma(z^i \cdot \theta)\) and the equation becomes:</p>
<p>\[ Loss = - \left( y^{(i)}\log (\sigma(z^{(i)} \cdot \theta)) + (1-y^{(i)})\log (1-\sigma(z^{(i)} \cdot \theta)) \right) \]</p>
<div class="highlight">
<pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"p"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
    <span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span> 
<span class="p">})</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"p"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Log-Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Loss (Y=1)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"log_loss_example"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/log_loss_example.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So what is this telling us? This is for the case where a tweet is labeled positive and at the far left, near 0 (<code>log(0)</code> is undefined so you can use a really small probability but not 0) our model is saying that it probably isn't a positive tweet, so the log-loss is fairly high, then as we move along the x-axis our model is saying that it is more and more likely that the tweet is positive so our log-loss goes down, until we reach the point where our model says that it's 100% guaranteed to be a positive tweet, at which point our log-loss drops to zero. Fairly intuitive.</p>
<p>Let's look at the case where the tweet is actually negative (<i>y=0</i>). Since <i>p</i> is the probability that it's positive, when the label is 0 we need to take the log of <i>1-p</i> to see what the model thinks the probability is that it's negative.</p>
<div class="highlight">
<pre><span></span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">steps</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">probabilities</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s2">"p"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
    <span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span> 
<span class="p">})</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"p"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Log-Loss"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Loss (Y=0)"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"log_loss_y_0_example"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/log_loss_y_0_example.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So now we have basically the opposite loss. In this case the tweet is not positive so when the model puts a low likelihood that the tweet is positive the log-loss is small, but as you move along the x-axis the model is giving more probability to the notion that the tweet is positive so the log-loss gets larger.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org29d3d1f">
<h4 id="org29d3d1f">Training the Model</h4>
<div class="outline-text-4" id="text-org29d3d1f">
<p>To train the model we're going to use <a href="https://www.wikiwand.com/en/Gradient_descent">Gradient Descent</a>. What this means is that we're going to use the <i>gradient</i> of our loss function to figure out how to update our weights. The <i>gradient</i> is just the slope of the loss-function (but generalized to multiple dimensions).</p>
<p>How do we do this? First we calculate our model's estimate of the input being positive, then we calculate the gradient of its loss. If you remember from calculus the slope of a line is the derivative of its function so instead of calculating the loss, we'll calculate the derivative of the loss-function which is given as:</p>
<p>\[ \nabla_{\theta}L_{\theta} = \left [ \sigma(x \cdot \theta) - y \right] x_j \]</p>
<p>The rightmost term \(x_j\) represents one term in the input vector, the one that matches the weight - this has to be repeated for each \(\beta\) in \(\theta\) so in our case it will be repeated three times, with \(x\) being 1 for the bias term.</p>
<p>It's called stochastic gradient descent because the inputs are chosen randomly from our training set. This turns out to not give you a smooth descent so we're going to do <b>batch training</b> which changes our gradient a little.</p>
<p>\[ \nabla_{\theta_j}L_{\theta} = \frac{1}{m} \sum_{i=1}^m(\sigma(x \cdot \theta)-y)x_j \]</p>
<p>Our gradient is now the average of the gradients for each of the inputs in our training set. We update the weights by subtracting a fraction of the difference between the current weights and the gradient. The fraction \(\eta\) is called the <i>learning rate</i> and it controls how much the weights change, representng how fast our model will learn. If it is too large we can miss the minimum and if it's too large it will take too long to train the model, so we need to choose the right value for it to reach the minima within a feasible time.</p>
<p>Here's the algorithm in the rough.</p>
<ul class="org-ul">
<li><i>L</i>: Loss Function</li>
<li>\(\sigma\): probability function parameterized by \(\theta\)</li>
<li><i>x</i>: set of training inputs</li>
<li><i>y</i>: set of training labels</li>
</ul>
<script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<pre id="gradientdescent" style="display:hidden">
\begin{algorithm}
\caption{Gradient Descent}
\begin{algorithmic}
\STATE $\theta \gets 0$
\WHILE{not done}

 \FOR{each $(x^{(i)},y^{(i)})$ in training data}
  \State $\hat{y} \gets \sigma(x^{(i)}; \theta)$
  \State $loss \gets L(\hat{y}^{(i)}, y^{(i)})$
  \State $g \gets \nabla_{\theta} L(\hat{y}^{(i)}, y^{(i)})$
  \State $\theta \gets \theta - \eta g$
 \ENDFOR

\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescent"));
</script>
<p>We can translate this a little more.</p>
<pre id="gradientdescentengrish" style="display:hidden">
\begin{algorithm}
\caption{Gradient Descent}
\begin{algorithmic}
\STATE Initialize the weights
\WHILE{the loss is still too high}

 \FOR{each $(x^{(i)},y^{(i)})$ in training data}
  \State What is our probability that the input is positive?
  \State How far off are we?
  \State What direction would we need to head to maximize the error?
  \State Let's go in the opposite direction.
 \ENDFOR

\ENDWHILE
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescentengrish"));
</script>
<p>Note that the losses aren't needed for the algorithm to train the model, just for assessing how well the model did.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgf668d9f">
<h4 id="orgf668d9f">Implement It</h4>
<div class="outline-text-4" id="text-orgf668d9f"></div>
<ul class="org-ul">
<li><a id="org5f12368"></a>The Function<br>
<div class="outline-text-5" id="text-org5f12368">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
                     <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                     <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Finds the weights for the model</span>

<span class="sd">    Args:</span>
<span class="sd">     x: the tweet vectors</span>
<span class="sd">     y: the positive/negative labels</span>
<span class="sd">     weights: the regression weights</span>
<span class="sd">     learning_rate: (eta) how much to update the weights</span>
<span class="sd">     iterations: the number of times to repeat training</span>
<span class="sd">    """</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">learning_rate</span> <span class="o">/=</span> <span class="n">rows</span>
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
        <span class="c1"># average loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)))</span> <span class="o">+</span>
                               <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">))))</span><span class="o">/</span><span class="n">rows</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span><span class="o">.</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
<p>If you look at the implementation you can see that there are some changes made to it from what I wrote earlier. This is because the algorithm I wrote in pseudocode came from a book while the implementation that I made came from a Coursera assignment. The main differences being that we use a set number of iterations to train the model and the learning rate is divided by the number of training examples. Of course, you could just divide the learning rate before passing it in to the function so it doesn't really change it that much. I also had to take into account the fact that you can't just take a dot product of two matrices if their shapes aren't compatible - the rows of the left hand matrix has to match the columns of the right hand matrix) so there's some transposing of matrices being done. Our actual implementation might be more like this.</p>
<pre id="gradientdescentimplementation" style="display:hidden">
\begin{algorithm}
\caption{Gradient Descent Implemented}
\begin{algorithmic}
\STATE $\theta \gets 0$
\STATE $m \gets rows(X)$
\FOR{$iteration \in$ \{0 $\ldots iterations-1$ \}}
  \STATE $\hat{Y} \gets \sigma(X \cdot \theta)$
  \STATE $loss \gets -\frac{1}{m}(Y^T \cdot \ln \hat{Y}) + (1 - Y)^T \cdot (\ln 1 - \hat{Y})$
  \STATE $\nabla \gets \sum (\hat{Y} - Y)^T \cdot x$
  \STATE $\theta \gets \theta - \frac{\eta}{m} \nabla^T$
 \ENDFOR
\end{algorithmic}
\end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("gradientdescentimplementation"));
</script></div>
</li>
<li><a id="org1b68203"></a>Test It<br>
<div class="outline-text-5" id="text-org1b68203">
<p>First we'll make a fake (random) input set to make it easier to check the gradient descent.</p>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">fake</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2000</span>
<span class="n">fake_tweet_vectors</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">fake</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>Now, the fake labels - we'll make around 35% of them negative and the rest positive.</p>
<div class="highlight">
<pre><span></span><span class="n">fake_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.35</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="org93cf60c"></a>Do the Descent<br>
<div class="outline-text-5" id="text-org93cf60c">
<p>So now we can pass our test data into the gradient descent function and see what happens.</p>
<div class="highlight">
<pre><span></span><span class="n">fake_weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">fake_loss</span><span class="p">,</span> <span class="n">fake_weights</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">fake_tweet_vectors</span><span class="p">,</span>
                                           <span class="n">y</span><span class="o">=</span><span class="n">fake_labels</span><span class="p">,</span> 
                                           <span class="n">weights</span><span class="o">=</span><span class="n">fake_weights</span><span class="p">,</span>
                                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                                           <span class="n">iterations</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
<span class="n">expect</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">fake_loss</span><span class="p">,</span> <span class="mf">0.67094970</span><span class="p">,</span> <span class="n">rel_tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The log-loss after training is </span><span class="si">{</span><span class="n">fake_loss</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The trained weights are </span><span class="si">{</span><span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">fake_weights</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
The log-loss after training is 0.67094970.
The trained weights are [4.1e-07, 0.00035658, 7.309e-05]
</pre></div>
</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org116f605">
<h3 id="org116f605">Train the Model</h3>
<div class="outline-text-3" id="text-org116f605">
<p>Now that we have our parts let's actually train the model using the real training data. I originally did this expecting numpy arrays (like in earlier steps I was expecting python lists instead of numpy arrays - stuff changes) so I'll be extracting the relevant columns from the pandas DataFrame and converting them back to arrays.</p>
<div class="highlight">
<pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">1e-9</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">final_loss</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">train_vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">training</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">eta</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="n">iterations</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The log-loss after training is </span><span class="si">{</span><span class="n">final_loss</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The resulting vector of weights is "</span>
      <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weights</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TweetSentiment</span><span class="p">(</span><span class="n">train_vectorizer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">()</span>

<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">training</span><span class="o">.</span><span class="n">sentiment</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">training</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
2020-07-27 17:54:58,357 graeae.timers.timer start: Started: 2020-07-27 17:54:58.357765
2020-07-27 17:54:58,776 graeae.timers.timer end: Ended: 2020-07-27 17:54:58.776834
2020-07-27 17:54:58,777 graeae.timers.timer end: Elapsed: 0:00:00.419069
The log-loss after training is 0.22043072.
The resulting vector of weights is [6e-08, 0.00053899, -0.0005613]
Training Accuracy: 0.997625
</pre>
<div class="highlight">
<pre><span></span><span class="n">plot_losses</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"Log-Loss"</span><span class="p">:</span> <span class="n">losses</span><span class="p">})</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">plot_losses</span><span class="o">.</span><span class="n">hvplot</span><span class="p">()</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Training Losses"</span><span class="p">,</span>
                            <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                            <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                            <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                            <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span>
                            <span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"training_loss"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/training_loss.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>As you can see, the losses are still on the decline, but we'll stop here to see how it's doing.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org8a91205">
<h3 id="org8a91205">Test the Model</h3>
<div class="outline-text-3" id="text-org8a91205">
<p>This will be a class to predict the sentiment of a tweet using our model.</p>
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.vectorizer</span> <span class="kn">import</span> <span class="n">TweetVectorizer</span>


<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TweetSentiment</span><span class="p">:</span>
    <span class="sd">"""Predicts the sentiment of a tweet</span>

<span class="sd">    Args:</span>
<span class="sd">     vectorizer: something to vectorize tweets</span>
<span class="sd">     theta: vector of weights for the logistic regression model</span>
<span class="sd">    """</span>
    <span class="n">vectorizer</span><span class="p">:</span> <span class="n">TweetVectorizer</span>
    <span class="n">theta</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>

    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectors</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">"""the logistic function</span>

<span class="sd">       Args:</span>
<span class="sd">        vectors: a matrix of bias, positive, negative counts</span>

<span class="sd">       Returns:</span>
<span class="sd">        array of probabilities that the tweets are positive</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">vectors</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">probability_positive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">"""Calculates the probability of the tweet being positive</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: a tweet to classify</span>

<span class="sd">       Returns:</span>
<span class="sd">        the probability that the tweet is a positive one</span>
<span class="sd">       """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">extract_features</span><span class="p">(</span><span class="n">tweet</span><span class="p">,</span> <span class="n">as_array</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tweet</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">"""Decides if the tweet was positive or not</span>

<span class="sd">       Args:</span>
<span class="sd">        tweet: the tweet message to classify.</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)))</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">"""Get the sentiments of the vectorized tweets</span>

<span class="sd">       Note:</span>
<span class="sd">        this assumes that the vectorizer passed in has the tweets</span>

<span class="sd">       Returns:</span>
<span class="sd">        array of predicted sentiments (1 for positive 0 for negative)</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">sentiment</span> <span class="o">=</span> <span class="n">TweetSentiment</span><span class="p">(</span><span class="n">test_vectorizer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'I am happy'</span><span class="p">,</span> <span class="s1">'I am bad'</span><span class="p">,</span> <span class="s1">'this movie should have been great.'</span><span class="p">,</span> <span class="s1">'great'</span><span class="p">,</span> <span class="s1">'great great'</span><span class="p">,</span> <span class="s1">'great great great'</span><span class="p">,</span> <span class="s1">'great great great great'</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">tweet</span><span class="si">}</span><span class="s1"> -&gt; </span><span class="si">{</span><span class="n">sentiment</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
<pre class="example">
I am happy -&gt; 0.5183237992258976
I am bad -&gt; 0.4924963884222927
this movie should have been great. -&gt; 0.5156997144475827
great -&gt; 0.5158056039006712
great great -&gt; 0.5315796358935646
great great great -&gt; 0.5472908064541816
great great great great -&gt; 0.5629083094155534
</pre>
<p>Strangely very near the center. Probably because the words weren't that commonly used in our training set.</p>
<div class="highlight">
<pre><span></span><span class="n">totals</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Great positive percentage: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="s1">'great'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="o">/</span><span class="n">totals</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> %"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Great negative percentage: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="s1">'great'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="o">/</span><span class="n">totals</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> % "</span><span class="p">)</span>
</pre></div>
<pre class="example">
Great positive percentage: 0.24 %
Great negative percentage: 0.03 % 
</pre>
<p>Now we can see how it did overall.</p>
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">sentiment</span><span class="p">()</span>
<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">testing</span><span class="o">.</span><span class="n">sentiment</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testing</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.996
</pre>
<p>Almost suspiciously good.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgb06b6eb">
<h3 id="orgb06b6eb">The Wrong Stuff</h3>
<div class="outline-text-3" id="text-orgb06b6eb">
<div class="highlight">
<pre><span></span><span class="n">wrong_places</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">testing</span><span class="o">.</span><span class="n">sentiment</span>
<span class="n">wrong</span> <span class="o">=</span> <span class="n">testing</span><span class="p">[</span><span class="n">wrong_places</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wrong</span><span class="p">))</span>
</pre></div>
<pre class="example">
8
</pre>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">wrong</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"*"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tweet number </span><span class="si">{</span><span class="n">row</span><span class="o">.</span><span class="n">Index</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="n">test_raw</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">row</span><span class="o">.</span><span class="n">Index</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tweet: </span><span class="si">{</span><span class="n">raw</span><span class="o">.</span><span class="n">tweet</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">train_vectorizer</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Probability Positive: </span><span class="si">{</span><span class="n">sentiment</span><span class="o">.</span><span class="n">probability_positive</span><span class="p">(</span><span class="n">raw</span><span class="o">.</span><span class="n">tweet</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Actual Classification: </span><span class="si">{</span><span class="n">row</span><span class="o">.</span><span class="n">sentiment</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">token</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2">Positive: </span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span><span class="si">}</span><span class="s2"> "</span>
              <span class="sa">f</span><span class="s2">"Negative: </span><span class="si">{</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span><span class="p">[(</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
<pre class="example" id="org208ad08">
**********
Tweet number 64
Tweet: @_sarah_mae omg you can't just tell this and don't say more :p can't wait to know !!!! ❤️
Tokens: ['omg', "can't", 'tell', 'say', ':p', "can't", 'wait', 'know', '❤', '️']
Probability Positive: 0.48137283482824483
Actual Classification: 1

omg     Positive: 11 Negative: 51
can't   Positive: 36 Negative: 145
tell    Positive: 20 Negative: 19
say     Positive: 48 Negative: 52
:p      Positive: 113 Negative: 0
can't   Positive: 36 Negative: 145
wait    Positive: 59 Negative: 37
know    Positive: 123 Negative: 100
❤       Positive: 18 Negative: 20
️       Positive: 9 Negative: 18

**********
Tweet number 118
Tweet: @bae_ts WHATEVER STIL L YOUNG &amp;gt;:-(
Tokens: ['whatev', 'stil', 'l', 'young', '&gt;:-(']
Probability Positive: 0.5006402767570053
Actual Classification: 0

whatev  Positive: 5 Negative: 0
stil    Positive: 0 Negative: 0
l       Positive: 4 Negative: 1
young   Positive: 2 Negative: 3
&gt;:-(         Positive: 0 Negative: 2

**********
Tweet number 435
Tweet: @wtfxmbs AMBS please it's harry's jeans :)):):):(
Tokens: ['amb', 'pleas', "harry'", 'jean', ':)', '):', '):', '):']
Probability Positive: 0.821626817973081
Actual Classification: 0

amb     Positive: 0 Negative: 0
pleas   Positive: 76 Negative: 215
harry'  Positive: 0 Negative: 1
jean    Positive: 0 Negative: 1
:)      Positive: 2967 Negative: 1
):      Positive: 7 Negative: 1
):      Positive: 7 Negative: 1
):      Positive: 7 Negative: 1

**********
Tweet number 458
Tweet: @GODDAMMlT SRSLY FUCK U UNFOLLOWER HOPE UR FUTURE CHILD UNPARENTS U &amp;gt;:-(
Tokens: ['srsli', 'fuck', 'u', 'unfollow', 'hope', 'ur', 'futur', 'child', 'unpar', 'u', '&gt;:-(']
Probability Positive: 0.5157383070453547
Actual Classification: 0

srsli   Positive: 1 Negative: 4
fuck    Positive: 19 Negative: 48
u       Positive: 193 Negative: 162
unfollow        Positive: 55 Negative: 8
hope    Positive: 119 Negative: 77
ur      Positive: 28 Negative: 20
futur   Positive: 13 Negative: 1
child   Positive: 3 Negative: 3
unpar   Positive: 0 Negative: 0
u       Positive: 193 Negative: 162
&gt;:-(         Positive: 0 Negative: 2

**********
Tweet number 493
Tweet: 5h + kids makes all ://:(\\\
Tokens: ['5h', 'kid', 'make', ':/']
Probability Positive: 0.5003797971971914
Actual Classification: 0

5h      Positive: 0 Negative: 0
kid     Positive: 17 Negative: 16
make    Positive: 87 Negative: 77
:/      Positive: 4 Negative: 8

**********
Tweet number 788
Tweet: i love got7's outfit for just right &amp;gt;:( its so fun
Tokens: ['love', 'got', '7', 'outfit', 'right', '&gt;:(', 'fun']
Probability Positive: 0.5197464496373044
Actual Classification: 0

love    Positive: 306 Negative: 114
got     Positive: 55 Negative: 70
7       Positive: 5 Negative: 11
outfit  Positive: 3 Negative: 3
right   Positive: 41 Negative: 39
&gt;:(  Positive: 0 Negative: 36
fun     Positive: 48 Negative: 26

**********
Tweet number 995
Tweet: I ATE YOUR LAST COOKIE SHIR0 &amp;gt;:D
Tokens: ['ate', 'last', 'cooki', 'shir', '0', '&gt;:d']
Probability Positive: 0.4961173289819544
Actual Classification: 1

ate     Positive: 3 Negative: 8
last    Positive: 35 Negative: 58
cooki   Positive: 0 Negative: 2
shir    Positive: 0 Negative: 0
0       Positive: 1 Negative: 0
&gt;:d  Positive: 3 Negative: 0

**********
Tweet number 1662
Tweet: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring
Tokens: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']
Probability Positive: 0.5038917149486426
Actual Classification: 0

sr      Positive: 0 Negative: 1
financi         Positive: 0 Negative: 0
analyst         Positive: 0 Negative: 0
expedia         Positive: 0 Negative: 0
inc     Positive: 1 Negative: 2
bellevu         Positive: 0 Negative: 0
wa      Positive: 0 Negative: 0
financ  Positive: 0 Negative: 0
expediajob      Positive: 0 Negative: 0
job     Positive: 28 Negative: 12
job     Positive: 28 Negative: 12
hire    Positive: 0 Negative: 0
</pre>
<p>It looks like these were tweets with uncommon tokens. Personally I'm not sure what to make of some of them myself. And I'm not sure about the classifications - why is a job posting considered a negative tweet?</p>
</div>
</div>
<div class="outline-3" id="outline-container-org257c064">
<h3 id="org257c064">Some Fresh Tweets</h3>
<div class="outline-text-3" id="text-org257c064">
<p>First someone reacting to a post about the <a href="https://www.atlasobscura.com/places/clown-motel">Clown Motel</a> in Tonopah, Nevada. The previous link was to Atlas Obscura, but the tweet came from <a href="https://www.thrillist.com/travel/nation/clown-motel-nevada-hame-anand">thrillist</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">tweet</span> <span class="o">=</span> <span class="s2">"Nah dude. I drove by that at night and it was the creepiest thing ever. The whole town gave me bad vibes. I still shudder when I think about it."</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classified as </span><span class="si">{</span><span class="n">sentiments</span><span class="p">[</span><span class="n">sentiment</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Classified as negative
</pre>
<p>Seems reasonable.</p>
<div class="highlight">
<pre><span></span><span class="n">tweet</span> <span class="o">=</span> <span class="s2">"This is just dope. Quaint! I’d love to have an ironic drive-in wedding in Las Vegas and then stay in a clown motel as newly weds for one night. I bet they have Big Clown Suits for newly weds, haha."</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Classified as </span><span class="si">{</span><span class="n">sentiments</span><span class="p">[</span><span class="n">sentiment</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Classified as positive
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgb77eaa8">
<h3 id="orgb77eaa8">Compare to SKLearn</h3>
<div class="outline-text-3" id="text-orgb77eaa8">
<div class="highlight">
<pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="s2">"bias positive negative"</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">"neg_log_loss"</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">columns</span><span class="p">],</span> <span class="n">training</span><span class="o">.</span><span class="n">sentiment</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">testing</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testing</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Accuracy: 0.995
</pre>
<p>So it did pretty much the same just using the default parameters. We could probably do a parameter search but that's okay for now.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0a19b15">
<h3 id="org0a19b15">Vizualizing the Model</h3>
<div class="outline-text-3" id="text-org0a19b15">
<p>Since we've been given the model's weights we can plot its output when fed the vectors to see how it separates the data. To get the equation for the separation line we need to solve for the positive or negative terms when the product of the weights and the vector is 0 (\(\theta \times x = 0\), where <i>x</i> is our vector \(\langle bias, positive, negative \rangle\)).</p>
<p>Get ready for some algebra.</p>
\begin{align} \theta \times x &amp;= 0\\ \theta \times \langle bias, positive, negative \rangle &amp;= 0\\ \theta \times \langle 1, positive, negative \rangle &amp;= 0\\ \theta_0 + \theta_1 \times positive + \theta_2 \times negative &amp;= 0\\ \theta_2 \times negative &amp;= -\theta_0 - \theta_1 \times positive\\ negative &amp;= \frac{-\theta_0 - \theta_1 \times positive}{\theta_2}\\ \end{align}
<p>This is the equation for our separation line (on our plot <code>positive</code> is the <i>x-axis</i> and <code>negative</code> is the <i>y-axis</i>, which we can translate to a function to apply to our data.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">negative</span><span class="p">(</span><span class="n">theta</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">positive</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""Calculate the negative value</span>

<span class="sd">    This calculates the value for the separation line</span>

<span class="sd">    Args:</span>
<span class="sd">     theta: list of weights for the logistic regression</span>
<span class="sd">     positive: count of positive tweets matching tweet</span>

<span class="sd">    Returns:</span>
<span class="sd">     the calculated negative value for the separation line</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">theta</span><span class="o">.</span><span class="n">bias</span>
            <span class="o">-</span> <span class="n">positive</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span><span class="o">/</span><span class="n">theta</span><span class="o">.</span><span class="n">negative</span>

<span class="n">theta</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span><span class="p">)</span>
<span class="n">negative_</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">negative</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
<p>We plotted the vectorized data before, now we can add our regression line.</p>
<div class="highlight">
<pre><span></span><span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span>
    <span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">"Positive"</span><span class="p">,</span> <span class="s2">"@positive{0,0}"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Negative"</span><span class="p">,</span> <span class="s2">"@negative{0,0}"</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="s2">"@Sentiment"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="n">training</span><span class="p">[</span><span class="s2">"regression negative"</span><span class="p">]</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">positive</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">positive</span><span class="p">:</span> <span class="n">negative_</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="n">positive</span><span class="p">))</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"regression negative"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span> <span class="n">fill_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">])</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
                               <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
                               <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                               <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
                               <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative Tweet Sentiment"</span><span class="p">,</span>
                           <span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">scatter</span> <span class="o">*</span> <span class="n">line</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_scatter_with_model"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/positive_negative_scatter_with_model.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Let's see if a log-log scale helps.</p>
<div class="highlight">
<pre><span></span><span class="n">line</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"regression negative"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">)</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span> <span class="n">by</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span>
                                  <span class="n">fill_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                  <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">color_cycle</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">])</span>

<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">scatter</span> <span class="o">*</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">xrotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">font_scale</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Positive vs Negative Tweet Sentiment"</span><span class="p">,</span>
    <span class="n">logx</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">logy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_scatter_log"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/implementing-twitter-logistic-regression/positive_negative_scatter_log.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The log-scale seems to break the auto-scaling of the plot so you'll have to zoom out a little bit (with the <i>Wheel Zoom</i> tool on the toolbar) which will show you that the model did a pretty good job of separating the positive from the negative. You can see that some of the points aren't really linearly separable using our vectors so this is probably as good as it can get.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org2b5bb45">
<h2 id="org2b5bb45">End</h2>
<div class="outline-text-2" id="text-org2b5bb45">
<p>This concludes the series begun with the post on <a href="posts/nlp/01-twitter-preprocessing-with-nltk/">pre-processing tweets</a>.</p>
<p>I should mention that I used <a href="posts/bibliographies/bib-speech-and-language-processing-jurafsky-martin/">Speech and Language Processing</a> to understanding the math.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nlp/twitter-word-frequencies/">Twitter Word Frequencies</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nlp/twitter-word-frequencies/" rel="bookmark"><time class="published dt-published" datetime="2020-07-07T18:19:19-07:00" itemprop="datePublished" title="2020-07-07 18:19">2020-07-07 18:19</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nlp/twitter-word-frequencies/#org679200d">Beginning</a>
<ul>
<li><a href="posts/nlp/twitter-word-frequencies/#orga7a68f2">Setup</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-word-frequencies/#org017fcb2">Middle</a>
<ul>
<li><a href="posts/nlp/twitter-word-frequencies/#org06f07d4">Word Frequencies</a></li>
<li><a href="posts/nlp/twitter-word-frequencies/#orgc8879f3">Counting</a></li>
<li><a href="posts/nlp/twitter-word-frequencies/#orgbf3e369">Plotting</a></li>
</ul>
</li>
<li><a href="posts/nlp/twitter-word-frequencies/#org417d724">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org679200d">
<h2 id="org679200d">Beginning</h2>
<div class="outline-text-2" id="text-org679200d">
<p>In the previous post in this series (<a href="posts/nlp/01-twitter-preprocessing-with-nltk/">Twitter Preprocessing With NLTK</a>) I made a pre-processor for tweets, now I'm going to make a counter that counts how many times a certain token shows up in positive and negative tweets.</p>
</div>
<div class="outline-3" id="outline-container-orga7a68f2">
<h3 id="orga7a68f2">Setup</h3>
<div class="outline-text-3" id="text-orga7a68f2"></div>
<div class="outline-4" id="outline-container-org1585bd6">
<h4 id="org1585bd6">Imports</h4>
<div class="outline-text-4" id="text-org1585bd6">
<div class="highlight">
<pre><span></span><span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># from pypi</span>
<span class="kn">from</span> <span class="nn">bokeh.models</span> <span class="kn">import</span> <span class="n">HoverTool</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">twitter_samples</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>

<span class="c1"># some helper stuff</span>
<span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge5e4b10">
<h4 id="orge5e4b10">The Data</h4>
<div class="outline-text-4" id="text-orge5e4b10">
<p>First we'll load the training data that I set-up while building the tweet pre-processor.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">"posts/nlp/.env"</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_PROCESSED"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">training_raw</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_TRAINING_RAW"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">training</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Rows: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">training</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
                       tweet  label
0  [park, get, sunlight, :)]      1
Rows: 8,000
</pre>
<p>I also made an object to pass around to make sure I didn't switch the numeric <code>positive</code> and <code>negative</code> encodings so let's load that.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_SENTIMENT"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Sentiment</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Sentiment</span><span class="p">)</span>
</pre></div>
<pre class="example">
Namespace(decode={1: 'positive', 0: 'negative'}, encode={'positive': 1, 'negative': 0}, negative=0, positive=1)
</pre></div>
</div>
<div class="outline-4" id="outline-container-org40a8951">
<h4 id="org40a8951">Plotting and Printing</h4>
<div class="outline-text-4" id="text-org40a8951">
<p>This is some preliminary setup of the plotter and table-printer so I don't have to keep typing the same things over and over.</p>
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"01b-twitter-word-frequencies"</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span>
                <span class="n">folder_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">"files/posts/nlp/</span><span class="si">{</span><span class="n">SLUG</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_PLOT"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">Plot</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org017fcb2">
<h2 id="org017fcb2">Middle</h2>
<div class="outline-text-2" id="text-org017fcb2"></div>
<div class="outline-3" id="outline-container-org06f07d4">
<h3 id="org06f07d4">Word Frequencies</h3>
<div class="outline-text-3" id="text-org06f07d4">
<p>We're going to build up a <a href="https://docs.python.org/3/library/collections.html#collections.Counter">Counter</a> of token frequencies. The keys will be <code>(token, sentiment)</code> tuples and the values will be the counts for the token-sentiment pairs.</p>
</div>
<div class="outline-4" id="outline-container-orgb34e959">
<h4 id="orgb34e959">Tests</h4>
<div class="outline-text-4" id="text-orgb34e959">
<p>These are the tests for the implementation that follows them.</p>
</div>
<ul class="org-ul">
<li><a id="org7afabdc"></a>The Tangles<br>
<div class="outline-text-5" id="text-org7afabdc">
<div class="highlight">
<pre><span></span>Feature: A Word Frequency Counter

In order to get a sense of how the words correlate with sentiment
I want to be able to count word-sentiment pairs.

&lt;&lt;counter-feature&gt;&gt;

&lt;&lt;call-feature&gt;&gt;
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># pypi</span>
<span class="kn">from</span> <span class="nn">expects</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">be</span><span class="p">,</span>
    <span class="n">equal</span><span class="p">,</span>
    <span class="n">expect</span>
    <span class="p">)</span>

<span class="kn">from</span> <span class="nn">pytest_bdd</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">given</span><span class="p">,</span>
    <span class="n">scenarios</span><span class="p">,</span>
    <span class="n">then</span><span class="p">,</span>
    <span class="n">when</span>
<span class="p">)</span>

<span class="c1"># testing setup</span>
<span class="kn">from</span> <span class="nn">fixtures</span> <span class="kn">import</span> <span class="n">katamari</span>

<span class="c1"># software under test</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.counter</span> <span class="kn">import</span> <span class="n">WordCounter</span>
<span class="kn">from</span> <span class="nn">neurotic.nlp.twitter.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>

<span class="n">scenarios</span><span class="p">(</span><span class="s2">"../../features/twitter/word_frequencies.feature"</span><span class="p">)</span>

<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">creation</span><span class="o">&gt;&gt;</span>


<span class="o">&lt;&lt;</span><span class="n">test</span><span class="o">-</span><span class="n">call</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
</li>
<li><a id="org277b2a8"></a>Setup<br>
<div class="outline-text-5" id="text-org277b2a8">
<div class="highlight">
<pre><span></span>Scenario: The Word Counter is created
  Given a word counter class
  When the word counter is created
  Then it has the expected attributes
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The Word Counter is created</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a word counter class"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_class</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">definition</span> <span class="o">=</span> <span class="n">WordCounter</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the word counter is created"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">create_word_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">faker</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">Mock</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">Mock</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">Mock</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">definition</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                           <span class="n">labels</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">processor</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"it has the expected attributes"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_attributes</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">be</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">processor</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
<li><a id="orgf33ca70"></a>The Call<br>
<div class="outline-text-5" id="text-orgf33ca70">
<div class="highlight">
<pre><span></span>Scenario: The Word Frequency counter is called
  Given a word frequency counter
  When the counter is called
  Then the counts are the expected
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># Scenario: The Word Frequency counter is called</span>


<span class="nd">@given</span><span class="p">(</span><span class="s2">"a word frequency counter"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">setup_word_frequency_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">,</span> <span class="n">mocker</span><span class="p">):</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"a b aab a b c"</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span><span class="p">,</span>
                                   <span class="n">labels</span><span class="o">=</span><span class="n">katamari</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>

    <span class="n">bad_sentiment</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"c aab aab"</span><span class="p">]</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">tweets</span> <span class="o">+=</span> <span class="n">bad_sentiment</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># since the tokenizer removes and changes words</span>
    <span class="c1"># I'm going to mock it out</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">mocker</span><span class="o">.</span><span class="n">MagicMock</span><span class="p">(</span><span class="n">TwitterProcessor</span><span class="p">)</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">process</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">expected</span> <span class="o">=</span> <span class="p">{(</span><span class="s2">"a"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="s2">"b"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="s2">"aab"</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span><span class="mi">1</span><span class="p">,</span>
                         <span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="s2">"aab"</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mi">2</span><span class="p">}</span>
    <span class="k">return</span>


<span class="nd">@when</span><span class="p">(</span><span class="s2">"the counter is called"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">call_counter</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counter</span><span class="o">.</span><span class="n">counts</span>
    <span class="k">return</span>


<span class="nd">@then</span><span class="p">(</span><span class="s2">"the counts are the expected"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_counts</span><span class="p">(</span><span class="n">katamari</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">katamari</span><span class="o">.</span><span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">expect</span><span class="p">(</span><span class="n">katamari</span><span class="o">.</span><span class="n">expected</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
    <span class="k">return</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orga930e14">
<h4 id="orga930e14">Implementation</h4>
<div class="outline-text-4" id="text-orga930e14">
<p>This is going to be a counter class that pre-processes the tweets and then counts the frequency of word-sentiment pairs.</p>
<div class="highlight">
<pre><span></span><span class="c1"># A Word Counter</span>

<span class="c1"># from python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">typing</span>

<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">attr</span>

<span class="c1"># this project</span>
<span class="kn">from</span> <span class="nn">.processor</span> <span class="kn">import</span> <span class="n">TwitterProcessor</span>

<span class="nd">@attr</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">auto_attribs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">WordCounter</span><span class="p">:</span>
    <span class="sd">"""A word-sentiment counter</span>

<span class="sd">    Args:</span>
<span class="sd">     tweets: list of unprocessed tweets</span>
<span class="sd">     labels: list of 1's (positive) and 0's that identifies sentiment for each tweet</span>
<span class="sd">    """</span>
    <span class="n">tweets</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">_process</span><span class="p">:</span> <span class="n">TwitterProcessor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_processed</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_counts</span><span class="p">:</span> <span class="n">Counter</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TwitterProcessor</span><span class="p">:</span>
        <span class="sd">"""A callable to process tweets to lists of words"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_process</span> <span class="o">=</span> <span class="n">TwitterProcessor</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">processed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">"""The processed and tokenized tweets"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_processed</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processed</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">counts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Counter</span><span class="p">:</span>
        <span class="sd">"""Processes the tweets and labels</span>

<span class="sd">       Returns:</span>
<span class="sd">        counts of word-sentiment pairs</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> \
                <span class="sa">f</span><span class="s2">"Tweets: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tweets</span><span class="p">)</span><span class="si">}</span><span class="s2">, Labels: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">tweet</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">processed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tweet</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span><span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">label</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counts</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc8879f3">
<h3 id="orgc8879f3">Counting</h3>
<div class="outline-text-3" id="text-orgc8879f3">
<p>Now that we've implemented the counter we might as well get to counting. This is going to be kind of hacky, but I originally wasn't saving the processed data and so was expecting this thing to process it. Maybe I'll change it to look better late. But, anyway that's why I'm assigning the column to the <code>._processed</code> attribute.</p>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">WordCounter</span><span class="p">(</span><span class="n">tweets</span><span class="o">=</span><span class="n">training</span><span class="o">.</span><span class="n">tweet</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">training</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
<span class="n">counter</span><span class="o">.</span><span class="n">_processed</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">tweet</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">counts</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total token-sentiment pairs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Total token-sentiment pairs: 11,476
</pre>
<p>What are the most common? To make the rest of the post easier I'm going to set up a pandas DataFrame.</p>
<div class="highlight">
<pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">top_counts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sentiments</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
    <span class="n">token</span><span class="p">,</span> <span class="n">sentiment</span> <span class="o">=</span> <span class="n">key</span>
    <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="n">sentiments</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentiment</span><span class="p">)</span>
    <span class="n">top_counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>

<span class="n">top_counts</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
    <span class="n">token</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span>
    <span class="n">count</span><span class="o">=</span><span class="n">top_counts</span><span class="p">,</span>
    <span class="n">sentiment</span><span class="o">=</span><span class="n">sentiments</span><span class="p">,</span>
<span class="p">))</span>

<span class="n">top_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"sentiment"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">Sentiment</span><span class="o">.</span><span class="n">decode</span><span class="p">[</span><span class="n">row</span><span class="p">])</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">top_counts</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">20</span><span class="p">]))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">token</th>
<th class="org-right" scope="col">count</th>
<th class="org-left" scope="col">sentiment</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">:(</td>
<td class="org-right">3705</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">:)</td>
<td class="org-right">2967</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">:-)</td>
<td class="org-right">547</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">:D</td>
<td class="org-right">537</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">thank</td>
<td class="org-right">516</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">:-(</td>
<td class="org-right">407</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">follow</td>
<td class="org-right">349</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">love</td>
<td class="org-right">306</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">i'm</td>
<td class="org-right">282</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">…</td>
<td class="org-right">261</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">miss</td>
<td class="org-right">241</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">…</td>
<td class="org-right">228</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">pleas</td>
<td class="org-right">215</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">follow</td>
<td class="org-right">211</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">get</td>
<td class="org-right">200</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">want</td>
<td class="org-right">197</td>
<td class="org-left">negative</td>
</tr>
<tr>
<td class="org-left">day</td>
<td class="org-right">194</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">u</td>
<td class="org-right">193</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">good</td>
<td class="org-right">189</td>
<td class="org-left">positive</td>
</tr>
<tr>
<td class="org-left">like</td>
<td class="org-right">189</td>
<td class="org-left">positive</td>
</tr>
</tbody>
</table>
<p>It's interesting that the only tokens in the top 20 that are both positive and negative are ellipses and "follow" and that the four most common tokens were smileys, although given the nature of tweets I guess the use of smileys (emoticons?) shouldn't be so surprising. I didn't notice this at first, but the most common token is a negative one.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgbf3e369">
<h3 id="orgbf3e369">Plotting</h3>
<div class="outline-text-3" id="text-orgbf3e369">
<p>The counts themselves are interesting, but it might be more informative to look at their distribution as well as whether some tokens are more positive or negative.</p>
</div>
<div class="outline-4" id="outline-container-orgec72c14">
<h4 id="orgec72c14">Positive Vs Negative</h4>
<div class="outline-text-4" id="text-orgec72c14">
<div class="highlight">
<pre><span></span><span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="s2">"@token"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="s2">"@sentiment"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Count"</span><span class="p">,</span> <span class="s2">"@count"</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span><span class="o">=</span><span class="n">tooltips</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">"bar"</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">"sentiment"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"count"</span><span class="p">,</span>
                         <span class="n">hover_cols</span><span class="o">=</span><span class="s2">"all"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>    
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span> <span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Positive and Negative"</span><span class="p">,</span>
    <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">],</span>
    <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">,</span>
    <span class="n">line_color</span><span class="o">=</span><span class="s2">"white"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">embedded</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"positive_negative_distribution"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">embedded</span><span class="p">()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-word-frequencies/positive_negative_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>So it looks like negative sentiment is more common for the tokens, even though the tweets themselves were evenly split, maybe because the negative tweets had more diverse tokens.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgb6b9033">
<h4 id="orgb6b9033">Distribution</h4>
<div class="outline-text-4" id="text-orgb6b9033">
<div class="highlight">
<pre><span></span><span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="s2">"@token"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Sentiment"</span><span class="p">,</span> <span class="s2">"@sentiment"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Count"</span><span class="p">,</span> <span class="s2">"@count"</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span><span class="o">=</span><span class="n">tooltips</span><span class="p">)</span>

<span class="n">CUTOFF</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">top_counts</span><span class="p">[:</span><span class="n">CUTOFF</span><span class="p">]</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">"count"</span><span class="p">,</span> <span class="n">hover_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">"token"</span><span class="p">,</span> <span class="s2">"sentiment"</span><span class="p">],</span>
    <span class="n">loglog</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
        <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">],</span>
        <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
        <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">,</span>
        <span class="n">line_color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">tan</span><span class="p">,</span>
        <span class="n">xaxis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Log-Log Count Distribution (top </span><span class="si">{</span><span class="n">CUTOFF</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"count_distribution"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-word-frequencies/count_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>This shows how steep the drop is from the two most common tokens which are then followed by a long tail. Without the logarithmic axes the drop is even more pronounced.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org09a21cd">
<h4 id="org09a21cd">Positive Vs Negative by Tweet</h4>
<div class="outline-text-4" id="text-org09a21cd">
<div class="highlight">
<pre><span></span><span class="n">CUTOFF</span> <span class="o">=</span> <span class="mi">250</span>

<span class="n">top_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"positive"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="o">.</span><span class="n">sentiment</span><span class="o">==</span><span class="s2">"positive"</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>

<span class="n">top_counts</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s2">"negative"</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="s2">"count"</span><span class="p">]</span> <span class="k">if</span> <span class="n">row</span><span class="o">.</span><span class="n">sentiment</span><span class="o">==</span><span class="s2">"negative"</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span>
<span class="p">)</span>

<span class="n">tooltips</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="s2">"@token"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Positive"</span><span class="p">,</span> <span class="s2">"@positive"</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"Negative"</span><span class="p">,</span> <span class="s2">"@negative"</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">hover</span> <span class="o">=</span> <span class="n">HoverTool</span><span class="p">(</span><span class="n">tooltips</span><span class="o">=</span><span class="n">tooltips</span><span class="p">)</span>

<span class="n">grouped</span> <span class="o">=</span> <span class="n">top_counts</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">"token"</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s2">"positive"</span><span class="p">:</span> <span class="s2">"sum"</span><span class="p">,</span> <span class="s2">"negative"</span><span class="p">:</span> <span class="s2">"sum"</span><span class="p">})</span>
<span class="n">to_plot</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="c1"># log plots can't have zero values</span>
<span class="n">MIN</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">"positive"</span><span class="p">,</span> <span class="s2">"negative"</span><span class="p">):</span>
    <span class="n">to_plot</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_plot</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">MAX</span> <span class="o">=</span> <span class="n">to_plot</span><span class="o">.</span><span class="n">negative</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Curve</span><span class="p">(([</span><span class="n">MIN</span><span class="p">,</span> <span class="n">MAX</span><span class="p">],</span> <span class="p">[</span><span class="n">MIN</span><span class="p">,</span> <span class="n">MAX</span><span class="p">]))</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">red</span><span class="p">)</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">to_plot</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">loglog</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">blue</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">"positive"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"negative"</span><span class="p">,</span>
    <span class="n">hover_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">"token"</span><span class="p">])</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">scatter</span> <span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
        <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">hover</span><span class="p">],</span>
        <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Positive"</span><span class="p">,</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="s2">"Negative"</span><span class="p">,</span>
        <span class="n">fontscale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">"Log-Log Positive vs Negative"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"scatter_plot"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<object data="posts/nlp/twitter-word-frequencies/scatter_plot.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The tokens along or around the diagonal are evenly positive and negative so they probably aren't useful indicators of sentiment in and of themselves, while those furthest from the diagonal are the most biased to one side or the other so we might expect them to be useful in guessing a tweet's sentiment.</p>
<p>There are some unexpectedly negative tokens like "love" (400, 152) and "thank" (620, 107), but at this point we haven't really started to look at the sentiment yet so I'll leave further exploration for later.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org417d724">
<h2 id="org417d724">End</h2>
<div class="outline-text-2" id="text-org417d724">
<p>Since the counter gets re-used I'm going to pickle it for later.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TWITTER_COUNTER"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
<p>Next in this series: <a href="posts/nlp/the-tweet-vectorizer/">The Tweet Vectorizer</a></p>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-12.html" rel="prev">Newer posts</a></li>
<li class="next"><a href="index-10.html" rel="next">Older posts</a></li>
</ul>
<script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
<script type="text/x-mathjax-config">

        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']],},

        });
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script>
<script>

    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"></script><!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script>
</body>
</html>
