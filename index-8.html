<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>In Too Deep (old posts, page 8) | In Too Deep</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/In-Too-Deep/index-8.html" rel="canonical">
<link href="index-9.html" rel="prev" type="text/html">
<link href="index-7.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>
<script async src="javascript/bokeh-1.3.4.min.js" type="text/javascript"></script>
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/In-Too-Deep/"><span id="blog-title">In Too Deep</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/In-Too-Deep/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/">Convolutional Neural Networks and Fashion MNIST</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/" rel="bookmark"><time class="published dt-published" datetime="2019-06-30T16:26:01-07:00" itemprop="datePublished" title="2019-06-30 16:26">2019-06-30 16:26</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org1b78b81">Beginning</a>
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org086f318">Imports</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org117375f">Set Up</a></li>
</ul>
</li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org1491630">Middle</a>
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgfd4371a">Some Exploratory Work</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgdde40df">10 Epochs</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org5505aef">15 Epochs</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgfae0a7d">20 Epochs</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org5c7627f">Visualizing the Convolutions and Pooling</a></li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#orgb1dc78e">Exercises</a></li>
</ul>
</li>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org0e44448">End</a>
<ul>
<li><a href="/posts/keras/convolutional-neural-networks-and-fashion-mnist/#org5a2a839">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org1b78b81">
<h2 id="org1b78b81">Beginning</h2>
<div class="outline-text-2" id="text-org1b78b81">
<p>The goal of this exercise is to create a model that can classify the Fashion MNIST data better than our previous single hidden-layer model.</p>
</div>
<div class="outline-3" id="outline-container-org086f318">
<h3 id="org086f318">Imports</h3>
<div class="outline-text-3" id="text-org086f318"></div>
<div class="outline-4" id="outline-container-org27e25bb">
<h4 id="org27e25bb">PyPi</h4>
<div class="outline-text-4" id="text-org27e25bb">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5291f07">
<h4 id="org5291f07">My Stuff</h4>
<div class="outline-text-4" id="text-org5291f07">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.timers</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org117375f">
<h3 id="org117375f">Set Up</h3>
<div class="outline-text-3" id="text-org117375f"></div>
<div class="outline-4" id="outline-container-org7f48bba">
<h4 id="org7f48bba">The Timer</h4>
<div class="outline-text-4" id="text-org7f48bba">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc4db611">
<h4 id="orgc4db611">The Data</h4>
<div class="outline-text-4" id="text-orgc4db611">
<div class="highlight">
<pre><span></span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">())</span>

<span class="n">training_images</span> <span class="o">=</span> <span class="n">training_images</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">testing_images</span> <span class="o">=</span> <span class="n">testing_images</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgeeb8f5e">
<h4 id="orgeeb8f5e">Plotting</h4>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1491630">
<h2 id="org1491630">Middle</h2>
<div class="outline-text-2" id="text-org1491630"></div>
<div class="outline-3" id="outline-container-orgfd4371a">
<h3 id="orgfd4371a">Some Exploratory Work</h3>
<div class="outline-text-3" id="text-orgfd4371a"></div>
<div class="outline-4" id="outline-container-org533e439">
<h4 id="org533e439">A Baseline Model</h4>
<div class="outline-text-4" id="text-org533e439">
<p>Our baseline that we want to beat is a model with a single dense hidden layer with 128 nodes.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span> 
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing Loss: {loss:.2f} Testing Accuracy: {accuracy: .2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
WARNING: Logging before flag parsing goes to stderr.
W0703 11:50:56.498819 140182964418368 deprecation.py:506] From /home/brunhilde/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2019-07-03 11:50:56,502 graeae.timers.timer start: Started: 2019-07-03 11:50:56.502607
I0703 11:50:56.502984 140182964418368 timer.py:70] Started: 2019-07-03 11:50:56.502607
Epoch 1/10
60000/60000 - 5s - loss: 0.4973 - acc: 0.8252
Epoch 2/10
60000/60000 - 5s - loss: 0.3742 - acc: 0.8656
Epoch 3/10
60000/60000 - 5s - loss: 0.3382 - acc: 0.8775
Epoch 4/10
60000/60000 - 5s - loss: 0.3146 - acc: 0.8839
Epoch 5/10
60000/60000 - 4s - loss: 0.2976 - acc: 0.8897
Epoch 6/10
60000/60000 - 4s - loss: 0.2818 - acc: 0.8963
Epoch 7/10
60000/60000 - 4s - loss: 0.2707 - acc: 0.9002
Epoch 8/10
60000/60000 - 5s - loss: 0.2597 - acc: 0.9039
Epoch 9/10
60000/60000 - 5s - loss: 0.2502 - acc: 0.9066
Epoch 10/10
60000/60000 - 5s - loss: 0.2409 - acc: 0.9094
2019-07-03 11:51:42,904 graeae.timers.timer end: Ended: 2019-07-03 11:51:42.904683
I0703 11:51:42.904865 140182964418368 timer.py:77] Ended: 2019-07-03 11:51:42.904683
2019-07-03 11:51:42,907 graeae.timers.timer end: Elapsed: 0:00:46.402076
I0703 11:51:42.907317 140182964418368 timer.py:78] Elapsed: 0:00:46.402076
Testing Loss: 0.36 Testing Accuracy:  0.87
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgebfadd0">
<h4 id="orgebfadd0">A Convolutional Neural Network</h4>
<div class="outline-text-4" id="text-orgebfadd0">
<p>The convolutional layer expects a single tensor instead of a feed of many of them so you need to reshape the input to make it work.</p>
<div class="highlight">
<pre><span></span><span class="n">training_images</span> <span class="o">=</span> <span class="n">training_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">testing_images</span> <span class="o">=</span> <span class="n">testing_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>Our model starts with a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D">Conv2D layer</a>. The arguments we're using are:</p>
<ul class="org-ul">
<li><code>filters</code>: the dimensionality of the output space (the number of output filters in the convolution)</li>
<li><code>kernel_size</code>: The height and width of the convolution window</li>
<li><code>activation</code>: The activation function for the output</li>
<li><code>input_shape</code>: If this is the first layer in the model you have to tell it what the input shape is</li>
</ul>
<p>The output of the convolutional layers go to a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D">MaxPool2D</a> layer. The only argument we're passing in is <code>pool_size</code>, the factors by which to downsize the input. Using <code>(2, 2)</code> will reduce the size in half. After the convolutions and pooling are applied, the output is sent through a version of the fully-connected network that we were using before (see the baseline model above).</p>
</div>
<ul class="org-ul">
<li><a id="orgac35889"></a>A Model Builder<br>
<div class="outline-text-5" id="text-orgac35889">
<p>Something to make it a little easier to re-use things. Note that in the original notebook the first example has 64 filters in the CNN, but later it says that it's better to start with 32 (and the exercises expect that you used 32) so I'm using that as the default value.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_stop</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="k">class</span> <span class="nc">Stop</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">loss</span><span class="p">):</span>
                <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Stopping point reached at epoch {epoch}"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="n">Stop</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">stop</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">ModelBuilder</span><span class="p">:</span>
    <span class="sd">"""Builds, trains, and tests our model</span>

<span class="sd">    Args:</span>
<span class="sd">     training_images: images to train on</span>
<span class="sd">     training_labels: labels for the training data</span>
<span class="sd">     testing_images: images to test the trained model with</span>
<span class="sd">     testing_labels: labels for the testing data</span>
<span class="sd">     additional_convolutions: convolutions besides the input convolution</span>
<span class="sd">     epochs: number of times to repeat training</span>
<span class="sd">     filters: number of filters in the output of the convolutional layers</span>
<span class="sd">     use_callback: use the Stop to end trainig</span>
<span class="sd">     callback_loss: loss to use for the callback</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_images</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">training_images</span><span class="p">,</span>
                 <span class="n">training_labels</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">training_labels</span><span class="p">,</span>
                 <span class="n">testing_images</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">testing_images</span><span class="p">,</span>
                 <span class="n">testing_labels</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="n">testing_labels</span><span class="p">,</span>
                 <span class="n">additional_convolutions</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                 <span class="n">filters</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">use_callback</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">callback_loss</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_images</span> <span class="o">=</span> <span class="n">training_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_labels</span> <span class="o">=</span> <span class="n">training_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">testing_images</span> <span class="o">=</span> <span class="n">testing_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">testing_labels</span> <span class="o">=</span> <span class="n">testing_labels</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">additional_convolutions</span> <span class="o">=</span> <span class="n">additional_convolutions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filters</span> <span class="o">=</span> <span class="n">filters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_callback</span> <span class="o">=</span> <span class="n">use_callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback_loss</span> <span class="o">=</span> <span class="n">callback_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">return</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Stop</span><span class="p">:</span>
        <span class="sd">"""The callback to stop the training"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">get_stop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">callback_loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
        <span class="sd">"""Our CNN Model"""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">,</span> 
                <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">convolution</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">additional_convolutions</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> 
                                                               <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span> 
                                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>

    <span class="k">def</span> <span class="nf">print_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Print out the summary for the model"""</span>
        <span class="k">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">       Fit the model to the training data</span>
<span class="sd">       """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_callback</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_labels</span><span class="p">,</span> 
                           <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_labels</span><span class="p">,</span> 
                           <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">"""Check the loss and accuracy of the model against the testing set</span>

<span class="sd">       Returns:</span>
<span class="sd">        (loss, accuracy): the output of the evaluation of the testing data</span>
<span class="sd">       """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">testing_images</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""Builds and tests the model"""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing Loss: {loss:.2f}  Testing Accuracy: {accuracy:.2f}"</span><span class="p">)</span>
        <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="c1"># model = create_model()</span>
<span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">builder</span><span class="o">.</span><span class="n">print_summary</span><span class="p">()</span>
</pre></div>
<pre class="example">
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 11, 11, 32)        9248      
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 5, 5, 32)          0         
_________________________________________________________________
flatten_17 (Flatten)         (None, 800)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 128)               102528    
_________________________________________________________________
dense_35 (Dense)             (None, 10)                1290      
=================================================================
Total params: 113,386
Trainable params: 113,386
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgf4906a1">
<h4 id="orgf4906a1">Layer By Layer</h4>
<div class="outline-text-4" id="text-orgf4906a1">
<ul class="org-ul">
<li>Our input is a set of 28 x 28 images.</li>
<li>Because we didn't pad the images, the convolutional layer "trims" off one row and column on each side (the center cell can't reach the outermost cells) so we get a 26 x 26 grid with 64 filters (which is what we set up in the definition).</li>
<li>The Max Pooling layer the halves the image so we have 13 x 13 grid with 64 filters</li>
<li>The next convolution layer once again trims off one row on each side so we have a 11 x 11 grid with 64 filters</li>
<li>Then the Max Pooling halves the grid once again so we have a 5 x 5 grid with 64 filters</li>
<li>The Flatten layer outputs a vector with 1,600 cells (<i>5 x 5 x 64 = 1,600</i>).</li>
<li>The first Dense layer has 128 neurons in it so that's the size of the output</li>
<li>And the final Dense layer converts it to 10 outputs to match the number of labels we have</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/5
60000/60000 - 17s - loss: 0.4671 - acc: 0.8290
Epoch 2/5
60000/60000 - 17s - loss: 0.3149 - acc: 0.8844
Epoch 3/5
60000/60000 - 17s - loss: 0.2688 - acc: 0.9003
Epoch 4/5
60000/60000 - 17s - loss: 0.2414 - acc: 0.9112
Epoch 5/5
60000/60000 - 17s - loss: 0.2175 - acc: 0.9198
Testing Loss: 0.28  Testing Accuracy: 0.89
</pre>
<p>Using the Convolutional Neural Network we've gone from 88% to 91% accuracy.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgdde40df">
<h3 id="orgdde40df">10 Epochs</h3>
<div class="outline-text-3" id="text-orgdde40df">
<p>Using five epochs it appears that the loss is still going down while the accuracy is going up. What happens with ten epochs?</p>
<div class="highlight">
<pre><span></span><span class="n">builder_10</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">builder_10</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/10
60000/60000 - 16s - loss: 0.4807 - acc: 0.8242
Epoch 2/10
60000/60000 - 16s - loss: 0.3233 - acc: 0.8825
Epoch 3/10
60000/60000 - 15s - loss: 0.2776 - acc: 0.8976
Epoch 4/10
60000/60000 - 16s - loss: 0.2474 - acc: 0.9082
Epoch 5/10
60000/60000 - 16s - loss: 0.2273 - acc: 0.9155
Epoch 6/10
60000/60000 - 16s - loss: 0.2030 - acc: 0.9240
Epoch 7/10
60000/60000 - 16s - loss: 0.1854 - acc: 0.9314
Epoch 8/10
60000/60000 - 16s - loss: 0.1693 - acc: 0.9361
Epoch 9/10
60000/60000 - 15s - loss: 0.1540 - acc: 0.9419
Epoch 10/10
60000/60000 - 16s - loss: 0.1419 - acc: 0.9467
Testing Loss: 0.26  Testing Accuracy: 0.91
</pre>
<p>It looks like it's still learning.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org5505aef">
<h3 id="org5505aef">15 Epochs</h3>
<div class="outline-text-3" id="text-org5505aef">
<div class="highlight">
<pre><span></span><span class="n">builder_15</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">builder_15</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/15
60000/60000 - 16s - loss: 0.4754 - acc: 0.8260
Epoch 2/15
60000/60000 - 16s - loss: 0.3155 - acc: 0.8834
Epoch 3/15
60000/60000 - 16s - loss: 0.2725 - acc: 0.9001
Epoch 4/15
60000/60000 - 16s - loss: 0.2447 - acc: 0.9096
Epoch 5/15
60000/60000 - 16s - loss: 0.2199 - acc: 0.9180
Epoch 6/15
60000/60000 - 16s - loss: 0.1996 - acc: 0.9248
Epoch 7/15
60000/60000 - 16s - loss: 0.1813 - acc: 0.9316
Epoch 8/15
60000/60000 - 16s - loss: 0.1666 - acc: 0.9372
Epoch 9/15
60000/60000 - 16s - loss: 0.1525 - acc: 0.9430
Epoch 10/15
60000/60000 - 15s - loss: 0.1374 - acc: 0.9484
Epoch 11/15
60000/60000 - 16s - loss: 0.1257 - acc: 0.9527
Epoch 12/15
60000/60000 - 15s - loss: 0.1135 - acc: 0.9569
Epoch 13/15
60000/60000 - 16s - loss: 0.1025 - acc: 0.9615
Epoch 14/15
60000/60000 - 15s - loss: 0.0937 - acc: 0.9647
Epoch 15/15
60000/60000 - 16s - loss: 0.0849 - acc: 0.9682
Testing Loss: 0.34  Testing Accuracy: 0.91
</pre>
<p>It looks like it's started to overfit, the accuracy is okay, but the loss is a little worse.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgfae0a7d">
<h3 id="orgfae0a7d">20 Epochs</h3>
<div class="outline-text-3" id="text-orgfae0a7d">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
Epoch 1/20
60000/60000 - 16s - loss: 0.4759 - acc: 0.8264
Epoch 2/20
60000/60000 - 16s - loss: 0.3218 - acc: 0.8822
Epoch 3/20
60000/60000 - 16s - loss: 0.2767 - acc: 0.8982
Epoch 4/20
60000/60000 - 16s - loss: 0.2469 - acc: 0.9083
Epoch 5/20
60000/60000 - 16s - loss: 0.2218 - acc: 0.9177
Epoch 6/20
60000/60000 - 16s - loss: 0.2015 - acc: 0.9244
Epoch 7/20
60000/60000 - 16s - loss: 0.1848 - acc: 0.9309
Epoch 8/20
60000/60000 - 15s - loss: 0.1698 - acc: 0.9361
Epoch 9/20
60000/60000 - 14s - loss: 0.1525 - acc: 0.9424
Epoch 10/20
60000/60000 - 15s - loss: 0.1435 - acc: 0.9457
Epoch 11/20
60000/60000 - 16s - loss: 0.1306 - acc: 0.9504
Epoch 12/20
60000/60000 - 15s - loss: 0.1172 - acc: 0.9556
Epoch 13/20
60000/60000 - 15s - loss: 0.1079 - acc: 0.9594
Epoch 14/20
60000/60000 - 15s - loss: 0.0993 - acc: 0.9626
Epoch 15/20
60000/60000 - 15s - loss: 0.0900 - acc: 0.9658
Epoch 16/20
60000/60000 - 15s - loss: 0.0829 - acc: 0.9686
Epoch 17/20
60000/60000 - 15s - loss: 0.0746 - acc: 0.9720
Epoch 18/20
60000/60000 - 16s - loss: 0.0713 - acc: 0.9736
Epoch 19/20
60000/60000 - 15s - loss: 0.0638 - acc: 0.9760
Epoch 20/20
60000/60000 - 15s - loss: 0.0594 - acc: 0.9781
Testing Loss: 0.45  Testing Accuracy: 0.91
</pre>
<p>It looks like it might be overfitting - both the loss and the accuracy went down a little.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org5c7627f">
<h3 id="org5c7627f">Visualizing the Convolutions and Pooling</h3>
<div class="outline-text-3" id="text-org5c7627f">
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">testing_labels</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
<pre class="example">
[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7
 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6
 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]

</pre>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">builder_10</span><span class="o">.</span><span class="n">model</span>
<span class="n">figure</span><span class="p">,</span> <span class="n">axis_array</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">FIRST_IMAGE</span><span class="o">=</span><span class="mi">0</span>
<span class="n">SECOND_IMAGE</span><span class="o">=</span><span class="mi">7</span>
<span class="n">THIRD_IMAGE</span><span class="o">=</span><span class="mi">26</span>
<span class="n">CONVOLUTION_NUMBER</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">layer_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">]</span>

<span class="n">activation_model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">layer_outputs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">f1</span> <span class="o">=</span> <span class="n">activation_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">[</span><span class="n">FIRST_IMAGE</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:,</span> <span class="n">CONVOLUTION_NUMBER</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'inferno'</span><span class="p">)</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">f2</span> <span class="o">=</span> <span class="n">activation_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">[</span><span class="n">SECOND_IMAGE</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:,</span> <span class="n">CONVOLUTION_NUMBER</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'inferno'</span><span class="p">)</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">f3</span> <span class="o">=</span> <span class="n">activation_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">[</span><span class="n">THIRD_IMAGE</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f3</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="p">,</span> <span class="p">:,</span> <span class="n">CONVOLUTION_NUMBER</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'inferno'</span><span class="p">)</span>
  <span class="n">axis_array</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="layer_visualization.png" src="/posts/keras/convolutional-neural-networks-and-fashion-mnist/layer_visualization.png"></p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb1dc78e">
<h3 id="orgb1dc78e">Exercises</h3>
<div class="outline-text-3" id="text-orgb1dc78e"></div>
<div class="outline-4" id="outline-container-org6e6c38c">
<h4 id="org6e6c38c">1. Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.</h4>
<div class="outline-text-4" id="text-org6e6c38c"></div>
<ul class="org-ul">
<li><a id="org2e030bb"></a>16 Nodes<br>
<div class="outline-text-5" id="text-org2e030bb">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 12:06:27,700 graeae.timers.timer start: Started: 2019-07-03 12:06:27.700578
I0703 12:06:27.700625 140182964418368 timer.py:70] Started: 2019-07-03 12:06:27.700578
Epoch 1/10
60000/60000 - 17s - loss: 0.5169 - acc: 0.8100
Epoch 2/10
60000/60000 - 17s - loss: 0.3536 - acc: 0.8714
Epoch 3/10
60000/60000 - 17s - loss: 0.3075 - acc: 0.8873
Epoch 4/10
60000/60000 - 17s - loss: 0.2808 - acc: 0.8959
Epoch 5/10
60000/60000 - 16s - loss: 0.2590 - acc: 0.9027
Epoch 6/10
60000/60000 - 17s - loss: 0.2419 - acc: 0.9100
Epoch 7/10
60000/60000 - 17s - loss: 0.2276 - acc: 0.9156
Epoch 8/10
60000/60000 - 17s - loss: 0.2140 - acc: 0.9182
Epoch 9/10
60000/60000 - 17s - loss: 0.2030 - acc: 0.9233
Epoch 10/10
60000/60000 - 17s - loss: 0.1934 - acc: 0.9266
2019-07-03 12:09:18,226 graeae.timers.timer end: Ended: 2019-07-03 12:09:18.226577
I0703 12:09:18.226756 140182964418368 timer.py:77] Ended: 2019-07-03 12:09:18.226577
2019-07-03 12:09:18,229 graeae.timers.timer end: Elapsed: 0:02:50.525999
I0703 12:09:18.229464 140182964418368 timer.py:78] Elapsed: 0:02:50.525999
Testing Loss: 0.29  Testing Accuracy: 0.90
</pre>
<p>The smaller model had slightly more loss than the 32 node model as well as a little less accuracy.</p>
</div>
</li>
<li><a id="org428efe7"></a>64 Nodes<br>
<div class="outline-text-5" id="text-org428efe7">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 12:09:19,711 graeae.timers.timer start: Started: 2019-07-03 12:09:19.711082
I0703 12:09:19.711113 140182964418368 timer.py:70] Started: 2019-07-03 12:09:19.711082
Epoch 1/10
60000/60000 - 19s - loss: 0.4367 - acc: 0.8428
Epoch 2/10
60000/60000 - 18s - loss: 0.2923 - acc: 0.8929
Epoch 3/10
60000/60000 - 18s - loss: 0.2472 - acc: 0.9087
Epoch 4/10
60000/60000 - 18s - loss: 0.2156 - acc: 0.9205
Epoch 5/10
60000/60000 - 18s - loss: 0.1893 - acc: 0.9298
Epoch 6/10
60000/60000 - 18s - loss: 0.1665 - acc: 0.9380
Epoch 7/10
60000/60000 - 18s - loss: 0.1460 - acc: 0.9456
Epoch 8/10
60000/60000 - 18s - loss: 0.1285 - acc: 0.9500
Epoch 9/10
60000/60000 - 18s - loss: 0.1142 - acc: 0.9568
Epoch 10/10
60000/60000 - 18s - loss: 0.0972 - acc: 0.9621
2019-07-03 12:12:23,275 graeae.timers.timer end: Ended: 2019-07-03 12:12:23.274851
I0703 12:12:23.275002 140182964418368 timer.py:77] Ended: 2019-07-03 12:12:23.274851
2019-07-03 12:12:23,277 graeae.timers.timer end: Elapsed: 0:03:03.563769
I0703 12:12:23.277686 140182964418368 timer.py:78] Elapsed: 0:03:03.563769
Testing Loss: 0.32  Testing Accuracy: 0.91
</pre>
<p>This has the same accuracy as the 32 node model but with a slight increase in the loss.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgf8488fc">
<h4 id="orgf8488fc">2. Remove the final Convolution. What impact will this have on accuracy or training time?</h4>
<div class="outline-text-4" id="text-orgf8488fc">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">additional_convolutions</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 12:12:24,795 graeae.timers.timer start: Started: 2019-07-03 12:12:24.795249
I0703 12:12:24.795282 140182964418368 timer.py:70] Started: 2019-07-03 12:12:24.795249
Epoch 1/10
60000/60000 - 14s - loss: 0.3897 - acc: 0.8607
Epoch 2/10
60000/60000 - 14s - loss: 0.2642 - acc: 0.9042
Epoch 3/10
60000/60000 - 14s - loss: 0.2218 - acc: 0.9187
Epoch 4/10
60000/60000 - 14s - loss: 0.1883 - acc: 0.9306
Epoch 5/10
60000/60000 - 14s - loss: 0.1619 - acc: 0.9391
Epoch 6/10
60000/60000 - 14s - loss: 0.1387 - acc: 0.9482
Epoch 7/10
60000/60000 - 14s - loss: 0.1171 - acc: 0.9564
Epoch 8/10
60000/60000 - 14s - loss: 0.1000 - acc: 0.9629
Epoch 9/10
60000/60000 - 14s - loss: 0.0831 - acc: 0.9702
Epoch 10/10
60000/60000 - 14s - loss: 0.0728 - acc: 0.9729
2019-07-03 12:14:46,396 graeae.timers.timer end: Ended: 2019-07-03 12:14:46.396417
I0703 12:14:46.396641 140182964418368 timer.py:77] Ended: 2019-07-03 12:14:46.396417
2019-07-03 12:14:46,400 graeae.timers.timer end: Elapsed: 0:02:21.601168
I0703 12:14:46.400143 140182964418368 timer.py:78] Elapsed: 0:02:21.601168
Testing Loss: 0.31  Testing Accuracy: 0.92
</pre>
<p>Once again the accuracy is a little better than the 32 node model but the testing loss is also a little higher. We probably need more data.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org04153df">
<h4 id="org04153df">3. How about adding more Convolutions? What impact do you think this will have? Experiment with it.</h4>
<div class="outline-text-4" id="text-org04153df">
<div class="highlight">
<pre><span></span>"results output"body
</pre></div>
<pre class="example">
# Out[21]:

</pre></div>
</div>
<div class="outline-4" id="outline-container-orgb23c63c">
<h4 id="orgb23c63c">4. In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!</h4>
<div class="outline-text-4" id="text-orgb23c63c">
<div class="highlight">
<pre><span></span><span class="n">builder</span> <span class="o">=</span> <span class="n">ModelBuilder</span><span class="p">(</span><span class="n">use_callback</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callback_loss</span><span class="o">=</span><span class="mf">0.19</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">builder</span><span class="p">()</span>
</pre></div>
<pre class="example">
2019-07-03 15:20:50,279 graeae.timers.timer start: Started: 2019-07-03 15:20:50.279833
I0703 15:20:50.279866 140182964418368 timer.py:70] Started: 2019-07-03 15:20:50.279833
Epoch 1/100
60000/60000 - 17s - loss: 0.4773 - acc: 0.8277
Epoch 2/100
60000/60000 - 17s - loss: 0.3204 - acc: 0.8840
Epoch 3/100
60000/60000 - 17s - loss: 0.2777 - acc: 0.8986
Epoch 4/100
60000/60000 - 17s - loss: 0.2463 - acc: 0.9089
Epoch 5/100
60000/60000 - 17s - loss: 0.2220 - acc: 0.9179
Epoch 6/100
60000/60000 - 17s - loss: 0.2029 - acc: 0.9250
Epoch 7/100
Stopping point reached at epoch 6
60000/60000 - 17s - loss: 0.1827 - acc: 0.9314
2019-07-03 15:22:51,538 graeae.timers.timer end: Ended: 2019-07-03 15:22:51.537895
I0703 15:22:51.538049 140182964418368 timer.py:77] Ended: 2019-07-03 15:22:51.537895
2019-07-03 15:22:51,540 graeae.timers.timer end: Elapsed: 0:02:01.258062
I0703 15:22:51.540425 140182964418368 timer.py:78] Elapsed: 0:02:01.258062
Testing Loss: 0.25  Testing Accuracy: 0.91
</pre>
<p>This does about the same as the 10 epoch version, so we didn't save much, but it gives us a way to stop without guessing the number of epochs.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org0e44448">
<h2 id="org0e44448">End</h2>
<div class="outline-text-2" id="text-org0e44448"></div>
<div class="outline-3" id="outline-container-org5a2a839">
<h3 id="org5a2a839">Source</h3>
<div class="outline-text-3" id="text-org5a2a839">
<ul class="org-ul">
<li>This is a redo of the <a href="https://github.com/lmoroney/dlaicourse/blob/master/course%201%20-%20part%206%20-%20lesson%202%20-%20notebook.ipynb">Improving Computer Vision Accuracy Using Convolutions</a> notebook.</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/keras/handwriting-recognition-exercise/">Handwriting Recognition Exercise</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/handwriting-recognition-exercise/" rel="bookmark"><time class="published dt-published" datetime="2019-06-30T13:57:26-07:00" itemprop="datePublished" title="2019-06-30 13:57">2019-06-30 13:57</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org70b4c46">Beginning</a>
<ul>
<li><a href="/posts/keras/handwriting-recognition-exercise/#orgee1330c">Imports</a></li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org6b8f79b">The Plotting</a></li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#orgb67eca2">The Dataset</a></li>
</ul>
</li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org89c9bb9">Middle</a>
<ul>
<li><a href="/posts/keras/handwriting-recognition-exercise/#orgde06b33">The Dataset</a></li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org09a0984">The Model</a></li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org4a06a14">The Callback</a></li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#orgc4d0d88">Trying Some Models</a></li>
</ul>
</li>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org1196b2e">End</a>
<ul>
<li><a href="/posts/keras/handwriting-recognition-exercise/#org4edbc5e">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org70b4c46">
<h2 id="org70b4c46">Beginning</h2>
<div class="outline-text-2" id="text-org70b4c46">
<p>The goal of this exercise is to train a classifier on the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> dataset that reaches 99% during training without using a fixed number of training epochs.</p>
</div>
<div class="outline-3" id="outline-container-orgee1330c">
<h3 id="orgee1330c">Imports</h3>
<div class="outline-text-3" id="text-orgee1330c"></div>
<div class="outline-4" id="outline-container-org511c4c0">
<h4 id="org511c4c0">Python</h4>
<div class="outline-text-4" id="text-org511c4c0">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org59d65c3">
<h4 id="org59d65c3">From PyPi</h4>
<div class="outline-text-4" id="text-org59d65c3">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0bdd6a0">
<h4 id="org0bdd6a0">My Stuff</h4>
<div class="outline-text-4" id="text-org0bdd6a0">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.visualization.embed</span> <span class="kn">import</span> <span class="n">EmbedHoloview</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org6b8f79b">
<h3 id="org6b8f79b">The Plotting</h3>
<div class="outline-text-3" id="text-org6b8f79b">
<div class="highlight">
<pre><span></span><span class="n">embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">EmbedHoloview</span><span class="p">,</span> 
    <span class="n">folder_path</span><span class="o">=</span><span class="s2">"../../files/posts/keras/handwriting-recognition-exercise/"</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">holoviews</span><span class="o">.</span><span class="n">extension</span><span class="p">(</span><span class="s2">"bokeh"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb67eca2">
<h3 id="orgb67eca2">The Dataset</h3>
<div class="outline-text-3" id="text-orgb67eca2">
<div class="highlight">
<pre><span></span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org89c9bb9">
<h2 id="org89c9bb9">Middle</h2>
<div class="outline-text-2" id="text-org89c9bb9"></div>
<div class="outline-3" id="outline-container-orgde06b33">
<h3 id="orgde06b33">The Dataset</h3>
<div class="outline-text-3" id="text-orgde06b33"></div>
<div class="outline-4" id="outline-container-org0d91635">
<h4 id="org0d91635">What do we have here?</h4>
<div class="outline-text-4" id="text-org0d91635">
<div class="highlight">
<pre><span></span><span class="n">rows</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">training_images</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training Images: {rows:,} ({x} x {y})"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Training Images: 60,000 (28 x 28)

</pre>
<p>The Fashion MNIST dataset that I looked at previously was meant to be a drop-in replacement for this data set so it has the same number of images and the images are the same size.</p>
<div class="highlight">
<pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">training_images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="s2">"hover"</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="n">f</span><span class="s2">"MNIST Handwritten {training_labels[index]}"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sample_image"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/keras/handwriting-recognition-exercise/sample_image.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>The dataset is a set of hand-written digits (one each image) that we want to be able to classify.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">training_images</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">training_images</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</pre></div>
<pre class="example">
0
255

</pre>
<p>The images are 28 x 28 matrices of values from 0 (representing black) to 255 (representing white).</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgcc30f7d">
<h4 id="orgcc30f7d">Normalizing the Data</h4>
<div class="outline-text-4" id="text-orgcc30f7d">
<p>We want the values to be from 0 to 1 so I'm going to normalize them.</p>
<div class="highlight">
<pre><span></span><span class="n">training_images_normalized</span> <span class="o">=</span> <span class="n">training_images</span><span class="o">/</span><span class="mi">255</span>
<span class="n">testing_images_normalized</span> <span class="o">=</span> <span class="n">testing_images</span><span class="o">/</span><span class="mi">255</span>
<span class="k">print</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</pre></div>
<pre class="example">
1.0
0.0

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org09a0984">
<h3 id="org09a0984">The Model</h3>
<div class="outline-text-3" id="text-org09a0984">
<p>This is going to be a model with one hidden layer.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
    <span class="sd">"""Build a sequential model with one hidden layer</span>

<span class="sd">    Args:</span>
<span class="sd">     units: number of units in the hidden layer</span>
<span class="sd">    """</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

    <span class="c1"># flatten the image</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

    <span class="c1"># the hidden layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span> 
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4a06a14">
<h3 id="org4a06a14">The Callback</h3>
<div class="outline-text-3" id="text-org4a06a14">
<p>To make the training end at 99% accuracy I'll add a callback.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Stop</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="s2">"acc"</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">)</span> <span class="ow">and</span>  <span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"acc"</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.99</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Stopping point reached at epoch {epoch}"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Model Accuracy: {logs.get('accuracy')}"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
    <span class="sd">"""Build and trains the model</span>

<span class="sd">    Args:</span>
<span class="sd">     units: number of neurons in the hidden layer</span>
<span class="sd">    """</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">Stop</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="s2">"adam"</span><span class="p">,</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="s2">"sparse_categorical_crossentropy"</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span>
              <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callbacks</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">outcome_key</span><span class="p">):</span>
    <span class="sd">"""tests the model"""</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">outcomes</span><span class="p">[</span><span class="n">outcome_key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing: Loss={loss}, Accuracy: {accuracy}"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Testing A Prediction"</span><span class="p">)</span>
    <span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classifications</span><span class="p">))</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">classifications</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"expected label: {testing_labels[index]}"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"actual label: {selected.argmax()}"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc4d0d88">
<h3 id="orgc4d0d88">Trying Some Models</h3>
<div class="outline-text-3" id="text-orgc4d0d88"></div>
<div class="outline-4" id="outline-container-org3a8e24f">
<h4 id="org3a8e24f">128 Nodes</h4>
<div class="outline-text-4" id="text-org3a8e24f">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train</span><span class="p">()</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"128 Nodes"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Epoch 1/100
{'loss': 0.2586968289529284, 'acc': 0.92588335}
60000/60000 - 2s - loss: 0.2587 - acc: 0.9259
Epoch 2/100
{'loss': 0.11452680859503647, 'acc': 0.9655833}
60000/60000 - 2s - loss: 0.1145 - acc: 0.9656
Epoch 3/100
{'loss': 0.0795439642144988, 'acc': 0.97606665}
60000/60000 - 2s - loss: 0.0795 - acc: 0.9761
Epoch 4/100
{'loss': 0.05808031236998116, 'acc': 0.9816667}
60000/60000 - 2s - loss: 0.0581 - acc: 0.9817
Epoch 5/100
{'loss': 0.04466566459426346, 'acc': 0.98588336}
60000/60000 - 2s - loss: 0.0447 - acc: 0.9859
Epoch 6/100
{'loss': 0.03590909656824855, 'acc': 0.9885333}
60000/60000 - 2s - loss: 0.0359 - acc: 0.9885
Epoch 7/100
{'loss': 0.02741284582785641, 'acc': 0.9912}
Stopping point reached at epoch 6
Model Accuracy: None
60000/60000 - 2s - loss: 0.0274 - acc: 0.9912
Testing: Loss=15.376291691160201, Accuracy: 0.9764000177383423

Testing A Prediction
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
expected label: 0
actual label: 0
</pre>
<p>Well, here we can see why the Fashion MNIST data set was created, even with this simple network we were able to reach our goal in 7 epochs. Even the testing accuracy and loss was pretty good.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1196b2e">
<h2 id="org1196b2e">End</h2>
<div class="outline-text-2" id="text-org1196b2e"></div>
<div class="outline-3" id="outline-container-org4edbc5e">
<h3 id="org4edbc5e">Source</h3>
<div class="outline-text-3" id="text-org4edbc5e">
<ul class="org-ul">
<li>Taken from the <a href="https://github.com/lmoroney/dlaicourse/tree/master/Exercises/Exercise%202%20-%20Handwriting%20Recognition">Exercise 2 - Handwriting Recognition</a> notebook on github</li>
</ul>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/keras/beyond-hello/">Beyond Hello</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/beyond-hello/" rel="bookmark"><time class="published dt-published" datetime="2019-06-27T11:52:14-07:00" itemprop="datePublished" title="2019-06-27 11:52">2019-06-27 11:52</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/beyond-hello/#org671eda7">Beginning</a>
<ul>
<li><a href="/posts/keras/beyond-hello/#org467f47b">Imports</a></li>
<li><a href="/posts/keras/beyond-hello/#orgb6934ec">The Timer</a></li>
<li><a href="/posts/keras/beyond-hello/#orga7779c9">The Plotting</a></li>
<li><a href="/posts/keras/beyond-hello/#org756c544">The Data Set</a></li>
</ul>
</li>
<li><a href="/posts/keras/beyond-hello/#org04d6c56">Middle</a>
<ul>
<li><a href="/posts/keras/beyond-hello/#org4649256">Looking At The dataset</a></li>
<li><a href="/posts/keras/beyond-hello/#orgbaff8df">The Example</a></li>
<li><a href="/posts/keras/beyond-hello/#orgecf0bd0">Exercises</a></li>
</ul>
</li>
<li><a href="/posts/keras/beyond-hello/#orgdccde0e">End</a>
<ul>
<li><a href="/posts/keras/beyond-hello/#org556b09c">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org671eda7">
<h2 id="org671eda7">Beginning</h2>
<div class="outline-text-2" id="text-org671eda7">
<p>This is going to use <a href="https://keras.io/">keras</a> (and <a href="https://www.tensorflow.org/">tensorflow</a>) to learn to categorize images in the <a href="https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/">Fashion MNIST</a> dataset.</p>
</div>
<div class="outline-3" id="outline-container-org467f47b">
<h3 id="org467f47b">Imports</h3>
<div class="outline-text-3" id="text-org467f47b"></div>
<div class="outline-4" id="outline-container-org2ed9194">
<h4 id="org2ed9194">Python</h4>
<div class="outline-text-4" id="text-org2ed9194">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org180c32d">
<h4 id="org180c32d">PyPi</h4>
<div class="outline-text-4" id="text-org180c32d">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5016875">
<h4 id="org5016875">My Stuff</h4>
<div class="outline-text-4" id="text-org5016875">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.visualization.embed</span> <span class="kn">import</span> <span class="n">EmbedHoloview</span>
<span class="kn">from</span> <span class="nn">graeae.timers</span> <span class="kn">import</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb6934ec">
<h3 id="orgb6934ec">The Timer</h3>
<div class="outline-text-3" id="text-orgb6934ec">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga7779c9">
<h3 id="orga7779c9">The Plotting</h3>
<div class="outline-text-3" id="text-orga7779c9">
<div class="highlight">
<pre><span></span><span class="n">embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloview</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="s2">"../../files/posts/keras/beyond-hello/"</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">holoviews</span><span class="o">.</span><span class="n">extension</span><span class="p">(</span><span class="s2">"bokeh"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org756c544">
<h3 id="org756c544">The Data Set</h3>
<div class="outline-text-3" id="text-org756c544">
<p>Keras includes the fashion mnist dataset and can be retrieved using the <a href="https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles">datasets.fashion_mnist</a> property.</p>
<div class="highlight">
<pre><span></span><span class="p">(</span><span class="n">training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
<p>Unfortunately the function doesn't let you pass in the path to where you're going to store the files (it's stored in <code>~/.keras/datasets/fashion-mnist/</code>).</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org04d6c56">
<h2 id="org04d6c56">Middle</h2>
<div class="outline-text-2" id="text-org04d6c56"></div>
<div class="outline-3" id="outline-container-org4649256">
<h3 id="org4649256">Looking At The dataset</h3>
<div class="outline-text-3" id="text-org4649256"></div>
<div class="outline-4" id="outline-container-org55f78b5">
<h4 id="org55f78b5">The Labels</h4>
<div class="outline-text-4" id="text-org55f78b5">
<p>There are 10 categories of images encoded as integers in the label sets. The keras site lists them as these:</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Label</th>
<th class="org-left" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-left">T-Shirt/Top</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-left">Trouser</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-left">Pullover</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-left">Dress</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-left">Coat</td>
</tr>
<tr>
<td class="org-right">5</td>
<td class="org-left">Sandal</td>
</tr>
<tr>
<td class="org-right">6</td>
<td class="org-left">Shirt</td>
</tr>
<tr>
<td class="org-right">7</td>
<td class="org-left">Sneaker</td>
</tr>
<tr>
<td class="org-right">8</td>
<td class="org-left">Bag</td>
</tr>
<tr>
<td class="org-right">9</td>
<td class="org-left">Ankle Boot</td>
</tr>
</tbody>
</table>
<p>To make it easier to interpret later on I'll make a secret decoder ring.</p>
<div class="highlight">
<pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">"T-Shirt/Top"</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">"Trouser"</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">"Pullover"</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s2">"Dress"</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s2">"Coat"</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s2">"Sandal"</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s2">"Shirt"</span><span class="p">,</span>
    <span class="mi">7</span> <span class="p">:</span> <span class="s2">"Sneaker"</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s2">"Bag"</span><span class="p">,</span>
    <span class="mi">9</span> <span class="p">:</span> <span class="s2">"Ankle Boot"</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7820f05">
<h4 id="org7820f05">The Number Of Images</h4>
<div class="outline-text-4" id="text-org7820f05">
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">training_images</span><span class="p">))</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">training_images</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"rows: {rows:,} image: {width} x {height}"</span><span class="p">)</span>
<span class="n">rows</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">testing_images</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"rows: {rows:,} image: {width} x {height}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
&lt;class 'numpy.ndarray'&gt;
rows: 60,000 image: 28 x 28
rows: 10,000 image: 28 x 28

</pre>
<p>We have 60,000 grayscale 28 by 28 pixel images to use for training (it would be 28 x 28 x 3 if the images were RGB) and 10,000 grayscale 28 by 28 pixel images to use for testing.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org4b71388">
<h4 id="org4b71388">A Sample Image</h4>
<div class="outline-text-4" id="text-org4b71388">
<div class="highlight">
<pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">training_images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="s2">"hover"</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="n">f</span><span class="s2">"Label {training_labels[index]} ({labels[training_labels[index]]})"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"sample_image"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/keras/beyond-hello/sample_image.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Although it looks like it's a color image that's because holoviews adds artificial coloring to it. If you hover over the images the <code>x</code> and <code>y</code> values are the pixel coordinates and the <code>z</code> values are the grayscale values (so if you hover over black it should be 0, and if you hover over a white pixel it should be 255).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org644cb2e">
<h4 id="org644cb2e">Normalizing The Data</h4>
<div class="outline-text-4" id="text-org644cb2e">
<p>Since the pixel values are from 0 (black) to 255 (white) we need to normalize them to values from 0 to 1 to work with a neural network.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"minimum value: {training_images.min()} maximum value: {training_images.max()}"</span><span class="p">)</span>
<span class="n">training_images_normalized</span> <span class="o">=</span> <span class="n">training_images</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">testing_images_normalized</span> <span class="o">=</span> <span class="n">testing_images</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"minimum value: {training_images_normalized.min()} maximum value: {training_images_normalized.max()}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
minimum value: 0 maximum value: 255
minimum value: 0.0 maximum value: 1.0

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgbaff8df">
<h3 id="orgbaff8df">The Example</h3>
<div class="outline-text-3" id="text-orgbaff8df">
<p>This is a worked example given in the original notebook.</p>
</div>
<div class="outline-4" id="outline-container-org1767811">
<h4 id="org1767811">Define The Model</h4>
<div class="outline-text-4" id="text-org1767811">
<p>Once again the network will be a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/sequential">Sequential</a> one - a linear stack of layers, and there will be three layers, a <a href="https://www.tensorflow.org/api_docs/python/tf/layers/flatten">Flatten</a> layer to flatten our image into a vector with 784 cells (instead of a 28 x 28 matrix), followed by two <a href="https://www.tensorflow.org/api_docs/python/tf/layers/dense">dense</a>, or fully-connected, layers.</p>
<p>Each of the dense layers will get an activation function. The first dense layer (the hidden layer) gets a <a href="//www.tensorflow.org/api_docs/python/tf/nn/relu">ReLU</a> (<a href="//www.wikiwand.com/en/rectifier_(neural_networks)">Rectified Linear Unit</a>) function which makes it non-linear by returning the input only if it is greater than 0, otherwise it returns 0 (so it filters out negative numbers), and the second dense layer gets a <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax">softmax</a> function to identify the biggest value (and thus our most likely label for the input).</p>
<div class="highlight">
<pre><span></span> <span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
 <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
 <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
 <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>
</pre></div>
<p>There are 10 labels to predict so the last layer has 10 neurons.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgece800f">
<h4 id="orgece800f">Compile The Model</h4>
<div class="outline-text-4" id="text-orgece800f">
<p>This time we're going to compile the model using the <a href="https://www.tensorflow.org/api_docs/python/tf/train/adamoptimizer">adam optimizer</a>. confusingly, there's two of them in tensorflow, the "regular" one, and a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/adam">keras</a> version. we'll use the non-keras version. The loss, however, is the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparsecategoricalcrossentropy">keras version</a> as is the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/accuracy">accuracy</a>, which is just the number correct divided by the total count.</p>
<div class="highlight">
<pre><span></span> <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">"adam"</span><span class="p">,</span>
               <span class="n">loss</span> <span class="o">=</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
               <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre></div>
<p>And now we fit it.</p>
<div class="highlight">
<pre><span></span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<pre class="example">
Epoch 1/5
60000/60000 - 2s - loss: 0.5015 - acc: 0.8242
Epoch 2/5
60000/60000 - 2s - loss: 0.3796 - acc: 0.8635
Epoch 3/5
60000/60000 - 2s - loss: 0.3420 - acc: 0.8754
Epoch 4/5
60000/60000 - 2s - loss: 0.3176 - acc: 0.8830
Epoch 5/5
60000/60000 - 2s - loss: 0.2975 - acc: 0.8908
</pre>
<p>At the end of training the model is about 89% accurate.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org7b12115">
<h4 id="org7b12115">Check The Model Against The Test-Data</h4>
<div class="outline-text-4" id="text-org7b12115">
<p>The sequential model's <a href="https://www.tensorflow.org/api_docs/python/tf/keras/sequential#evaluate">evaluate</a> method will let us test it against the test set.</p>
<div class="highlight">
<pre><span></span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> 
                                 <span class="n">testing_labels</span><span class="p">,</span> 
                                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
 <span class="n">outcomes</span> <span class="o">=</span> <span class="p">{</span><span class="mi">128</span><span class="p">:</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)}</span>
 <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"loss: {loss:.2f} accuracy: {accuracy:.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
loss: 53.34 accuracy: 0.86

</pre>
<p>It had an accuracy of about 85%.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgecf0bd0">
<h3 id="orgecf0bd0">Exercises</h3>
<div class="outline-text-3" id="text-orgecf0bd0"></div>
<div class="outline-4" id="outline-container-orgdc67f10">
<h4 id="orgdc67f10">Exercise 1</h4>
<div class="outline-text-4" id="text-orgdc67f10">
<p>What does the output of the next code-block mean?</p>
<div class="highlight">
<pre><span></span><span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classifications</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]

</pre>
<p>Since we used the softmax method, the output is a vector representing the 10 labels, with a 1 where the predicted label is (so in this case it predicts 9).</p>
<div class="highlight">
<pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">testing_images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span>
    <span class="n">image</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="s2">"hover"</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="n">f</span><span class="s2">"Label {testing_labels[index]} ({labels[testing_labels[index]]})"</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">size</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"exercise_1_image"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/keras/beyond-hello/exercise_1_image.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Expected Label: {testing_labels[0]}, {labels[testing_labels[0]]}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Actual Label: {classifications[0].argmax()}, {labels[classifications[0].argmax()]}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Expected Label: 9, Ankle Boot
Actual Label: 9, Ankle Boot

</pre>
<p>So our model predicts that the first image is an <i>ankle boot</i>, which is correct.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org37bd0a2">
<h4 id="org37bd0a2">Exercise 2</h4>
<div class="outline-text-4" id="text-org37bd0a2">
<p>Experiment with different values for the number of <i>units</i> in the <b>dense</b> layer.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">"""creates, trains and tests the model</span>

<span class="sd">    args:</span>
<span class="sd">     units: number of units for the dense layer</span>
<span class="sd">     epochs: number of times to train the model</span>
<span class="sd">    """</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"building a model with {units} units in the dense layer"</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="c1"># add the matrix -&gt; vector layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

    <span class="c1"># add the layer that does the work</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> 
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">"adam"</span><span class="p">,</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"finished training the model"</span>
    <span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> 
                  <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"testing: loss={loss}, accuracy={100 * accuracy}%"</span><span class="p">)</span>
    <span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classifications</span><span class="p">))</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">classifications</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"expected label: {testing_labels[index]}, "</span>
          <span class="n">f</span><span class="s2">"{labels[testing_labels[index]]}"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"actual label: {selected.argmax()}, {labels[selected.argmax()]}"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org6622b6a"></a>512 Neurons<br>
<div class="outline-text-5" id="text-org6622b6a">
<div class="highlight">
<pre><span></span><span class="n">units</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="n">units</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example">
2019-06-30 11:40:58,135 graeae.timers.timer start: Started: 2019-06-30 11:40:58.135283
I0630 11:40:58.135326 140129240835904 timer.py:70] Started: 2019-06-30 11:40:58.135283
building a model with 512 units in the dense layer
Epoch 1/5
60000/60000 - 2s - loss: 0.4738 - acc: 0.8316
Epoch 2/5
60000/60000 - 2s - loss: 0.3585 - acc: 0.8680
Epoch 3/5
60000/60000 - 2s - loss: 0.3218 - acc: 0.8819
Epoch 4/5
60000/60000 - 2s - loss: 0.2971 - acc: 0.8904
Epoch 5/5
60000/60000 - 2s - loss: 0.2808 - acc: 0.8963
2019-06-30 11:41:09,089 graeae.timers.timer end: Ended: 2019-06-30 11:41:09.089237
I0630 11:41:09.089263 140129240835904 timer.py:77] Ended: 2019-06-30 11:41:09.089237
2019-06-30 11:41:09,089 graeae.timers.timer end: Elapsed: 0:00:10.953954
I0630 11:41:09.089937 140129240835904 timer.py:78] Elapsed: 0:00:10.953954

testing: loss=65.45295433635712, accuracy=84.96999740600586%
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
expected label: 8, Bag
actual label: 8, Bag
</pre>
<p>The model with the 512 neuron layer has less loss and better accuracy when compared to the original model with a 128 neuron layer.</p>
</div>
</li>
<li><a id="org54052db"></a>1020 Neurons<br>
<div class="outline-text-5" id="text-org54052db">
<div class="highlight">
<pre><span></span><span class="n">units</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="n">units</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example">
2019-06-30 11:41:11,857 graeae.timers.timer start: Started: 2019-06-30 11:41:11.857953
I0630 11:41:11.857974 140129240835904 timer.py:70] Started: 2019-06-30 11:41:11.857953
building a model with 1024 units in the dense layer
Epoch 1/5
60000/60000 - 3s - loss: 0.4707 - acc: 0.8323
Epoch 2/5
60000/60000 - 3s - loss: 0.3588 - acc: 0.8696
Epoch 3/5
60000/60000 - 2s - loss: 0.3229 - acc: 0.8815
Epoch 4/5
60000/60000 - 3s - loss: 0.2973 - acc: 0.8891
Epoch 5/5
60000/60000 - 2s - loss: 0.2786 - acc: 0.8957
2019-06-30 11:41:25,030 graeae.timers.timer end: Ended: 2019-06-30 11:41:25.030862
I0630 11:41:25.030889 140129240835904 timer.py:77] Ended: 2019-06-30 11:41:25.030862
2019-06-30 11:41:25,031 graeae.timers.timer end: Elapsed: 0:00:13.172909
I0630 11:41:25.031725 140129240835904 timer.py:78] Elapsed: 0:00:13.172909

testing: loss=54.632147045129535, accuracy=86.79999709129333%
[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
expected label: 9, Ankle Boot
actual label: 7, Sneaker
</pre>
<p>The model did slightly better than the original 128 unit model, probably because fewer nodes don't give it enough "knobs" to tune to make an accurate match. Oddly it didn't do as well as the 512 unit model, perhaps because with that many neurons we need more data (or more epochs?). On this run it got the prediction for the single case wrong, although it doesn't usually (it should happen around 13 % of the time if the accuracy holds up).</p>
<div class="highlight">
<pre><span></span><span class="n">units</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">create_and_test_model</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="n">units</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
<pre class="example">
2019-06-30 11:41:27,717 graeae.timers.timer start: Started: 2019-06-30 11:41:27.717040
I0630 11:41:27.717062 140129240835904 timer.py:70] Started: 2019-06-30 11:41:27.717040
building a model with 1024 units in the dense layer
Epoch 1/10
60000/60000 - 3s - loss: 0.4665 - acc: 0.8330
Epoch 2/10
60000/60000 - 3s - loss: 0.3593 - acc: 0.8675
Epoch 3/10
60000/60000 - 3s - loss: 0.3181 - acc: 0.8830
Epoch 4/10
60000/60000 - 3s - loss: 0.2964 - acc: 0.8899
Epoch 5/10
60000/60000 - 3s - loss: 0.2763 - acc: 0.8965
Epoch 6/10
60000/60000 - 3s - loss: 0.2621 - acc: 0.9021
Epoch 7/10
60000/60000 - 2s - loss: 0.2496 - acc: 0.9052
Epoch 8/10
60000/60000 - 3s - loss: 0.2384 - acc: 0.9109
Epoch 9/10
60000/60000 - 2s - loss: 0.2279 - acc: 0.9149
Epoch 10/10
60000/60000 - 2s - loss: 0.2209 - acc: 0.9165
2019-06-30 11:41:54,160 graeae.timers.timer end: Ended: 2019-06-30 11:41:54.160517
I0630 11:41:54.160544 140129240835904 timer.py:77] Ended: 2019-06-30 11:41:54.160517
2019-06-30 11:41:54,161 graeae.timers.timer end: Elapsed: 0:00:26.443477
I0630 11:41:54.161170 140129240835904 timer.py:78] Elapsed: 0:00:26.443477

testing: loss=64.08433327770233, accuracy=86.41999959945679%
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
expected label: 0, T-Shirt/Top
actual label: 0, T-Shirt/Top
</pre>
<p>It seems to be overfitting the data, it looks like we'd need more data for this many nodes. According to the original notebook, this should be more accurate, but that's not true of the test-set. Maybe they meant in comparison to the original 128 unit network, not the 512 unit network.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"|Units | Loss | Accuracy|"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"|-+-+-|"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"|{units}| {loss:.2f}| {accuracy: .2f}|"</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Units</th>
<th class="org-right" scope="col">Loss</th>
<th class="org-right" scope="col">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">128</td>
<td class="org-right">53.34</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-right">512</td>
<td class="org-right">65.45</td>
<td class="org-right">0.85</td>
</tr>
<tr>
<td class="org-right">1024</td>
<td class="org-right">64.08</td>
<td class="org-right">0.86</td>
</tr>
</tbody>
</table>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orga8cc897">
<h4 id="orga8cc897">Exercise: Another Layer</h4>
<div class="outline-text-4" id="text-orga8cc897">
<p>What happens if you add another layer between the 512 unit layer and the output?</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"Adding an extra layer with 256 units"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                                        <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                        <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(),</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing: loss={loss}, accuracy={100 * accuracy}%"</span><span class="p">)</span>
<span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classifications</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Expected Label: {testing_labels[0]}, {labels[testing_labels[0]]}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Actual Label: {classifications.argmax()}, {labels[classifications.argmax()]}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Adding an extra layer with 256 units
Epoch 1/5
60000/60000 - 3s - loss: 0.4672 - acc: 0.8305
Epoch 2/5
60000/60000 - 3s - loss: 0.3549 - acc: 0.8695
Epoch 3/5
60000/60000 - 4s - loss: 0.3202 - acc: 0.8819
Epoch 4/5
60000/60000 - 4s - loss: 0.2975 - acc: 0.8904
Epoch 5/5
60000/60000 - 4s - loss: 0.2787 - acc: 0.8960

Testing: loss=46.68517806854248, accuracy=87.18000054359436%
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
Expected Label: 9, Ankle Boot
Actual Label: 9, Ankle Boot
</pre>
<p>The testing accuracy was slightly lower (pretty much the same) but it improved the loss.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org33946a6">
<h4 id="org33946a6">Exercise: More Epochs</h4>
<div class="outline-text-4" id="text-org33946a6">
<p>What happens if you train for 15 or 30 epochs?</p>
</div>
<ul class="org-ul">
<li><a id="orgcdfabb8"></a>15 Epochs<br>
<div class="outline-text-5" id="text-orgcdfabb8">
<div class="highlight">
<pre><span></span><span class="n">create_and_test_model</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
</pre></div>
<pre class="example">
2019-06-30 11:42:17,312 graeae.timers.timer start: Started: 2019-06-30 11:42:17.312462
I0630 11:42:17.312490 140129240835904 timer.py:70] Started: 2019-06-30 11:42:17.312462
building a model with 512 units in the dense layer
Epoch 1/15
60000/60000 - 4s - loss: 0.4746 - acc: 0.8299
Epoch 2/15
60000/60000 - 3s - loss: 0.3558 - acc: 0.8697
Epoch 3/15
60000/60000 - 2s - loss: 0.3230 - acc: 0.8804
Epoch 4/15
60000/60000 - 2s - loss: 0.2969 - acc: 0.8892
Epoch 5/15
60000/60000 - 2s - loss: 0.2804 - acc: 0.8954
Epoch 6/15
60000/60000 - 2s - loss: 0.2644 - acc: 0.9022
Epoch 7/15
60000/60000 - 2s - loss: 0.2526 - acc: 0.9058
Epoch 8/15
60000/60000 - 2s - loss: 0.2427 - acc: 0.9093
Epoch 9/15
60000/60000 - 2s - loss: 0.2331 - acc: 0.9122
Epoch 10/15
60000/60000 - 2s - loss: 0.2217 - acc: 0.9166
Epoch 11/15
60000/60000 - 2s - loss: 0.2136 - acc: 0.9191
Epoch 12/15
60000/60000 - 2s - loss: 0.2046 - acc: 0.9232
Epoch 13/15
60000/60000 - 2s - loss: 0.1997 - acc: 0.9250
Epoch 14/15
60000/60000 - 2s - loss: 0.1919 - acc: 0.9279
Epoch 15/15
60000/60000 - 2s - loss: 0.1863 - acc: 0.9294
2019-06-30 11:42:54,542 graeae.timers.timer end: Ended: 2019-06-30 11:42:54.542345
I0630 11:42:54.542373 140129240835904 timer.py:77] Ended: 2019-06-30 11:42:54.542345
2019-06-30 11:42:54,543 graeae.timers.timer end: Elapsed: 0:00:37.229883
I0630 11:42:54.543807 140129240835904 timer.py:78] Elapsed: 0:00:37.229883

testing: loss=59.34430006275177, accuracy=87.44999766349792%
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
expected label: 3, Dress
actual label: 3, Dress
</pre>
<p>The accuracy went up slightly, but the loss went up even more.</p>
</div>
</li>
<li><a id="orgc7e050e"></a>30 Epochs<br>
<div class="outline-text-5" id="text-orgc7e050e">
<div class="highlight">
<pre><span></span><span class="n">create_and_test_model</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</pre></div>
<pre class="example">
2019-06-30 11:42:57,431 graeae.timers.timer start: Started: 2019-06-30 11:42:57.431973
I0630 11:42:57.431994 140129240835904 timer.py:70] Started: 2019-06-30 11:42:57.431973
building a model with 512 units in the dense layer
Epoch 1/30
60000/60000 - 2s - loss: 0.4750 - acc: 0.8312
Epoch 2/30
60000/60000 - 2s - loss: 0.3623 - acc: 0.8686
Epoch 3/30
60000/60000 - 2s - loss: 0.3226 - acc: 0.8818
Epoch 4/30
60000/60000 - 3s - loss: 0.2990 - acc: 0.8901
Epoch 5/30
60000/60000 - 2s - loss: 0.2814 - acc: 0.8961
Epoch 6/30
60000/60000 - 2s - loss: 0.2644 - acc: 0.9017
Epoch 7/30
60000/60000 - 2s - loss: 0.2529 - acc: 0.9061
Epoch 8/30
60000/60000 - 2s - loss: 0.2433 - acc: 0.9089
Epoch 9/30
60000/60000 - 2s - loss: 0.2305 - acc: 0.9124
Epoch 10/30
60000/60000 - 2s - loss: 0.2211 - acc: 0.9164
Epoch 11/30
60000/60000 - 2s - loss: 0.2133 - acc: 0.9186
Epoch 12/30
60000/60000 - 2s - loss: 0.2065 - acc: 0.9222
Epoch 13/30
60000/60000 - 2s - loss: 0.1998 - acc: 0.9243
Epoch 14/30
60000/60000 - 2s - loss: 0.1905 - acc: 0.9284
Epoch 15/30
60000/60000 - 2s - loss: 0.1828 - acc: 0.9307
Epoch 16/30
60000/60000 - 2s - loss: 0.1782 - acc: 0.9322
Epoch 17/30
60000/60000 - 2s - loss: 0.1714 - acc: 0.9348
Epoch 18/30
60000/60000 - 2s - loss: 0.1672 - acc: 0.9367
Epoch 19/30
60000/60000 - 2s - loss: 0.1622 - acc: 0.9390
Epoch 20/30
60000/60000 - 2s - loss: 0.1556 - acc: 0.9405
Epoch 21/30
60000/60000 - 2s - loss: 0.1518 - acc: 0.9422
Epoch 22/30
60000/60000 - 2s - loss: 0.1463 - acc: 0.9445
Epoch 23/30
60000/60000 - 2s - loss: 0.1451 - acc: 0.9441
Epoch 24/30
60000/60000 - 2s - loss: 0.1408 - acc: 0.9468
Epoch 25/30
60000/60000 - 2s - loss: 0.1340 - acc: 0.9499
Epoch 26/30
60000/60000 - 2s - loss: 0.1325 - acc: 0.9488
Epoch 27/30
60000/60000 - 2s - loss: 0.1271 - acc: 0.9520
Epoch 28/30
60000/60000 - 2s - loss: 0.1246 - acc: 0.9532
Epoch 29/30
60000/60000 - 2s - loss: 0.1235 - acc: 0.9539
Epoch 30/30
60000/60000 - 2s - loss: 0.1199 - acc: 0.9550
2019-06-30 11:44:03,867 graeae.timers.timer end: Ended: 2019-06-30 11:44:03.867668
I0630 11:44:03.867694 140129240835904 timer.py:77] Ended: 2019-06-30 11:44:03.867668
2019-06-30 11:44:03,868 graeae.timers.timer end: Elapsed: 0:01:06.435695
I0630 11:44:03.868357 140129240835904 timer.py:78] Elapsed: 0:01:06.435695

testing: loss=96.21011676330566, accuracy=87.44999766349792%
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
expected label: 1, Trouser
actual label: 1, Trouser
</pre>
<p>The accuracy seems to be around the same, but the loss is getting pretty high.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org9f46f32">
<h4 id="org9f46f32">Early Stopping</h4>
<div class="outline-text-4" id="text-org9f46f32">
<p>What if you want to stop when the loss reaches a certain point? In Keras/tensorflow <a href="https://www.tensorflow.org/beta/guide/keras/custom_callback">you can set a callback</a> that stops the training (and other things, like plot images or store the values as you progress for later plotting.)</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">Stop</span><span class="p">(</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.4</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Stopping point reached at epoch {epoch}"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
<p>The <code>logs</code> dict will contain all the metrics, so even though we used loss, you could also, in this case, use <i>Mean Absolute Error</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">Stop</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
  <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">),</span>
  <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span> 
              <span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_images_normalized</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callbacks</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">testing_images</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">outcomes</span><span class="p">[</span><span class="s2">"512 (early stopping)"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Testing: Loss={loss}, Accuracy: {accuracy}"</span><span class="p">)</span>
<span class="n">classifications</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testing_images</span><span class="p">)</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classifications</span><span class="p">))</span>
<span class="n">selected</span> <span class="o">=</span> <span class="n">classifications</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">selected</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"expected label: {testing_labels[index]}, {labels[testing_labels[index]]}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"actual label: {selected.argmax()}, {labels[selected.argmax()]}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Epoch 1/5
60000/60000 - 2s - loss: 0.4765 - acc: 0.8295
Epoch 2/5
Stopping point reached at epoch 1
60000/60000 - 2s - loss: 0.3597 - acc: 0.8679

Testing: Loss=58.14345246582031, Accuracy: 0.8514999747276306
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
expected label: 9, Ankle Boot
actual label: 9, Ankle Boot
</pre>
<p>By setting a threshold for the loss we were able to stop after two epochs instead of going to the full five epochs, which saves on training time, but also sometimes reduces the performance on the testing set slightly (the training that went the full five epochs stopped at a loss of 0.28, not 0.4). I just noticed that the 512 unit network actually didn't do better this time (each time I run this notebook things change slightly) but normally it is the model that performs the best.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"|Units | Loss | Accuracy|"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"|-+-+-|"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"|{units}| {loss:.2f}| {accuracy: .2f}|"</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Units</th>
<th class="org-right" scope="col">Loss</th>
<th class="org-right" scope="col">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">128</td>
<td class="org-right">53.34</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-right">512</td>
<td class="org-right">65.45</td>
<td class="org-right">0.85</td>
</tr>
<tr>
<td class="org-right">1024</td>
<td class="org-right">64.08</td>
<td class="org-right">0.86</td>
</tr>
<tr>
<td class="org-right">512 (early stopping)</td>
<td class="org-right">58.14</td>
<td class="org-right">0.85</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgdccde0e">
<h2 id="orgdccde0e">End</h2>
<div class="outline-text-2" id="text-orgdccde0e"></div>
<div class="outline-3" id="outline-container-org556b09c">
<h3 id="org556b09c">Source</h3>
<div class="outline-text-3" id="text-org556b09c">
<p>This is a re-do of the <a href="https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%204%20-%20Lesson%202%20-%20Notebook.ipynb">Beyond Hello World, A Computer Vision Example</a> notebook on github by <a href="https://github.com/lmoroney">Laurence Moroney</a>.</p>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/keras/hello-there/">Hello There</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/keras/hello-there/" rel="bookmark"><time class="published dt-published" datetime="2019-06-25T06:59:52-07:00" itemprop="datePublished" title="2019-06-25 06:59">2019-06-25 06:59</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/keras/hello-there/#org0e91074">Beginning</a>
<ul>
<li><a href="/posts/keras/hello-there/#orgd7330dc">Imports</a></li>
<li><a href="/posts/keras/hello-there/#org929e311">Set Up</a></li>
</ul>
</li>
<li><a href="/posts/keras/hello-there/#org80b0ec3">Middle</a>
<ul>
<li><a href="/posts/keras/hello-there/#org6a6dd5e">The Data</a></li>
<li><a href="/posts/keras/hello-there/#org8c45873">Defining the Neural Network</a></li>
<li><a href="/posts/keras/hello-there/#org60cb059">Compiling the Model</a></li>
<li><a href="/posts/keras/hello-there/#org20577df">Training The Model</a></li>
<li><a href="/posts/keras/hello-there/#org314e99a">Make a Prediction</a></li>
</ul>
</li>
<li><a href="/posts/keras/hello-there/#org4e50596">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org0e91074">
<h2 id="org0e91074">Beginning</h2>
<div class="outline-text-2" id="text-org0e91074">
<p>This 'Hello World' takes data created by a simple linear model and trains a neural network to model it. The actual model will take this form:</p>
<p>\[ y = mx + b \]</p>
</div>
<div class="outline-3" id="outline-container-orgd7330dc">
<h3 id="orgd7330dc">Imports</h3>
<div class="outline-text-3" id="text-orgd7330dc"></div>
<div class="outline-4" id="outline-container-org238de78">
<h4 id="org238de78">Python</h4>
<div class="outline-text-4" id="text-org238de78">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org08c1c94">
<h4 id="org08c1c94">PyPi</h4>
<div class="outline-text-4" id="text-org08c1c94">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4efc31b">
<h4 id="org4efc31b">My Stuff</h4>
<div class="outline-text-4" id="text-org4efc31b">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.visualization.embed</span> <span class="kn">import</span> <span class="n">EmbedHoloview</span> <span class="k">as</span> <span class="n">EmbedHoloviews</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org929e311">
<h3 id="org929e311">Set Up</h3>
<div class="outline-text-3" id="text-org929e311"></div>
<div class="outline-4" id="outline-container-orgd57ee2f">
<h4 id="orgd57ee2f">Plotting</h4>
<div class="outline-text-4" id="text-orgd57ee2f">
<div class="highlight">
<pre><span></span><span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> 
                <span class="n">folder_path</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/keras/hello-there/"</span><span class="p">))</span>

<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">holoviews</span><span class="o">.</span><span class="n">extension</span><span class="p">(</span><span class="s2">"bokeh"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbcf750d">
<h4 id="orgbcf750d">The Random Seed</h4>
<div class="outline-text-4" id="text-orgbcf750d">
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2019</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org80b0ec3">
<h2 id="org80b0ec3">Middle</h2>
<div class="outline-text-2" id="text-org80b0ec3"></div>
<div class="outline-3" id="outline-container-org6a6dd5e">
<h3 id="org6a6dd5e">The Data</h3>
<div class="outline-text-3" id="text-org6a6dd5e">
<div class="highlight">
<pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,))</span> <span class="o">-</span> <span class="mi">10</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">intercept</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                             <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>
</pre></div>
<pre class="example">
[ 8.06964429 -2.13838987  2.47939923  2.75754802  7.60998138 -4.01655961
  4.0439654   8.06412323  7.62763853 -1.88500404]
[121.48751002  50.03127093  82.35579458  84.30283614 118.26986963
  36.88408272  93.30775783 121.44886259 118.39346971  51.80497172]

</pre>
<p>Our line is</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\\</span><span class="s2">["</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"y = {slope} x + {intercept}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\\</span><span class="s2">]"</span><span class="p">)</span>
</pre></div>
<p>\[ y = 7 x + 65 \] \[ y = 7 x + 32 \]</p>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">Y</span><span class="p">))</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"data_scatter"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/keras/hello-there/data_scatter.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object></div>
</div>
<div class="outline-3" id="outline-container-org8c45873">
<h3 id="org8c45873">Defining the Neural Network</h3>
<div class="outline-text-3" id="text-org8c45873">
<p>Our model will be a fully-connected network with one layer with one neuron that takes one input.</p>
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential">Sequential</a> : A linear stack of layers</li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">Dense</a>: A densely connected neural network layer</li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
<p><b>Note:</b> The original notebook passed the Dense layer into the constructor, but this gives a warning that you should pass in the dtype instead. Adding it to the constructed object seems to be the way they prefer to do it currently.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org60cb059">
<h3 id="org60cb059">Compiling the Model</h3>
<div class="outline-text-3" id="text-org60cb059">
<p>"Compiling" in this case means telling the model what optimizer and loss methods to use. In this case it will be <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent?oldformat=true">Stochastic Gradient Descent</a> and <a href="https://en.wikipedia.org/wiki/Mean_squared_error?oldformat=true">Mean Squared Error</a>.</p>
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile"><code>Sequential.compile</code></a></li>
</ul>
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'sgd'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">'mean_squared_error'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org20577df">
<h3 id="org20577df">Training The Model</h3>
<div class="outline-text-3" id="text-org20577df">
<p>Training is done with the model's <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit">fit</a> method. <code>epochs</code> is the number of times to repeat training.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
<pre class="example">
Epoch 1/500

10/10 [==============================] - 0s 7ms/sample - loss: 9059.2910
Epoch 2/500

10/10 [==============================] - 0s 142us/sample - loss: 3522.3921
Epoch 3/500

10/10 [==============================] - 0s 117us/sample - loss: 2619.3438
Epoch 4/500

10/10 [==============================] - 0s 96us/sample - loss: 2428.1226
Epoch 5/500

10/10 [==============================] - 0s 117us/sample - loss: 2347.3765
Epoch 6/500

10/10 [==============================] - 0s 114us/sample - loss: 2284.8735
Epoch 7/500

10/10 [==============================] - 0s 141us/sample - loss: 2226.4395
Epoch 8/500

10/10 [==============================] - 0s 125us/sample - loss: 2169.8687
Epoch 9/500

10/10 [==============================] - 0s 121us/sample - loss: 2114.7925
Epoch 10/500

10/10 [==============================] - 0s 131us/sample - loss: 2061.1226
Epoch 11/500

10/10 [==============================] - 0s 126us/sample - loss: 2008.8164
Epoch 12/500

10/10 [==============================] - 0s 139us/sample - loss: 1957.8376
Epoch 13/500

10/10 [==============================] - 0s 140us/sample - loss: 1908.1527
Epoch 14/500

10/10 [==============================] - 0s 147us/sample - loss: 1859.7283
Epoch 15/500

10/10 [==============================] - 0s 152us/sample - loss: 1812.5332
Epoch 16/500

10/10 [==============================] - 0s 140us/sample - loss: 1766.5355
Epoch 17/500

10/10 [==============================] - 0s 160us/sample - loss: 1721.7054
Epoch 18/500

10/10 [==============================] - 0s 112us/sample - loss: 1678.0129
Epoch 19/500

10/10 [==============================] - 0s 116us/sample - loss: 1635.4291
Epoch 20/500

10/10 [==============================] - 0s 114us/sample - loss: 1593.9260
Epoch 21/500

10/10 [==============================] - 0s 113us/sample - loss: 1553.4761
Epoch 22/500

10/10 [==============================] - 0s 108us/sample - loss: 1514.0527
Epoch 23/500

10/10 [==============================] - 0s 109us/sample - loss: 1475.6299
Epoch 24/500

10/10 [==============================] - 0s 98us/sample - loss: 1438.1820
Epoch 25/500

10/10 [==============================] - 0s 124us/sample - loss: 1401.6846
Epoch 26/500

10/10 [==============================] - 0s 118us/sample - loss: 1366.1134
Epoch 27/500

10/10 [==============================] - 0s 111us/sample - loss: 1331.4449
Epoch 28/500

10/10 [==============================] - 0s 102us/sample - loss: 1297.6560
Epoch 29/500

10/10 [==============================] - 0s 115us/sample - loss: 1264.7249
Epoch 30/500

10/10 [==============================] - 0s 118us/sample - loss: 1232.6293
Epoch 31/500

10/10 [==============================] - 0s 107us/sample - loss: 1201.3483
Epoch 32/500

10/10 [==============================] - 0s 108us/sample - loss: 1170.8608
Epoch 33/500

10/10 [==============================] - 0s 106us/sample - loss: 1141.1475
Epoch 34/500

10/10 [==============================] - 0s 113us/sample - loss: 1112.1881
Epoch 35/500

10/10 [==============================] - 0s 113us/sample - loss: 1083.9634
Epoch 36/500

10/10 [==============================] - 0s 117us/sample - loss: 1056.4552
Epoch 37/500

10/10 [==============================] - 0s 96us/sample - loss: 1029.6449
Epoch 38/500

10/10 [==============================] - 0s 120us/sample - loss: 1003.5151
Epoch 39/500

10/10 [==============================] - 0s 101us/sample - loss: 978.0483
Epoch 40/500

10/10 [==============================] - 0s 108us/sample - loss: 953.2279
Epoch 41/500

10/10 [==============================] - 0s 104us/sample - loss: 929.0374
Epoch 42/500

10/10 [==============================] - 0s 111us/sample - loss: 905.4608
Epoch 43/500

10/10 [==============================] - 0s 104us/sample - loss: 882.4824
Epoch 44/500

10/10 [==============================] - 0s 113us/sample - loss: 860.0872
Epoch 45/500

10/10 [==============================] - 0s 118us/sample - loss: 838.2604
Epoch 46/500

10/10 [==============================] - 0s 117us/sample - loss: 816.9874
Epoch 47/500

10/10 [==============================] - 0s 100us/sample - loss: 796.2543
Epoch 48/500

10/10 [==============================] - 0s 108us/sample - loss: 776.0475
Epoch 49/500

10/10 [==============================] - 0s 128us/sample - loss: 756.3533
Epoch 50/500

10/10 [==============================] - 0s 120us/sample - loss: 737.1589
Epoch 51/500

10/10 [==============================] - 0s 139us/sample - loss: 718.4517
Epoch 52/500

10/10 [==============================] - 0s 144us/sample - loss: 700.2191
Epoch 53/500

10/10 [==============================] - 0s 126us/sample - loss: 682.4492
Epoch 54/500

10/10 [==============================] - 0s 126us/sample - loss: 665.1305
Epoch 55/500

10/10 [==============================] - 0s 137us/sample - loss: 648.2512
Epoch 56/500

10/10 [==============================] - 0s 156us/sample - loss: 631.8002
Epoch 57/500

10/10 [==============================] - 0s 131us/sample - loss: 615.7667
Epoch 58/500

10/10 [==============================] - 0s 117us/sample - loss: 600.1400
Epoch 59/500

10/10 [==============================] - 0s 119us/sample - loss: 584.9100
Epoch 60/500

10/10 [==============================] - 0s 138us/sample - loss: 570.0665
Epoch 61/500

10/10 [==============================] - 0s 102us/sample - loss: 555.5996
Epoch 62/500

10/10 [==============================] - 0s 117us/sample - loss: 541.4998
Epoch 63/500

10/10 [==============================] - 0s 117us/sample - loss: 527.7579
Epoch 64/500

10/10 [==============================] - 0s 118us/sample - loss: 514.3649
Epoch 65/500

10/10 [==============================] - 0s 104us/sample - loss: 501.3116
Epoch 66/500

10/10 [==============================] - 0s 113us/sample - loss: 488.5895
Epoch 67/500

10/10 [==============================] - 0s 113us/sample - loss: 476.1904
Epoch 68/500

10/10 [==============================] - 0s 109us/sample - loss: 464.1059
Epoch 69/500

10/10 [==============================] - 0s 179us/sample - loss: 452.3281
Epoch 70/500

10/10 [==============================] - 0s 117us/sample - loss: 440.8490
Epoch 71/500

10/10 [==============================] - 0s 118us/sample - loss: 429.6613
Epoch 72/500

10/10 [==============================] - 0s 118us/sample - loss: 418.7576
Epoch 73/500

10/10 [==============================] - 0s 116us/sample - loss: 408.1307
Epoch 74/500

10/10 [==============================] - 0s 115us/sample - loss: 397.7733
Epoch 75/500

10/10 [==============================] - 0s 119us/sample - loss: 387.6787
Epoch 76/500

10/10 [==============================] - 0s 122us/sample - loss: 377.8404
Epoch 77/500

10/10 [==============================] - 0s 124us/sample - loss: 368.2518
Epoch 78/500

10/10 [==============================] - 0s 120us/sample - loss: 358.9065
Epoch 79/500

10/10 [==============================] - 0s 123us/sample - loss: 349.7983
Epoch 80/500

10/10 [==============================] - 0s 104us/sample - loss: 340.9213
Epoch 81/500

10/10 [==============================] - 0s 107us/sample - loss: 332.2696
Epoch 82/500

10/10 [==============================] - 0s 117us/sample - loss: 323.8374
Epoch 83/500

10/10 [==============================] - 0s 108us/sample - loss: 315.6192
Epoch 84/500

10/10 [==============================] - 0s 117us/sample - loss: 307.6096
Epoch 85/500

10/10 [==============================] - 0s 113us/sample - loss: 299.8033
Epoch 86/500

10/10 [==============================] - 0s 108us/sample - loss: 292.1950
Epoch 87/500

10/10 [==============================] - 0s 97us/sample - loss: 284.7798
Epoch 88/500

10/10 [==============================] - 0s 116us/sample - loss: 277.5528
Epoch 89/500

10/10 [==============================] - 0s 123us/sample - loss: 270.5092
Epoch 90/500

10/10 [==============================] - 0s 122us/sample - loss: 263.6443
Epoch 91/500

10/10 [==============================] - 0s 118us/sample - loss: 256.9538
Epoch 92/500

10/10 [==============================] - 0s 121us/sample - loss: 250.4329
Epoch 93/500

10/10 [==============================] - 0s 118us/sample - loss: 244.0775
Epoch 94/500

10/10 [==============================] - 0s 124us/sample - loss: 237.8834
Epoch 95/500

10/10 [==============================] - 0s 118us/sample - loss: 231.8465
Epoch 96/500

10/10 [==============================] - 0s 136us/sample - loss: 225.9629
Epoch 97/500

10/10 [==============================] - 0s 140us/sample - loss: 220.2286
Epoch 98/500

10/10 [==============================] - 0s 148us/sample - loss: 214.6397
Epoch 99/500

10/10 [==============================] - 0s 144us/sample - loss: 209.1927
Epoch 100/500

10/10 [==============================] - 0s 153us/sample - loss: 203.8839
Epoch 101/500

10/10 [==============================] - 0s 146us/sample - loss: 198.7099
Epoch 102/500

10/10 [==============================] - 0s 145us/sample - loss: 193.6671
Epoch 103/500

10/10 [==============================] - 0s 142us/sample - loss: 188.7523
Epoch 104/500

10/10 [==============================] - 0s 184us/sample - loss: 183.9622
Epoch 105/500

10/10 [==============================] - 0s 121us/sample - loss: 179.2937
Epoch 106/500

10/10 [==============================] - 0s 115us/sample - loss: 174.7437
Epoch 107/500

10/10 [==============================] - 0s 143us/sample - loss: 170.3092
Epoch 108/500

10/10 [==============================] - 0s 163us/sample - loss: 165.9872
Epoch 109/500

10/10 [==============================] - 0s 123us/sample - loss: 161.7748
Epoch 110/500

10/10 [==============================] - 0s 112us/sample - loss: 157.6694
Epoch 111/500

10/10 [==============================] - 0s 139us/sample - loss: 153.6682
Epoch 112/500

10/10 [==============================] - 0s 131us/sample - loss: 149.7685
Epoch 113/500

10/10 [==============================] - 0s 127us/sample - loss: 145.9678
Epoch 114/500

10/10 [==============================] - 0s 145us/sample - loss: 142.2635
Epoch 115/500

10/10 [==============================] - 0s 134us/sample - loss: 138.6532
Epoch 116/500

10/10 [==============================] - 0s 111us/sample - loss: 135.1345
Epoch 117/500

10/10 [==============================] - 0s 116us/sample - loss: 131.7051
Epoch 118/500

10/10 [==============================] - 0s 148us/sample - loss: 128.3628
Epoch 119/500

10/10 [==============================] - 0s 120us/sample - loss: 125.1053
Epoch 120/500

10/10 [==============================] - 0s 118us/sample - loss: 121.9304
Epoch 121/500

10/10 [==============================] - 0s 127us/sample - loss: 118.8361
Epoch 122/500

10/10 [==============================] - 0s 121us/sample - loss: 115.8204
Epoch 123/500

10/10 [==============================] - 0s 117us/sample - loss: 112.8811
Epoch 124/500

10/10 [==============================] - 0s 106us/sample - loss: 110.0165
Epoch 125/500

10/10 [==============================] - 0s 112us/sample - loss: 107.2246
Epoch 126/500

10/10 [==============================] - 0s 97us/sample - loss: 104.5035
Epoch 127/500

10/10 [==============================] - 0s 132us/sample - loss: 101.8514
Epoch 128/500

10/10 [==============================] - 0s 92us/sample - loss: 99.2667
Epoch 129/500

10/10 [==============================] - 0s 96us/sample - loss: 96.7476
Epoch 130/500

10/10 [==============================] - 0s 125us/sample - loss: 94.2923
Epoch 131/500

10/10 [==============================] - 0s 185us/sample - loss: 91.8994
Epoch 132/500

10/10 [==============================] - 0s 127us/sample - loss: 89.5672
Epoch 133/500

10/10 [==============================] - 0s 131us/sample - loss: 87.2943
Epoch 134/500

10/10 [==============================] - 0s 157us/sample - loss: 85.0790
Epoch 135/500

10/10 [==============================] - 0s 134us/sample - loss: 82.9199
Epoch 136/500

10/10 [==============================] - 0s 150us/sample - loss: 80.8156
Epoch 137/500

10/10 [==============================] - 0s 124us/sample - loss: 78.7647
Epoch 138/500

10/10 [==============================] - 0s 121us/sample - loss: 76.7658
Epoch 139/500

10/10 [==============================] - 0s 111us/sample - loss: 74.8177
Epoch 140/500

10/10 [==============================] - 0s 109us/sample - loss: 72.9190
Epoch 141/500

10/10 [==============================] - 0s 122us/sample - loss: 71.0685
Epoch 142/500

10/10 [==============================] - 0s 113us/sample - loss: 69.2649
Epoch 143/500

10/10 [==============================] - 0s 119us/sample - loss: 67.5071
Epoch 144/500

10/10 [==============================] - 0s 125us/sample - loss: 65.7940
Epoch 145/500

10/10 [==============================] - 0s 110us/sample - loss: 64.1243
Epoch 146/500

10/10 [==============================] - 0s 159us/sample - loss: 62.4970
Epoch 147/500

10/10 [==============================] - 0s 115us/sample - loss: 60.9109
Epoch 148/500

10/10 [==============================] - 0s 136us/sample - loss: 59.3652
Epoch 149/500

10/10 [==============================] - 0s 139us/sample - loss: 57.8586
Epoch 150/500

10/10 [==============================] - 0s 127us/sample - loss: 56.3903
Epoch 151/500

10/10 [==============================] - 0s 122us/sample - loss: 54.9593
Epoch 152/500

10/10 [==============================] - 0s 102us/sample - loss: 53.5645
Epoch 153/500

10/10 [==============================] - 0s 159us/sample - loss: 52.2052
Epoch 154/500

10/10 [==============================] - 0s 129us/sample - loss: 50.8803
Epoch 155/500

10/10 [==============================] - 0s 122us/sample - loss: 49.5891
Epoch 156/500

10/10 [==============================] - 0s 129us/sample - loss: 48.3307
Epoch 157/500

10/10 [==============================] - 0s 132us/sample - loss: 47.1041
Epoch 158/500

10/10 [==============================] - 0s 136us/sample - loss: 45.9088
Epoch 159/500

10/10 [==============================] - 0s 130us/sample - loss: 44.7437
Epoch 160/500

10/10 [==============================] - 0s 117us/sample - loss: 43.6082
Epoch 161/500

10/10 [==============================] - 0s 121us/sample - loss: 42.5016
Epoch 162/500

10/10 [==============================] - 0s 119us/sample - loss: 41.4230
Epoch 163/500

10/10 [==============================] - 0s 125us/sample - loss: 40.3718
Epoch 164/500

10/10 [==============================] - 0s 125us/sample - loss: 39.3473
Epoch 165/500

10/10 [==============================] - 0s 106us/sample - loss: 38.3487
Epoch 166/500

10/10 [==============================] - 0s 183us/sample - loss: 37.3755
Epoch 167/500

10/10 [==============================] - 0s 133us/sample - loss: 36.4271
Epoch 168/500

10/10 [==============================] - 0s 139us/sample - loss: 35.5026
Epoch 169/500

10/10 [==============================] - 0s 118us/sample - loss: 34.6017
Epoch 170/500

10/10 [==============================] - 0s 136us/sample - loss: 33.7236
Epoch 171/500

10/10 [==============================] - 0s 140us/sample - loss: 32.8677
Epoch 172/500

10/10 [==============================] - 0s 138us/sample - loss: 32.0336
Epoch 173/500

10/10 [==============================] - 0s 127us/sample - loss: 31.2207
Epoch 174/500

10/10 [==============================] - 0s 139us/sample - loss: 30.4284
Epoch 175/500

10/10 [==============================] - 0s 121us/sample - loss: 29.6562
Epoch 176/500

10/10 [==============================] - 0s 185us/sample - loss: 28.9036
Epoch 177/500

10/10 [==============================] - 0s 126us/sample - loss: 28.1701
Epoch 178/500

10/10 [==============================] - 0s 213us/sample - loss: 27.4552
Epoch 179/500

10/10 [==============================] - 0s 115us/sample - loss: 26.7585
Epoch 180/500

10/10 [==============================] - 0s 111us/sample - loss: 26.0794
Epoch 181/500

10/10 [==============================] - 0s 201us/sample - loss: 25.4176
Epoch 182/500

10/10 [==============================] - 0s 124us/sample - loss: 24.7726
Epoch 183/500

10/10 [==============================] - 0s 130us/sample - loss: 24.1439
Epoch 184/500

10/10 [==============================] - 0s 130us/sample - loss: 23.5312
Epoch 185/500

10/10 [==============================] - 0s 127us/sample - loss: 22.9340
Epoch 186/500

10/10 [==============================] - 0s 130us/sample - loss: 22.3520
Epoch 187/500

10/10 [==============================] - 0s 100us/sample - loss: 21.7848
Epoch 188/500

10/10 [==============================] - 0s 128us/sample - loss: 21.2319
Epoch 189/500

10/10 [==============================] - 0s 124us/sample - loss: 20.6931
Epoch 190/500

10/10 [==============================] - 0s 150us/sample - loss: 20.1680
Epoch 191/500

10/10 [==============================] - 0s 122us/sample - loss: 19.6561
Epoch 192/500

10/10 [==============================] - 0s 154us/sample - loss: 19.1573
Epoch 193/500

10/10 [==============================] - 0s 132us/sample - loss: 18.6711
Epoch 194/500

10/10 [==============================] - 0s 128us/sample - loss: 18.1973
Epoch 195/500

10/10 [==============================] - 0s 127us/sample - loss: 17.7355
Epoch 196/500

10/10 [==============================] - 0s 128us/sample - loss: 17.2854
Epoch 197/500

10/10 [==============================] - 0s 151us/sample - loss: 16.8468
Epoch 198/500

10/10 [==============================] - 0s 125us/sample - loss: 16.4192
Epoch 199/500

10/10 [==============================] - 0s 105us/sample - loss: 16.0025
Epoch 200/500

10/10 [==============================] - 0s 135us/sample - loss: 15.5964
Epoch 201/500

10/10 [==============================] - 0s 102us/sample - loss: 15.2006
Epoch 202/500

10/10 [==============================] - 0s 119us/sample - loss: 14.8149
Epoch 203/500

10/10 [==============================] - 0s 100us/sample - loss: 14.4389
Epoch 204/500

10/10 [==============================] - 0s 109us/sample - loss: 14.0725
Epoch 205/500

10/10 [==============================] - 0s 122us/sample - loss: 13.7154
Epoch 206/500

10/10 [==============================] - 0s 108us/sample - loss: 13.3673
Epoch 207/500

10/10 [==============================] - 0s 113us/sample - loss: 13.0281
Epoch 208/500

10/10 [==============================] - 0s 109us/sample - loss: 12.6975
Epoch 209/500

10/10 [==============================] - 0s 118us/sample - loss: 12.3753
Epoch 210/500

10/10 [==============================] - 0s 138us/sample - loss: 12.0612
Epoch 211/500

10/10 [==============================] - 0s 118us/sample - loss: 11.7551
Epoch 212/500

10/10 [==============================] - 0s 123us/sample - loss: 11.4568
Epoch 213/500

10/10 [==============================] - 0s 126us/sample - loss: 11.1661
Epoch 214/500

10/10 [==============================] - 0s 127us/sample - loss: 10.8827
Epoch 215/500

10/10 [==============================] - 0s 130us/sample - loss: 10.6065
Epoch 216/500

10/10 [==============================] - 0s 171us/sample - loss: 10.3374
Epoch 217/500

10/10 [==============================] - 0s 140us/sample - loss: 10.0750
Epoch 218/500

10/10 [==============================] - 0s 150us/sample - loss: 9.8193
Epoch 219/500

10/10 [==============================] - 0s 144us/sample - loss: 9.5702
Epoch 220/500

10/10 [==============================] - 0s 154us/sample - loss: 9.3273
Epoch 221/500

10/10 [==============================] - 0s 187us/sample - loss: 9.0906
Epoch 222/500

10/10 [==============================] - 0s 160us/sample - loss: 8.8599
Epoch 223/500

10/10 [==============================] - 0s 156us/sample - loss: 8.6350
Epoch 224/500

10/10 [==============================] - 0s 113us/sample - loss: 8.4159
Epoch 225/500

10/10 [==============================] - 0s 109us/sample - loss: 8.2023
Epoch 226/500

10/10 [==============================] - 0s 111us/sample - loss: 7.9942
Epoch 227/500

10/10 [==============================] - 0s 107us/sample - loss: 7.7913
Epoch 228/500

10/10 [==============================] - 0s 196us/sample - loss: 7.5936
Epoch 229/500

10/10 [==============================] - 0s 129us/sample - loss: 7.4009
Epoch 230/500

10/10 [==============================] - 0s 132us/sample - loss: 7.2131
Epoch 231/500

10/10 [==============================] - 0s 107us/sample - loss: 7.0300
Epoch 232/500

10/10 [==============================] - 0s 104us/sample - loss: 6.8516
Epoch 233/500

10/10 [==============================] - 0s 122us/sample - loss: 6.6777
Epoch 234/500

10/10 [==============================] - 0s 124us/sample - loss: 6.5083
Epoch 235/500

10/10 [==============================] - 0s 178us/sample - loss: 6.3431
Epoch 236/500

10/10 [==============================] - 0s 196us/sample - loss: 6.1821
Epoch 237/500

10/10 [==============================] - 0s 177us/sample - loss: 6.0253
Epoch 238/500

10/10 [==============================] - 0s 196us/sample - loss: 5.8724
Epoch 239/500

10/10 [==============================] - 0s 111us/sample - loss: 5.7233
Epoch 240/500

10/10 [==============================] - 0s 113us/sample - loss: 5.5781
Epoch 241/500

10/10 [==============================] - 0s 128us/sample - loss: 5.4365
Epoch 242/500

10/10 [==============================] - 0s 110us/sample - loss: 5.2986
Epoch 243/500

10/10 [==============================] - 0s 121us/sample - loss: 5.1641
Epoch 244/500

10/10 [==============================] - 0s 98us/sample - loss: 5.0330
Epoch 245/500

10/10 [==============================] - 0s 119us/sample - loss: 4.9053
Epoch 246/500

10/10 [==============================] - 0s 96us/sample - loss: 4.7808
Epoch 247/500

10/10 [==============================] - 0s 130us/sample - loss: 4.6595
Epoch 248/500

10/10 [==============================] - 0s 146us/sample - loss: 4.5413
Epoch 249/500

10/10 [==============================] - 0s 159us/sample - loss: 4.4260
Epoch 250/500

10/10 [==============================] - 0s 117us/sample - loss: 4.3137
Epoch 251/500

10/10 [==============================] - 0s 121us/sample - loss: 4.2042
Epoch 252/500

10/10 [==============================] - 0s 168us/sample - loss: 4.0975
Epoch 253/500

10/10 [==============================] - 0s 124us/sample - loss: 3.9936
Epoch 254/500

10/10 [==============================] - 0s 131us/sample - loss: 3.8922
Epoch 255/500

10/10 [==============================] - 0s 147us/sample - loss: 3.7934
Epoch 256/500

10/10 [==============================] - 0s 130us/sample - loss: 3.6972
Epoch 257/500

10/10 [==============================] - 0s 131us/sample - loss: 3.6034
Epoch 258/500

10/10 [==============================] - 0s 110us/sample - loss: 3.5119
Epoch 259/500

10/10 [==============================] - 0s 120us/sample - loss: 3.4228
Epoch 260/500

10/10 [==============================] - 0s 110us/sample - loss: 3.3359
Epoch 261/500

10/10 [==============================] - 0s 142us/sample - loss: 3.2513
Epoch 262/500

10/10 [==============================] - 0s 169us/sample - loss: 3.1688
Epoch 263/500

10/10 [==============================] - 0s 125us/sample - loss: 3.0884
Epoch 264/500

10/10 [==============================] - 0s 125us/sample - loss: 3.0100
Epoch 265/500

10/10 [==============================] - 0s 133us/sample - loss: 2.9336
Epoch 266/500

10/10 [==============================] - 0s 124us/sample - loss: 2.8591
Epoch 267/500

10/10 [==============================] - 0s 122us/sample - loss: 2.7866
Epoch 268/500

10/10 [==============================] - 0s 122us/sample - loss: 2.7159
Epoch 269/500

10/10 [==============================] - 0s 110us/sample - loss: 2.6469
Epoch 270/500

10/10 [==============================] - 0s 121us/sample - loss: 2.5798
Epoch 271/500

10/10 [==============================] - 0s 136us/sample - loss: 2.5143
Epoch 272/500

10/10 [==============================] - 0s 111us/sample - loss: 2.4505
Epoch 273/500

10/10 [==============================] - 0s 117us/sample - loss: 2.3883
Epoch 274/500

10/10 [==============================] - 0s 118us/sample - loss: 2.3277
Epoch 275/500

10/10 [==============================] - 0s 104us/sample - loss: 2.2686
Epoch 276/500

10/10 [==============================] - 0s 117us/sample - loss: 2.2110
Epoch 277/500

10/10 [==============================] - 0s 129us/sample - loss: 2.1549
Epoch 278/500

10/10 [==============================] - 0s 163us/sample - loss: 2.1002
Epoch 279/500

10/10 [==============================] - 0s 132us/sample - loss: 2.0469
Epoch 280/500

10/10 [==============================] - 0s 120us/sample - loss: 1.9950
Epoch 281/500

10/10 [==============================] - 0s 126us/sample - loss: 1.9444
Epoch 282/500

10/10 [==============================] - 0s 121us/sample - loss: 1.8950
Epoch 283/500

10/10 [==============================] - 0s 127us/sample - loss: 1.8469
Epoch 284/500

10/10 [==============================] - 0s 143us/sample - loss: 1.8001
Epoch 285/500

10/10 [==============================] - 0s 134us/sample - loss: 1.7544
Epoch 286/500

10/10 [==============================] - 0s 116us/sample - loss: 1.7099
Epoch 287/500

10/10 [==============================] - 0s 112us/sample - loss: 1.6665
Epoch 288/500

10/10 [==============================] - 0s 118us/sample - loss: 1.6242
Epoch 289/500

10/10 [==============================] - 0s 104us/sample - loss: 1.5830
Epoch 290/500

10/10 [==============================] - 0s 126us/sample - loss: 1.5428
Epoch 291/500

10/10 [==============================] - 0s 120us/sample - loss: 1.5036
Epoch 292/500

10/10 [==============================] - 0s 120us/sample - loss: 1.4655
Epoch 293/500

10/10 [==============================] - 0s 120us/sample - loss: 1.4283
Epoch 294/500

10/10 [==============================] - 0s 114us/sample - loss: 1.3920
Epoch 295/500

10/10 [==============================] - 0s 102us/sample - loss: 1.3567
Epoch 296/500

10/10 [==============================] - 0s 120us/sample - loss: 1.3223
Epoch 297/500

10/10 [==============================] - 0s 107us/sample - loss: 1.2887
Epoch 298/500

10/10 [==============================] - 0s 113us/sample - loss: 1.2560
Epoch 299/500

10/10 [==============================] - 0s 198us/sample - loss: 1.2242
Epoch 300/500

10/10 [==============================] - 0s 163us/sample - loss: 1.1931
Epoch 301/500

10/10 [==============================] - 0s 146us/sample - loss: 1.1628
Epoch 302/500

10/10 [==============================] - 0s 149us/sample - loss: 1.1333
Epoch 303/500

10/10 [==============================] - 0s 153us/sample - loss: 1.1045
Epoch 304/500

10/10 [==============================] - 0s 113us/sample - loss: 1.0765
Epoch 305/500

10/10 [==============================] - 0s 190us/sample - loss: 1.0492
Epoch 306/500

10/10 [==============================] - 0s 171us/sample - loss: 1.0226
Epoch 307/500

10/10 [==============================] - 0s 135us/sample - loss: 0.9966
Epoch 308/500

10/10 [==============================] - 0s 107us/sample - loss: 0.9713
Epoch 309/500

10/10 [==============================] - 0s 103us/sample - loss: 0.9467
Epoch 310/500

10/10 [==============================] - 0s 118us/sample - loss: 0.9227
Epoch 311/500

10/10 [==============================] - 0s 105us/sample - loss: 0.8992
Epoch 312/500

10/10 [==============================] - 0s 125us/sample - loss: 0.8764
Epoch 313/500

10/10 [==============================] - 0s 122us/sample - loss: 0.8542
Epoch 314/500

10/10 [==============================] - 0s 132us/sample - loss: 0.8325
Epoch 315/500

10/10 [==============================] - 0s 100us/sample - loss: 0.8114
Epoch 316/500

10/10 [==============================] - 0s 118us/sample - loss: 0.7908
Epoch 317/500

10/10 [==============================] - 0s 136us/sample - loss: 0.7707
Epoch 318/500

10/10 [==============================] - 0s 147us/sample - loss: 0.7511
Epoch 319/500

10/10 [==============================] - 0s 155us/sample - loss: 0.7321
Epoch 320/500

10/10 [==============================] - 0s 126us/sample - loss: 0.7135
Epoch 321/500

10/10 [==============================] - 0s 127us/sample - loss: 0.6954
Epoch 322/500

10/10 [==============================] - 0s 126us/sample - loss: 0.6778
Epoch 323/500

10/10 [==============================] - 0s 131us/sample - loss: 0.6606
Epoch 324/500

10/10 [==============================] - 0s 129us/sample - loss: 0.6438
Epoch 325/500

10/10 [==============================] - 0s 127us/sample - loss: 0.6275
Epoch 326/500

10/10 [==============================] - 0s 136us/sample - loss: 0.6115
Epoch 327/500

10/10 [==============================] - 0s 125us/sample - loss: 0.5960
Epoch 328/500

10/10 [==============================] - 0s 118us/sample - loss: 0.5809
Epoch 329/500

10/10 [==============================] - 0s 134us/sample - loss: 0.5661
Epoch 330/500

10/10 [==============================] - 0s 160us/sample - loss: 0.5518
Epoch 331/500

10/10 [==============================] - 0s 124us/sample - loss: 0.5378
Epoch 332/500

10/10 [==============================] - 0s 156us/sample - loss: 0.5241
Epoch 333/500

10/10 [==============================] - 0s 121us/sample - loss: 0.5108
Epoch 334/500

10/10 [==============================] - 0s 118us/sample - loss: 0.4979
Epoch 335/500

10/10 [==============================] - 0s 126us/sample - loss: 0.4852
Epoch 336/500

10/10 [==============================] - 0s 139us/sample - loss: 0.4729
Epoch 337/500

10/10 [==============================] - 0s 143us/sample - loss: 0.4609
Epoch 338/500

10/10 [==============================] - 0s 122us/sample - loss: 0.4492
Epoch 339/500

10/10 [==============================] - 0s 123us/sample - loss: 0.4378
Epoch 340/500

10/10 [==============================] - 0s 157us/sample - loss: 0.4267
Epoch 341/500

10/10 [==============================] - 0s 124us/sample - loss: 0.4159
Epoch 342/500

10/10 [==============================] - 0s 128us/sample - loss: 0.4053
Epoch 343/500

10/10 [==============================] - 0s 129us/sample - loss: 0.3950
Epoch 344/500

10/10 [==============================] - 0s 215us/sample - loss: 0.3850
Epoch 345/500

10/10 [==============================] - 0s 135us/sample - loss: 0.3752
Epoch 346/500

10/10 [==============================] - 0s 123us/sample - loss: 0.3657
Epoch 347/500

10/10 [==============================] - 0s 133us/sample - loss: 0.3564
Epoch 348/500

10/10 [==============================] - 0s 109us/sample - loss: 0.3474
Epoch 349/500

10/10 [==============================] - 0s 152us/sample - loss: 0.3386
Epoch 350/500

10/10 [==============================] - 0s 122us/sample - loss: 0.3300
Epoch 351/500

10/10 [==============================] - 0s 125us/sample - loss: 0.3216
Epoch 352/500

10/10 [==============================] - 0s 136us/sample - loss: 0.3134
Epoch 353/500

10/10 [==============================] - 0s 119us/sample - loss: 0.3055
Epoch 354/500

10/10 [==============================] - 0s 121us/sample - loss: 0.2977
Epoch 355/500

10/10 [==============================] - 0s 144us/sample - loss: 0.2902
Epoch 356/500

10/10 [==============================] - 0s 128us/sample - loss: 0.2828
Epoch 357/500

10/10 [==============================] - 0s 137us/sample - loss: 0.2756
Epoch 358/500

10/10 [==============================] - 0s 129us/sample - loss: 0.2686
Epoch 359/500

10/10 [==============================] - 0s 137us/sample - loss: 0.2618
Epoch 360/500

10/10 [==============================] - 0s 137us/sample - loss: 0.2552
Epoch 361/500

10/10 [==============================] - 0s 139us/sample - loss: 0.2487
Epoch 362/500

10/10 [==============================] - 0s 132us/sample - loss: 0.2424
Epoch 363/500

10/10 [==============================] - 0s 121us/sample - loss: 0.2362
Epoch 364/500

10/10 [==============================] - 0s 134us/sample - loss: 0.2303
Epoch 365/500

10/10 [==============================] - 0s 132us/sample - loss: 0.2244
Epoch 366/500

10/10 [==============================] - 0s 128us/sample - loss: 0.2187
Epoch 367/500

10/10 [==============================] - 0s 126us/sample - loss: 0.2132
Epoch 368/500

10/10 [==============================] - 0s 117us/sample - loss: 0.2078
Epoch 369/500

10/10 [==============================] - 0s 118us/sample - loss: 0.2025
Epoch 370/500

10/10 [==============================] - 0s 136us/sample - loss: 0.1973
Epoch 371/500

10/10 [==============================] - 0s 156us/sample - loss: 0.1923
Epoch 372/500

10/10 [==============================] - 0s 141us/sample - loss: 0.1875
Epoch 373/500

10/10 [==============================] - 0s 117us/sample - loss: 0.1827
Epoch 374/500

10/10 [==============================] - 0s 151us/sample - loss: 0.1781
Epoch 375/500

10/10 [==============================] - 0s 113us/sample - loss: 0.1735
Epoch 376/500

10/10 [==============================] - 0s 120us/sample - loss: 0.1691
Epoch 377/500

10/10 [==============================] - 0s 123us/sample - loss: 0.1648
Epoch 378/500

10/10 [==============================] - 0s 127us/sample - loss: 0.1607
Epoch 379/500

10/10 [==============================] - 0s 130us/sample - loss: 0.1566
Epoch 380/500

10/10 [==============================] - 0s 135us/sample - loss: 0.1526
Epoch 381/500

10/10 [==============================] - 0s 141us/sample - loss: 0.1487
Epoch 382/500

10/10 [==============================] - 0s 174us/sample - loss: 0.1450
Epoch 383/500

10/10 [==============================] - 0s 139us/sample - loss: 0.1413
Epoch 384/500

10/10 [==============================] - 0s 144us/sample - loss: 0.1377
Epoch 385/500

10/10 [==============================] - 0s 118us/sample - loss: 0.1342
Epoch 386/500

10/10 [==============================] - 0s 135us/sample - loss: 0.1308
Epoch 387/500

10/10 [==============================] - 0s 110us/sample - loss: 0.1275
Epoch 388/500

10/10 [==============================] - 0s 139us/sample - loss: 0.1242
Epoch 389/500

10/10 [==============================] - 0s 158us/sample - loss: 0.1211
Epoch 390/500

10/10 [==============================] - 0s 116us/sample - loss: 0.1180
Epoch 391/500

10/10 [==============================] - 0s 117us/sample - loss: 0.1150
Epoch 392/500

10/10 [==============================] - 0s 139us/sample - loss: 0.1121
Epoch 393/500

10/10 [==============================] - 0s 118us/sample - loss: 0.1093
Epoch 394/500

10/10 [==============================] - 0s 115us/sample - loss: 0.1065
Epoch 395/500

10/10 [==============================] - 0s 105us/sample - loss: 0.1038
Epoch 396/500

10/10 [==============================] - 0s 112us/sample - loss: 0.1012
Epoch 397/500

10/10 [==============================] - 0s 111us/sample - loss: 0.0986
Epoch 398/500

10/10 [==============================] - 0s 107us/sample - loss: 0.0961
Epoch 399/500

10/10 [==============================] - 0s 110us/sample - loss: 0.0936
Epoch 400/500

10/10 [==============================] - 0s 121us/sample - loss: 0.0913
Epoch 401/500

10/10 [==============================] - 0s 100us/sample - loss: 0.0890
Epoch 402/500

10/10 [==============================] - 0s 103us/sample - loss: 0.0867
Epoch 403/500

10/10 [==============================] - 0s 107us/sample - loss: 0.0845
Epoch 404/500

10/10 [==============================] - 0s 110us/sample - loss: 0.0824
Epoch 405/500

10/10 [==============================] - 0s 114us/sample - loss: 0.0803
Epoch 406/500

10/10 [==============================] - 0s 141us/sample - loss: 0.0782
Epoch 407/500

10/10 [==============================] - 0s 129us/sample - loss: 0.0762
Epoch 408/500

10/10 [==============================] - 0s 133us/sample - loss: 0.0743
Epoch 409/500

10/10 [==============================] - 0s 142us/sample - loss: 0.0724
Epoch 410/500

10/10 [==============================] - 0s 107us/sample - loss: 0.0706
Epoch 411/500

10/10 [==============================] - 0s 181us/sample - loss: 0.0688
Epoch 412/500

10/10 [==============================] - 0s 162us/sample - loss: 0.0670
Epoch 413/500

10/10 [==============================] - 0s 102us/sample - loss: 0.0653
Epoch 414/500

10/10 [==============================] - 0s 189us/sample - loss: 0.0637
Epoch 415/500

10/10 [==============================] - 0s 117us/sample - loss: 0.0621
Epoch 416/500

10/10 [==============================] - 0s 109us/sample - loss: 0.0605
Epoch 417/500

10/10 [==============================] - 0s 116us/sample - loss: 0.0590
Epoch 418/500

10/10 [==============================] - 0s 110us/sample - loss: 0.0575
Epoch 419/500

10/10 [==============================] - 0s 104us/sample - loss: 0.0560
Epoch 420/500

10/10 [==============================] - 0s 128us/sample - loss: 0.0546
Epoch 421/500

10/10 [==============================] - 0s 119us/sample - loss: 0.0532
Epoch 422/500

10/10 [==============================] - 0s 114us/sample - loss: 0.0518
Epoch 423/500

10/10 [==============================] - 0s 199us/sample - loss: 0.0505
Epoch 424/500

10/10 [==============================] - 0s 124us/sample - loss: 0.0493
Epoch 425/500

10/10 [==============================] - 0s 200us/sample - loss: 0.0480
Epoch 426/500

10/10 [==============================] - 0s 192us/sample - loss: 0.0468
Epoch 427/500

10/10 [==============================] - 0s 136us/sample - loss: 0.0456
Epoch 428/500

10/10 [==============================] - 0s 134us/sample - loss: 0.0444
Epoch 429/500

10/10 [==============================] - 0s 132us/sample - loss: 0.0433
Epoch 430/500

10/10 [==============================] - 0s 111us/sample - loss: 0.0422
Epoch 431/500

10/10 [==============================] - 0s 119us/sample - loss: 0.0411
Epoch 432/500

10/10 [==============================] - 0s 119us/sample - loss: 0.0401
Epoch 433/500

10/10 [==============================] - 0s 120us/sample - loss: 0.0391
Epoch 434/500

10/10 [==============================] - 0s 112us/sample - loss: 0.0381
Epoch 435/500

10/10 [==============================] - 0s 146us/sample - loss: 0.0371
Epoch 436/500

10/10 [==============================] - 0s 148us/sample - loss: 0.0362
Epoch 437/500

10/10 [==============================] - 0s 145us/sample - loss: 0.0353
Epoch 438/500

10/10 [==============================] - 0s 146us/sample - loss: 0.0344
Epoch 439/500

10/10 [==============================] - 0s 167us/sample - loss: 0.0335
Epoch 440/500

10/10 [==============================] - 0s 138us/sample - loss: 0.0326
Epoch 441/500

10/10 [==============================] - 0s 135us/sample - loss: 0.0318
Epoch 442/500

10/10 [==============================] - 0s 149us/sample - loss: 0.0310
Epoch 443/500

10/10 [==============================] - 0s 135us/sample - loss: 0.0302
Epoch 444/500

10/10 [==============================] - 0s 150us/sample - loss: 0.0295
Epoch 445/500

10/10 [==============================] - 0s 163us/sample - loss: 0.0287
Epoch 446/500

10/10 [==============================] - 0s 135us/sample - loss: 0.0280
Epoch 447/500

10/10 [==============================] - 0s 152us/sample - loss: 0.0273
Epoch 448/500

10/10 [==============================] - 0s 142us/sample - loss: 0.0266
Epoch 449/500

10/10 [==============================] - 0s 158us/sample - loss: 0.0259
Epoch 450/500

10/10 [==============================] - 0s 160us/sample - loss: 0.0252
Epoch 451/500

10/10 [==============================] - 0s 173us/sample - loss: 0.0246
Epoch 452/500

10/10 [==============================] - 0s 161us/sample - loss: 0.0240
Epoch 453/500

10/10 [==============================] - 0s 171us/sample - loss: 0.0234
Epoch 454/500

10/10 [==============================] - 0s 190us/sample - loss: 0.0228
Epoch 455/500

10/10 [==============================] - 0s 192us/sample - loss: 0.0222
Epoch 456/500

10/10 [==============================] - 0s 194us/sample - loss: 0.0216
Epoch 457/500

10/10 [==============================] - 0s 197us/sample - loss: 0.0211
Epoch 458/500

10/10 [==============================] - 0s 181us/sample - loss: 0.0206
Epoch 459/500

10/10 [==============================] - 0s 185us/sample - loss: 0.0200
Epoch 460/500

10/10 [==============================] - 0s 193us/sample - loss: 0.0195
Epoch 461/500

10/10 [==============================] - 0s 209us/sample - loss: 0.0190
Epoch 462/500

10/10 [==============================] - 0s 209us/sample - loss: 0.0185
Epoch 463/500

10/10 [==============================] - 0s 212us/sample - loss: 0.0181
Epoch 464/500

10/10 [==============================] - 0s 201us/sample - loss: 0.0176
Epoch 465/500

10/10 [==============================] - 0s 154us/sample - loss: 0.0172
Epoch 466/500

10/10 [==============================] - 0s 157us/sample - loss: 0.0167
Epoch 467/500

10/10 [==============================] - 0s 153us/sample - loss: 0.0163
Epoch 468/500

10/10 [==============================] - 0s 112us/sample - loss: 0.0159
Epoch 469/500

10/10 [==============================] - 0s 153us/sample - loss: 0.0155
Epoch 470/500

10/10 [==============================] - 0s 156us/sample - loss: 0.0151
Epoch 471/500

10/10 [==============================] - 0s 144us/sample - loss: 0.0147
Epoch 472/500

10/10 [==============================] - 0s 156us/sample - loss: 0.0143
Epoch 473/500

10/10 [==============================] - 0s 142us/sample - loss: 0.0140
Epoch 474/500

10/10 [==============================] - 0s 144us/sample - loss: 0.0136
Epoch 475/500

10/10 [==============================] - 0s 153us/sample - loss: 0.0133
Epoch 476/500

10/10 [==============================] - 0s 145us/sample - loss: 0.0129
Epoch 477/500

10/10 [==============================] - 0s 157us/sample - loss: 0.0126
Epoch 478/500

10/10 [==============================] - 0s 130us/sample - loss: 0.0123
Epoch 479/500

10/10 [==============================] - 0s 111us/sample - loss: 0.0120
Epoch 480/500

10/10 [==============================] - 0s 111us/sample - loss: 0.0117
Epoch 481/500

10/10 [==============================] - 0s 111us/sample - loss: 0.0114
Epoch 482/500

10/10 [==============================] - 0s 121us/sample - loss: 0.0111
Epoch 483/500

10/10 [==============================] - 0s 121us/sample - loss: 0.0108
Epoch 484/500

10/10 [==============================] - 0s 106us/sample - loss: 0.0105
Epoch 485/500

10/10 [==============================] - 0s 106us/sample - loss: 0.0103
Epoch 486/500

10/10 [==============================] - 0s 107us/sample - loss: 0.0100
Epoch 487/500

10/10 [==============================] - 0s 105us/sample - loss: 0.0098
Epoch 488/500

10/10 [==============================] - 0s 107us/sample - loss: 0.0095
Epoch 489/500

10/10 [==============================] - 0s 109us/sample - loss: 0.0093
Epoch 490/500

10/10 [==============================] - 0s 120us/sample - loss: 0.0090
Epoch 491/500

10/10 [==============================] - 0s 113us/sample - loss: 0.0088
Epoch 492/500

10/10 [==============================] - 0s 116us/sample - loss: 0.0086
Epoch 493/500

10/10 [==============================] - 0s 113us/sample - loss: 0.0084
Epoch 494/500

10/10 [==============================] - 0s 146us/sample - loss: 0.0081
Epoch 495/500

10/10 [==============================] - 0s 110us/sample - loss: 0.0079
Epoch 496/500

10/10 [==============================] - 0s 125us/sample - loss: 0.0077
Epoch 497/500

10/10 [==============================] - 0s 110us/sample - loss: 0.0075
Epoch 498/500

10/10 [==============================] - 0s 116us/sample - loss: 0.0074
Epoch 499/500

10/10 [==============================] - 0s 122us/sample - loss: 0.0072
Epoch 500/500

10/10 [==============================] - 0s 108us/sample - loss: 0.0070
</pre></div>
</div>
<div class="outline-3" id="outline-container-org314e99a">
<h3 id="org314e99a">Make a Prediction</h3>
<div class="outline-text-3" id="text-org314e99a">
<p>What would <i>y</i> be if <i>x=100</i>?</p>
<div class="highlight">
<pre><span></span><span class="n">input_value</span> <span class="o">=</span> <span class="p">[</span><span class="mf">100.0</span><span class="p">]</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
</pre></div>
<pre class="example">
[[766.0348]]

</pre>
<p>The actual value is</p>
<div class="highlight">
<pre><span></span><span class="n">actual</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">slope</span><span class="p">)</span> <span class="o">+</span> <span class="n">intercept</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"y = {actual}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"difference = {actual - predicted[0][0]}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
y = 765
difference = -1.0347900390625

</pre>
<p>So it was pretty close, but not exact.</p>
</div>
<div class="outline-4" id="outline-container-orgec86474">
<h4 id="orgec86474">Comparing to a Linear Regression Model</h4>
<div class="outline-text-4" id="text-orgec86474">
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">input_value</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
<pre class="example">
[765.]

</pre>
<p>The linear model got it exactly right, as you might expect, but this isn't really a problem that exploits the positive features of machine learning.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org4e50596">
<h2 id="org4e50596">End</h2>
<div class="outline-text-2" id="text-org4e50596">
<ul class="org-ul">
<li>Taken from <a href="https://github.com/lmoroney/dlaicourse/blob/master/Course%201%20-%20Part%202%20-%20Lesson%202%20-%20Notebook.ipynb">"The Hello World of Deep Learning With Neural Networks" notebook on github</a></li>
</ul>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/fastai/building-an-image-dataset/">Building an image dataset</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/fastai/building-an-image-dataset/" rel="bookmark"><time class="published dt-published" datetime="2019-06-23T10:27:16-07:00" itemprop="datePublished" title="2019-06-23 10:27">2019-06-23 10:27</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/fastai/building-an-image-dataset/#org9fc466a">Beginning</a>
<ul>
<li><a href="/posts/fastai/building-an-image-dataset/#org18dff16">Imports</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#orga1e4c5a">Set Up</a></li>
</ul>
</li>
<li><a href="/posts/fastai/building-an-image-dataset/#orgf06c695">Middle</a>
<ul>
<li><a href="/posts/fastai/building-an-image-dataset/#org4c16c33">Downloading</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#orgc05495e">Checking the Images</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#org8d13767">View the Data</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#orgad583a0">The Resnet 34 Model</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#orgebd738f">Interpretation</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#org3f6c534">Looking at the mistakes</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#org3c1821a">Take Two</a></li>
<li><a href="/posts/fastai/building-an-image-dataset/#orgae10795">Interpretation</a></li>
</ul>
</li>
<li><a href="/posts/fastai/building-an-image-dataset/#orgbd093ef">End</a>
<ul>
<li><a href="/posts/fastai/building-an-image-dataset/#org6ab2e05">Source</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org9fc466a">
<h2 id="org9fc466a">Beginning</h2>
<div class="outline-text-2" id="text-org9fc466a"></div>
<div class="outline-3" id="outline-container-org18dff16">
<h3 id="org18dff16">Imports</h3>
<div class="outline-text-3" id="text-org18dff16"></div>
<div class="outline-4" id="outline-container-orgc4c32a9">
<h4 id="orgc4c32a9">Python</h4>
<div class="outline-text-4" id="text-orgc4c32a9">
<div class="highlight">
<pre><span></span>from pathlib import Path
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd66473f">
<h4 id="orgd66473f">PyPi</h4>
<div class="outline-text-4" id="text-orgd66473f">
<p>The lecture uses javascript pasted into the browser to download images but I'm going to try a python library built to download images - <a href="https://google-images-download.readthedocs.io/en/latest/index.html">Google Imaged Download</a>. The documentation mentions that it uses <a href="https://www.seleniumhq.org/">Selenium</a> but it doesn't explicitly state (or at least not that I could see) that it requires you to install <a href="http://chromedriver.chromium.org/downloads">Chrome Driver</a> (not Gecko Driver like I originally did), and therefore you need a Chromium-based browser as well.</p>
<div class="highlight">
<pre><span></span>from google_images_download.google_images_download import googleimagesdownload as GoogleImages
from fastai.metrics import error_rate
from fastai.vision.data import (imagenet_stats, ImageDataBunch, verify_images)
from fastai.vision.learner import cnn_learner, ClassificationInterpretation
from fastai.vision import models
from fastai.vision.transform import get_transforms

import numpy
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd82ca67">
<h4 id="orgd82ca67">My Stuff</h4>
<div class="outline-text-4" id="text-orgd82ca67">
<div class="highlight">
<pre><span></span>from graeae import EnvironmentLoader
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orga1e4c5a">
<h3 id="orga1e4c5a">Set Up</h3>
<div class="outline-text-3" id="text-orga1e4c5a"></div>
<div class="outline-4" id="outline-container-org871bfc0">
<h4 id="org871bfc0">The Environment</h4>
<div class="outline-text-4" id="text-org871bfc0">
<div class="highlight">
<pre><span></span>environment = EnvironmentLoader()
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd421a18">
<h4 id="orgd421a18">The Download</h4>
<div class="outline-text-4" id="text-orgd421a18">
<div class="highlight">
<pre><span></span>google_images = GoogleImages()
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgda852ed">
<h4 id="orgda852ed">The Output Path</h4>
<div class="outline-text-4" id="text-orgda852ed">
<div class="highlight">
<pre><span></span>weed_path = Path(environment["WEEDS"]).expanduser()
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf06c695">
<h2 id="orgf06c695">Middle</h2>
<div class="outline-text-2" id="text-orgf06c695"></div>
<div class="outline-3" id="outline-container-org4c16c33">
<h3 id="org4c16c33">Downloading</h3>
<div class="outline-text-3" id="text-org4c16c33"></div>
<div class="outline-4" id="outline-container-org0f8decd">
<h4 id="org0f8decd">Dandelions</h4>
<div class="outline-text-4" id="text-org0f8decd">
<div class="highlight">
<pre><span></span>keywords = dict(
    keywords="dandelion",
    limit=1000,
    type="photo",
    output_directory=str(weed_path),
    chromedriver="/usr/local/bin/chromedriver",
)
</pre></div>
<p>The library can't find the chromedriver for some reason, even though it's on the path. Also, in creating the output folder it appears to expect that the output directory is a string so you have to convert the path.</p>
<div class="highlight">
<pre><span></span>paths = google_images.download(keywords)
</pre></div>
<pre class="example">

Item no.: 1 --&gt; Item name = dandelion
Evaluating...
Getting you a lot of images. This may take a few moments...
Reached end of Page.
Starting Download...
Completed Image ====&gt; 1.dandelion-benefits-1296x728-feature.jpg
Completed Image ====&gt; 2.324083_1100.jpg
Completed Image ====&gt; 3.DandelionFlower.jpg
Completed Image ====&gt; 4.Dandelion-in-Spring.jpg
Completed Image ====&gt; 5.220px-TaraxacumOfficinaleSeed.JPG
Completed Image ====&gt; 6.dandelions-in-a-field.jpg
Completed Image ====&gt; 7.dandelionleaves2.jpg
Completed Image ====&gt; 8.81MteT13V7L._SX425_.jpg
Completed Image ====&gt; 9._103888633_hi016427699.jpg
Completed Image ====&gt; 10.21711_dandelion1.rev.1401296268.jpg
Completed Image ====&gt; 11.dandelions-1030x687.jpg
Completed Image ====&gt; 12.dandelions.jpg
Completed Image ====&gt; 13.6caf5b570c7c435ea2f0258b2337b964.jpg
Completed Image ====&gt; 14.dandelion-2065913_1920.jpg
Completed Image ====&gt; 15.urban-foraging.png
Completed Image ====&gt; 16.Newly-discovered-form-of-natural-flight-found-in-dandelion-seeds-730x410.jpg
Completed Image ====&gt; 17.dandelion-uses.jpg
Completed Image ====&gt; 18.Dandelion-GettyImages-135558263-588f7eb73df78caebc084c58.jpg
Completed Image ====&gt; 19.Yellow-and-fluffy-white-dandelions.jpg
Completed Image ====&gt; 20.howdandelion.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 21.Use-dandelions-for-food-and-medicine.jpg
Completed Image ====&gt; 22.1400945145878.jpeg
Completed Image ====&gt; 23.00951_01_dandelion.jpg
Completed Image ====&gt; 24.Dan_1024x1024.jpg
Completed Image ====&gt; 25.dandel08-l.jpg
Completed Image ====&gt; 26.Dandelion-Meaning.jpg
Completed Image ====&gt; 27.shutterstock_529155295-860x430.jpg
Completed Image ====&gt; 28.hotw-dandelion1-e1533580213163-300x300.jpg
Completed Image ====&gt; 29.TM_Header_Dandelion101_02.jpg
Completed Image ====&gt; 30.2017-04-05-01.jpg
Completed Image ====&gt; 31.dandelion-taraxacum-officinale-primary_400a4ee2-b6fd-4307-b372-d2b529c0e4dc_300x.jpg
Completed Image ====&gt; 32.overhead.jpg
Completed Image ====&gt; 33.dandelions_1.jpg
Completed Image ====&gt; 34.dandelion.jpg
Completed Image ====&gt; 35.Dandelion-seeds.jpg
Completed Image ====&gt; 36.Dandelion-Salad-with-Warm-Pecan-Vinaigrette-500x500.jpg
Completed Image ====&gt; 37.tankist276_shutterstock_31471963.jpg
Completed Image ====&gt; 38.dandelion.jpg
Completed Image ====&gt; 39.Screen_Shot_2016-01-17_at_5.52.50_PM_1024x1024.png
Completed Image ====&gt; 40.bullseye-dandelion-blossom.jpg
Completed Image ====&gt; 41.719fF478nPL._SL1323_.jpg
Completed Image ====&gt; 42.Dandelion_Bloom.jpg
Completed Image ====&gt; 43.dandelion-wine-tall18.jpg
Completed Image ====&gt; 44.220px-Dandelion_seedhead_with_only_a_single_seed_still_attached.jpg
Completed Image ====&gt; 45.dandelion-meadow-full_0.jpg
Completed Image ====&gt; 46.dandelion-gummy-bears-11.jpg
Completed Image ====&gt; 47.dan-860x430.jpg
Completed Image ====&gt; 48.stock-photo-dandelions-130064053_master.jpg
Completed Image ====&gt; 49.dandelion-1306911_1920.jpg
Completed Image ====&gt; 50.image_6521e-Dandelion.jpg
Completed Image ====&gt; 51.Dandelion-in-Australia.jpg
Completed Image ====&gt; 52.DandelionMeanings3.jpg
Completed Image ====&gt; 53.220px-Kantoutanpopo.jpg
Completed Image ====&gt; 54.101618_HT_dandelion_feat.jpg
Completed Image ====&gt; 55.Dandelion-group.JPG
Completed Image ====&gt; 56.shutterstock_274297355-800x450.jpg
Completed Image ====&gt; 57.dandelion-810x378.jpg
Completed Image ====&gt; 58.dandelions-on-a-chopping-board.jpg
Completed Image ====&gt; 59.81575be68362cb4059be6363a2aed906_grande.png
Completed Image ====&gt; 60.16893922_web1_190519-pdn-andrew-may1-web.jpg
Completed Image ====&gt; 61.Dandelion-in-a-gout-diet-500x300.jpg
Completed Image ====&gt; 62.dandelion-flowers-field_0.jpg
Completed Image ====&gt; 63.181022-dandelion-full.gif
Completed Image ====&gt; 64.dandelion-flowers.jpg
Completed Image ====&gt; 65.dandelion-shortbread-7.jpg
Completed Image ====&gt; 66.1484330534065.jpg
Completed Image ====&gt; 67.dandelion_1600.jpg
Completed Image ====&gt; 68.vegetable-organic-dandelion-greens-1_1024x1024.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 69.IMG_0813-1024x1024.jpg
Completed Image ====&gt; 70.f_12.jpg
Completed Image ====&gt; 71.642x361_7_Ways_Dandelion_Tea_Could_Be_Good_for_You.jpg
Completed Image ====&gt; 72.1525109821_5ae7543d0dc81.JPG
Completed Image ====&gt; 73.dandelion-seed-head-400x300.jpg
Completed Image ====&gt; 74.2017-04-05-06.jpg
Completed Image ====&gt; 75.dandelion-1024x769.jpg
Completed Image ====&gt; 76.1678-28-Amazing-Benefits-Of-Dandelion-Dudal-For-Skin-Hair-And-Health-ss.jpg
Completed Image ====&gt; 77.Dandelion.width-800.jpg
Completed Image ====&gt; 78.Basket-of-Dandelions.jpg
Completed Image ====&gt; 79.maxresdefault.jpg
Completed Image ====&gt; 80.dandelion-field-maigi.jpg
Completed Image ====&gt; 81.5aec5ff6cb772.image.jpg
Completed Image ====&gt; 82.gettyimages-157508237-1555967430.jpg
Completed Image ====&gt; 83.dandelion-field-flora-159081.jpg
Completed Image ====&gt; 84.dandelion-seeds.jpg
Completed Image ====&gt; 85.7181016_xl-1050x519.png
Invalid or missing image format. Skipping...
Completed Image ====&gt; 86.Dandelion_and_bee_350.jpg
Completed Image ====&gt; 87.dandelion-1.jpg
Completed Image ====&gt; 88.Dandelion-5.jpeg
Completed Image ====&gt; 89.Benefits-Of-Dandelion.jpg
Completed Image ====&gt; 90.Dandelion.jpg
Completed Image ====&gt; 91.dandelions.jpg
Completed Image ====&gt; 92.diy-dandelion-playdough-recipe.jpg
Completed Image ====&gt; 93.47000037%402x.jpg
Completed Image ====&gt; 94.2-dandelion-blowing-bess-hamiti.jpg
Completed Image ====&gt; 95.dandy.jpg
Completed Image ====&gt; 96.Dandelion-5.jpg
Completed Image ====&gt; 97.101456886_feature.png
Completed Image ====&gt; 98.ingredient-IQ-dandelions-1142x474-c.jpg
Completed Image ====&gt; 99.Dandelion-5.jpg
Completed Image ====&gt; 100.dandelion-2260690_960_720.jpg
Completed Image ====&gt; 101.d41586-018-07032-6_16203056.jpg
Completed Image ====&gt; 102.DandelionBG.jpg
Completed Image ====&gt; 103.h-yellow-dandelion-flower.jpg
Completed Image ====&gt; 104.GettyImages-145629450-581829635f9b581c0b104942.jpg
Completed Image ====&gt; 105.115738809%282%29.jpg
Completed Image ====&gt; 106.dandelion_smart-fix.jpg
Completed Image ====&gt; 107.dandelion-tea-620_620x350_71484652381.jpg
Completed Image ====&gt; 108.dandelion-1-ADJUSTED-248x300.jpg
Completed Image ====&gt; 109.dandelion-pesto-1-1030x687.jpg
Completed Image ====&gt; 110.Grandmas-Dandelion-Soup-overheadW-700x542.jpg
Completed Image ====&gt; 111.Health-benefits-of-Dandelion-2.jpg
Completed Image ====&gt; 112.814v-YsM2dL._SL1201_.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 113.making-dandelion-vinegar-500x375.jpg
Completed Image ====&gt; 114.dandelions.jpg
Completed Image ====&gt; 115.sow-thistle-vs-dandelion.jpg
Completed Image ====&gt; 116.dandelions_article.jpg
Completed Image ====&gt; 117.Dandelion_Feature_xl_10556655_(Custom).jpg
Completed Image ====&gt; 118.Dandelion_1-2000x1180.jpg
Completed Image ====&gt; 119.1-dandelion-seeds-bess-hamiti.jpg
Completed Image ====&gt; 120.DandelionTincture.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 121.dandelion-leaves-500x500.png
Completed Image ====&gt; 122.Dandelion_tires_technology_Continental.jpg
Completed Image ====&gt; 123.violet-in-dandelions.jpg
Completed Image ====&gt; 124.yellow-dandelions-bright-flowers-on-260nw-598445252.jpg
Completed Image ====&gt; 125.Dandelion-300x225.jpg
Completed Image ====&gt; 126.dandelion.jpg
Completed Image ====&gt; 127.Dandelion%20Festival%20Webpage%20Image.jpg
Completed Image ====&gt; 128.dandelion-3.jpg
Completed Image ====&gt; 129.DandelionHoney-5a840cb33128340037a09e0e.jpg
Completed Image ====&gt; 130.AN150-Dandelion-Greens-732x549-thumb.jpg
Completed Image ====&gt; 131.Dandelion_400x400.jpg
Completed Image ====&gt; 132.dandelion.JPG
Completed Image ====&gt; 133.5ac3a71a821e5.image.jpg
Completed Image ====&gt; 134.BENS_DANDELION.jpg
Completed Image ====&gt; 135.dandelion-flowers-big.jpg
Completed Image ====&gt; 136.sauteed-dandelions-with-eggs-leeks-and-feta-1-9-600x900.jpg
Completed Image ====&gt; 137.13979689_f1024.jpg
Completed Image ====&gt; 138.177102678.jpg
Completed Image ====&gt; 139.dandelion-wine-recipe-1.jpg
Completed Image ====&gt; 140.10881341-large.jpg
Completed Image ====&gt; 141.DandelionTeaUpdate_Header.jpg
Completed Image ====&gt; 142.dandelion-wild-taraxacum-officinale-seeds-amkha-seed_716.jpg
Completed Image ====&gt; 143.dandelionbeer-banner-panorama.jpg
Completed Image ====&gt; 144.maxresdefault.jpg
Completed Image ====&gt; 145.east-coast-dandelion.jpg
Completed Image ====&gt; 146.dandelion-seeds-in-the-sunlight-vector-20571994.jpg
Completed Image ====&gt; 147.dandelions.jpg
Completed Image ====&gt; 148.TM_Embed_Dandelion101_SS.jpg
Completed Image ====&gt; 149.Dandelion1.jpg
Completed Image ====&gt; 150.Washing-Dandelions.jpg
Completed Image ====&gt; 151.best+way+to+get+rid+of+dandelions+permanently.jpeg
Completed Image ====&gt; 152.14239953175_96bc487474_b.jpg
Completed Image ====&gt; 153.pink_dandelion_-_3.jpg
Completed Image ====&gt; 154.dandelion-plants.jpg
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)&gt;
Completed Image ====&gt; 155.dandelion_flower_full.jpg
Completed Image ====&gt; 156.Common_Dandelion.jpg
Completed Image ====&gt; 157.480453655_0.jpg
Completed Image ====&gt; 158.dandelion-vinegar-FB.jpg
Completed Image ====&gt; 159.medicinal-mixology-dandelion.jpg
Completed Image ====&gt; 160.93298382-blue-abstract-dandelion-flower-texture-background-sunrise-extreme-macro-soft-focus-.jpg
Completed Image ====&gt; 161.5b60acbc92c3f9c95ecadc52_dandelion-health-salad-flowers-161568.jpg
Completed Image ====&gt; 162.170px-Seed_head_dandelion.jpg
Completed Image ====&gt; 163.dandelion.jpg
Completed Image ====&gt; 164.pexels-photo-1099105.jpeg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 165.fieldofDandelions.jpg
Completed Image ====&gt; 166.dandelion-leaves1-400x300.jpg
Completed Image ====&gt; 167.30f917292dac4b478a665f319c982f69.jpg
Completed Image ====&gt; 168.dandelion-root-tea-health-benefits-bright.jpg
Completed Image ====&gt; 169.2016-10-18-dandelion.jpg
Completed Image ====&gt; 170.Dandelion-seeds20150806-30610-1836jds.jpg
Completed Image ====&gt; 171.220px-A_dandelion.jpg
Completed Image ====&gt; 172.5644-004-BBAB2EF4.jpg
Completed Image ====&gt; 173.858X1920_2a3d0912ec2465521b06b14633c8cfac.png
Completed Image ====&gt; 174.dandelion-flower-300x225.jpg
Completed Image ====&gt; 175.dandelion-recipes-1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 176.5c13ef0e9848de205dc3a28d_g94Z7beTiBSs4qZSinKk9w13jAr2BFLyiT7BBYNHDZcw-v5pf_AAjSvgmYxqawn3EA45mtke5B79v6ay5rhjYrD4um0_4Ib42i9EJV7CrsuixS0tWzQfi5m55t5CX2S3Y7rBmjw7.jpeg
Completed Image ====&gt; 177.dandelion-flower-02.jpg
Completed Image ====&gt; 178.dan3.gif
Completed Image ====&gt; 179.boiled-dandelion-greens-810x455.jpg
Completed Image ====&gt; 180.dandylion_0.jpg
Completed Image ====&gt; 181.issue43_main.jpg
Completed Image ====&gt; 182.D5a6ytyX4AAQXsL.jpg
Completed Image ====&gt; 183.IMG_1291-1024x1024.jpg
Completed Image ====&gt; 184.Dandelion-Oil-Pin-2.jpg
Completed Image ====&gt; 185.Small-Dandelion-Flower-Temporary-Tattoo-Design-Idea-Shoulder.jpg
Completed Image ====&gt; 186.Taraxacum_officinale_02_Fr_web_2015_fullsize.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 187.wild-dandelion-recipes-jpg.jpg
Completed Image ====&gt; 188.Pic+Dandelion+Leaf.jpg
Completed Image ====&gt; 189.Dandelions-Harvesting-Health-Benefits-Recipes-683x1024.jpg
Completed Image ====&gt; 190.dandy-31a.jpg
Completed Image ====&gt; 191.08recipehealth_600-articleLarge.jpg
Completed Image ====&gt; 192.Thumb_01.jpg
Completed Image ====&gt; 193.dandelion-timelapse_1024.gif
Completed Image ====&gt; 194.dandelion-1557110__340.jpg
Completed Image ====&gt; 195.Holistic_Dadelion_3840x2160.jpg
Completed Image ====&gt; 196.Dandelions.jpg
Completed Image ====&gt; 197.glass-of-dandelion-mead.jpg
Completed Image ====&gt; 198.1469054896651.jpg
Completed Image ====&gt; 199.dandelion1.jpg
Completed Image ====&gt; 200.970c5432eea14b5988b0c9c3d94e4656.jpg
Completed Image ====&gt; 201.WP_20130506_004-300x225.jpg
Completed Image ====&gt; 202.Fun-with-Dandelions-FB.jpg
Completed Image ====&gt; 203.35405.jpg
Completed Image ====&gt; 204.dandelion1205.jpg
Completed Image ====&gt; 205.CarolinaFalseDandelion_DSC_2728.jpg
Completed Image ====&gt; 206.dandelion_root_leaf_prod.jpeg
Completed Image ====&gt; 207.maxresdefault.jpg
Completed Image ====&gt; 208.dandelion1.jpg
Completed Image ====&gt; 209.dandelion-salad-recipe-taraxacum-officinalis-750x420.png
Completed Image ====&gt; 210.FOR-WEB_Dandelions.jpg
Completed Image ====&gt; 211.abstract-black-dandelion-flying-seeds-260nw-1220847928.jpg
Completed Image ====&gt; 212.how-control-dandelions-1.jpg
Completed Image ====&gt; 213.DandelionFlowersForPost.jpg
Completed Image ====&gt; 214.dandelion-leaves.jpg
Completed Image ====&gt; 215.solitarybeeondandelion.jpg
Completed Image ====&gt; 216.dandelion-taraxacum-officinale-4250938.jpg.webp
Completed Image ====&gt; 217.single-stem-dandelion-artificial-flowers.jpg
Completed Image ====&gt; 218.dandelions-682x1024.png
Completed Image ====&gt; 219.IMG_1712-768x268.jpg
Completed Image ====&gt; 220.Dandelion-1024x768.jpg
Completed Image ====&gt; 221.image_16.jpg
Completed Image ====&gt; 222.hotw-notadandelion3-wild-lettuce-Lactuca-serriola-e1533581057911-300x300.jpg
Completed Image ====&gt; 223.russian_dandelion_rubber_root-01.jpg
Completed Image ====&gt; 224.dandelion_seeds_full.jpg
Completed Image ====&gt; 225.244875.jpg
Completed Image ====&gt; 226.D3916383-6EF5-4803-8B6A-608064271CBA_w250_r0_s.jpg
Completed Image ====&gt; 227.Manuel_Findeis_shutterstock_638530378.jpg
Completed Image ====&gt; 228.dsc_0027.jpg
Completed Image ====&gt; 229.dandelion-yard-harvest-2018-750x563.jpg
Completed Image ====&gt; 230.D7l6ZWLWsAUpcKg.jpg
Completed Image ====&gt; 231.Dandelion-Plant.jpg
Completed Image ====&gt; 232.how-to-get-rid-of-dandelions-1-920x425.jpg
Completed Image ====&gt; 233.ela-henry-dandelion2.jpg
Completed Image ====&gt; 234.157482566-56a47d4e3df78cf77282b010.jpg
Completed Image ====&gt; 235.Dandelion-DNM.jpg
Completed Image ====&gt; 236.DANDELIONS_848x480_1241231939639.jpg
Completed Image ====&gt; 237.dandelion-tea-new-wide.jpeg
Completed Image ====&gt; 238.sow-thistle.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 239.dandelion-flower.jpg
Completed Image ====&gt; 240.taraxacum-officinale-004.jpg
Completed Image ====&gt; 241.dandelion-greens-recipes-salad-1068x713.jpg
Completed Image ====&gt; 242.dandelion-tea-benefits.jpg
Completed Image ====&gt; 243.Greens1_grande.jpg
Completed Image ====&gt; 244.78425884_XS.jpg
Completed Image ====&gt; 245.tenor.gif
Completed Image ====&gt; 246.51hy7xMx0HL._SL500_AC_SS350_.jpg
Completed Image ====&gt; 247.common-dandelion-300px.jpg
Completed Image ====&gt; 248.dandy-21a.jpg
Completed Image ====&gt; 249.dandelion-feature.jpg
Completed Image ====&gt; 250.GettyImages-575385175-dd039eb.jpg
Completed Image ====&gt; 251.Dandelion.jpg
Completed Image ====&gt; 252.dandelion-greens-weeds-950x535.png
Completed Image ====&gt; 253.GettyImages-535804358-5acd2fa6c5542e003619cd9d.jpg
Completed Image ====&gt; 254.20130124-222423.jpg
Completed Image ====&gt; 255.dandelion-puntarelle-salad-header.jpg
Completed Image ====&gt; 256.FEATURED-Best-Dandelion-Killer.jpg
Completed Image ====&gt; 257.20554032-flower-dandelion-white-on-black-background-vector-illustration.jpg
Completed Image ====&gt; 258.lessons-learned-from-the-dandelion-facebook-post.jpg
Completed Image ====&gt; 259.dandelions.jpg
Completed Image ====&gt; 260.95794138-2b59-4778-bac5-04361b868857.jpg
Completed Image ====&gt; 261.dandelion-seeds.jpg
Completed Image ====&gt; 262.dandelion_benefits_article.jpg
Completed Image ====&gt; 263.false-dandelion-poisoning.jpg
Completed Image ====&gt; 264.dandelion-tea-2.jpg
Completed Image ====&gt; 265.dandelion.jpg
Completed Image ====&gt; 266.image.jpg
Completed Image ====&gt; 267.flower_2_750.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 268.33984953915_d19a51a3c0.jpg
Completed Image ====&gt; 269.dandelion-rubber-taraxagum-lab-anklam-764x375.jpg
Completed Image ====&gt; 270.20160507-dandelion.png
Completed Image ====&gt; 271.Dandelion-Greens-Benefits-Nutrition-and-Recipes.jpg
Completed Image ====&gt; 272.Dandelion-Doodle-7.jpg
Completed Image ====&gt; 273.Dandelion-Flower-in-Bloom-700x543.jpg
Completed Image ====&gt; 274.creamy-dandelion-soup-ck-x.jpg
Completed Image ====&gt; 275.bf064e25455239bdfff071b426af008c.jpg
Completed Image ====&gt; 276.dandelion-magnesium-lotion-update-FB-800x419.jpg
Completed Image ====&gt; 277.yellow-dandelion.jpg
Completed Image ====&gt; 278.How-to-Get-Rid-of-Dandelions.jpg
Completed Image ====&gt; 279.dandelion-in-seed.jpg
Completed Image ====&gt; 280.2261.png
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
Completed Image ====&gt; 281.blog-featured-dandelion-20171221-1300.jpg
Completed Image ====&gt; 282.dandelion_trueandfalse3.jpg
Completed Image ====&gt; 283.dandelion_pic-200x300_large.jpg
Completed Image ====&gt; 284.Maelkebotte05.jpg
Completed Image ====&gt; 285.Dandelion.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 286.01_dandelion_things-doctors-wish-you-knew-about-using-dandelion-root-for-detox_483980608-eskymaks-760x506.jpg
Completed Image ====&gt; 287.dandelion-vector-background.jpg
Completed Image ====&gt; 288.Dandelion_Summer_2011-II_harvest.jpg
Completed Image ====&gt; 289.521962154-577d12ea5f9b585875b16536.jpg
Completed Image ====&gt; 290.1.jpg
Completed Image ====&gt; 291.78fb14fd-2df1-4d71-a558-7c933957afb5.png
Completed Image ====&gt; 292.Dandelions-health-benefits-Naturimedica.jpg
Completed Image ====&gt; 293.dandelion-seed-Jev7rl3-600.jpg
Completed Image ====&gt; 294.Dandy-beer-sm-765x1024.jpg
Completed Image ====&gt; 295.Dandelions-at-Cottage-Creek.jpg
Completed Image ====&gt; 296.mid_1476817137_dandelion.jpg
Completed Image ====&gt; 297.DandelionTincture.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 298.dandelion-soap-short-pin.jpg
Completed Image ====&gt; 299.mountain_dandelion_lg.jpg
Completed Image ====&gt; 300.36b47bc13eb896724cc1793ab283b26f.jpg
Completed Image ====&gt; 301.Dandelion-jelly-pin2.png
Completed Image ====&gt; 302.Garden-Thugs-and-Bedwetters-How-to-Eat-More-Dandelion.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 303.dandelion_true.jpg
Completed Image ====&gt; 304.dandelion-4228400__340.jpg
Completed Image ====&gt; 305.burkmarr_dandelion_120404_2.JPG
Completed Image ====&gt; 306.Harvesting-Dandelion-Root-Tea-from-Your-Garden.jpg
Completed Image ====&gt; 307.dandelion-recipes.jpg
Completed Image ====&gt; 308.dandelion-greens.jpg
Completed Image ====&gt; 309.Fun-with-Dandelions-Cover.jpg
Completed Image ====&gt; 310.dandelions.jpg
Completed Image ====&gt; 311.dandelion-1311709_1920-678x381.jpg
Completed Image ====&gt; 312.dandelion-jelly-815x1024.jpg
Completed Image ====&gt; 313.flowers_Hawkweed_wiki.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 314.health-benefits-dandelions.png
Completed Image ====&gt; 315.dandelion-680x248.jpg
Completed Image ====&gt; 316.48337e5f4230737fdb3467f22a9d9a6c.jpg
Completed Image ====&gt; 317.dandelion-wall-decal.jpg
Completed Image ====&gt; 318.dandelion.jpg
Completed Image ====&gt; 319.Chicory-Dandelion-Italiko-Rosso-RC106C-LSS-000_5320.jpg
Completed Image ====&gt; 320.header-dandelion.jpg
Completed Image ====&gt; 321.dandelion.jpg
Completed Image ====&gt; 322.8c160acd-1672-4011-a892-1baa844cbe29-2060x1236.jpeg
Completed Image ====&gt; 323.erock3d_dandelions_promo_830_large-900x0.jpg
Completed Image ====&gt; 324.dandelionbasket-300x225.jpg
Completed Image ====&gt; 325.dandelion-seeds-nature-spring-101538.jpeg
Completed Image ====&gt; 326.Pic+Dandelions+on+Table.jpg
Completed Image ====&gt; 327.carolina-false-dandelion-11511-carolinafalsedandelion-dsc-2746.jpg
Completed Image ====&gt; 328.Bircham-dense-dandelions-640.jpg
Completed Image ====&gt; 329.How-To-Harvest-Dandelion-Roots-7-Ways-To-Use-It.jpg
Completed Image ====&gt; 330.dandelion-tea.jpg
Completed Image ====&gt; 331.87685360_XS.jpg
Completed Image ====&gt; 332.1280-687839744-yellow-white-dandelion-macro.jpg
Completed Image ====&gt; 333.5-Weeds-FeaturedImage.png
Completed Image ====&gt; 334.Dandelion-structure-251x300.jpg
Completed Image ====&gt; 335.image_06.jpg
Completed Image ====&gt; 336.taraxacum-officinale-005.jpg
Completed Image ====&gt; 337.6151_IMG02499.JPG
Completed Image ====&gt; 338.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-6.jpg
Completed Image ====&gt; 339.D59VaEvWkAA21CS.jpg
Completed Image ====&gt; 340.dandelion-wine-stefan-steinbauer-107535-unsplash-600x400.jpg
Completed Image ====&gt; 341.kill-dandelion4-e1522653020254.png
Completed Image ====&gt; 342.The-Natural-Health-Benefits-of-Dandelions744.jpg
Completed Image ====&gt; 343.Dandelion-6.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 344.3508699639_7f84f1e059.jpg
Completed Image ====&gt; 345.511353956_1280x720.jpg
Completed Image ====&gt; 346.Dandelion-seed-head.JPG
Completed Image ====&gt; 347.1469056164106.jpg
Completed Image ====&gt; 348.Honey-bee-on-Dandelion.jpg
Completed Image ====&gt; 349.dandelion_full_width.jpg
Completed Image ====&gt; 350.IMG_0366-1.jpg
Completed Image ====&gt; 351.maxresdefault.jpg
Completed Image ====&gt; 352.Using-Dandelions-for-Gift-Giving-for-Image-Hort.jpg
Completed Image ====&gt; 353.487456455.0.jpg
Completed Image ====&gt; 354.DandelionsWeedsx450.jpg
Completed Image ====&gt; 355.dandelion-seeds-close-blowing-blue-260nw-614668772.jpg
Completed Image ====&gt; 356.Dandelion-roots-leaves-and-flowers-are-powerful-superfoods.jpg
Completed Image ====&gt; 357.white-dandelion-closeup-natural-spring-background_78450-189.jpg
Completed Image ====&gt; 358.dandelion-greens-harvest-2018-1-750x478.jpg
Completed Image ====&gt; 359.Dandelion-Infused-Carrier-Oil.jpg
Completed Image ====&gt; 360.common-dandelion-taraxacum-officinale-agg-asteraceae-XD18NA.jpg
Completed Image ====&gt; 361.aid2229943-v4-1200px-Get-Rid-of-Dandelions-in-a-Lawn-Step-12.jpg
Completed Image ====&gt; 362.Radicchio-Italiko-Rossa-dandelion-RC106-LSS-000_6639.jpg
Completed Image ====&gt; 363.seedneeds-dandelion.jpeg
Completed Image ====&gt; 364.Dandelion7-1024x768.jpg
Completed Image ====&gt; 365.dandelions-rev.jpg
Completed Image ====&gt; 366.photo_for_Grandms_Says_large.jpg
Completed Image ====&gt; 367.04_Dandelion_Things-Doctors-Wish-You-Knew-About-Using-Dandelion-Root-for-Detox_617857592-Creative-Family-760x506.jpg
Completed Image ====&gt; 368.1280-687213634-few-yellow-dandelions-flowers-green-leaves.jpg
Completed Image ====&gt; 369.mid_1473552572_dandelion-health-benefits.png
Completed Image ====&gt; 370.how-to-get-rid-of-dandelions.jpg
Completed Image ====&gt; 371.dandelion-4.jpeg
Completed Image ====&gt; 372.Dandelion_Cover_S1illustration-1.jpg
Completed Image ====&gt; 373.dandelions.jpg
Completed Image ====&gt; 374.Dandelion-Mead-2238.jpg
Completed Image ====&gt; 375.5454.jpg
Completed Image ====&gt; 376.d41586-018-07084-8_16206024.jpg
Completed Image ====&gt; 377.Dandelion-fritters.jpg
Completed Image ====&gt; 378.Dandelion.jpg
Completed Image ====&gt; 379.Dandelion-Buds-for-Capers-1.jpg
Completed Image ====&gt; 380.2017-04-05-07.jpg
Completed Image ====&gt; 381.hotw-notadandelion4-lesser-celandine-Ficaria-verna-300x300.jpg
Completed Image ====&gt; 382.Dandelion.png
Completed Image ====&gt; 383.Dandelion_155.jpg
Completed Image ====&gt; 384.dandelion%20seeds%20resize.jpg
Completed Image ====&gt; 385.how-control-dandelions-2.jpg
Completed Image ====&gt; 386.1.-Dandelion-Taraoffi-open-flower.jpg
Completed Image ====&gt; 387.IMG_5207-e1496971515552-1024x1365.jpg
Completed Image ====&gt; 388.Dandelions.jpg
Completed Image ====&gt; 389.4608685970.jpg
Completed Image ====&gt; 390.dandelion-2817950_960_720.jpg
Completed Image ====&gt; 391.dandelion-2.jpg
Completed Image ====&gt; 392.9770-featured_image-dandelion-root-can-help-cancer-patients.jpg
Completed Image ====&gt; 393.Dandelion_[fasciated]_2015_05_02_Adlington_Rivington_Drinking_001p3.jpg
Completed Image ====&gt; 394.dandelion_falseclose.jpg
Completed Image ====&gt; 395.DandelionMeanings5.jpg
Completed Image ====&gt; 396.dandelion-salve-600.jpg
Completed Image ====&gt; 397.dandelion2.jpg
Completed Image ====&gt; 398.a820e7d5a9ccfa10378178542c78b826.jpg
Completed Image ====&gt; 399.220px-Dandelion_greens_for_sale_at_Whole_Foods.jpg
Completed Image ====&gt; 400.dandelion_greens_7.jpg
Completed Image ====&gt; 401.austin-1000.jpg
Completed Image ====&gt; 402.flowers_750.jpg
Completed Image ====&gt; 403.Screen_Shot_2018-08-14_at_10.59.57_AM_1024x1024.png
Completed Image ====&gt; 404.Dandelion-1-1.jpg
Completed Image ====&gt; 405.dandelion2.jpg
Completed Image ====&gt; 406.tenor.gif
Completed Image ====&gt; 407.dandelion1.jpg
Completed Image ====&gt; 408.FWJSJB5JHKUBNMH.LARGE.jpg
Completed Image ====&gt; 409.yellow-dandelion-flowers-with-leaves-green-grass_88211-498.jpg
Completed Image ====&gt; 410.141339732_be1addc651_b.jpg
Completed Image ====&gt; 411.dandelion-flower.jpg
Completed Image ====&gt; 412.Dandelion-0X7A0972.jpg
Completed Image ====&gt; 413.natural-dandelion-killer-p1.jpg
Completed Image ====&gt; 414.Beauty-Dandelion-Flower-Nature-Spring-Summer-4126160.jpg
Completed Image ====&gt; 415.dandelion-products-2.jpg
Completed Image ====&gt; 416.Dandelion11.jpg
Completed Image ====&gt; 417.1-Taraxacum_officinale__Dandelion_.JPG
Completed Image ====&gt; 418.129100129-56a6d33b5f9b58b7d0e4ff0b.jpg
Completed Image ====&gt; 419.CF004390.jpg
Completed Image ====&gt; 420.411aZphlo1L._SL500_AC_SS350_.jpg
Completed Image ====&gt; 421.600x600bf.png
Completed Image ====&gt; 422.diente_leon_taraxacum2.jpeg
Completed Image ====&gt; 423.dandelion-oil-recipe.jpg
Completed Image ====&gt; 424.130862457-56a47d633df78cf77282b064.jpg
Completed Image ====&gt; 425.violet-in-dandelions-2.jpg
Completed Image ====&gt; 426.dandelion.jpg
Completed Image ====&gt; 427.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-3.jpg
Completed Image ====&gt; 428.big_dandelion_leaves.jpg
Completed Image ====&gt; 429.howto-Get-Rid-of-Dandelions.jpg
Completed Image ====&gt; 430.dandelionwhole-225x300.jpg
Completed Image ====&gt; 431.MJR051210Dandelion.jpg
Completed Image ====&gt; 432.Organic-Dandelion-Root-Tea_735x1102-no-text.jpg
Completed Image ====&gt; 433.dandelion-cover-1400x407.jpg
Completed Image ====&gt; 434.dandelions%20large_0.jpg
Completed Image ====&gt; 435.dandelion-bunch.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 436.dandelion-3.jpg
Completed Image ====&gt; 437.How-to-make-tassel-flowers-dandelion-36.jpg
Completed Image ====&gt; 438.D68o0TZU0AE-R1a.jpg
Completed Image ====&gt; 439.dandelionjuice.jpg
Completed Image ====&gt; 440.dandelions-uncurling-with-bee.jpg
Completed Image ====&gt; 441.IMG_5910.JPG
Completed Image ====&gt; 442.image_07.jpg
Completed Image ====&gt; 443.How-to-Make-Dandelion-Wine-with-These-2-Easy-Recipes.jpg
Completed Image ====&gt; 444.dandelion-background-8948.jpg
Completed Image ====&gt; 445.Dandelion-Tea-During-Pregnancy.jpg
Completed Image ====&gt; 446.4559568.jpg
Completed Image ====&gt; 447.maxresdefault.jpg
Completed Image ====&gt; 448.dandelion-400x265.jpg
Completed Image ====&gt; 449.img-crabgrass-control.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 450.dandelionflower.jpg
Completed Image ====&gt; 451.spring-foraging-dandelions.jpg
Completed Image ====&gt; 452.IMG_4782-300x255.jpg
Completed Image ====&gt; 453.dandelion.jpg
Completed Image ====&gt; 454.03358_01_italiko_red.jpg
Completed Image ====&gt; 455.weeds-dandelion-taraxacum-officinale-dock-leaf-rumex-obtusifolius-BAJ7JD.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 456.taraxacum-erythrospermum-25.jpg
Completed Image ====&gt; 457.dandelion-baby.jpg
Completed Image ====&gt; 458.dandelion-madness-wide18.jpg
Completed Image ====&gt; 459.dandelion-800x600.jpg
Completed Image ====&gt; 460.Dandelion-1.jpg
Completed Image ====&gt; 461.dandelion-root-uses-side-effects-benefits-of-dandelion-root-tea-picture-of-dandelion.jpg
Completed Image ====&gt; 462.Dandelion-Green-Smoothie.jpg
Completed Image ====&gt; 463.Radicchio-Italiko-Rossa-dandelion-RC106-LSS-000_66421.jpg
Completed Image ====&gt; 464.71100863.jpg
Completed Image ====&gt; 465.Featured-images-dandelion-salve.png
Completed Image ====&gt; 466.dandelion-field2.jpg
Completed Image ====&gt; 467.3+Pick+dandelions+to+make+a+crown.JPG
Completed Image ====&gt; 468.dandelions.jpg
Completed Image ====&gt; 469.common-dandelion.gif
Completed Image ====&gt; 470.pexels-photo-54300.jpeg
Completed Image ====&gt; 471.dandelion-coffee-710x473.jpg
Completed Image ====&gt; 472.fotolia_7485888_XS.jpg
Completed Image ====&gt; 473.dandelion.jpg
Completed Image ====&gt; 474.3.-Dandelion-all-seeds-ripe-past-mid-bloom.jpg
Completed Image ====&gt; 475.Cats-ear1-996x1024.jpg
Completed Image ====&gt; 476.tumblr_pj49mhW3na1rf9609_540.jpg
Completed Image ====&gt; 477.Dandelion.jpg
Completed Image ====&gt; 478.b05141.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 479.KMA_Cumber_030511_0104.jpg
Completed Image ====&gt; 480.taraxacum-officinale.jpg
Completed Image ====&gt; 481.dandelion_catsearclose.jpg
Completed Image ====&gt; 482.dandelion_root_1.png
Completed Image ====&gt; 483.5b9ee04e2200005600da32c9.jpeg
Completed Image ====&gt; 484.kuva4564.jpg
Completed Image ====&gt; 485.Dandelion-5.jpg
Completed Image ====&gt; 486.dandelion-seeds-1.jpg
Completed Image ====&gt; 487.make-dandelion-pesto.jpg
Completed Image ====&gt; 488.Dandy.jpg
Completed Image ====&gt; 489.1280-685976962-landscape-with-white-dandelions.jpg
Completed Image ====&gt; 490.dandelion-root-vs-leaf.jpg
Completed Image ====&gt; 491.product_Dandelion-Root.jpg
Completed Image ====&gt; 492.productlifestyle_herbal_DandelionLeafRoot.03.jpg
Completed Image ====&gt; 493.dandelion.jpg
Completed Image ====&gt; 494.Dandelion-Salad_exps8314CW143041D01_09_2b_RMS-696x696.jpg
Completed Image ====&gt; 495.Making-and-Using-Dandelion-Oil-harvest.jpg
Completed Image ====&gt; 496.5566871810_9d6a6c31f9.jpg
Completed Image ====&gt; 497.dandelion.jpg
Completed Image ====&gt; 498.common-dandelion-11475-p1050689.jpg
Completed Image ====&gt; 499.1264555489_08aeda6936_b.jpg
Completed Image ====&gt; 500.dandelion.jpg
Completed Image ====&gt; 501.pr_dandelion3.jpg
Completed Image ====&gt; 502.b588d853274f473be15b774715e5d368.jpg
Completed Image ====&gt; 503.323710_256.jpg
Completed Image ====&gt; 504.picking-dandelions.jpg
Completed Image ====&gt; 505.common-dandelion.jpg
Completed Image ====&gt; 506.dandelion_plant.jpg
Completed Image ====&gt; 507.dandelion-seeds-before-wind.jpg
Completed Image ====&gt; 508.7184130_orig.jpeg
Completed Image ====&gt; 509.DandelionMeaning.jpg
Completed Image ====&gt; 510.Pet-Safe-Dandelion-Killer.jpg
Completed Image ====&gt; 511.dandelion-greens-nutrition-facts.jpg
Completed Image ====&gt; 512.d72ce06565df4294117f1a7e580361e1.png
Completed Image ====&gt; 513.dandelion.jpg
Completed Image ====&gt; 514.front-5-1-of-1.jpg
Completed Image ====&gt; 515.flower_3_750.jpg
Completed Image ====&gt; 516.close-blooming-yellow-dandelion-flowers-260nw-586117580.jpg
Completed Image ====&gt; 517.95ce9f089c3f15129c4c1549997bca3a.jpg
Completed Image ====&gt; 518.dendy-5a7a44538e1b6e00374b0bd2.jpg
Completed Image ====&gt; 519.the-fascination-of-the-dandelion-4214388__340.jpg
Completed Image ====&gt; 520.dandelion-pollinators.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 521.tg-03052017-dandelions_large.jpg
Completed Image ====&gt; 522.dandelion-tea-min-ef607fdada.jpg
Completed Image ====&gt; 523.Dandelion-Tea-for-health.jpg
Completed Image ====&gt; 524.hotw-dandelion4-300x300.jpg
Completed Image ====&gt; 525.dandelion-40436_186x186.jpg
Completed Image ====&gt; 526.DandelionCloseup2_1024x1024.jpg
Completed Image ====&gt; 527.Dandelion-bud.jpg
Completed Image ====&gt; 528.yellow-dandelions.jpg
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
Completed Image ====&gt; 529.Dandelions.jpg
Completed Image ====&gt; 530.maxresdefault.jpg
Completed Image ====&gt; 531.photo4.jpg
Completed Image ====&gt; 532.dandelion-vinegar-top.jpg
Completed Image ====&gt; 533.set-realistic-images-yellow-white-dandelion-flowers-with-leaves-different-stages-flowering-isolated_1284-20369.jpg
Completed Image ====&gt; 534.Dandelion_seeds.jpg
Completed Image ====&gt; 535.dandelion-root-cures-cancer-14.jpg
Completed Image ====&gt; 536.image_18.jpg
Completed Image ====&gt; 537.tumblr_pj49mfNZpS1rf9609_540.jpg
Completed Image ====&gt; 538.tenor.gif
Completed Image ====&gt; 539.D5ul7YwWwAAmDQ3.jpg
Completed Image ====&gt; 540.dandelion%20black%20011814.jpg
Completed Image ====&gt; 541.35407.jpg
Completed Image ====&gt; 542.dandelion-greens-0201.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 543.220px-Danedlion_Maria_Sibylla_Merian.png
Completed Image ====&gt; 544.Pic+Dandelion+seeds.jpg
Completed Image ====&gt; 545.b9c34c540c2eb313518e98c69ebe541a.jpg
Completed Image ====&gt; 546.How-to-make-tassel-flowers-dandelion-28.jpg
Completed Image ====&gt; 547.taraxacum-officinale-erythrospermum-leaves.jpg
Completed Image ====&gt; 548.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-5.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 549.Dandelion%20and%20Rabbits.jpg
Completed Image ====&gt; 550.4B23ACC2-6259-4728-ABCB-9F5BA2BFF115_w408_r1_s.jpg
Completed Image ====&gt; 551.DandelionNoFlower_JENKS266.png
Completed Image ====&gt; 552.Dandelion-8-1.jpg
Completed Image ====&gt; 553.1200-39502840-closeup-view-of-dandelion.jpg
Completed Image ====&gt; 554.dandelion+taproot.jpg
Completed Image ====&gt; 555.flower-flight-seeds-air-705187.jpeg
Completed Image ====&gt; 556.Dandelion-Leaves-in-Spinner.jpg
Completed Image ====&gt; 557.large.jpg
Completed Image ====&gt; 558.23327027036_aafb55e8d5.jpg
Completed Image ====&gt; 559.Dandelion-Magnesium-Lotion-Updated-Pin-2.jpg
Completed Image ====&gt; 560.dandelion-sketch-drawing-2.jpg
Completed Image ====&gt; 561.Dandelion-2.jpg
Completed Image ====&gt; 562.Zadiraka_Evgenii_shutterstock_428696311.jpg
Completed Image ====&gt; 563.Radicchio-Italiko-Rossa-dandelion-RC106-LSS-000_6640.jpg
Completed Image ====&gt; 564.carolina-false-dandelion-11511-carolinafalsedandelion-dsc-2749.jpg
Completed Image ====&gt; 565.DSCN8514.jpg
Completed Image ====&gt; 566.dandelion-47.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 567.dandelion_ed_sm.jpg
Completed Image ====&gt; 568.775759.jpg
Completed Image ====&gt; 569.Dandelion-Roots-and-Greens.jpg
Completed Image ====&gt; 570.common-dandelion-dandelion-flower-bud-56896.jpeg
Completed Image ====&gt; 571.dandelion3.jpg
Completed Image ====&gt; 572.field-spring-grass-green-yellow-dandelion-flower-nature-plant-switzerland-flora-XE9W9X.jpg
Completed Image ====&gt; 573.italian_dandelion_bn.jpg
Completed Image ====&gt; 574.dandelion-seed.jpg
Completed Image ====&gt; 575.Dandelion8-813x1024.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 576.KMA_Cumber_030511_0101.jpg
Completed Image ====&gt; 577.dandelion-flowers.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 578.dandelion-bloom-big-56a586013df78cf77288b0e4.jpg
Completed Image ====&gt; 579.HalfSeeded-Dandelion.jpg
Completed Image ====&gt; 580.dandelion-flower-4000x2667-florets-blue-sky-4k-4837.jpg
Completed Image ====&gt; 581.dandelion_and_me.jpg
Completed Image ====&gt; 582.35466.jpg
Completed Image ====&gt; 583.105663996_XS.jpg
Completed Image ====&gt; 584.8af259449855a9de879e32130dfc6cea--dandelion-recipes-tea-recipes.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 585.giphy.gif
Completed Image ====&gt; 586.434711.jpg
Completed Image ====&gt; 587.image_17.jpg
Completed Image ====&gt; 588.dandelion-3416140__340.jpg
Completed Image ====&gt; 589.xdandelions_03.jpg
Completed Image ====&gt; 590.dandelion-lookalike-300x225.jpg
Completed Image ====&gt; 591.D5ul8kLWAAERGVa.jpg
Completed Image ====&gt; 592.taraxacum-erythrospermum-36-2.jpg
Completed Image ====&gt; 593.hqdefault.jpg
Completed Image ====&gt; 594.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-Dandelion-Common-Taraxacum-Officinale-1-Names-left-to-right-1.jpg
Completed Image ====&gt; 595.dandelion-260nw-705892267.jpg
Completed Image ====&gt; 596.hotw-notadandelion2-hawkweed-Hieracium-sp-e1533580997451-300x300.jpg
Completed Image ====&gt; 597.1280-683362620-dandelions-in-the-meadow.jpg
Completed Image ====&gt; 598.dandelion-jelly-recipe.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 599.Dandelion_258756.jpg
Completed Image ====&gt; 600.dandy-fritters-4.jpg
Completed Image ====&gt; 601.29644459615_67c226b51c.jpg
Completed Image ====&gt; 602.Dandelion5-768x1024.jpg
Completed Image ====&gt; 603.Dandelions-600x469.jpg
Completed Image ====&gt; 604.a-wild-dandelion-flower-growing-in-a-field-of-herbal-lavender-plants-M1NF68.jpg
Completed Image ====&gt; 605.dandelion-cultivated.jpg
Completed Image ====&gt; 606.02634_01_clio.jpg
Completed Image ====&gt; 607.common-dandelion-11475-p1050600.jpg
Completed Image ====&gt; 608.pexels-photo-289323.jpeg
Completed Image ====&gt; 609.dandelionleaf-300x268.jpg
Completed Image ====&gt; 610.image_20.jpg
Completed Image ====&gt; 611.dandelion-3381676__340.jpg
Completed Image ====&gt; 612.taraxacum-officinale-3.jpg
Completed Image ====&gt; 613.Dandelions-in-a-basket.jpg
Completed Image ====&gt; 614.f2466aa07c857ea6ff2a4c1a737bc803--dandelion-clock-dandelion-seeds.jpg
Completed Image ====&gt; 615.woman-blowing-on-dandelion-muted-260nw-159554021.jpg
Completed Image ====&gt; 616.dandelion-leaf.jpg
Completed Image ====&gt; 617.35408.jpg
Completed Image ====&gt; 618.dandelions.jpg
Completed Image ====&gt; 619.78493247_XS.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 620.hqdefault.jpg
Completed Image ====&gt; 621.dandy-fritters-6.jpg
Completed Image ====&gt; 622.hotw-notadandelion1-cats-ear-Hypochaeris-radicata-300x300.jpg
Completed Image ====&gt; 623.Dandelion2-768x1024.jpg
Completed Image ====&gt; 624.D5ul9FPWAAExe88.jpg
Completed Image ====&gt; 625.a-crop-of-yellow-dandelion-wildflowers-seen-in-bloom-along-a-country-lane-during-spring-in-the-midwest-MP2FHF.jpg
Completed Image ====&gt; 626.cats-ear-dandelion-11666-catseardandelion-dsc-0943.jpg
Completed Image ====&gt; 627.1280-655540010-dandelions-in-meadow.jpg
Completed Image ====&gt; 628.image_09.jpg
Completed Image ====&gt; 629.d0a8a5846634d3916ea064ec1ac299e7.jpg
Completed Image ====&gt; 630.dandelion-soap-with-flowers.jpg
Completed Image ====&gt; 631.vector-dandelion-flying-seeds-on-260nw-600709604.jpg
Completed Image ====&gt; 632.dandelion-sky-flower-nature-39669.jpeg
Completed Image ====&gt; 633.Cats-ear-and-dandelion.jpg
Completed Image ====&gt; 634.bumblebee-dandelion-01.jpg
Completed Image ====&gt; 635.taraxacum-erythrospermum-26.jpg
Completed Image ====&gt; 636.dandelion-808255__340.jpg
Completed Image ====&gt; 637.hqdefault.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 638.dandelion-root-2-710x556.jpg
Completed Image ====&gt; 639.dandelion-roots.jpg
Completed Image ====&gt; 640.common-dandelion-11475-p1050186.jpg
Completed Image ====&gt; 641.image_19.jpg
Completed Image ====&gt; 642.cd54390321e2aaf9c38a8f31ebecfc80--dandelion-painting-creative-art.jpg
Completed Image ====&gt; 643.meadow-dandelions-on-sunny-day-260nw-1080645086.jpg
Completed Image ====&gt; 644.dandelion-recipes-short-pin.jpg
Completed Image ====&gt; 645.Cats-ear4-1024x968.jpg
Completed Image ====&gt; 646.AdobeStock_206345546.jpg
Completed Image ====&gt; 647.dandelion-142969__340.jpg
Completed Image ====&gt; 648.common-dandelion-11475-crown.jpg
Completed Image ====&gt; 649.dandelion-infestation.jpg
Completed Image ====&gt; 650.17fba7eedcc069e1843e0b730f27c4d6--iphone-wallpaper-quotes-phone-backgrounds.jpg
Completed Image ====&gt; 651.blowing-dandelion-seeds-white-background-260nw-1110414380.jpg
Completed Image ====&gt; 652.Thumb_02.jpg
Completed Image ====&gt; 653.Dandelion1-1024x768.jpg
Completed Image ====&gt; 654.dandelion-mead-2.jpg
Completed Image ====&gt; 655.hqdefault.jpg
Completed Image ====&gt; 656.dandelion-445228__340.jpg
Completed Image ====&gt; 657.carolina-false-dandelion-11511-carolinafalsedandelion-dsc-2759.jpg
Completed Image ====&gt; 658.c28d5f9dd784f5a5fe3d4be50b42fea3.jpg
Completed Image ====&gt; 659.closeup-dandelion-on-natural-background-260nw-282705149.jpg
Completed Image ====&gt; 660.dandelion-control.jpg
Completed Image ====&gt; 661.Cats-ear5-1024x768.jpg
Completed Image ====&gt; 662.maxresdefault.jpg
Completed Image ====&gt; 663.field_CarolinaFalseDandelion_plan_nc.jpg
Completed Image ====&gt; 664.13309c9c828345aa1787e915522b0c98.jpg
Completed Image ====&gt; 665.dandelion-flower-on-white-background-260nw-626460182.jpg
Completed Image ====&gt; 666.image_01.jpg
Completed Image ====&gt; 667.Dandelion6-882x1024.jpg
Completed Image ====&gt; 668.common-dandelion-11475-crown2.jpg
Completed Image ====&gt; 669.maxresdefault.jpg
Completed Image ====&gt; 670.530255bf511721d0deb0432fb73b2834.jpg
Completed Image ====&gt; 671.9f9ec10577b1098067c833188e86e64f--precious-children-beautiful-children.jpg


Unfortunately all 1000 could not be downloaded because some images were not downloadable. 671 is all we got for this search filter!

Errors: 34

</pre></div>
</div>
<div class="outline-4" id="outline-container-orgaac7872">
<h4 id="orgaac7872">Cat's Ear</h4>
<div class="outline-text-4" id="text-orgaac7872">
<div class="highlight">
<pre><span></span>keywords["keywords"] = "cat's ear weed"
cats_ear_paths = google_images.download(keywords)
</pre></div>
<pre class="example">

Item no.: 1 --&gt; Item name = cat's ear weed
Evaluating...
Getting you a lot of images. This may take a few moments...
Reached end of Page.
Starting Download...
Completed Image ====&gt; 1.cats-ear-a.jpg
Completed Image ====&gt; 2.hypochaerisleaves_bl.jpg
Completed Image ====&gt; 3.commoncatsear4.jpg
Completed Image ====&gt; 4.commoncatsear5.jpg
Completed Image ====&gt; 5.catsear-root.jpg
Completed Image ====&gt; 6.weeds2.jpg
Completed Image ====&gt; 7.catsear%20N1.jpg
Completed Image ====&gt; 8.cats-ear-dandelion-11666-weed5.jpg
Completed Image ====&gt; 9.catsear-d.jpg
Completed Image ====&gt; 10.cats-ear-400x267.jpg
Completed Image ====&gt; 11.cats-ear-400x299.jpg
Completed Image ====&gt; 12.0910catsearwhole3.jpg
Completed Image ====&gt; 13.hqdefault.jpg
Completed Image ====&gt; 14.cats-ear-dandelion-11666-weeds.jpg
Completed Image ====&gt; 15.common_catsear_leaves.gif
Completed Image ====&gt; 16.commoncatsear3.jpg
Completed Image ====&gt; 17.hypochaerisradicata24.jpg
Completed Image ====&gt; 18.Hairy_Catsear004_Forest_Kim_Starr_StarrEnvironmental_bugwood.org.jpg
Completed Image ====&gt; 19.cats-ear-dandelion-11666-weed3.jpg
Completed Image ====&gt; 20.catsear.jpg
Completed Image ====&gt; 21.cats-ear-dandelion-11666-weeds2.jpg
Completed Image ====&gt; 22.A-large-common-catsear-plant-665x509.jpg
Completed Image ====&gt; 23.Catsear-Eat-Medicinally.jpg
Completed Image ====&gt; 24.hypochaerisradicata12.jpg
Completed Image ====&gt; 25.hairy-cats-ear.jpg
Completed Image ====&gt; 26.cats-ear-weed.jpg
Completed Image ====&gt; 27.radicata3a.jpg
Completed Image ====&gt; 28.cats-ear-common-hypochoeris-radicata-miw251235-X3H67K.jpg
Completed Image ====&gt; 29.1hairycatsear.jpg
Completed Image ====&gt; 30.flatweed%20leaves%20N2.jpg
Completed Image ====&gt; 31.Hypochaeris%2Bradicata%2BCats%2BEar%2BLawn%2BWeed.JPG
Completed Image ====&gt; 32.hryra456w.jpg
Completed Image ====&gt; 33.commoncatsear6.jpg
Completed Image ====&gt; 34.hypochaeris-radicata-flat-weed-catsear-450w-401971948.jpg
Completed Image ====&gt; 35.IMG_3733-800x600.jpg
Completed Image ====&gt; 36.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-1.jpg
Completed Image ====&gt; 37.1-cats-ear-bcfarmsandfood.jpg
Completed Image ====&gt; 38.cats-ear-dandelion-11666-weed4.jpg
Completed Image ====&gt; 39.21fbdef630731afef86dc698ccdc5359.jpg
Completed Image ====&gt; 40.3f6214d352afd3ae4f0690701af56a51--small-white-flowers-root-system.jpg
Completed Image ====&gt; 41.cats-ear-dandelion-11666-p1060807-catseardandelion.jpg
Completed Image ====&gt; 42.Smoothcatsear.jpg
Completed Image ====&gt; 43.cats_ear_young_rosette.jpg
Completed Image ====&gt; 44.6971204959_edc5453fb0.jpg
Completed Image ====&gt; 45.hairy-wild-lettuce-weed-hypochoeris-radicata-l-spotted-cat-s-ear-growing-field-originated-europe-widely-spread-36599587.jpg
Completed Image ====&gt; 46.weed-cats-ear-1.jpg
Completed Image ====&gt; 47.Cat%27s_Ear_03_0.jpg
Completed Image ====&gt; 48.8d568cf5b869971da7b8cd25bc56bb2b--lawn-turf-seeded.jpg
Completed Image ====&gt; 49.depositphotos_169837052-stock-photo-cats-ear-weed.jpg
Completed Image ====&gt; 50.Hairy_Catsear001_OhioStateUniv_bugwood.org.jpg
Completed Image ====&gt; 51.Catsear.jpg
Completed Image ====&gt; 52.cats-ear.jpg
Completed Image ====&gt; 53.dandelions-696x389.jpg
IOError on an image...trying next one... Error: [Errno 104] Connection reset by peer
Completed Image ====&gt; 54.22494268149_babe30dbdf.jpg
Completed Image ====&gt; 55.avopix-401971945.jpg
Completed Image ====&gt; 56.cats-ear-dandelion-11666-catseardandelion2.jpg
Completed Image ====&gt; 57.220px-Hypochaeris_radicata_3285.JPG
Completed Image ====&gt; 58.6dfedb655a994e9ba06853e5bec5710d--purple-flowers-weed.jpg
Completed Image ====&gt; 59.hypochaeris-radicata-cats-ear-weed-F0W6JC.jpg
Completed Image ====&gt; 60.hypochaerisradicata30.jpg
Completed Image ====&gt; 61.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-Dandelion-Common-Taraxacum-Officinale-1-Names-left-to-right-1.jpg
Completed Image ====&gt; 62.7968ae66dca9b2dce70683ffc502b3b079208cb5_hypochaeris-radicata-855538_1920.jpg
Completed Image ====&gt; 63.yellow-flower-surrounding-green-leafs-450w-772058455.jpg
Completed Image ====&gt; 64.cats-ear-weed-Hypochaeris-radicata.png
Completed Image ====&gt; 65.Hypochoeris%20radica%20FOM%201204%20plant.JPG
Completed Image ====&gt; 66.6971201505_4597311f45.jpg
Completed Image ====&gt; 67.stock-photo-hypochaeris-radicata-flat-weed-cat-s-ear-spotted-cat-s-ear-rosetted-annual-herb-leaves-rough-401971933.jpg
Completed Image ====&gt; 68.Hypochaeris-radicata_5524931_Rob-Routledge-Custom.jpg
Completed Image ====&gt; 69.e40db66802af5867cb31ec3ba3b1e3af--wild-geranium-garden-weeds.jpg
Completed Image ====&gt; 70.Hypochoeris%20radicata%20FOM%201204%20base%20fl%20stem.JPG
Completed Image ====&gt; 71.Cats-Ear-weed.jpg
Completed Image ====&gt; 72.resizedflora2new.jpg
Completed Image ====&gt; 73.hypochaerisradicata18.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 74.cats-ear-common-hypochoeris-radicata-miw251235-GGJE6F.jpg
Completed Image ====&gt; 75.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-2.jpg
Completed Image ====&gt; 76.cats_ear_hairy_leaves.jpg
Completed Image ====&gt; 77.Spotted_catsear--Hypochaeris_radicata--m.s.jpg
Completed Image ====&gt; 78.206b27b09c92e64a11fe9fb07f9f6f30--bad-bad-cat-ears.jpg
Completed Image ====&gt; 79.Hairy_Catsear003_BMacDonald_SaultCollege_bugwood.org.jpg
Completed Image ====&gt; 80.Catsear.jpg
Completed Image ====&gt; 81.flat-broad-leaf-weeds-1-la.jpg
Completed Image ====&gt; 82.salad2ee612.jpg
Completed Image ====&gt; 83.il_794xN.1433296245_tbjj.jpg
Completed Image ====&gt; 84.Catsear-Leaf-e1526729175371-1024x474.jpg
Completed Image ====&gt; 85.Catsear-400x533.jpg
Completed Image ====&gt; 86.bishops-weed-poisoning.jpg
Completed Image ====&gt; 87.Hypochaeris-radicata_1555100_Ohio-State-Weed-Lab.jpg
Completed Image ====&gt; 88.cats-ear-dandelion-11666-catseardandelion-dsc-0852.jpg
Completed Image ====&gt; 89.stock-photo-flatweed-aka-catsear-or-hairy-cats-air-the-plant-is-an-invasive-weed-and-commonly-found-in-lawns-1405386989.jpg
Completed Image ====&gt; 90.220px-Hypochaeris.radicata.Alan.JPG
Completed Image ====&gt; 91.7594b2248e5c277a2432cb10a4367d26--erecta-perennial.jpg
Completed Image ====&gt; 92.big_catsear20002.JPG
Completed Image ====&gt; 93.cats-ear-2.jpg
Completed Image ====&gt; 94.glaucous_goosefoot_plant.jpg
Completed Image ====&gt; 95.cats-ear-flower-P582XH.jpg
Completed Image ====&gt; 96.hqdefault.jpg
Completed Image ====&gt; 97.il_794xN.1169788393_4i7s.jpg
Completed Image ====&gt; 98.hypochaeris-radicata-flat-weed-catsear-450w-401971930.jpg
Completed Image ====&gt; 99.foodanddrink_flavor1-1-7e214cd899f0f8fe.jpg
Completed Image ====&gt; 100.hairy-cats-ear.jpg
Completed Image ====&gt; 101.Cats-ear-Dandelion.jpg
Completed Image ====&gt; 102.catsear-800x600.jpg
Completed Image ====&gt; 103.cats-ear-flowers.jpg
Completed Image ====&gt; 104.flatweed%20stems%20N2.jpg
Completed Image ====&gt; 105.man-picking-out-hairy-cat-ear-yard-doing-work-wild-weed-name-weed-93068245.jpg
Completed Image ====&gt; 106.cats-ear-picture.png
Completed Image ====&gt; 107.Cats_Ear_400.jpg
Completed Image ====&gt; 108.sjm-l-foraging-08xx-3.jpg
Completed Image ====&gt; 109.catsear-f.jpg
Completed Image ====&gt; 110.Marijuana-plant-1062908_1920-588a59853df78caebc1562c3.jpg
Completed Image ====&gt; 111.Hairy_Catsear002_OhioStateUniv_bugwood.org.jpg
Completed Image ====&gt; 112.220px-Hypochaeris_radicata_3294.JPG
Completed Image ====&gt; 113.53270f55f3affe0d9b731603d710878e--plantago-garden-weeds.jpg
Completed Image ====&gt; 114.dandelions-1.jpg
Completed Image ====&gt; 115.catsear+1.JPG
Completed Image ====&gt; 116.tall-yellow-flowers-weed-spring-print-special-prints-only-limited-time-only-tall-green-weed-yellow-flowers.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 117.Cat%27s_Ear_04_0.jpg
Completed Image ====&gt; 118.image003.jpg
Completed Image ====&gt; 119.spotted-cats-ear-hypochaeris-radicata-_0394-small.jpg
Completed Image ====&gt; 120.Flat_weed_%283148973339%29.jpg
Completed Image ====&gt; 121.hairy-cats-ear-2.jpg
Completed Image ====&gt; 122.SUBU-UrbanForaging-HairyCatsEar.jpg
Completed Image ====&gt; 123.cats-ear-seed-head-P5828X.jpg
Completed Image ====&gt; 124.il_794xN.1123180936_2153.jpg
Completed Image ====&gt; 125.1c5907_04c2da8055f14522bfd4ba2219f71cbf_mv2_1024x768.png
Completed Image ====&gt; 126.wicker-img-115.jpg
Completed Image ====&gt; 127.hyrad3.jpg
Completed Image ====&gt; 128.stock-photo-common-hypochaeris-radicata-rough-catsear-hairy-dandelion-with-small-yellow-rosette-flowers-is-449030662.jpg
Completed Image ====&gt; 129.180921-urban-foraging-edible-weeds-Common-Cats-Ear-350x467.jpg
Completed Image ====&gt; 130.hyrad0.jpg
Completed Image ====&gt; 131.hypochaerisradicata33.jpg
Completed Image ====&gt; 132.cats-ears-rosette1.jpg
Completed Image ====&gt; 133.more-early-spring-weeds-024.jpg
Completed Image ====&gt; 134.hryar0866w.jpg
Completed Image ====&gt; 135.cats-ear-leaf.jpg
Completed Image ====&gt; 136.22872980622_f2143c35a5.jpg
Completed Image ====&gt; 137.Cats-Ear.jpg
Completed Image ====&gt; 138.catsear.jpg
Completed Image ====&gt; 139.catsear.jpg
Completed Image ====&gt; 140.fi-cats-ear-400x250.jpg
Completed Image ====&gt; 141.catsear_sm.jpg
Completed Image ====&gt; 142.9a5dc2821d4819d8450d5cdec70b40ec--white-flowers-weed.jpg
Completed Image ====&gt; 143.common-cats-ear-flowers-hypochaeris-radicata-growing-on-a-road-near-B8KCYY.jpg
Completed Image ====&gt; 144.Cat%27s_Ear_02_0.jpg
Completed Image ====&gt; 145.Jolt-Bottle-10L.jpg
Completed Image ====&gt; 146.stock-photo-hypochaeris-radicata-flat-weed-cat-s-ear-spotted-cat-s-ear-rosetted-annual-herb-leaves-rough-401971939.jpg
Completed Image ====&gt; 147.cats-ear-dandelion-11666-catseardandelion-dsc-0943.jpg
Completed Image ====&gt; 148.rgh_catear1.jpg
Completed Image ====&gt; 149.57262993_1833695570063461_5251219451713260277_n.jpg
Completed Image ====&gt; 150.cats-ears-flowers.jpg
Completed Image ====&gt; 151.weed17.JPG
Completed Image ====&gt; 152.hypochaeris_radicata.jpg
Completed Image ====&gt; 153.180921-urban-foraging-edible-weeds-Bristly-Oxtongue-700x525.jpg
Completed Image ====&gt; 154.leaveshairy.jpg
Completed Image ====&gt; 155.Cats-Ear-Dandelion-300x225.jpeg
Completed Image ====&gt; 156.1555112.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 157.very-tall-yellow-flowers-cats-ears-flowering-in-the-yard-tall-yellow-flowers-uk.jpg
Completed Image ====&gt; 158.c06340.jpg
Completed Image ====&gt; 159.stock-photo-cat-s-ears-weed-blooming-1365578216.jpg
Completed Image ====&gt; 160.Cat%2527s+Ear+Hypochaeris+radicata.JPG
Completed Image ====&gt; 161.Capeweed.jpg
Completed Image ====&gt; 162.Sonchus_oleraceus.CA.1.jpg
Completed Image ====&gt; 163.e552a1409669b3da20115d918169fdae---day-blue-flowers.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 164.61161833_319462918969475_1265022715123205547_n.jpg
Completed Image ====&gt; 165.catsear4-25b-500x500.jpg
Completed Image ====&gt; 166.Catsear-Weed-Source-Macleay-Grass-Man-600x600.jpg
Completed Image ====&gt; 167.purslane1-150x150.jpg
Completed Image ====&gt; 168.CatsearDandelion.jpg
Completed Image ====&gt; 169.hygla3.jpg
Completed Image ====&gt; 170.dune-grass-with-cats-ear-flower-weed-aberdovey-wales-A38949.jpg
Completed Image ====&gt; 171.13613.jpg
Completed Image ====&gt; 172.A-weed-tea-in-the-garden-as-a-cold-sets-in.jpg
Completed Image ====&gt; 173.il_794xN.1123137668_ab0a.jpg
Completed Image ====&gt; 174.cats_ear_flower_involucre.jpg
Completed Image ====&gt; 175.city-dandelions_main.jpg
Completed Image ====&gt; 176.tree-white-sweet-flower-animal-cute-looking-bush-pet-fur-portrait-young-green-fluffy-kitten-cat-sitting-feline-mammal-garden-fauna-eyes-whiskers-kitty-furry-ears-vertebrate-weeds-domestic-adorable-small-to-medium-sized-cats-cat-like-mammal-domestic-short-haired-cat-778591.jpg
Completed Image ====&gt; 177.cats-ear-p1.jpg
Completed Image ====&gt; 178.resizedcats-ear.jpg
Completed Image ====&gt; 179.Hypochoeris%20radica%20FOM%200105%20flower%20n%20seed.JPG
Completed Image ====&gt; 180.hypochaerisradicata28.jpg
Completed Image ====&gt; 181.weed_sowthistle.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 182.cats_ear_20-2-2018.JPG
Completed Image ====&gt; 183.catsear-c.jpg
Completed Image ====&gt; 184.Hypochaeris-radicata_1553145_Theodore-Webster.jpg
Completed Image ====&gt; 185.Erodium_cicutarium.jpg
Completed Image ====&gt; 186.Cats-Ear-MagicZoom.jpg
Completed Image ====&gt; 187.mixed-weeds450.jpg
Completed Image ====&gt; 188.cats-ear-leaves.jpg
Completed Image ====&gt; 189.Cats-Ear.jpg
Completed Image ====&gt; 190.white-evil-cat-dirt-weeds-background-looking-walks-to-camera-fur-body-short-darker-hair-head-ears-blue-eyes-mouth-107341620.jpg
Completed Image ====&gt; 191.tall-yellow-flowers-plant-yellow-flowers-stock-photos-tall-yellow-flowers-tall-yellow-flower-weed-mullein.jpg
Completed Image ====&gt; 192.Chamberbitter.jpg
Completed Image ====&gt; 193.18342238_10210932305478001_2194864223501874184_n-2.jpg
Completed Image ====&gt; 194.cats_ear.jpg
Completed Image ====&gt; 195.Hypochoeris%20radicata%20leaf1.JPG
Completed Image ====&gt; 196.hryar3172w.jpg
Completed Image ====&gt; 197.CATSEAR.jpeg
Completed Image ====&gt; 198.cats_ear_30-7-2017.JPG
Completed Image ====&gt; 199.51Dl1xkwsFL._SX466_.jpg
Completed Image ====&gt; 200.1493844821307.jpg
Completed Image ====&gt; 201.catsear-flowers.jpg
Completed Image ====&gt; 202.yellow-flower-weed-bright-yellow-flowers-have-five-petals-prolific-seed-producer-pods-will-scatter-seed-for-several-feet-when-touched-yellow-flower-weed-georgia.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 203.2167069%20Bindii%20weed_1_0.jpg
Completed Image ====&gt; 204.catsear02.jpg
Completed Image ====&gt; 205.cats_ear_plants.jpg
Completed Image ====&gt; 206.Cats-Ear-2000x500.jpg
Completed Image ====&gt; 207.hygla0.jpg
Completed Image ====&gt; 208.Hypochaeris_glabra.CA.1.jpg
Completed Image ====&gt; 209.Wintergrass.jpg
Completed Image ====&gt; 210.common-plantain-bcfarmsandfood-350.jpg
Completed Image ====&gt; 211.catsear_weed.jpg
Completed Image ====&gt; 212.sjm-l-foraging-08xx-2.jpg
Completed Image ====&gt; 213.20111209_0399.jpg
Completed Image ====&gt; 214.HypochoerisRadicata2.jpg
Completed Image ====&gt; 215.cats-ear.jpg
Completed Image ====&gt; 216.flatweed-aka-catsear-hairy-cats-260nw-1407002897.jpg
Completed Image ====&gt; 217.dandelion-leaves1-150x150.jpg
Completed Image ====&gt; 218.1555110.jpg
Completed Image ====&gt; 219.lampu4-25b.jpg
Completed Image ====&gt; 220.stock-photo-flowers-on-the-meadow-455171974.jpg
Completed Image ====&gt; 221.dandelion-lookalike-300x225.jpg
Completed Image ====&gt; 222.weedy-herb-garden-pre-vinegar-530x398.jpg
Completed Image ====&gt; 223.Hawkbit-MagicZoom.jpg
Completed Image ====&gt; 224.weedsdangeroustopets1.png
Completed Image ====&gt; 225.mouse-ear-chickweed-identification-uk.png
Completed Image ====&gt; 226.51kp43W4s7L._UX385_.jpg
Completed Image ====&gt; 227.pc1.jpg
Completed Image ====&gt; 228.Philip-Stark-collects-wild-greens-in-a-bowl-900x600.jpeg
Completed Image ====&gt; 229.adorable-animal-cat-1049260.jpg
Completed Image ====&gt; 230.dandelion-for-parrots.jpg
Completed Image ====&gt; 231.87617533.jpg
Completed Image ====&gt; 232.paleo1549d8.jpg
Completed Image ====&gt; 233.22468103028_b936aee910.jpg
Completed Image ====&gt; 234.cats-ears-rosette2.jpg
Completed Image ====&gt; 235.1408532.large.jpg
Completed Image ====&gt; 236.20141005_083252.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 237.1-Agrostemma_githago-001.JPG
Completed Image ====&gt; 238.cats-ear-dandelion-11666-rosette.jpg
Completed Image ====&gt; 239.hypochoerisglabra3.jpg
Completed Image ====&gt; 240.broadsword_1200x1200.jpg
Completed Image ====&gt; 241.American-Burnweed-300x225.jpeg
Completed Image ====&gt; 242.Cat%27s_Ear_01_0.jpg
Completed Image ====&gt; 243.sweet_vernal_grass_mix.jpg
Completed Image ====&gt; 244.cats_ear_flower.jpg
Completed Image ====&gt; 245.purple-deadnettle2-bcfarmsandfood-350.jpg
Completed Image ====&gt; 246.avopix-401971936.jpg
Completed Image ====&gt; 247.hyrad5.jpg
Completed Image ====&gt; 248.Sonchus_oleraceus.CA.5.jpg
Completed Image ====&gt; 249.IMG_5626.jpg
Completed Image ====&gt; 250.cats-ear-flower.jpg
Completed Image ====&gt; 251.hryar1076w.jpg
Completed Image ====&gt; 252.White-Clover-MagicZoom.jpg
Completed Image ====&gt; 253.tiny_weed_rosette_30-7-2018.JPG
Completed Image ====&gt; 254.Weeds.png
Completed Image ====&gt; 255.Catsear-1-Turf-Finder.jpg
Completed Image ====&gt; 256.450px-Conyza_canadensis_5.jpg
Completed Image ====&gt; 257.catsear11.jpg
Completed Image ====&gt; 258.50780572_2184030598357710_2118009451204679055_n.jpg
Completed Image ====&gt; 259.cats%2Bear%2B7583.jpg
Completed Image ====&gt; 260.dandelion-150x150.jpg
Completed Image ====&gt; 261.weed-dandelion-yellow.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 262.61gTJ2OEnLL._UX679_.jpg
Completed Image ====&gt; 263.prickly-lettuce-bouquet.jpg
Completed Image ====&gt; 264.catsear-b.jpg
Completed Image ====&gt; 265.IKdvqQIAStyaS8GFLgUV_20180925_170436_medium.jpg
Completed Image ====&gt; 266.180921-urban-foraging-edible-weeds-top1-1200x800.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 267.bindii-lawn-weeds-2-copy.jpg
Completed Image ====&gt; 268.foxglove.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 269.cannabis-pets-cbd-plant-boulder-holistic.jpg
Completed Image ====&gt; 270.mallowedibleweeds.jpg
Completed Image ====&gt; 271.cudweed.jpg
Completed Image ====&gt; 272.55855669_801504030226629_90144045439261161_n.jpg
Completed Image ====&gt; 273.2-dandelion-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 274.165wh.jpg
Completed Image ====&gt; 275.Dandelion-False-Hairy-Cats-Ear-Hypochaeris-Radicata-4.jpg
Completed Image ====&gt; 276.catsear_smooth3b.jpg
Completed Image ====&gt; 277.hyrad6.jpg
Completed Image ====&gt; 278.APratt2-107-1.jpg
Completed Image ====&gt; 279.elephant-ear-poison-225x300.jpg
Completed Image ====&gt; 280.get-rid-cats-dogs-marijuana.jpg
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'assets.hightimes.com'. (_ssl.c:1056)&gt;
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 281.Pic546-to-600.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 282.hypochaerisradicata13.jpg
Completed Image ====&gt; 283.Birds-Foot-Trefoil-MagicZoom.jpg
Completed Image ====&gt; 284.catsear+2.JPG
Completed Image ====&gt; 285.Hypochaeris_radicata.1.jpg
Completed Image ====&gt; 286.weeds-blackberry.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 287.cats_ear_fruit.jpg
Completed Image ====&gt; 288.snw.jpg
Completed Image ====&gt; 289.1491442973779.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 290.zone-8-kale-150x150.jpg
Completed Image ====&gt; 291.lambs-ears-ground-cover-plant.jpg
Completed Image ====&gt; 292.hryar0885w.jpg
Completed Image ====&gt; 293.252.jpg
Completed Image ====&gt; 294.Spotted_catsear--Hypochaeris_radicata--s.s.jpg
Completed Image ====&gt; 295.dsc_6761.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 296.catsear13.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 297.White-Clover-300x300.jpg
Completed Image ====&gt; 298.Ammi-majus.jpg
Completed Image ====&gt; 299.queen-annes-lace-bcfarmsandfood-350.jpg
Completed Image ====&gt; 300.chickweed-Mouse-Ear.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 301.jimsonweed.jpg
Completed Image ====&gt; 302.maxresdefault.jpg
Completed Image ====&gt; 303.Pic544-to-600.jpg
Completed Image ====&gt; 304.weed-identification.jpg
Completed Image ====&gt; 305.weeds-panic-veldt-grassjpg.jpg
Completed Image ====&gt; 306.toad_rush.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 307.Cirsium_arvense.2.jpg
Completed Image ====&gt; 308.hypochoerisglabra5.jpg
Completed Image ====&gt; 309.Get-Rid-of-Foxtails-Step-12.jpg
Completed Image ====&gt; 310.cat-marijuana-1024x576.jpg
Completed Image ====&gt; 311.0488276-05.jpg
Completed Image ====&gt; 312.agriculture-weeds-smooth-catsear-hypochaeris-glabra-aka-false-dandelion-flatweed-glabrous-catsear-flowering-plants-california-usa-x432r3.jpg
Completed Image ====&gt; 313.weed_dandelion.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 314.cannabis.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 315.25343015684_f8d326024c.jpg
Completed Image ====&gt; 316.Kalanchoe-Daigremontiana-Mother-of-Thousands.jpg
Completed Image ====&gt; 317.aquilegia2_24-5-2013.JPG
Completed Image ====&gt; 318.8206A.jpg
Completed Image ====&gt; 319.catsear12.jpg
Completed Image ====&gt; 320.935.jpg
Completed Image ====&gt; 321.cats-ear-dandelion-11666-backofleaf.jpg
Completed Image ====&gt; 322.sjm-l-foraging-08xx-1.jpg
Completed Image ====&gt; 323.Taraxacum%20officinale%20flower%20n%20leaves%20FOM%200305.JPG
Completed Image ====&gt; 324.Crows-foot.jpg
Completed Image ====&gt; 325.209440.jpg
Completed Image ====&gt; 326.mouse-ear-chickweed-leaf-300x200.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 327.HIGH-compressor-1.jpg
Completed Image ====&gt; 328.Weeds-Jimboomba-Turf.jpg
Completed Image ====&gt; 329.my-cat-ate-my-pot-plants.jpg
Completed Image ====&gt; 330.5-buttercup-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 331.Bindii-Weed-Source-Macleay-Grass-Man-600x600.jpg
Completed Image ====&gt; 332.plantainedibleweed.jpg
Completed Image ====&gt; 333.Violet-MagicZoom.jpg
Completed Image ====&gt; 334.healing-weeds-cats-ear-21.jpeg
Completed Image ====&gt; 335.daisy-flower-in-lawn-300x200.jpg
Completed Image ====&gt; 336.hyrad2.jpg
Completed Image ====&gt; 337.Heres-Everything-You-Wanted-to-Know-About-Animals-Getting-High-on-Weed2.jpg
Completed Image ====&gt; 338.rgh_catear4.jpg
Completed Image ====&gt; 339.101751667.jpg
Completed Image ====&gt; 340.capeweed.jpg
Completed Image ====&gt; 341.hawkweed_yellow.jpg
Completed Image ====&gt; 342.Bur-Chervil.jpg
Completed Image ====&gt; 343.catsear-e.jpg
Completed Image ====&gt; 344.9172201878_cb185f5cfc_z.jpg
Completed Image ====&gt; 345.Chrysanthemum_sp.-003.JPG
Completed Image ====&gt; 346.man-picking-out-hairy-cat-ear-yard-doing-work-wild-weed-name-weed-93197638.jpg
Completed Image ====&gt; 347.Sticky-Chick-Weed-300x225.jpeg
Completed Image ====&gt; 348.Cirsium_vulgare.1.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 349.568x334_Pets__Pot_main_image.jpg
Completed Image ====&gt; 350.Hypochaeris_radicata_2925.jpg
Completed Image ====&gt; 351.1-sow%2Bthistle%2B%25281%2529.JPG
Completed Image ====&gt; 352.cats-ear-2.jpg
Completed Image ====&gt; 353.agriculture-weeds-smooth-catsear-hypochaeris-glabra-aka-false-dandelion-g3e7rm.jpg
Completed Image ====&gt; 354.Pic545-to-600.jpg
Completed Image ====&gt; 355.P1080227.jpg
Completed Image ====&gt; 356.foxtail-7.jpg
Completed Image ====&gt; 357.165wh.jpg
Completed Image ====&gt; 358.weeds-privet.jpg
Completed Image ====&gt; 359.daisy2-bcfarmsandfood-350.jpg
Completed Image ====&gt; 360.shotweed.jpg
Completed Image ====&gt; 361.maxresdefault.jpg
Completed Image ====&gt; 362.daisy-featured-300x225.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 363.p7030074.jpg
Completed Image ====&gt; 364.cats-ear-dandelion-11666-p1060809-catseardandelion.jpg
Completed Image ====&gt; 365.dandelionleaf-300x268.jpg
IOError on an image...trying next one... Error: The read operation timed out
Completed Image ====&gt; 366.artemesia_frigida.png
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 367.grass-allergy.jpg
Completed Image ====&gt; 368.Pruning-Perennials-Joe-Pye-Weed.jpg
Completed Image ====&gt; 369.silver_grass_flowerhead.jpg
Completed Image ====&gt; 370.weed_dandelionflower-e1401844344375.jpg
Completed Image ====&gt; 371.180813-plants-full.jpg
Completed Image ====&gt; 372.catsear05.jpg
Completed Image ====&gt; 373.23.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 374.stale-seedbed-400x267.jpg
Completed Image ====&gt; 375.ONCRMBOR7BEW7CDVHK2IGKNPPQ.jpg
Completed Image ====&gt; 376.Lawn-Bur-Weed-300x225.jpeg
Completed Image ====&gt; 377.Cat%20Drug%20High%20Weed%20Animal%20Women%20BlackSweatshirt%20Wellcoda%20169.jpg
Completed Image ====&gt; 378.pigweededible.jpg
Completed Image ====&gt; 379.18417030228_6ce89c2449_b.jpg
Completed Image ====&gt; 380.Hypochaeris-radicata_5374507_Joseph-M-DiTomaso.jpg
Completed Image ====&gt; 381.meowijuana-1.jpg
Completed Image ====&gt; 382.37-instagrams-of-cats-smoking-weed-1-5121-1356025825-0_big.jpg
Completed Image ====&gt; 383.62001490_171579480524447_7750664418236853070_n.jpg
Completed Image ====&gt; 384.180921-urban-foraging-edible-weeds-Sweet-Fennel-t-350x467.jpg
Completed Image ====&gt; 385.2011-04-17%2BMesa%2BCity%2BCemetery%2BVisit%2BApr%2B17%252C%2B2011%2B5-02%2BPM.jpg
Completed Image ====&gt; 386.foraged-greens-900x720.jpg
Completed Image ====&gt; 387.Bindii.jpg
Completed Image ====&gt; 388.Catsear-Flower-e1526729196211-1024x732.jpg
Completed Image ====&gt; 389.hairy-cats-ear-hypochaeris-radicata-E7E59K.jpg
Completed Image ====&gt; 390.Cats-ear-and-dandelion.jpg
Completed Image ====&gt; 391.merlin_153330861_e1ab69aa-0179-4559-9552-88006e761fe5-articleLarge.jpg
Completed Image ====&gt; 392.White-Clover.jpg
Completed Image ====&gt; 393.14215561_f520.jpg
Completed Image ====&gt; 394.cats_cannabis.jpg
Completed Image ====&gt; 395.165wh.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 396.weeds-english-ivy.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 397.herb-garden-after-vinegar-530x398.jpg
Completed Image ====&gt; 398.Cudweed-300x300.jpg
Completed Image ====&gt; 399.hryra8664w.jpg
Completed Image ====&gt; 400.1555101.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 401.poison-ivy-thinkstockphotos-139254587-335jpg.jpg
Completed Image ====&gt; 402.landscape-1516707756-dog-poisonous-plants.jpg
Completed Image ====&gt; 403.3-daisy-weed-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 404.capeweed_plants.jpg
Completed Image ====&gt; 405.hypochoerisglabra4.jpg
Completed Image ====&gt; 406.Echium_vulgare.2.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 407.Pic548-to-600.jpg
Completed Image ====&gt; 408.catsear.jpg
Completed Image ====&gt; 409.1200px-Starr_030612-0063_Tribulus_terrestris.jpg
Completed Image ====&gt; 410.web_-_Marshmallow_weed.jpg
Completed Image ====&gt; 411.DSC_0171.jpg
Completed Image ====&gt; 412.jimsonweed-thinkstockphotos-490349982-590lc030916.jpg
Completed Image ====&gt; 413.kisspng-whiskers-cat-drawing-clip-art-weed-emoji-5b3ef8aaeacb84.9666256615308535469617.jpg
Completed Image ====&gt; 414.weed_deadnettle_stock.jpg
Completed Image ====&gt; 415.dog-15-new-marijuana-intoxication-image-01.jpg
Completed Image ====&gt; 416.cute-grey-cat-play-hunter-with-kitten-doll-as-victim-lay-on-floor-keep-cats-from-eating-plants-weed-plant-video-why-does-my-eat-plastic.jpg
Completed Image ====&gt; 417.mouse-ear-chickweed-flower-300x200.jpg
Completed Image ====&gt; 418.catsear%20300.jpg
Completed Image ====&gt; 419.weed-control-in-gardens.png
Completed Image ====&gt; 420.48ee8437bb0c1a80eac6522bad6656ab--medicinal-plants-edible-plants.jpg
Completed Image ====&gt; 421.Chick-Weed-300x225.jpeg
Completed Image ====&gt; 422.100_6717-150x150.jpg
Completed Image ====&gt; 423.Barberry.jpg
Completed Image ====&gt; 424.maxresdefault.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 425.Carrot-Weed.jpg
Completed Image ====&gt; 426.522286_442253175816597_2146322357_n.jpg
Completed Image ====&gt; 427.elephant-ear-400x267.jpg
Completed Image ====&gt; 428.weeds-angled-onion.jpg
Completed Image ====&gt; 429.page_1_thumb_large.jpg
Completed Image ====&gt; 430.aquilegia1_24-5-2013.JPG
Completed Image ====&gt; 431.catsear09.jpg
Completed Image ====&gt; 432.gardening-25183771280.jpg
Completed Image ====&gt; 433.fathen_sm.jpg
Completed Image ====&gt; 434.cats-ear-plant-Hypochaeris-radicata.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Invalid or missing image format. Skipping...
Completed Image ====&gt; 435.purslaneedibleweed.JPG
Completed Image ====&gt; 436.Flick-weed.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 437.Prunella_vulgaris.4.jpg
Completed Image ====&gt; 438.1465FA7F-C301-4A42-9E71-94841CD48B44-600x600.png
Completed Image ====&gt; 439.catsear-or-false-dandelion-12apr14-sg.jpg
Completed Image ====&gt; 440.3500.jpg
Completed Image ====&gt; 441.Pic549-to-600.jpg
Completed Image ====&gt; 442.Greater-Plantain-MagicZoom.jpg
Completed Image ====&gt; 443.Bindii.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 444.amaranth-young.jpg
Completed Image ====&gt; 445.a1557035154_10.jpg
Completed Image ====&gt; 446.o50r2lets4hdmivvkekb.jpg
Completed Image ====&gt; 447.Golden_Chain__Laburnum_anagyroides_-001.JPG
Completed Image ====&gt; 448.original-grid-image-16561-1389327124-4.jpg
Completed Image ====&gt; 449.1555103.jpg
Completed Image ====&gt; 450.catsear-flower.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
IOError on an image...trying next one... Error: timed out
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 451.13612.jpg
Completed Image ====&gt; 452.Creeping-Oxalis.jpg
Completed Image ====&gt; 453.weeds-white-arum-lily.jpg
Completed Image ====&gt; 454.can-you-legally-get-your-pets-high-605-1433531189.jpg
Completed Image ====&gt; 455.dogs-and-marijuana-jpg.jpg
Completed Image ====&gt; 456.bracken-fern.jpg
Completed Image ====&gt; 457.248mbr.jpg
Completed Image ====&gt; 458.Taraxacum%20officinale%20flower%20n%20leaves%20FOM%200305.JPG
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 459.Golden_Chain__Laburnum_anagyroides_-001.JPG
Completed Image ====&gt; 460.page_1_thumb_large.jpg
Completed Image ====&gt; 461.Violet-MagicZoom.jpg
Completed Image ====&gt; 462.weeds-english-ivy.jpg
Completed Image ====&gt; 463.Pets-and-weed-killers5-2017.jpg
Completed Image ====&gt; 464.Bur-Chervil.jpg
Completed Image ====&gt; 465.Cat-rubbing-against-flower-pot-2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 466.agriculture-weeds-common-catsear-stock-photo__2370629.jpg
Completed Image ====&gt; 467.poison-hemlock-flowers-FML-small.jpg
Completed Image ====&gt; 468.Pic548-to-600.jpg
Completed Image ====&gt; 469.spring-flower-display-surrounding-cat-on-table-154456721-57dbf41f5f9b58651657b7f7.jpg
Completed Image ====&gt; 470.16946550711_23e5293dd0_b.jpg
Completed Image ====&gt; 471.tumblr_mfjyjzqhsk1r2sq16o1_500.jpg
Completed Image ====&gt; 472.sl4.jpg
Completed Image ====&gt; 473.weed_deadnettle_stock.jpg
Completed Image ====&gt; 474.catsear-flower-elena-perelman-canvas-print.jpg
Completed Image ====&gt; 475.Kerr-PoisonousPlants1007-2005-9.jpg
Completed Image ====&gt; 476.queen-annes-lace-bcfarmsandfood-350.jpg
Completed Image ====&gt; 477.feral-cats-threatening-hawaii_v.jpg
Completed Image ====&gt; 478.045-530x353.jpg
Completed Image ====&gt; 479.cat%20insurance%20cheat%20grass.jpg
Completed Image ====&gt; 480.cats-ear-id.jpg
Completed Image ====&gt; 481.A-dog-looking-confused-and-surprised.jpg
Completed Image ====&gt; 482.i-see-orange-weed-and-a-huge-chicken-and-a-idk-and-3-cats-and-2-little-kids_o_3780067.jpg
Completed Image ====&gt; 483.hypochaerisradicata13.jpg
Completed Image ====&gt; 484.cool-weed-dog-56cc88673df78cfb37a05c8d.jpg
Completed Image ====&gt; 485.catsear05.jpg
Completed Image ====&gt; 486.inner-banner.jpg
Completed Image ====&gt; 487.hryar0885w.jpg
Completed Image ====&gt; 488.tumblr_mwbql05glX1smbf1ao1_500.gif
Completed Image ====&gt; 489.Cannabis_d3df19_6276013.jpg
Completed Image ====&gt; 490.can-you-legally-get-your-pets-high-605-1433531189.jpg
Completed Image ====&gt; 491.Bindii.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 492.Cirsium_vulgare.1.jpg
Completed Image ====&gt; 493.Wild-Green-salad-900x900.jpg
Completed Image ====&gt; 494.maxresdefault.jpg
Completed Image ====&gt; 495.THINGS-C.jpg
Completed Image ====&gt; 496.e552a1409669b3da20115d918169fdae---day-blue-flowers.jpg
Completed Image ====&gt; 497.11huntcat.jpg
Completed Image ====&gt; 498.cat-allergies1.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 499.17742.jpg
Completed Image ====&gt; 500.2012-03-09+15.31.25.jpg
Completed Image ====&gt; 501.giphy.gif
Invalid or missing image format. Skipping...
Completed Image ====&gt; 502.foxtail-caused-by-heat.jpg
Completed Image ====&gt; 503.cats_ear_fruit.jpg
Completed Image ====&gt; 504.Clover%20Rabbitfoot.jpg
Completed Image ====&gt; 505.unknown_weed_rosette_30-1-2019_th.JPG
Completed Image ====&gt; 506.stale-seedbed-400x267.jpg
Completed Image ====&gt; 507.Virgo.jpg
Completed Image ====&gt; 508.962b1b4c21716cd4903b9f8b981fa6a1.jpg
Completed Image ====&gt; 509.silver_grass_flowerhead.jpg
Completed Image ====&gt; 510.Bindii-Jo-Jo.jpg
Completed Image ====&gt; 511.purslaneedibleweed.JPG
Completed Image ====&gt; 512.Chick-Weed-300x225.jpeg
Completed Image ====&gt; 513.man-picking-out-hairy-cat-ear-yard-doing-work-wild-weed-name-weed-93197658.jpg
Completed Image ====&gt; 514.weed-identification.jpg
Completed Image ====&gt; 515.artemesia_frigida.png
Completed Image ====&gt; 516.165wh.jpg
Completed Image ====&gt; 517.my-dog-wanted-to-help-me-pull-weeds-19504935.png
Completed Image ====&gt; 518.Hemlock__Conium_maculatum-2.JPG
Completed Image ====&gt; 519.Pic549-to-600.jpg
Completed Image ====&gt; 520.weeds-montbresia.jpg
Completed Image ====&gt; 521.cats-ear-2.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 522.1-img_1968.jpg
Completed Image ====&gt; 523.5-buttercup-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 524.weed-619-386.jpg
Completed Image ====&gt; 525.hyrad2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 526.SIP912141.jpg
Completed Image ====&gt; 527.Oxalis-Lawn-Weed-Source-Hans-Hillewaert-600x600.jpg
Completed Image ====&gt; 528.180921-urban-foraging-edible-weeds-chickweed-700x467.jpg
Completed Image ====&gt; 529.buttercup_sm.jpg
Completed Image ====&gt; 530.sl3.jpg
Completed Image ====&gt; 531.EquatorialOptimisticCrustacean-small.gif
Completed Image ====&gt; 532.catsear09.jpg
Completed Image ====&gt; 533.8340094778_1ee96fd317_b.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 534.best-med-cine-56cc88383df78cfb37a05c6c.jpg
Completed Image ====&gt; 535.1555114.jpg
Completed Image ====&gt; 536.agriculture-weeds-smooth-catsear-hypochaeris-glabra-aka-false-dandelion-flatweed-glabrous-catsear-flowering-plants-california-usa-x432r3.jpg
Completed Image ====&gt; 537.aquilegia2_24-5-2013.JPG
Completed Image ====&gt; 538.cats-catnip.jpg
Completed Image ====&gt; 539.cats-ear-dandelion-11666-rosette.jpg
Completed Image ====&gt; 540.Echium_vulgare.2.jpg
Completed Image ====&gt; 541.Greater-Plantain-MagicZoom.jpg
Completed Image ====&gt; 542.maxresdefault.jpg
Completed Image ====&gt; 543.tumblr_nb1icfniKz1qjof8lo1_500.jpg
Completed Image ====&gt; 544.capeweed_plants.jpg
Completed Image ====&gt; 545.P1010703.JPG
Completed Image ====&gt; 546.Jimson-Weed-Thinkstock-146897299-335lc031213.jpg
Completed Image ====&gt; 547.elephant-ear-400x267.jpg
Completed Image ====&gt; 548.poisoning.jpg
Completed Image ====&gt; 549.Khasia_Berry___Cotoneaster_simonsii-002.JPG
Completed Image ====&gt; 550.2011-04-17%2BMesa%2BCity%2BCemetery%2BVisit%2BApr%2B17%252C%2B2011%2B5-02%2BPM.jpg
Completed Image ====&gt; 551.daisy2-bcfarmsandfood-350.jpg
Completed Image ====&gt; 552.daisy-featured-300x225.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 553.weeds-japanese-honeysuckle.jpg
Completed Image ====&gt; 554.Pic543-copy-to-600.jpg
Completed Image ====&gt; 555.mistflower.png
Completed Image ====&gt; 556.thistle_sm.jpg
Completed Image ====&gt; 557.weed-herbarium-header-03.jpg
Completed Image ====&gt; 558.lambsquartersedibleweeds.jpg
Completed Image ====&gt; 559.165wh.jpg
Completed Image ====&gt; 560.12761486.jpg
Completed Image ====&gt; 561.weed_garlicmustard.jpg
Completed Image ====&gt; 562.Onion-Grass.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 563.unknown_weed_11-3-2017_th.JPG
Completed Image ====&gt; 564.sl2.jpg
Completed Image ====&gt; 565.Prunella_vulgaris.4.jpg
Completed Image ====&gt; 566.hairy-cats-ear-hypochaeris-radicata-E7E59K.jpg
Completed Image ====&gt; 567.1555099.jpg
Completed Image ====&gt; 568.Mouse-Ear-Hawkweed-MagicZoom.jpg
Completed Image ====&gt; 569.Carpet-Weed-300x225.jpeg
Completed Image ====&gt; 570.p1010850-2.jpeg
Completed Image ====&gt; 571.fathen.jpg
Completed Image ====&gt; 572.mile-a-minute-weed-400x300.jpg
Completed Image ====&gt; 573.OHW_hairy-leaves.jpg
Completed Image ====&gt; 574.Solanum_nigrum-003.JPG
Completed Image ====&gt; 575.3-daisy-weed-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 576.sorell.jpg
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 577.catsear06.jpg
Completed Image ====&gt; 578.chickweededible-1.jpg
Completed Image ====&gt; 579.fleabane.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 580.maxresdefault.jpg
Completed Image ====&gt; 581.cats-ear-dandelion-11666-backofleaf.jpg
Invalid or missing image format. Skipping...
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 582.weeds-sweet-pittosporum.jpg
Completed Image ====&gt; 583.unknown_rosette_4-1-2019_th.JPG
Completed Image ====&gt; 584.cat-garden-1024x680.jpg
Completed Image ====&gt; 585.Calluna_vulgaris.2.jpg
Completed Image ====&gt; 586.2012-05-04+08.22.23.jpg
Completed Image ====&gt; 587.Sick-cat-iStock_000024111758-335lc030314.jpg
Completed Image ====&gt; 588.1555107.jpg
Completed Image ====&gt; 589.spotted-cats-ear-FC9FY5.jpg
Completed Image ====&gt; 590.mouse-ear-chickweed-featured-300x225.jpg
Completed Image ====&gt; 591.Purple_toadflax__Linaria_purpurea_-1.JPG
Completed Image ====&gt; 592.sl6.jpg
Completed Image ====&gt; 593.OHW_impact-small.jpg
Completed Image ====&gt; 594.Creeping-Buttercup-MagicZoom.jpg
Completed Image ====&gt; 595.yorkshire_fog_flowerheads.jpg
Completed Image ====&gt; 596.hedge-bindweed-morning-glory-bcfarmsandfood-350.jpg
Completed Image ====&gt; 597.hryra8645w.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 598.cats-ear-dandelion-11666-p1060809-catseardandelion.jpg
Completed Image ====&gt; 599.dandelion-growing-in-lawn-c836e0d1.jpg
Completed Image ====&gt; 600.catsear14.jpg
Completed Image ====&gt; 601.curlydock.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 602.Rubus_armeniacus.2.jpg
Completed Image ====&gt; 603.2012-03-03+12.44.26.jpg
Completed Image ====&gt; 604.hqdefault.jpg
Completed Image ====&gt; 605.feathery_weed_30-12-2017_th.JPG
Completed Image ====&gt; 606.wireweed1.jpg
Completed Image ====&gt; 607.fathen.jpg
Completed Image ====&gt; 608.weed-killer.jpg
Completed Image ====&gt; 609.cats_ear_branching_stem.jpg
Completed Image ====&gt; 610.vetch2-bcfarmsandfood-350.jpg
Completed Image ====&gt; 611.yellow-salsify-broadleaf-biennial-perennial-weed-detail-ed4e71e5_0.jpg
Completed Image ====&gt; 612.hryra3805w.jpg
Completed Image ====&gt; 613.star-wars-weed-control.jpg
Completed Image ====&gt; 614.wildflowers-cats-ear-bladder-campion-red-clover-on-the-side-of-a-path-with-mountains-in-the-background-fulpmes-austria-MMB3D0.jpg
Completed Image ====&gt; 615.Use-a-Knapsack-Sprayer-for-Lawn-Care.jpg
Completed Image ====&gt; 616.catsear08.jpg
Completed Image ====&gt; 617.Leycesteria_formosa.2.jpg
Completed Image ====&gt; 618.maxresdefault.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 619.aquilegia1_24-5-2013.JPG
Completed Image ====&gt; 620.weed-killers.jpg
Completed Image ====&gt; 621.mouseear-chickweed-11495-weed1.jpg
Completed Image ====&gt; 622.4-plantain-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 623.Poa_annua.jpg
Completed Image ====&gt; 624.catsear10.jpg
Completed Image ====&gt; 625.Cichorium_intybus.1.jpg
Completed Image ====&gt; 626.low_rosette_weed_27-4-2015_th.jpg
Completed Image ====&gt; 627.100873658.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 628.maxresdefault.jpg
Completed Image ====&gt; 629.lawn-weeds-header.jpg
Completed Image ====&gt; 630.6-horsetail-bcfarmsandfood-600x450.jpg
Completed Image ====&gt; 631.cats-ear-spotted-cats-ear-gosmore-hairy-cats-ear-spotted-cats-ear-hypochaeris-radicata-hypochoeris-radicata-blooming-germany-XB4BT9.jpg
Completed Image ====&gt; 632.Spot-Spray-Weeds.jpg
Completed Image ====&gt; 633.mouse_ear_chickweed_mature.jpg
Completed Image ====&gt; 634.Tragopogon_spp.3.jpg
Completed Image ====&gt; 635.unknown_rosette_Pratt_St_16-2-2019.JPG
Completed Image ====&gt; 636.SIP949359.jpg
Completed Image ====&gt; 637.Hieracium_albiflorum.jpg
Completed Image ====&gt; 638.wild%20radish.jpg
Completed Image ====&gt; 639.maxresdefault.jpg
Completed Image ====&gt; 640.unknown_rosette_St_Pancras_Way_16-2-2019.JPG
Completed Image ====&gt; 641.Physalis_peruviana.1.jpg
Completed Image ====&gt; 642.101298339.jpg
Completed Image ====&gt; 643.maxresdefault.jpg
Completed Image ====&gt; 644.maxresdefault.jpg


Unfortunately all 1000 could not be downloaded because some images were not downloadable. 644 is all we got for this search filter!

Errors: 60

</pre></div>
</div>
<div class="outline-4" id="outline-container-org8fca318">
<h4 id="org8fca318">Purslane</h4>
<div class="outline-text-4" id="text-org8fca318">
<div class="highlight">
<pre><span></span>keywords["keywords"] = "purslane"
purslane_paths = google_images.download(keywords)
</pre></div>
<pre class="example">

Item no.: 1 --&gt; Item name = purslane
Evaluating...
Getting you a lot of images. This may take a few moments...
Reached end of Page.
Starting Download...
Completed Image ====&gt; 1.A1mZr5a-KdL._SX425_.jpg
Completed Image ====&gt; 2.portulaca_oleracea_jacopo_venturagettyimages-crop.jpg
Completed Image ====&gt; 3.purslane-vertical-jpg.jpg
Completed Image ====&gt; 4.purslane-jpg.jpg
Completed Image ====&gt; 5.forageharvestfeast-purslane-banner-panorama.jpg
Completed Image ====&gt; 6.image-e1478826507715.jpeg
Completed Image ====&gt; 7.purslane-weed-520x390.jpg
Completed Image ====&gt; 8.2017-08-07-purslane-3-1024x768.jpg
Completed Image ====&gt; 9.purslane-1.jpg
Completed Image ====&gt; 10.purslane-all-mixed-up.jpg
Completed Image ====&gt; 11.Flowering-Purslane-900x1200.jpg
Completed Image ====&gt; 12.dsc_0045.jpg
Completed Image ====&gt; 13.Green-Leaf-French-Purslane-1.jpg
Completed Image ====&gt; 14.B9318213314Z.1_20150726075335_000_GEFBELDG9.1-0.jpg
Completed Image ====&gt; 15.costa-farms-annuals-4purspnk4pk-64_1000.jpg
Completed Image ====&gt; 16.5ac92729-purslane-plant-300x225.jpg
Completed Image ====&gt; 17.purslane-poisoning-.jpg
Completed Image ====&gt; 18.V_SaladGreens_Purslane.jpg
Completed Image ====&gt; 19.71v7yrDNNEL._SX425_.jpg
Completed Image ====&gt; 20.purslane-leaves.jpg
Completed Image ====&gt; 21.purslane.png
Completed Image ====&gt; 22.flowering-jpg.jpg
Completed Image ====&gt; 23.Purslane_seeds.jpg
Completed Image ====&gt; 24.colorful-portulaca-purslane-1080x520.jpg
Completed Image ====&gt; 25.Portulaca-Annual-Flower-HERO-Costa-Farms.jpg
Completed Image ====&gt; 26.Greens-Green-Purslane-LSS-000_4586.jpg
Completed Image ====&gt; 27.g40-2.jpg
Completed Image ====&gt; 28.Greens-Golden-Purslane-LSS-000_4577.jpg
Completed Image ====&gt; 29.pruslane-weed-or-food-growagoodlife.jpg
Completed Image ====&gt; 30.portulaca_mojave_fuchsia_improved_0.jpg
Completed Image ====&gt; 31.purslane-herb1-400x533.jpg
Completed Image ====&gt; 32.MG_6673.jpg
Completed Image ====&gt; 33.Purslane-Portulaca-Oleracea-Seeds.jpg
Completed Image ====&gt; 34.purslane_Melinda-600x347.jpg
Completed Image ====&gt; 35.Purslane.jpg
Completed Image ====&gt; 36.market_purslane_marieviljoen_gardenista.jpg
Completed Image ====&gt; 37.2011-08-02-at-15-11-23-1024x775.jpg
Completed Image ====&gt; 38.Purslane_Portulacca_oleracea_300-300x295.jpg
Completed Image ====&gt; 39.Purslane-GettyImages-746030149-5a3754d37bb28300370c9e8a.jpg
Completed Image ====&gt; 40.IMG_1789.jpg
Completed Image ====&gt; 41.purslane-poisoning.jpg
Completed Image ====&gt; 42.00386_01_goldenpurslane.jpg
Completed Image ====&gt; 43.purslane-2017-02.jpg
Completed Image ====&gt; 44.bebe45.jpg
Completed Image ====&gt; 45.51LRpVJ1AqL._SX425_.jpg
Completed Image ====&gt; 46.s-l640.jpg
Completed Image ====&gt; 47.080098_1.jpg
Completed Image ====&gt; 48.1*xfhwkB61ih2RR_bfUlb_0g.jpeg
Completed Image ====&gt; 49.Gruner-Red-purslane_grande.jpg
Completed Image ====&gt; 50.Portulaca-Pazzaz-Salmon-Glow-Costa-Farms-Annaul-Flower.jpg
Completed Image ====&gt; 51.Sea-purslane-retail-4-inch-copy.jpg
Completed Image ====&gt; 52.t7569_718x404.jpg
Completed Image ====&gt; 53.81ZrVgVrtyL._SX425_.jpg
Completed Image ====&gt; 54.sg20170724_pizazz.jpg
Completed Image ====&gt; 55.purslane-emily-peterson.jpg
Completed Image ====&gt; 56.Greens-Green-Purslane-LSS-000_4590.jpg
Completed Image ====&gt; 57.mojave_pink_0.jpg
Completed Image ====&gt; 58.292681.jpg
Completed Image ====&gt; 59.5b63151d4552a.image.jpg
Completed Image ====&gt; 60.pulling-up-purslane-GettyImages-1089332232-1200x798.jpg
Completed Image ====&gt; 61.VELEA19595_3.jpg
Completed Image ====&gt; 62.prod001969.jpg
Completed Image ====&gt; 63.p-10238-green_purslanemunich1.jpg
Completed Image ====&gt; 64.purslane_LRG.jpg
Completed Image ====&gt; 65.Common-Purslane-Spreading-Throughout-a-Garden-Bed-400x300.jpg
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1056)&gt;
Completed Image ====&gt; 66.il_794xN.1663722208_eh8a.jpg
Completed Image ====&gt; 67.Dont-Pick-This-Weed-If-It-Is-Growing-In-Your-Yard3.jpg
Completed Image ====&gt; 68.Verdolga.jpg
Completed Image ====&gt; 69.purslane-by-sidewalk.jpg
Completed Image ====&gt; 70.9909846.jpg
Completed Image ====&gt; 71.purslane_wild_crafted2.jpg
Completed Image ====&gt; 72.51bXpreO7zL._SX425_.jpg
Completed Image ====&gt; 73.il_794xN.1248151685_5pbi.jpg
Completed Image ====&gt; 74.purslane.jpg
Completed Image ====&gt; 75.tallgreenpurslane.JPG
Completed Image ====&gt; 76.blogger-image-1003545452.jpg
Completed Image ====&gt; 77.Purslane-in-a-furrow-no-attribution-FEATURE.jpg
Completed Image ====&gt; 78.green-purslane.jpg
Completed Image ====&gt; 79.purslanegolden.jpg
Completed Image ====&gt; 80.PUGR-purslane-summer.jpg
Completed Image ====&gt; 81.5502548-3x2-340x227.jpg
Completed Image ====&gt; 82.GOLDENPURSLANE.JPG
Completed Image ====&gt; 83.purslane-green-seed-wm_700_1400x.jpg
Completed Image ====&gt; 84.purslane.jpg
Completed Image ====&gt; 85.535-2.jpg
Completed Image ====&gt; 86.purslane-cu.jpg
Completed Image ====&gt; 87.Purslane-bowl.jpg
Completed Image ====&gt; 88.purslane.png
Completed Image ====&gt; 89.61y-UAoDskL._SX425_.jpg
Completed Image ====&gt; 90.il_fullxfull.1248144557_f66w.jpg
Completed Image ====&gt; 91.636663175704775283-DSC-0604.JPG
Completed Image ====&gt; 92.purslane-stems-big-580ffbda3df78c2c7309eb98.jpg
Completed Image ====&gt; 93.portulaca_large.jpg
Completed Image ====&gt; 94.26446z.jpg
Completed Image ====&gt; 95.Purslane1.jpg
Completed Image ====&gt; 96.774optimized.jpg
Completed Image ====&gt; 97.mojave_tangerine_0.jpg
Completed Image ====&gt; 98.1.jpg
Completed Image ====&gt; 99.snv8507-web_1.jpg
Completed Image ====&gt; 100.purslane-white.jpg
Completed Image ====&gt; 101.774optimized.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 102.Purslane-Green-LSS-000_2016.jpg
Completed Image ====&gt; 103.Green-purslane-(Portulaca-oleracea).jpg
Completed Image ====&gt; 104.IMG_3868-1024x768.jpg
Completed Image ====&gt; 105.purslane-green-portulaca-oleracea-sativa-seeds-amkha-seed_716.jpg
Completed Image ====&gt; 106.GoldbergGolden_605f51ac-4470-44a2-8987-f8abb00a40dd_grande.jpg
Completed Image ====&gt; 107.83356046-a-photo-of-green-purslane-pussley-or-purslane-flowers-portulaca-oleracea-l-and-green-leaves-top-view.jpg
Completed Image ====&gt; 108.sg20170724_mojave.jpg
Completed Image ====&gt; 109.purslane05.jpg
Completed Image ====&gt; 110.portulaca-oleracea-flower-buds.jpg
Completed Image ====&gt; 111.image-placeholder-title.jpg
Completed Image ====&gt; 112.Purslane-blooms-web.jpg
Completed Image ====&gt; 113.Sea-Purslane-photo1.jpg
Completed Image ====&gt; 114.500x375.JPG
Completed Image ====&gt; 115.10purslane1-cityroom-blogSpan.jpg
Completed Image ====&gt; 116.FSS20021PF-2.jpg
Completed Image ====&gt; 117.20-ways-to-Eat-Purslane-640x360.jpg
Completed Image ====&gt; 118.golden_purslane_marieviljoen_gardenista-e1474238985853.jpg
Completed Image ====&gt; 119.Purslane.jpg
Completed Image ====&gt; 120.purslane-rose.jpg
Completed Image ====&gt; 121.purslane-mass.jpg
Completed Image ====&gt; 122.Purslane-Green-LSS-000_2015.jpg
Completed Image ====&gt; 123.portulaca_oleracea_purslane-300x200.jpg
Completed Image ====&gt; 124.IMG_1754__05181.1457119760.JPG
Completed Image ====&gt; 125.53532003-common-purslane-verdolaga-pigweed-little-hogweed-or-pusley-flower.jpg
Completed Image ====&gt; 126.Common_purslane_-_Flickr_-_pellaea-880x495.jpg
Completed Image ====&gt; 127.purslane1.jpg
Completed Image ====&gt; 128.purslane-seeds-500x500.jpg
Completed Image ====&gt; 129.55296_original.jpg
Completed Image ====&gt; 130.purslane-seeds-2.jpg
Completed Image ====&gt; 131.vitamins-supplements-herbs_herbs_powers-of-purslane_545677448-600x450.jpg
Completed Image ====&gt; 132.Purslane-thick-leaves-high-in-omegas_620x.jpg
Completed Image ====&gt; 133.55294_original.jpg
Completed Image ====&gt; 134.Purslane-1-748x421.jpg
Completed Image ====&gt; 135.portulacaoleraceaseedswildfoodism.jpg
Completed Image ====&gt; 136.purslane2.jpg
Completed Image ====&gt; 137.Purslane_004MO.jpg
Completed Image ====&gt; 138.purslane.png
Completed Image ====&gt; 139.prod001969.jpg
Completed Image ====&gt; 140.123111-004-F6824B8B.jpg
Completed Image ====&gt; 141.99050531-flowers-of-portulaca-purslane-sun-plant-common-purslane-verdolaga-pigweed-little-hogweed-pusley.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 142.purslaneP.jpg
Completed Image ====&gt; 143.purslane-omega-3.jpg
Completed Image ====&gt; 144.s-l300.jpg
Completed Image ====&gt; 145.6420-purslane.jpg
Completed Image ====&gt; 146.W2IQIZBI5NF77G7FUHXPWR2MC4.jpg
Completed Image ====&gt; 147.DSCN1054.jpg
Completed Image ====&gt; 148.purslane-closeup-flower.jpg
Completed Image ====&gt; 149.369315.jpg
Completed Image ====&gt; 150.81xyPBI8o%2BL._SX466_.jpg
Completed Image ====&gt; 151.Slide05.jpg
Completed Image ====&gt; 152.purslane-samba-hot-rose.jpg
Completed Image ====&gt; 153.Purslane_Toucan_Scarlet_Shades_Seeds_Portulaca_Oleracea__44372.1507010678.jpg
Completed Image ====&gt; 154.0179Portulaca-oleracea,-Common-Purslane700x467.jpg
Completed Image ====&gt; 155.forage-harvest-feast_purslane-300x293.jpg
Completed Image ====&gt; 156.Purslane_golden_potted_300-300x285.jpg
Completed Image ====&gt; 157.img_0120-500x500.jpg
Completed Image ====&gt; 158.29019848146_230eeae4fd_b.jpg
Completed Image ====&gt; 159.maxresdefault.jpg
Completed Image ====&gt; 160.Foraging-for-Edible-Plants.jpg
Completed Image ====&gt; 161.022532098171.jpg
Completed Image ====&gt; 162.purslane.jpg
Completed Image ====&gt; 163.purslane-02.jpg
Completed Image ====&gt; 164.0808-GT-WN01.01-6x4.jpg
Completed Image ====&gt; 165.purslane-verdolagas-in-small-pot.jpg
Completed Image ====&gt; 166.lx-purslane.png
Completed Image ====&gt; 167.s-l300.jpg
Completed Image ====&gt; 168.Purlane-Flower.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 169.LL31Purslane.jpg
Completed Image ====&gt; 170.PURSLANE-1.jpg
Completed Image ====&gt; 171.rockpurslane.jpg
Completed Image ====&gt; 172.Purslane-Friend-or-Foe-of-the-Garden.jpg
Completed Image ====&gt; 173.Untitled-1.jpg
Completed Image ====&gt; 174.54b660b907e6d.image.jpg
Completed Image ====&gt; 175.14777329865_806cae6160_z.jpg
Completed Image ====&gt; 176.purslane.jpg
Completed Image ====&gt; 177.pourpier.jpg
Completed Image ====&gt; 178.429-purslane.jpg
Completed Image ====&gt; 179.portulaca_mojave_red_improved.jpg
Completed Image ====&gt; 180.purslane-golden-portulaca-oleracea-sativa-seeds-amkha-seed_252.jpg
Completed Image ====&gt; 181.128125222-56b09e5c3df78cf772d00f44.jpg
Completed Image ====&gt; 182.Purslane-a-vining-healthy-green_620x.jpg
Completed Image ====&gt; 183.Purslane-weed.jpg
Completed Image ====&gt; 184.516ukgfiC1L._SX425_.jpg
Completed Image ====&gt; 185.Greens-Green-Purslane-LSS-000_4585.jpg
Completed Image ====&gt; 186.1.jpg
Completed Image ====&gt; 187.purslane-flowerbud.jpg
Completed Image ====&gt; 188.Purslane.jpg
Completed Image ====&gt; 189.Portulaca-Grandiflora-bonsai-Mixed-Color-Moss-Rose-Purslane-Double-Flower-plant-For-Planting-Heat-Tolerant-Easy.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 190.purslane.jpg
Completed Image ====&gt; 191.958_6713_large.jpg
Completed Image ====&gt; 192.2017-06-04_1.jpg
Completed Image ====&gt; 193.MS487-12_480x480.jpg
Completed Image ====&gt; 194.83356042-a-photo-of-green-purslane-pussley-or-purslane-flowers-portulaca-oleracea-l-and-green-leaves-top-view.jpg
Completed Image ====&gt; 195.PurslaneFeature.jpg
Completed Image ====&gt; 196.Purslane+1+Phillips.jpg
Completed Image ====&gt; 197.purslane-poisoning-1.jpg
Completed Image ====&gt; 198.3-22Purslane%20to%20eat%20-2.jpg
Completed Image ====&gt; 199.778optimized.jpg
Completed Image ====&gt; 200.Common-purslane-Portulaca-oleracea-400x300.jpg
Completed Image ====&gt; 201.5d635b96-2506-4831-a9c3-7c23ba043e9a.jpeg
Completed Image ====&gt; 202.DSC0434.jpg
Completed Image ====&gt; 203.purslane-intro.jpg
Completed Image ====&gt; 204.purslane-stem.jpg
Completed Image ====&gt; 205.Purslane_Toucan_Fuchsia_Seeds_Portulaca_Oleracea.jpg
Completed Image ====&gt; 206.purslane-3.jpg
Completed Image ====&gt; 207.purslane-and-portulaca-4.jpg
Completed Image ====&gt; 208.Sea-Purslane-Sesuvium-portulacastrum-2.jpg
Completed Image ====&gt; 209.Common-purslane-fruit.jpg
Completed Image ====&gt; 210.ngi-purslane-salad.jpg
Completed Image ====&gt; 211.purslane-evening-wine.jpg
Completed Image ====&gt; 212.pink-purslane-11609-pinkpurslane-p1110521.jpg
Completed Image ====&gt; 213.hogweed1200.jpg
Completed Image ====&gt; 214.purslane_1260x630.jpg
Completed Image ====&gt; 215.D7s7CnjWsAE5jO6.jpg
Completed Image ====&gt; 216.purslane-herb-img.jpg
Completed Image ====&gt; 217.purslane-1024x768.jpg
Completed Image ====&gt; 218.MS486-12_480x480.jpg
Completed Image ====&gt; 219.91Ug47IDCfL._SL1500_.jpg
Completed Image ====&gt; 220.Close-up-flower-of-Purslane.jpg
Completed Image ====&gt; 221.51fb91dcfa534494fc9494b7d34060cc.jpg
Completed Image ====&gt; 222.Purslane.jpg
Completed Image ====&gt; 223.Purslane_-Lynn-Sosnoskie-University-of-Georgia-Bugwood.org_-450x440.jpg
Completed Image ====&gt; 224.IMG_1054.jpg
Completed Image ====&gt; 225.Green_Leaf_French_Purslane__30637.1499125232.500.750.jpg
Completed Image ====&gt; 226.purslane.jpg
Completed Image ====&gt; 227.Purslane.jpg
Completed Image ====&gt; 228.purslane-flowers.jpg
Completed Image ====&gt; 229.purslane-garden.jpg
Completed Image ====&gt; 230.rBVaI1oRe--AT6L4AAPRaPkf1Xk868.jpg
Completed Image ====&gt; 231.4873654099_b6a4e38a75_z.jpg
Completed Image ====&gt; 232.200908-r-xl-chilled-zucchini-soup-with-purslane.jpg
Completed Image ====&gt; 233.s-l300.jpg
Completed Image ====&gt; 234.2-purslane.jpg
Completed Image ====&gt; 235.maxresdefault.jpg
Completed Image ====&gt; 236.Tall-Green-Purslane_03899770-bfb9-46b6-bcf3-c45c2f4218f2_grande.jpg
Completed Image ====&gt; 237.purslane-fb.jpg
Completed Image ====&gt; 238.Purslane.jpg
Completed Image ====&gt; 239.purslane-fresh-640-325x260.jpg
Completed Image ====&gt; 240.pourpier.jpg
Completed Image ====&gt; 241.2040_dbweb.jpg
Completed Image ====&gt; 242.Purslane+2+Licher.jpg
Completed Image ====&gt; 243.purslane-plant.jpg
Completed Image ====&gt; 244.Portulaca_oleracea_8349675986.jpg
Completed Image ====&gt; 245.76236390-common-purslane-verdolaga-or-pusley-flower-in-the-garden.jpg
Completed Image ====&gt; 246.Pickled-Purslane-760x428.jpg
Completed Image ====&gt; 247.102966_01_600x600.jpg
Completed Image ====&gt; 248.rbrain.lambs_.quarter.jpg
Completed Image ====&gt; 249.0180Portulaca-oleracea,-Common-Purslane700x467.jpg
Completed Image ====&gt; 250.Purslane.jpg
Completed Image ====&gt; 251.Golden-Leaf-French-Purslane-Seeds-Portulaca-oleracea-sativa_2_1024x1024_1d116f88-6242-4835-a3fe-46bd3d86e86a_1024x1024.jpg
Completed Image ====&gt; 252.product_4886.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 253.20100827-purslane-primary.jpg
Completed Image ====&gt; 254.Common-purslane.jpg
Completed Image ====&gt; 255.purslane-plant-big.jpg
Completed Image ====&gt; 256.5515.png
Completed Image ====&gt; 257.05recipehealth_600-articleLarge.jpg
Completed Image ====&gt; 258.il_794xN.1858839783_sn9f.jpg
Completed Image ====&gt; 259.purslane-jumbo-mango.jpg
Completed Image ====&gt; 260.purslane-2010.jpg
Completed Image ====&gt; 261.verdolaga-purslane-recipes-cover.jpg
Completed Image ====&gt; 262.purslane-picture.jpg
Completed Image ====&gt; 263.Purslane-flower-21.jpg
Completed Image ====&gt; 264.P1050280.jpg
Completed Image ====&gt; 265.purslane_marieviljoen_gardenista.jpg
Completed Image ====&gt; 266.purslane-page_orig.jpg
Completed Image ====&gt; 267.Purslane.jpg
Completed Image ====&gt; 268.55295_original.jpg
Completed Image ====&gt; 269.PurslanePlant1.jpg
Completed Image ====&gt; 270.purslane_IMGP1791.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 271.maxresdefault.jpg
Completed Image ====&gt; 272.purslane-001-Medium1.jpg
Completed Image ====&gt; 273.d5qjh9c_purslane_625x300_21_September_18.jpg
Completed Image ====&gt; 274.portulaca-oleracea-1.jpg
Completed Image ====&gt; 275.Front%20-%20Purslane.jpg
Completed Image ====&gt; 276.forage-harvest-feast_purslane-2.jpg
Completed Image ====&gt; 277.Portulaca-oleracea-Common-Purslane.jpg
Completed Image ====&gt; 278.purslane.JPG
Completed Image ====&gt; 279.Portulaca-Golden-Purslane-Plant.jpg
Completed Image ====&gt; 280.90371369-common-purslane-flower-in-garden-.jpg
Completed Image ====&gt; 281.flowers_750.jpg
Completed Image ====&gt; 282.purslane.jpg
Completed Image ====&gt; 283.500PCS-Mixed-Color-Moss-Rose-Purslane-Double-Flower-Seeds-For-Planting-Portulaca-Grandiflora-Heat-Tolerant-easy_grande_20220c06-e70c-40e5-afdc-48209a343aa6_x700.jpg
Completed Image ====&gt; 284.Purslane_1-for-web-Photo-credit-Howard-Schwartz.jpg
Completed Image ====&gt; 285.Herb-Green-Purslane-DSC03937.jpg
Completed Image ====&gt; 286.purslane-2017-01.jpg
Completed Image ====&gt; 287.purslane-1-400x300.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 288.a-close-up-view-of-common-purslane-portulaca-oleracea-focusing-on-K06TF5.jpg
Completed Image ====&gt; 289.purslane3.jpg
Completed Image ====&gt; 290.fab61s00g.jpg
Completed Image ====&gt; 291.purslane-flower-purslane-yellow-flower-132358967.jpg
Completed Image ====&gt; 292.purslane-bud.jpg
Completed Image ====&gt; 293.purslane-young.jpg
Completed Image ====&gt; 294.10004-featured_image-why-the-health-boosting-purslane-is-more-vegetable-than-weed.jpg
Completed Image ====&gt; 295.purslane-portulaca-oleraceae-young-plant-with-other-weeds-in-arable-seedbed-XDP50W.jpg
Completed Image ====&gt; 296.purslane-light-pink.jpg
Completed Image ====&gt; 297.Purslane+3+Makings.JPG
Completed Image ====&gt; 298.purslane-recipes.jpg
Completed Image ====&gt; 299.Luni-Purslane-Portulaca-Luniya-Noniya-Gonu.jpg
Completed Image ====&gt; 300.Portulaca-oleracea-Common-Purslane2.jpg
Completed Image ====&gt; 301.weeds_purslane4_zoom.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 302.img_86151.jpg
Completed Image ====&gt; 303.Purslane+1.jpg
Completed Image ====&gt; 304.habit_2_750.jpg
Completed Image ====&gt; 305.Portulaca_oleracea.6.jpg
Completed Image ====&gt; 306.Rock-purslane-400x267.jpg
Completed Image ====&gt; 307.RNP-1-4.jpg
Completed Image ====&gt; 308.growing_purslane_portulaca_x1.jpg
Completed Image ====&gt; 309.Water-purslane-1.gif
Completed Image ====&gt; 310.400-04773147c-Masterfile-loskutnikov_field_img_hero_988_380.webp
Completed Image ====&gt; 311.Purslane-web.jpg
Completed Image ====&gt; 312.main-img2.JPG
Completed Image ====&gt; 313.2013-0824-img_2513-purslane-in-field.jpg
Completed Image ====&gt; 314.claytonia_2000x.jpg
Completed Image ====&gt; 315.16467846-little-common-purslane-flowers.jpg
Completed Image ====&gt; 316.8960Portulaca-oleracea,-Common-Purselane350x350.jpg
Completed Image ====&gt; 317.Purslane-mulch1.jpg
Completed Image ====&gt; 318.purslane.jpg
Completed Image ====&gt; 319.Purslane-2-1.jpg
Completed Image ====&gt; 320.purslane-and-portulaca-6.jpg
Completed Image ====&gt; 321.cpurse2.JPG
Completed Image ====&gt; 322.SortingPurslanebyWayneMarshall.jpg
Completed Image ====&gt; 323.purslane-seeds.jpg
Completed Image ====&gt; 324.foo_22purslane.jpg
Completed Image ====&gt; 325.winterpurslane.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 326.DFEbkPwUAAExbfp.jpg
Completed Image ====&gt; 327.Portulaca-cupcake-peachy-Costa-Farms-annual-Flower.jpg
Completed Image ====&gt; 328.Herb-Golden-Purslane-HB222-DSC06838.jpg
Completed Image ====&gt; 329.TWE-Purslane-1100x550-c-center.png
Completed Image ====&gt; 330.HPL.Vegetative1.jpg
Completed Image ====&gt; 331.aid8846487-v4-728px-Harvest-Purslane-Step-9.jpg
Completed Image ====&gt; 332.sg100617_200.jpg
Completed Image ====&gt; 333.purslane.jpg
Completed Image ====&gt; 334.cpurse3.JPG
Completed Image ====&gt; 335.8142761aaa118c6e0b6734373d724098.jpg
Completed Image ====&gt; 336.30422405_1649662378454209_1691706053_n.jpg
Completed Image ====&gt; 337.purslane-path.jpg
Completed Image ====&gt; 338.purslane_leaves_edited_300.jpg
Completed Image ====&gt; 339.purslane.jpg
Completed Image ====&gt; 340.purslane-jumbo-punch.jpg
Completed Image ====&gt; 341.foraging-for-purslane.jpg
Completed Image ====&gt; 342.portulaca-oleracea-855543_960_720.jpg
Completed Image ====&gt; 343.DETA-1164.jpg
Completed Image ====&gt; 344.crop_common_purslane_growth_habit_lynn_sosnoskie_university_of_georgia_bugwood.jpg
Completed Image ====&gt; 345.7094a5-250.jpg
Completed Image ====&gt; 346.Purslane-Weed-1.jpg
Completed Image ====&gt; 347.tiny-yellow-purslane-flower.jpg
Completed Image ====&gt; 348.9909983_f520.jpg
Completed Image ====&gt; 349.maxresdefault.jpg
Completed Image ====&gt; 350.img1156.jpg
Completed Image ====&gt; 351.Purslane-in-the-Garden-768x1024.jpg
Completed Image ====&gt; 352.purslane.jpg
Completed Image ====&gt; 353.Purslane-Portulaca-aleracea-Pic-2.jpg
Completed Image ====&gt; 354.common-purslane-X7RDA8.jpg
Completed Image ====&gt; 355.Portulaca_olera_400.jpg
Completed Image ====&gt; 356.775optimized.jpg
Completed Image ====&gt; 357.s-l300.jpg
Completed Image ====&gt; 358.Purslane-Groundcover.jpg
Completed Image ====&gt; 359.file-20-01-2018-08-24-25.jpeg
Completed Image ====&gt; 360.Purslane-facts-and-health-benefits.jpg
Completed Image ====&gt; 361.purslane-weed.jpg
Completed Image ====&gt; 362.stems_750.jpg
Completed Image ====&gt; 363.1488566365Purslane-Portulaca-oleracea-form.jpg
Completed Image ====&gt; 364.Purslane_ip_0038.jpg
Completed Image ====&gt; 365.purslane-blog-header-1.jpg
Completed Image ====&gt; 366.14448499-common-purslane.jpg
Completed Image ====&gt; 367.Purslane.jpg
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)&gt;
Completed Image ====&gt; 368.rbrain.purslane.jpg
Completed Image ====&gt; 369.Purslane-Rio-Orange.jpg
Completed Image ====&gt; 370.purslane_-Tico-.jpg
Completed Image ====&gt; 371.101_1078.JPG
Completed Image ====&gt; 372.6292408931_c96b4440b8_b.jpg
Completed Image ====&gt; 373.5959808111_49952ffa46_z2.jpg
Completed Image ====&gt; 374.purslaneprod.jpg
Completed Image ====&gt; 375.purslane-health-benefits-2-03312016.jpg
Completed Image ====&gt; 376.Common-purslane-web.jpg
Completed Image ====&gt; 377.1402870328.jpg
Completed Image ====&gt; 378.edible-weeds-purslane-living-awarness.png
Completed Image ====&gt; 379.purslanedalcopyrightedimage1.jpg
Completed Image ====&gt; 380.verdolaga1.jpg
Completed Image ====&gt; 381.tasting-georgia-carla-capalbo-food-eating-weed-1.jpg
Completed Image ====&gt; 382.purslane-egg-salad-640.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 383.purslane.jpg
Completed Image ====&gt; 384.Purslane.jpg
Completed Image ====&gt; 385.Purslane-in-Sweet-Potato-Vines-300x173.jpg
Completed Image ====&gt; 386.purslane+2.png
Completed Image ====&gt; 387.1*-opEI2xzRT3r0yR6QnZo3A.jpeg
Completed Image ====&gt; 388.portulaca-oleracea-14.jpg
Completed Image ====&gt; 389.Upright-Portulaca.jpg
Completed Image ====&gt; 390.l_11641_porcellana-comune-erbe-commestibili.jpg
Completed Image ====&gt; 391.IMG_4922.jpg
Completed Image ====&gt; 392.verdolaga-purslane-recipes-purslane-closeup.jpg
Completed Image ====&gt; 393.20160701Portulaca_oleracea2.jpg
Completed Image ====&gt; 394.Portulaca_Scott_zona+via+flickr.jpg
Completed Image ====&gt; 395.DETA-233.jpg
Completed Image ====&gt; 396.purslane-3894134_960_720.jpg
Completed Image ====&gt; 397.photo-credit-ahmet7-1-900x900.jpg
Completed Image ====&gt; 398.Portulaca_oleracea_Ja_ao_1.jpg
Completed Image ====&gt; 399.Purslane.JPG
Completed Image ====&gt; 400.rdc-ad_102675.jpg
Completed Image ====&gt; 401.20130820-foraged-inbag.jpg
Completed Image ====&gt; 402.GREEN-FUSE-PURSLANE-HOT-SHOT-ROSE-FLAMBEAU-088.jpg
Completed Image ====&gt; 403.DSCN0516new-56a993a43df78cf772a87ae9.jpg
Completed Image ====&gt; 404.18796144252_7978fcbf02_b.jpg
Completed Image ====&gt; 405.purslane-benefits-696x463.jpg
Completed Image ====&gt; 406.purslane-samba-pink-bicolor.jpg
Completed Image ====&gt; 407.hqdefault.jpg
Completed Image ====&gt; 408.garden-portulaca-common-purslane-verdolaga-pigweed-little-hogweed-pusley-plants-blossom-red-flowers-sunny-dayn-126167445.jpg
Completed Image ====&gt; 409.ddd6aeb4fe.jpg
Completed Image ====&gt; 410.The-succulent-leaves-of-Portulaca-oleracea-purslane-is-also-used-in-the-Middle-East-and.png
Completed Image ====&gt; 411.purslane-3.jpg
Completed Image ====&gt; 412.Purslane.jpg
Completed Image ====&gt; 413.purslane_3456_3456_90.jpg
Completed Image ====&gt; 414.purslaneflowersjpg-9ca211b2e420edae.jpg
Completed Image ====&gt; 415.cpurse1.JPG
Completed Image ====&gt; 416.purslane-gravel.jpg
Completed Image ====&gt; 417.original.jpg
Completed Image ====&gt; 418.purslane_facebook.jpg
Completed Image ====&gt; 419.Sea-Purslane-young-leaves-carpeted-1024x576.jpg
Completed Image ====&gt; 420.Purslane_%28Portulaca_oleracea%29_3.jpg
Completed Image ====&gt; 421.pink-purslane-11609-pinkpurslane-p1120554.jpg
Completed Image ====&gt; 422.fab61s00h.jpg
Completed Image ====&gt; 423.20151222_180424.jpg
Completed Image ====&gt; 424.Blossom-Flower-Bloom-Portulaca-Plant-Purslane-2698485.jpg
Completed Image ====&gt; 425.MS487-32_480x480.jpg
Completed Image ====&gt; 426.577699219460c.image.jpg
Completed Image ====&gt; 427.bushy-purslane.jpg
Completed Image ====&gt; 428.Purslane-weed-or-eat-pinsm-2017.jpg
Completed Image ====&gt; 429.common-purslane-portulaca-oleracea-DJ7GEC.jpg
Completed Image ====&gt; 430.portulaca-468x1024.png
Completed Image ====&gt; 431.Purslane-w-text-720x432.jpg
Completed Image ====&gt; 432.image753.png
Completed Image ====&gt; 433.Purslane.jpg
Completed Image ====&gt; 434.whattoeat_lunch_purslane.jpg
Completed Image ====&gt; 435.87828666_XS.jpg
Completed Image ====&gt; 436.purslane.jpg
Completed Image ====&gt; 437.TWE_purslanelaves-1100x550-c-center.jpg
Completed Image ====&gt; 438.purslane-440x409.jpg
Completed Image ====&gt; 439.Pickled-Purslane-Patch.jpg
Completed Image ====&gt; 440.Purslane-9-1.jpg
Completed Image ====&gt; 441.92095713-colorful-common-purslane-flowers-wallpaper-concept-on-a-natural-background.jpg
Completed Image ====&gt; 442.purslane2-sm.jpg
Completed Image ====&gt; 443.purslane-young-2010.jpg
Completed Image ====&gt; 444.Purslane-Portulaca-oleracea.jpg
Completed Image ====&gt; 445.Sea-Purslane-Sesuvium-portulacastrum-1.jpg
Completed Image ====&gt; 446.770optimized.jpg
Completed Image ====&gt; 447.purslane-plants-care-colors-plant-indoors.jpg
Completed Image ====&gt; 448.hy6avany6y3unemasugabe8a4.jpg
Completed Image ====&gt; 449.1528413000_5b19bb48ea3e3.jpg
Completed Image ====&gt; 450.purslane.bmp
Completed Image ====&gt; 451.IMG_6404_2.jpg
Completed Image ====&gt; 452.Sea-purslane-2.jpg
Completed Image ====&gt; 453.purslane-red.jpg
Completed Image ====&gt; 454.Purslane-herb.jpg
Completed Image ====&gt; 455.c6dddd900ba4423fa627ac8349eabef7.jpg
Completed Image ====&gt; 456.3eab8114d55697a98be8d0c42aa0aa0a.jpg
Completed Image ====&gt; 457.Portulaca_oleracea_blossom.jpg
Completed Image ====&gt; 458.purslane-golden-2014.jpg
Completed Image ====&gt; 459.20-flower-seeds-gul-e-shama-purslane-flower-seeds-rainy-season-original-imaey5rqfutyzcsc.jpeg
Completed Image ====&gt; 460.purslane.jpg
Completed Image ====&gt; 461.purslane-for-bone1.jpg
Completed Image ====&gt; 462.dream-meaning-Purslane.jpeg
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'ediblenetwork.com'. (_ssl.c:1056)&gt;
Invalid or missing image format. Skipping...
Completed Image ====&gt; 463.portulaca-and-purslane-3-of-4.jpg
Completed Image ====&gt; 464.6659_15833_z.jpg
Completed Image ====&gt; 465.Purslane.jpg
Completed Image ====&gt; 466.purslane-plant-6.jpg
Completed Image ====&gt; 467.Purslane-Salad-2-1024x768.jpg
Completed Image ====&gt; 468.seapurslane1.jpg
Completed Image ====&gt; 469.purslane-5-spurge.jpg
Completed Image ====&gt; 470.flower_750.jpg
Completed Image ====&gt; 471.sp38202.jpg
Completed Image ====&gt; 472.21recipehealth-jumbo.jpg
Completed Image ====&gt; 473.4a1f48.jpg
Completed Image ====&gt; 474.IMG_2302.jpg
Completed Image ====&gt; 475.101422188%20%28640x427%29.jpg
Completed Image ====&gt; 476.GREEN-FUSE-PURSLANE-HOT-SHOT-ROSE-061.jpg
Completed Image ====&gt; 477.936259_6d496e932cea4619b1a3ae064b45a1eamv2-e1535693322513.jpg
Completed Image ====&gt; 478.purslane-tomato-salad-horiz-a-1800.jpg
Completed Image ====&gt; 479.IMG_1000.jpg
Completed Image ====&gt; 480.Purslane-plant.jpg
Completed Image ====&gt; 481.nature-plant-flower-groundcover-flowering-plant-common-purslane-herb-annual-plant-hypericum-1424617.jpg
Completed Image ====&gt; 482.purslane-roots.jpg
Completed Image ====&gt; 483.portulaca-oleracea-4.jpg
Completed Image ====&gt; 484.2011-garden-7-1-kalynskitchen.jpg
Completed Image ====&gt; 485.3787Portulaca-suffrutescens,-Shrubby-Purslane700x465.jpg
Completed Image ====&gt; 486.stock-photo-portulaca-oleracea--purslane-111303-20573.jpg
Completed Image ====&gt; 487.portulaca_oleracea.jpg
Completed Image ====&gt; 488.Purslane.jpg
Completed Image ====&gt; 489.sassafras.png
Completed Image ====&gt; 490.636069396794225188-DSC-0993.jpeg
Completed Image ====&gt; 491.MS487-22_480x480.jpg
Completed Image ====&gt; 492.hqdefault.jpg
Completed Image ====&gt; 493.1-purslane.jpg
Completed Image ====&gt; 494.B4-11.jpg
Completed Image ====&gt; 495.Purslane-Patch-300x189.jpg
Completed Image ====&gt; 496.basil-purslane-005-comp.jpg
Completed Image ====&gt; 497.DVG_004.JPG
Completed Image ====&gt; 498.sea-purslane.jpg
Completed Image ====&gt; 499.purslane-stem-pickles.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 500.purslane-flowering.jpg
Completed Image ====&gt; 501.1-image%20purslanejpg.jpg
Completed Image ====&gt; 502.purslane-1200x520.jpg
Completed Image ====&gt; 503.common-purslane-verdolaga-pigweed-common-purslane-verdolaga-pigweed-little-hogweed-sun-plant-sun-rose-bloom-early-119744052.jpg
Completed Image ====&gt; 504.Sea-purslane-1.jpg
Completed Image ====&gt; 505.Purslane%204.jpg
Completed Image ====&gt; 506.40-Purslane.jpg
Completed Image ====&gt; 507.4089c83976eccc4f05067d482acc88d3.jpg
Completed Image ====&gt; 508.purslane-ground-cover-300x225.jpg
Completed Image ====&gt; 509.fotolia_3834450_XS.jpg
Completed Image ====&gt; 510.14883248-common-purslane-verdolaga-pigweed-little-hogweed-or-pusley.jpg
Completed Image ====&gt; 511.purslane+growing.png
Completed Image ====&gt; 512.depositphotos_213023104-stock-photo-pink-common-purslane-portulaca-oleracea.jpg
Completed Image ====&gt; 513.purslane-portulaca-oleracea-grows-garden-450w-733460797.jpg
Completed Image ====&gt; 514.13842.jpg
Completed Image ====&gt; 515.Common-purslane-seedling.jpg
Completed Image ====&gt; 516.IMG_1074.jpg
Completed Image ====&gt; 517.PicMonkey-Collage.jpg
Completed Image ====&gt; 518.IMG_0053-1024x1024.jpg
Completed Image ====&gt; 519.HR72-Common-Purslane-plant-400x264.jpg
Completed Image ====&gt; 520.purslane-plant-flowers-portulaca-oleracea-aka-verdolaga-pigweed-little-GPXXJW.jpg
Completed Image ====&gt; 521.purslane-salad.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 522.Portulaca_olera_300.jpg
Completed Image ====&gt; 523.Purslane-rose-and-yellow.jpg
Completed Image ====&gt; 524.WhatsApp_Image_2018-06-28_at_05.24.40_grande.jpeg
Completed Image ====&gt; 525.purslane-hot-pink.jpg
Completed Image ====&gt; 526.walnut-purslane-coleslaw.jpg
Completed Image ====&gt; 527.220px-Portulaca_oleracea2.jpg
Completed Image ====&gt; 528.10-12-12+my+garden+harvest2.jpg
Completed Image ====&gt; 529.weeds_purslane3_zoom.jpg
Completed Image ====&gt; 530.GREEN-FUSE-PURSLANE-HOT-SHOT-YELLOW-035.jpg
Completed Image ====&gt; 531.gutter_purslane.jpg
Completed Image ====&gt; 532.1945.jpg
Completed Image ====&gt; 533.Portulaca_oleracea.5.jpg
Completed Image ====&gt; 534.purslane-mixed-900x675.jpg
Completed Image ====&gt; 535.80dcaa67-353c-4e92-b82a-994f83a23647_1.eeea81187009117ff20540f87e8e3159.jpeg
Completed Image ====&gt; 536.FEATURES_180609818_AR_0_SZKJLPRALUPR.jpg
Completed Image ====&gt; 537.health-benefits-of-purslane-or-gulasiman.jpg
Completed Image ====&gt; 538.purslane_golden.jpg
Completed Image ====&gt; 539.liH2o.jpg
Completed Image ====&gt; 540.wpid-0702131826_20130703162457717.jpg
Completed Image ====&gt; 541.wah-11.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 542.purslane_260x260-e1371130616681.jpg
Completed Image ====&gt; 543.purslane_by_chris_root.jpg
Completed Image ====&gt; 544.purslane.jpg
Completed Image ====&gt; 545.summer_purslane.jpg
Completed Image ====&gt; 546.656optimized.jpg
Completed Image ====&gt; 547.100981257.jpg
Completed Image ====&gt; 548.purslane.jpg
Completed Image ====&gt; 549.Herb-Purslane-Green-DSC_2738.jpg
Completed Image ====&gt; 550.DETA-237.jpg
Completed Image ====&gt; 551.PortulacaPortoGrande-2.jpg
Completed Image ====&gt; 552.plants_green_circles-common_purslane_wild_portulaca_portulaca.jpg
Completed Image ====&gt; 553.108417.jpg
Completed Image ====&gt; 554.closeupofsemizotu-1024x768.jpg
Completed Image ====&gt; 555.purslane-flower-big.jpg
Completed Image ====&gt; 556.4600243417_1b560f0b82_b.jpg
Completed Image ====&gt; 557.Portulaca-umbraticola-Wingpod-Purslane4.jpg
Completed Image ====&gt; 558.3788Portulaca-suffrutescens,-Shrubby-Purslane700x465.jpg
Completed Image ====&gt; 559.Purslane,-Pink-1.gif
Completed Image ====&gt; 560.Purslane,%20Common%20(Portulaca%20oleracea)%20Drive%20to%20Springfield%20Farm%20Sapcote%20SP%204828%209273%20(taken%2011.7.2006).JPG
Completed Image ====&gt; 561.PUR.jpg
Completed Image ====&gt; 562.purslane-and-portulaca-1.jpg
Completed Image ====&gt; 563.purslane-leaves.jpg
Completed Image ====&gt; 564.portulak-gemse-portulak-portulaca-oleracea-ssp-sativa-common-purslane-HBM7T1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 565.a-Experimental-field-of-Portulaca-oleracea-purslane-at-the-Ramat-Negev-R-D-station.png
Completed Image ====&gt; 566.pulsane.jpg
Completed Image ====&gt; 567.MS486-22_480x480.jpg
Completed Image ====&gt; 568.depositphotos_213023548-stock-photo-pink-common-purslane-portulaca-oleracea.jpg
Completed Image ====&gt; 569.the_persevering_purslane_1_l7.jpg
Completed Image ====&gt; 570.15094698-little-common-purslane-flowers.jpg
Completed Image ====&gt; 571.purslpix.jpg
Completed Image ====&gt; 572.colorful-purslane-flowers-260nw-1108525937.jpg
Completed Image ====&gt; 573.purslane.jpg
Completed Image ====&gt; 574.3182.jpg
Completed Image ====&gt; 575.Purslane_original.jpeg
Completed Image ====&gt; 576.purslane-peach-apricot.jpg
Completed Image ====&gt; 577.purslane-01.jpg
Completed Image ====&gt; 578.pink-purslane-11609-pinkpurslane-p1070236.jpg
Completed Image ====&gt; 579.picXMXrmQ.jpg
Completed Image ====&gt; 580.purslane-sm.jpg
Completed Image ====&gt; 581.purslane4.jpg
Completed Image ====&gt; 582.produce_purslane.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 583.purslane-patch-2010.jpg
Completed Image ====&gt; 584.GREEN-FUSE-PURSLANE-HOT-SHOT-ORANGE-066.jpg
Completed Image ====&gt; 585.HPL.GH1_.jpg
Completed Image ====&gt; 586.20100823purslane2.jpg
Completed Image ====&gt; 587.purslane1.JPG
Completed Image ====&gt; 588.groene_postelein_webshop_.jpg
Completed Image ====&gt; 589.garden-portulaca-common-purslane-verdolaga-pigweed-little-hogweed-pusley-plants-blossom-red-flowers-sunny-day-123827651.jpg
Completed Image ====&gt; 590.wpid-0703132036.jpg
Completed Image ====&gt; 591.purslane-in-hanging-basket.jpg
Completed Image ====&gt; 592.877.JPG
Completed Image ====&gt; 593.weeds_purslane1_zoom.jpg
Completed Image ====&gt; 594.seapurslane.jpg
Completed Image ====&gt; 595.purslane-puerto-rican-hot-pink-1.jpg
Completed Image ====&gt; 596.Water-purslane-2.gif
Completed Image ====&gt; 597.Portulaca%20oleracea_0.JPG
Completed Image ====&gt; 598.3789Portulaca-suffrutescens,-Shrubby-Purslane700x465.jpg
Completed Image ====&gt; 599.Herb-Golden-Purslane-HB227-LSS-000_7408.jpg
Completed Image ====&gt; 600.47a9a4ba6c861b185f585b82aa2ac8cd--purslane-recipes-purslane-benefits.jpg
Completed Image ====&gt; 601.purslane-flower-full.jpg
Completed Image ====&gt; 602.watermelon%20purslane%20salad_0.jpg
Completed Image ====&gt; 603.9909828.jpg
Completed Image ====&gt; 604.24139a.jpg
Completed Image ====&gt; 605.depositphotos_213023504-stock-photo-pink-common-purslane-portulaca-oleracea.jpg
Completed Image ====&gt; 606.purslane-in-windowbox.jpg
Completed Image ====&gt; 607.Different-types-of-purslane-with-brief-descriptions_Q320.jpg
Completed Image ====&gt; 608.87590070-flowered-purslane-plant.jpg
Completed Image ====&gt; 609.p16t344g891ir5edc111o120v9e84.jpg
Completed Image ====&gt; 610.PurslaneYellow1.jpg
Completed Image ====&gt; 611.Purslane-Hot-Shot-Flambeau-Rose-Green-Fuse-Botanicals.jpg
Completed Image ====&gt; 612.purslane-plant-300x300.jpg
Completed Image ====&gt; 613.779optimized.jpg
Completed Image ====&gt; 614.0e14e8.jpg
Completed Image ====&gt; 615.portulaca-oleracea-common-purslane-also-verdolaga-red-root-or-pursley-used-as-vegetable-salad-and-herb-MFNX50.jpg
Completed Image ====&gt; 616.6H-diGangi-Purslane-Seed-Pods.jpg
Completed Image ====&gt; 617.RHS_WSYD0012494_11644.JPG
Completed Image ====&gt; 618.Purslane-Flowers-Portulaca-Oleracea-L-2464659.jpg
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
Completed Image ====&gt; 619.purslane-and-portulaca-3.jpg
Completed Image ====&gt; 620.hqdefault.jpg
Completed Image ====&gt; 621.doha_qatar_may-common_purslane_wild_portulaca_portulaca.jpg
Completed Image ====&gt; 622.purslane-smoothie-recipe.jpg
Completed Image ====&gt; 623.5034972517_e6bf799ab3_o.jpg
Completed Image ====&gt; 624.45930.jpg
Completed Image ====&gt; 625.beautiful-yellow-pink-portulaca-oleracea-flowers-also-known-as-common-purslane-verdolaga-little-hogweed-red-root-pursl-120756034.jpg
Completed Image ====&gt; 626.500_F_249152684_Oy3mMu8Rjr1GEYfA67pR1Mm2FdP53uRI.jpg
Completed Image ====&gt; 627.purslane-gold.jpg
Completed Image ====&gt; 628.DETA-232.jpg
Completed Image ====&gt; 629.1549Portulaca-oleracea,-Common-Purslane700x464.jpg
Completed Image ====&gt; 630.purslane-foraged-wild.jpg
Completed Image ====&gt; 631.500_F_249152152_cLKmdhxlFw1jBpT3v1jJ0JJVph6lIzVk.jpg
Completed Image ====&gt; 632.purslane-vitamins-and-antioxidant1.jpg
Completed Image ====&gt; 633.Purslane-pink-2.gif
Completed Image ====&gt; 634.starterpurslane-822x1024.jpg
Completed Image ====&gt; 635.HPL.Vegetative2.jpg
Completed Image ====&gt; 636.6729656371_5396d56f4f_b.jpg
Completed Image ====&gt; 637.recipe_main_IMG_8796.jpg
Completed Image ====&gt; 638.99ef383c1e61271c949b07b87ec54ed5.jpg
Completed Image ====&gt; 639.Screen-Shot-2016-03-07-at-3.01.52-PM.png
Completed Image ====&gt; 640.773optimized.jpg
Completed Image ====&gt; 641.White_Purslane_01_0.jpg
Completed Image ====&gt; 642.Herbal_Green_Purslane_Portulaca_oleracea_L._Heirloom_Seeds__22134.1540401696.jpg
Completed Image ====&gt; 643.bright-yellow-flowers-of-common-purslane-portulaca-oleracea-succulent-plant-in-natural-gardens-of-rolle-town-in-switzerland-on-sunny-summer-day-PCYJB0.jpg
Completed Image ====&gt; 644.81120283-beautiful-of-common-purslane-flower-concept-nature-beautiful-.jpg
Completed Image ====&gt; 645.wild-purslane-superfood-ingredient.jpg
Completed Image ====&gt; 646.20151222_180358.jpg
Completed Image ====&gt; 647.web%202.jpg
Completed Image ====&gt; 648.ludwigia-palustris-13.jpg
Completed Image ====&gt; 649.purslane-2-copy1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 650.Herb-Golden-Purslane-HB222-DSC03679.jpg
Completed Image ====&gt; 651.Wingpod_purslane_%28Portulaca_umbraticola%29_flowers.jpg
Completed Image ====&gt; 652.PurslaneFruit.jpg
Completed Image ====&gt; 653.DETA-71.jpg
Completed Image ====&gt; 654.Post-15-Purslane-1024x681.jpg
Completed Image ====&gt; 655.portulaca-flower-blooming-garden-common-purslane-portulaca-flower-blooming-garden-common-purslane-136140398.jpg
Completed Image ====&gt; 656.winterpostelein_webshop_.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 657.3cc7b7.jpg
Completed Image ====&gt; 658.Field-Notes-Purslane.jpg
Completed Image ====&gt; 659.purslane-bright-pink.jpg
Completed Image ====&gt; 660.Sea%20Purslane.jpg
Completed Image ====&gt; 661.Portulaca_um_300.jpg
Completed Image ====&gt; 662.P1110877.png
Completed Image ====&gt; 663.MS487-42_480x480.jpg
Completed Image ====&gt; 664.777optimized.jpg
Completed Image ====&gt; 665.71f36ce5382f4b6cfea8518c52bf8f2e.jpg
Completed Image ====&gt; 666.9509976199_223b640144_z.jpg
Completed Image ====&gt; 667.portulaca-oleracea-plant.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 668.portulaca-oleracea-common-purslane-also-verdolaga-red-root-or-pursley-used-as-vegetable-salad-and-herb-MFNX5A.jpg
Completed Image ====&gt; 669.hqdefault.jpg
Completed Image ====&gt; 670.beautiful-pink-portulaca-oleracea-flowers-also-known-as-common-purslane-verdolaga-little-hogweed-red-root-pursley-beautiful-120756849.jpg
Completed Image ====&gt; 671.Purslane-1.jpg
Completed Image ====&gt; 672.e1e8b3.jpg
Completed Image ====&gt; 673.purslane_seedling_zoom.jpg
Completed Image ====&gt; 674.ludwigia-palustris-water-primrose_0812_121858.jpg
Completed Image ====&gt; 675.purslane-FM.jpg
Completed Image ====&gt; 676.portulaca-and-purslane-2-of-4.jpg
Completed Image ====&gt; 677.220px-Stewartonflower2.JPG
Completed Image ====&gt; 678.f2c195eb6aad458a96f90cb9c725f187.jpg
Completed Image ====&gt; 679.3786Portulaca-suffrutescens,-Shrubby-Purslane700x465.jpg
Completed Image ====&gt; 680.DETA-234.jpg
Completed Image ====&gt; 681.portulaca-oleracea-purslane-plant-andvalo-sierra-de-aracena-huelva-andalucia-spain-europe-XATBGW.jpg
Completed Image ====&gt; 682.o_19lul6uit11hd1a5q172v16vs18ij8.jpg
Completed Image ====&gt; 683.purslane-raven-7-7-18.jpg
Completed Image ====&gt; 684.Greens_Golden_Purslane_LSS_000_4571.jpg
Completed Image ====&gt; 685.sea-purslane.jpg
Completed Image ====&gt; 686.web%203.jpg
Completed Image ====&gt; 687.PinkPurslane_P1110522.jpg
Completed Image ====&gt; 688.pink-common-purslane-portulaca-oleracea-verdolaga-red-root-pink-common-purslane-portulaca-oleracea-verdolaga-red-root-125832393.jpg
Completed Image ====&gt; 689.1eedfc26f4b5e26d258d144a5fe795bf.jpg
Completed Image ====&gt; 690.8962Portulaca-oleracea,-Common-Purselane350x.jpg
Completed Image ====&gt; 691.maxresdefault.jpg
Completed Image ====&gt; 692.7982044498_19d420dc86_b.jpg
Completed Image ====&gt; 693.portulaca-oleracea-common-purslane-also-verdolaga-red-root-or-pursley-used-as-vegetable-salad-and-herb-MFNX5B.jpg
Completed Image ====&gt; 694.6a7f61.jpg
Completed Image ====&gt; 695.beautiful-yellow-pink-portulaca-oleracea-flowers-also-known-as-common-purslane-verdolaga-little-hogweed-red-root-pursley-120755532.jpg
Completed Image ====&gt; 696.Calandrinia-spectabilis-Rock-Purslane3.jpg
Completed Image ====&gt; 697.portulaca-oleracea-apex.jpg
Completed Image ====&gt; 698.chaffweed-n-water-purslane.jpg
Completed Image ====&gt; 699.2a1905efefabc9facd9645010553287a.jpg
Completed Image ====&gt; 700.maxresdefault.jpg
Completed Image ====&gt; 701.ddc574-250.jpg
Completed Image ====&gt; 702.common-purslane-verdolaga-pigweed-little-hogweed-pursley-portulak-FAK42Y.jpg
Completed Image ====&gt; 703.red-common-purslane-verdolaga-pigweed-little-hogweed-pusley-flowers-red-common-purslane-verdolaga-pigweed-112808321.jpg
Completed Image ====&gt; 704.hqdefault.jpg
Completed Image ====&gt; 705.6748157923_0f69cf3cb7_b.jpg
Completed Image ====&gt; 706.beautiful-white-portulaca-oleracea-flower-also-known-as-common-purslane-verdolaga-little-hogweed-red-root-or-pursley-PN7EF4.jpg
Completed Image ====&gt; 707.beautiful-yellow-portulaca-oleracea-flowers-also-known-as-common-purslane-verdolaga-little-hogweed-red-root-pursley-beautiful-120757310.jpg
Completed Image ====&gt; 708.120723035217-purslane-eatocracy-story-top.jpg
Completed Image ====&gt; 709.purslane-growing-in-a-crack-between-the-asphalt-and-concrete-of-a-parking-lot-in-englewood-cliffs-new-jersey-usa-S28JBD.jpg
Completed Image ====&gt; 710.2-harvesting-purslane.jpg
Completed Image ====&gt; 711.purslane-close-up-scientific-name-portulaca-oleracea-44912921.jpg


Unfortunately all 1000 could not be downloaded because some images were not downloadable. 711 is all we got for this search filter!

Errors: 24

</pre></div>
</div>
<div class="outline-4" id="outline-container-orgfda755e">
<h4 id="orgfda755e">Lamb's Quarters</h4>
<div class="outline-text-4" id="text-orgfda755e">
<div class="highlight">
<pre><span></span>keywords["keywords"] = "lamb's quarters"
lambs_ear_paths = google_images.download(keywords)
</pre></div>
<pre class="example">

Item no.: 1 --&gt; Item name = lamb's quarters
Evaluating...
Getting you a lot of images. This may take a few moments...
Reached end of Page.
Starting Download...
Completed Image ====&gt; 1.IMG_4309.jpg
Completed Image ====&gt; 2.IMG_4307.jpg
Completed Image ====&gt; 3.40081273240_cafa250f47_b.jpg
Completed Image ====&gt; 4.lambs-quarters_IMG_0449_grande.jpg
Completed Image ====&gt; 5.47-Lambsquarters.jpg
Completed Image ====&gt; 6.lambs-quarters.jpg
Completed Image ====&gt; 7.Chenopodium_album.jpg
Completed Image ====&gt; 8.IMG_1655.jpg
Completed Image ====&gt; 9.Lambs-Quarters.jpg
Completed Image ====&gt; 10.il_794xN.1817708283_5fxu.jpg
Completed Image ====&gt; 11.lambs-quarters-picture.jpg
Completed Image ====&gt; 12.hqdefault.jpg
Completed Image ====&gt; 13.800px-ChenopodiumAlbum001.jpg
Completed Image ====&gt; 14.lq1.jpg
Completed Image ====&gt; 15.0606LambsQ3.JPG
Completed Image ====&gt; 16.lambsquarter-jpg.jpg
Completed Image ====&gt; 17.897fdb7d41b2a40bd388739950cde303.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 18.IMG_1949.JPG
Completed Image ====&gt; 19.maxresdefault.jpg
Completed Image ====&gt; 20.Pinching-off-the-tender-tops-of-lambs-quarters.jpg
Completed Image ====&gt; 21.Lambsquarter-a.jpg
Completed Image ====&gt; 22.lambs-quarters-leaves.jpg
Completed Image ====&gt; 23.lambs-quarters-sq-jpg.jpg
Completed Image ====&gt; 24.chenopodium-album.jpg
Completed Image ====&gt; 25.Lambs-quarters-Chenopodium-album-2.jpg
Completed Image ====&gt; 26.lambsquarters1.jpg
Completed Image ====&gt; 27.lambsquarterpin.jpg
Completed Image ====&gt; 28.lambs-quarters-mature.jpeg
Completed Image ====&gt; 29.athens-plants-062.jpg
Completed Image ====&gt; 30.Lambsquarters%2003%20sm.jpg
Completed Image ====&gt; 31.Chenopodium%20album%20L,%20Lamb%27s%20quarters-4-2008.jpg
Completed Image ====&gt; 32.Lambs-Quarter.jpg
Completed Image ====&gt; 33.lambsquarters-02.jpg
Completed Image ====&gt; 34.40081272830_f0f1056999_b.jpg
Completed Image ====&gt; 35.lambsquarters.jpeg
Completed Image ====&gt; 36.29188940515_011c8fa723.jpg
Completed Image ====&gt; 37.41171244464_b24073acc0_b.jpg
Completed Image ====&gt; 38.fab09s00g.jpg
Completed Image ====&gt; 39.lambs-quarter-Breckenridge.jpg
Completed Image ====&gt; 40.61WGWZagnhL.jpg
Completed Image ====&gt; 41.lambsquarter-400x300.jpg
Completed Image ====&gt; 42.220px-Melganzenvoet_bloeiwijze_Chenopodium_album.jpg
Completed Image ====&gt; 43.IMG_1879.JPG
Completed Image ====&gt; 44.Close-up-of-the-waxy-coating-on-the-underside-of-a-lambs-quarter-leaf.jpg
Completed Image ====&gt; 45.Lambs-Quarter-Young.jpg
Completed Image ====&gt; 46.lambs-quarters-chenopodium-album-seeds-amkha-seed_706.jpg
Completed Image ====&gt; 47.foraging.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 48.5b2a52850161a1000dd71aed-original.jpg
Completed Image ====&gt; 49.3523545063_9992f08b83.jpg
Completed Image ====&gt; 50.lambs-quarters-pesto.jpg
Completed Image ====&gt; 51.lambs%2Bquarters.JPG
Completed Image ====&gt; 52.dsc_0144.jpg
Completed Image ====&gt; 53.fab09s00d.jpg
Completed Image ====&gt; 54.chenopodium-album-062016.jpg
Completed Image ====&gt; 55.img_8180.jpg
Completed Image ====&gt; 56.LambsQuarter.jpg
Completed Image ====&gt; 57.86741699919aac9fa183c76694193c41--wild-edibles-food-nutrition.jpg
Completed Image ====&gt; 58.lambsquarters-1100x825.jpg
Completed Image ====&gt; 59.Lambsquarter_wholeplant_edited_300.jpg
Completed Image ====&gt; 60.LambsQuarters.jpg
Completed Image ====&gt; 61.LambsQuarters.jpg
Completed Image ====&gt; 62.Lambsquarter-e.jpg
Completed Image ====&gt; 63.lambsquarters_orach.jpg
Completed Image ====&gt; 64.rbrain.lambs_.quarter.jpg
Completed Image ====&gt; 65.Lambs_Quarters-300x432.jpg
Completed Image ====&gt; 66.lamquart4.jpeg
Completed Image ====&gt; 67.IMG_1654.jpg
Completed Image ====&gt; 68.Lamb%2527s%2BQuarters.jpg
Completed Image ====&gt; 69.51OS2UgE4VL._SX425_.jpg
Completed Image ====&gt; 70.3-lambsquarter-dsc05877-3.jpg
Completed Image ====&gt; 71.fat-hen-or-lambs-quarters-chenopodium-album-young-plants-of-annual-arable-and-garden-weed-may-MTF1HD.jpg
Completed Image ====&gt; 72.Lambsquarter-b.jpg
Completed Image ====&gt; 73.182716-004-C85BE7CA.jpg
Completed Image ====&gt; 74.Chenopodium_shutterstock_207628225.jpg
Completed Image ====&gt; 75.91610fc0652c10b7aaa2cd451264ff87.jpg
Completed Image ====&gt; 76.9051444567_083a1fb386_b.jpg
Completed Image ====&gt; 77.Lambs-Quarters-9.jpg
Completed Image ====&gt; 78.Screen-Shot-2013-07-07-at-5.10.49-PM.png
Completed Image ====&gt; 79.s-l300.jpg
Completed Image ====&gt; 80.Chenopodium-album-L-Lambs-quarters-3-2008.jpg
Completed Image ====&gt; 81.maxresdefault.jpg
Completed Image ====&gt; 82.8262ab93f6f146ce5560f5d9bfcf842a.jpg
Completed Image ====&gt; 83.image38.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 84.Common_Lambsquarters6.JPG
Completed Image ====&gt; 85.Chenopodium%20botrys.jpg
Completed Image ====&gt; 86.lambs-quarter-or-pigweed-21657003.gif
Completed Image ====&gt; 87.s648401865701383597_p96_i1_w1600.jpeg
Completed Image ====&gt; 88.6-dust-and-spots-lambsquarter-dsc05871-2.jpg
Completed Image ====&gt; 89.Lambsquarters%20from%20above%20sm.jpg
Completed Image ====&gt; 90.PICT0807.JPG
Completed Image ====&gt; 91.IMG_1429.jpg
Completed Image ====&gt; 92.5.jpg
Completed Image ====&gt; 93.HR-5-1-1-Lambs-Quarters-seedlings.jpg
Completed Image ====&gt; 94.Oct-7-WFF-2.jpg
Completed Image ====&gt; 95.Lamb_s_Quarters.jpg
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 96.pix_lambsquarter_smythe.jpg
Completed Image ====&gt; 97.lambsquarters-seedling.jpg
Completed Image ====&gt; 98.lambs-quarters-s.jpg
Completed Image ====&gt; 99.182716-004-C85BE7CA.jpg
Completed Image ====&gt; 100.lambs-quarters1.jpg
Completed Image ====&gt; 101.Lambs-Quarters-6.jpg
Completed Image ====&gt; 102.lambsquarters4.jpg
Completed Image ====&gt; 103.IMG_20130704_080545_403_original.jpg
Completed Image ====&gt; 104.lambsquarters.jpg
Completed Image ====&gt; 105.lambs-flower-big.jpg
Completed Image ====&gt; 106.Lambs-Quarters.jpg
Completed Image ====&gt; 107.20160602_150859_1024x1024.jpg
Completed Image ====&gt; 108.7.jpg
Completed Image ====&gt; 109.lambs-quarters-soup.jpg
Completed Image ====&gt; 110.lambs%20quarters%20seed%20head%20sm.jpg
Completed Image ====&gt; 111.crop_common_lambsquarters_robert_videki_doronicum_kft_bugwood.jpg
Completed Image ====&gt; 112.Lambs-Quarters-5.jpg
Completed Image ====&gt; 113.file.jpeg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 114.chenopodium-album-87-2.jpg
Completed Image ====&gt; 115.s-l300.jpg
Completed Image ====&gt; 116.719NOVaKu7L._SY550_.jpg
Completed Image ====&gt; 117.lambs-quarter-leaf.jpg
Completed Image ====&gt; 118.IMG_2730.jpg
Completed Image ====&gt; 119.goosefoot.jpg
Completed Image ====&gt; 120.Lambs-Quarters.jpg
Completed Image ====&gt; 121.lambsquarterleaf-med.jpg
IOError on an image...trying next one... Error: The read operation timed out
Completed Image ====&gt; 122.lambsquarters-01.jpg
Completed Image ====&gt; 123.maxresdefault.jpg
Completed Image ====&gt; 124.lambsquarters4b.jpg
Completed Image ====&gt; 125.LambsQuartersFrittata6.jpg
Completed Image ====&gt; 126.lambs-quarters.jpg
Completed Image ====&gt; 127.Chenopodium-Album-Lambs-Quarters-Edible~~element27.jpg
Completed Image ====&gt; 128.chenopodium-album-lambs-quarters-0908_105734.jpg
Completed Image ====&gt; 129.Lambs_Quarters_Leaves_2.jpg
Completed Image ====&gt; 130.il_794xN.1275007463_l1ky.jpg
Completed Image ====&gt; 131.HR-5-1-2-Lambs-Quarters-leaves.jpg
Completed Image ====&gt; 132.Lambsquarter_leaves_edited_300.jpg
Completed Image ====&gt; 133.f96c29b825fbf543dd7f2a673f944fb5.jpg
Completed Image ====&gt; 134.lambsquarters4c.jpg
Completed Image ====&gt; 135.maxresdefault.jpg
Completed Image ====&gt; 136.LambsQtrs.jpg
Completed Image ====&gt; 137.Lambsquarters%2001%20sm.jpg
Completed Image ====&gt; 138.lambs-quarters.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 139.6fce5b9e90c97be49bf3f2720ab5b631.jpg
Completed Image ====&gt; 140.lambs_quarters_wild_crafted.jpg
Completed Image ====&gt; 141.28569084463_d658acc87f.jpg
Completed Image ====&gt; 142.Lambs-Quarters-Netseed-Pitseed-Goosefoot-Chenopodium-Berlandieri-3-Annual-FORB-Amaranth-Family-Amaranthaceae-NORTH-CENTRAL-A.-Blooms-Jul-Sep-Wet-Prairies-Meadows-Dry-Full-sun-1-4ft.jpg
Completed Image ====&gt; 143.lambs-quarters.jpg
Completed Image ====&gt; 144.20130523_141558.jpg
Completed Image ====&gt; 145.fat-hen-or-lambs-quarters-chenopodium-album-young-plants-of-annual-arable-and-garden-weed-may-MTF1GH.jpg
Completed Image ====&gt; 146.HR-5-1-3-Lambs-Quarters-plant.jpg
Completed Image ====&gt; 147.lambsquarters4.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 148.lambs-quarter-pesto.jpg
Completed Image ====&gt; 149.chenop-thumb-400x586-48787.jpg
Completed Image ====&gt; 150.Lambs_Quarters_Leaves_1.jpg
Completed Image ====&gt; 151.nature-shutterstock-editorial-4594294a.jpg
Completed Image ====&gt; 152.1200px-Chenopodium_berlandieri_NPS-1.jpg
Completed Image ====&gt; 153.Lambs-Quarters-Netseed-Pitseed-Goosefoot-Chenopodium-Berlandieri-2-Annual-FORB-Amaranth-Family-Amaranthaceae-NORTH-CENTRAL-A.-Blooms-Jul-Sep-Wet-Prairies-Meadows-Dry-Full-sun-1-4ft.jpg
Completed Image ====&gt; 154.1212974ed1.jpg
Completed Image ====&gt; 155.lambs-quarters-adult.jpg
Completed Image ====&gt; 156.Herb-of-the-Day-lambs-quarters-mcrl234e37pfyw0mb16oftuez75gn62tz1649sj444.jpg
Completed Image ====&gt; 157.immages.jpg
Completed Image ====&gt; 158.lambs-quarters-lambsquarters-pigweed-fat-hen-chenopodium-album-blooming-A9FT79.jpg
Completed Image ====&gt; 159.chenopodium-album-798739.jpg
Completed Image ====&gt; 160.fab09s00a.jpg
Completed Image ====&gt; 161.kirsten_johnson_28054192382_93de2f8413_b.jpg
Completed Image ====&gt; 162.hqdefault.jpg
Completed Image ====&gt; 163.30483712507_9e2e38ae05_b.jpg
Completed Image ====&gt; 164.5229b51ea69925208718db9d1b5b6bb0.jpg
Completed Image ====&gt; 165.v4-460px-Eat-Lamb%27s-Quarters-Step-9.jpg
Completed Image ====&gt; 166.lambsquarters2.JPG
Completed Image ====&gt; 167.Chenopodium%20album%20L,%20Lamb%27s%20quarters-2-2008.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 168.salt-and-vinegar-lambs-quarters.jpg
Completed Image ====&gt; 169.005.jpg
Completed Image ====&gt; 170.orache-plant2.jpg
Completed Image ====&gt; 171.LambsQuarters_01.JPG
Completed Image ====&gt; 172.lambs-quarters.png
Completed Image ====&gt; 173.51238110_lambs-quarters_1x1.jpg
Completed Image ====&gt; 174.SkxLOCRxxb.jpg
Completed Image ====&gt; 175.90e5ca26a56faf42ff0f0783aabc93cb.jpg
Completed Image ====&gt; 176.112491716-leaves-and-stem-of-lamb-s-quarters-chenopodium-album-.jpg
Completed Image ====&gt; 177.full_Magenta_20lambs_20quarter.019.jpg
Completed Image ====&gt; 178.IMG_0401-520x346.jpg
Completed Image ====&gt; 179.lambs-quarters-melde-goosefoot-chenopodium-album-X2RMK2.jpg
Completed Image ====&gt; 180.lambsquarters-full.jpg
Completed Image ====&gt; 181.lambs-quarters-herb-img-300x193.jpg
Completed Image ====&gt; 182._DSC0137.JPG
Completed Image ====&gt; 183.Lambs4.jpg
Completed Image ====&gt; 184.maxresdefault.jpg
Completed Image ====&gt; 185.1-Lambs-Quarters-Inhabited-Kitchen.jpg
Completed Image ====&gt; 186.Lambs-Quarters-3.jpg
Completed Image ====&gt; 187.28018891288_31c2cd1a4b_b.jpg
Completed Image ====&gt; 188.crop_common_lambsquarters_2_robert_videki_doronicum_kft_bugwood.jpg
Completed Image ====&gt; 189.chickweed_021.jpg
Completed Image ====&gt; 190.HR-5-1-4-Lambs-Quarters-top.jpg
Completed Image ====&gt; 191.img-1363_1.jpg
Completed Image ====&gt; 192.500_F_193778423_7i6ckxnSO5f8RsqhWE8gH8yxyQkBmOJj.jpg
Completed Image ====&gt; 193.dscn1013.jpg
Completed Image ====&gt; 194.Peronospora_variabilis_on_Lamb%27s_Quarters_-_Chenopodium_album_%2831548635238%29.jpg
Completed Image ====&gt; 195.tumblr_oqazp7GE5X1wni7kuo4_250.jpg
Completed Image ====&gt; 196.Lambs_quarters002_RMueller.jpg
Completed Image ====&gt; 197.57dc6835e6cbd.image.jpg
Completed Image ====&gt; 198.SS2227502.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 199.lambs+quarters.jpg
Completed Image ====&gt; 200.IMG_1361-e1437760717931.jpg
Completed Image ====&gt; 201.chenopodium-album-lambs-quarters-melde-260nw-1033466230.jpg
Completed Image ====&gt; 202.lambs-quarters-chenopodium-album-X85Y0W.jpg
Completed Image ====&gt; 203.chal_wp.jpg
Completed Image ====&gt; 204.Lambs_quarters_29_Aug_2018.jpg
Completed Image ====&gt; 205.Lambs-quarters-Chenopodium-murale-and-ilima-with-wedge-tailed-shearwater-burrows-in.png
Completed Image ====&gt; 206.35156896_1729018500487422_5909210383171715072_n.jpg
Completed Image ====&gt; 207.Lambsquarter_wholeplant2_edited_300.jpg
Completed Image ====&gt; 208.lambs-quarters-adult2.jpg
IOError on an image...trying next one... Error: The read operation timed out
Completed Image ====&gt; 209.b8a30e1dfe29bd0c791547ef64f3c453.jpg
Completed Image ====&gt; 210.cream-lambsquarter-soup-3.jpg
Completed Image ====&gt; 211.lambs_quarters_1.jpg
Completed Image ====&gt; 212.613095d678c8801d1745622f5f639cd7.jpg
Completed Image ====&gt; 213.51q94dCQzAL._SX425_.jpg
Completed Image ====&gt; 214.IMG_1877.JPG
Completed Image ====&gt; 215.Chenopodium_album_ENBLA02.jpg
Completed Image ====&gt; 216.img-5209.jpg
Completed Image ====&gt; 217.lambs+quarters+close+up.jpg
Completed Image ====&gt; 218.7f2ffa7e-bc4f-414a-a8de-f2c21e355194_1.39b1cae850ed21b5773290f5fdebff94.jpeg
Completed Image ====&gt; 219.F_lambs_quarters.jpeg
Completed Image ====&gt; 220.lambs-quarters-weed-199x300.jpg
Completed Image ====&gt; 221.IMG_2043wb15.jpg
Completed Image ====&gt; 222.lambsquarters_blanch.jpg
Completed Image ====&gt; 223.fat-hen-or-lambs-quarters-chenopodium-album-flowering-weed-in-a-growing-maize-crop-berkshire-july-PC38CF.jpg
Completed Image ====&gt; 224.10426207745_8853221b72_k-758x505.jpg
Completed Image ====&gt; 225.Young-lambs-quarters.jpg
Completed Image ====&gt; 226.08-05.gif
Completed Image ====&gt; 227.lams-quarters-2.jpg
Completed Image ====&gt; 228.chenopodium-album-lambs-quarters-melde-260nw-1036713301.jpg
Completed Image ====&gt; 229.chenopodium-album-63897-2.jpg
Completed Image ====&gt; 230.500_F_193778323_NN4beemWLlqJwumEPHnGFaH0UwTEfwrs.jpg
Completed Image ====&gt; 231.lqbrick-thumb-360x482-79892.jpg
Completed Image ====&gt; 232.Lambs-Quarters-3.jpg
Completed Image ====&gt; 233.lambs_quarters5_zoom.jpg
Completed Image ====&gt; 234.wild-spinach-dip-951x1024.jpg
Completed Image ====&gt; 235.lambs_quarters_3.jpg
Completed Image ====&gt; 236.6d228785fa830afbc7a8b8425490c795.jpg
Completed Image ====&gt; 237.Lambs-quarters-Chenopodium-34172.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 238.Lambs-Quarters-1.jpg
Completed Image ====&gt; 239.lambsquarters14.jpg
Completed Image ====&gt; 240.140720_0063.jpg
Completed Image ====&gt; 241.Lambs-Quarters-Netseed-Pitseed-Goosefoot-Chenopodium-Berlandieri-4-Annual-FORB-Amaranth-Family-Amaranthaceae-NORTH-CENTRAL-A.-Blooms-Jul-Sep-Wet-Prairies-Meadows-Dry-Full-sun-1-4ft.jpg
Completed Image ====&gt; 242.doha_qatar_march-lamb_quarters_chenopodium_album_white.jpg
Completed Image ====&gt; 243.fat-hen-or-lambs-quarters-chenopodium-album-young-plants-of-annual-arable-and-garden-weed-may-MTF1GM.jpg
Completed Image ====&gt; 244.35c86c.jpg
Completed Image ====&gt; 245.lambsquarters.jpg
Completed Image ====&gt; 246.lambsquarters-growing.jpg
Completed Image ====&gt; 247.washed-lambs-quarters.jpg
Completed Image ====&gt; 248.Chenopodium-album.png
Completed Image ====&gt; 249.2012-06-28_16-20-55_744.jpg
Completed Image ====&gt; 250.IMG_1767wb15.jpg
Completed Image ====&gt; 251.weeds-lambs-quarters-706x369.jpg
Completed Image ====&gt; 252.maxresdefault.jpg
Completed Image ====&gt; 253.7beb6d8135cd8433087c62b401211320.jpg
Completed Image ====&gt; 254.lambsquarters.jpg
Completed Image ====&gt; 255.cam01503.jpg
Completed Image ====&gt; 256.aid8858767-v4-728px-Harvest-Lamb%27s-Quarters-Step-2.jpg
Completed Image ====&gt; 257.lambs_quarters8_zoom.jpg
Completed Image ====&gt; 258.1403.jpeg
Completed Image ====&gt; 259.myeongaju.jpg
Completed Image ====&gt; 260.file.jpg
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
Completed Image ====&gt; 261.img-1364-orig.jpg
Completed Image ====&gt; 262.lambs-quarters.jpg
Completed Image ====&gt; 263.2942184_orig.jpg
Completed Image ====&gt; 264.large.jpg
Completed Image ====&gt; 265.IMG_0473.jpg
Completed Image ====&gt; 266.80182000.jpg
Completed Image ====&gt; 267.lambsquarter.jpg
Completed Image ====&gt; 268.lambs-quarters-chenopodium-album-ssp-album-X5CXAR.jpg
Completed Image ====&gt; 269.lamb-s-quarters.JPG
Completed Image ====&gt; 270.chenopodium-album-goosefoot.jpg
Completed Image ====&gt; 271.45372555122_802325f736_b.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 272.maxresdefault.jpg
Completed Image ====&gt; 273.IMG_1838.JPG
Completed Image ====&gt; 274.one-of-four-carrots.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 275.lambs-quarters-flower-plant-bud-260nw-1234938670.jpg
Completed Image ====&gt; 276.16.jpg
Completed Image ====&gt; 277.lambsquarter-leaf.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 278.lambs-quarters-grown-under-dry-conditions-300-.jpg
Completed Image ====&gt; 279.0071.jpg
Completed Image ====&gt; 280.Lambsquarter-d.jpg
Completed Image ====&gt; 281.Lambs-Quarter.jpg
Completed Image ====&gt; 282.lambs-quarter12.jpg
Completed Image ====&gt; 283.28018892828_779a102ecd_b.jpg
Completed Image ====&gt; 284.372E92F9-C82A-42EF-846F-0EFBD528C64F.jpeg
Completed Image ====&gt; 285.fab09s00c.jpg
Completed Image ====&gt; 286.dsc_0042.jpg
Completed Image ====&gt; 287.maxresdefault.jpg
Completed Image ====&gt; 288.magenta-lambs-quarters-tree-spinach-chenopodium-giganteum-with-love-lies-bleeding-amaranthus-caudatus-X96XEY.jpg
Completed Image ====&gt; 289.4632089665_45b904941c_z.jpg
URLError on an image...trying next one... Error: &lt;urlopen error _ssl.c:1039: The handshake operation timed out&gt;
Completed Image ====&gt; 290.Lambs-Quarters-7464-1024x819.jpg
Completed Image ====&gt; 291.Chenopodium-Album-Lambs-Quarters-Edible~~element9.jpg
Completed Image ====&gt; 292.0014.jpg
Completed Image ====&gt; 293.Chenopodium-album.commons.wikipedia.org_.jpg
Completed Image ====&gt; 294.lambs-quarters-roots-clipped.jpg
Completed Image ====&gt; 295.80181999.jpg
Completed Image ====&gt; 296.chenopodium-album-lambs-quarters-melde-260nw-1037340853.jpg
Completed Image ====&gt; 297.lambs-quarters-purslane-compressed.jpg
Completed Image ====&gt; 298.Lambs-Quarters.jpg
Completed Image ====&gt; 299.D869_29_197_1200.jpg
Completed Image ====&gt; 300.Chenopodium-album-L-Lambs-Quarters-a-highly-edible-plant-and-ubiquitous-weed-in-fields.png
Completed Image ====&gt; 301.f01817b340a1aa945b0438d27c5661bc.jpg
Completed Image ====&gt; 302.lambs_quarters6_zoom.jpg
Completed Image ====&gt; 303.forager_marie%2Bviljoen.jpg
Completed Image ====&gt; 304.lambsquarters.jpg
Completed Image ====&gt; 305.my-lambs-quarters-garden.jpg
Completed Image ====&gt; 306.lambs-quarters-cooked.jpg
Completed Image ====&gt; 307.b7a83d-250.jpg
Completed Image ====&gt; 308.DSC_9761-1024x685-426x426.jpg
Completed Image ====&gt; 309.12.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 310.20150705_170945.jpg
Completed Image ====&gt; 311.IMG_0826-1-1024x683.jpg
Completed Image ====&gt; 312.dry-lambs-quarters.jpg
Completed Image ====&gt; 313.500_F_193778251_KYlKL8m4BRfftCQ5d1ES9kfHUfVZhkMr.jpg
Completed Image ====&gt; 314.DSCF09231.jpg
Completed Image ====&gt; 315.Lambs-Quarters-620x413.jpg
Completed Image ====&gt; 316.rbrain.purslane.jpg
Completed Image ====&gt; 317.Saut%C3%A9ed_Lambsquarters.png
Invalid or missing image format. Skipping...
Completed Image ====&gt; 318.0012.jpg
Completed Image ====&gt; 319.LambsQuarters_02.JPG
Completed Image ====&gt; 320.lambs-quarters-herbal-salt.jpg
Completed Image ====&gt; 321.lambs-quarters.jpg
Completed Image ====&gt; 322.lambsquarters-1024x765.jpg
Completed Image ====&gt; 323.aid8858767-v4-728px-Harvest-Lamb%27s-Quarters-Step-4.jpg
Completed Image ====&gt; 324.Lambs-Quarters-21.jpg
Completed Image ====&gt; 325.lambs-quarters-2.png
Completed Image ====&gt; 326.lambs-quarters-young.jpg
Completed Image ====&gt; 327.purple_spots_300x300%2523.jpg
Completed Image ====&gt; 328.maxresdefault.jpg
Completed Image ====&gt; 329.Giant+Lambs+Quarters.jpg
Completed Image ====&gt; 330.pre-rm01936240170.jpg
Completed Image ====&gt; 331.5751933357_99b301cd8b_b.jpg
Completed Image ====&gt; 332.l1.jpg
Completed Image ====&gt; 333.Wild-Greens-with-Venison-Bacon-2-1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 334.13.jpg
Completed Image ====&gt; 335.lambs-quarters-seed.jpg
Completed Image ====&gt; 336.Lambs-Quarters-Netseed-Pitseed-Goosefoot-Chenopodium-Berlandieri-5-Annual-FORB-Amaranth-Family-Amaranthaceae-NORTH-CENTRAL-A.-Blooms-Jul-Sep-Wet-Prairies-Meadows-Dry-Full-sun-1-4ft.jpg
Completed Image ====&gt; 337.1210b5cec8.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 338.lamquart2.jpg
Completed Image ====&gt; 339.Lambsquarters-G017710.jpg
Completed Image ====&gt; 340.28566737544_e0f829e2ec.jpg
Completed Image ====&gt; 341.lambs-quarters-young-400x300.jpg
Completed Image ====&gt; 342.6a00d83451fd1569e2016302ceb912970d-500wi.jpg
Completed Image ====&gt; 343.lambsquarters.jpg
Completed Image ====&gt; 344.IMG_0608.jpg
Completed Image ====&gt; 345.lambs_quarters_4.jpg
Completed Image ====&gt; 346.chenopodium_album_1.jpg
URLError on an image...trying next one... Error: &lt;urlopen error [Errno -5] No address associated with hostname&gt;
Completed Image ====&gt; 347.bwi-blws143108.jpg
Completed Image ====&gt; 348.fab09s00h.jpg
Completed Image ====&gt; 349.Pin-template-2.jpg
Completed Image ====&gt; 350.Lambs-Quarters.jpg
Completed Image ====&gt; 351.lambs-quarters-flowering-300x400.jpg
Completed Image ====&gt; 352.chenopodium-album-lambs-quarters-melde-450w-1034298304.jpg
Completed Image ====&gt; 353.Peronospora_variabilis_on_Lamb%27s_Quarters_-_Chenopodium_album_%2845372554682%29.jpg
Completed Image ====&gt; 354.Svinm%C3%A5lla.jpg
Completed Image ====&gt; 355.img_0893-e1400525960569.jpg
Completed Image ====&gt; 356.chenopodium-album-plant.jpg
Completed Image ====&gt; 357.lambs-quarters-picked-plate-600x399.jpg
Completed Image ====&gt; 358.I0000aOk4TlQru7w.jpg
Completed Image ====&gt; 359.Lambs_quarters001_RMueller.jpg
Completed Image ====&gt; 360.magenta-lambs-quarters-tree-spinach-chenopodium-giganteum-red-coloured-CNRCTJ.jpg
Completed Image ====&gt; 361.il_570xN_1090248669_2gts.jpg
Completed Image ====&gt; 362.RMRS-2012-15.jpg
Completed Image ====&gt; 363.35942340585_1bd7ed663e_b.jpg
Completed Image ====&gt; 364.Lambs-Quarters-Netseed-Pitseed-Goosefoot-Chenopodium-Berlandieri-1-Annual-FORB-Amaranth-Family-Amaranthaceae-NORTH-CENTRAL-A.-Blooms-Jul-Sep-Wet-Prairies-Meadows-Dry-Full-sun-1-4ft.jpg
Completed Image ====&gt; 365.imgbin-quinoa-chenopodium-pallidicaule-lambs-quarters-chenopodium-giganteum-organic-food-quinoa-wheat-field-material-8A4P6AycGd8WeFetuzm359CYB.jpg
Completed Image ====&gt; 366.lambs-quarters.png
Completed Image ====&gt; 367.lambs-quarters-bloom.jpg
Completed Image ====&gt; 368.lambs-quarters-seed-album.jpg
Completed Image ====&gt; 369.lambsquarter.jpg
Completed Image ====&gt; 370.Lambs-Quarter-and-the-compost-heap-1-e1514828833127.jpg
Completed Image ====&gt; 371.img_0893.jpg
Completed Image ====&gt; 372.lambsquarters.jpg
Completed Image ====&gt; 373.lamquart3.jpg
Completed Image ====&gt; 374.chenopodium_album_young.jpg
Completed Image ====&gt; 375.45460.jpg
Completed Image ====&gt; 376.070828_CCU_AW_Amaranth_8443_dlh.jpg
Completed Image ====&gt; 377.lambsquarter4.jpg
Completed Image ====&gt; 378.Chenalbu_1.jpg
Completed Image ====&gt; 379.image53.jpg
Completed Image ====&gt; 380.fhr-88888-13286-686.jpg
Completed Image ====&gt; 381.I0000dDk0eIx4C98.jpg
Completed Image ====&gt; 382.0013.jpg
Completed Image ====&gt; 383.maxresdefault.jpg
Completed Image ====&gt; 384.doha_qatar_march-lamb_quarters_chenopodium_album_taken.jpg
Completed Image ====&gt; 385.LambsQuartersEdibleWeed.jpg
Completed Image ====&gt; 386.26160995259_3a485daaed_b.jpg
Completed Image ====&gt; 387.35142503_1729018573820748_7117205961357393920_n.jpg
Completed Image ====&gt; 388.tumblr_nr5cdnnEpq1qfpdsqo1_400.jpg
Completed Image ====&gt; 389.54446662_126516235117284_2366701395630533053_n.jpg
Completed Image ====&gt; 390.fab09s00f.jpg
Completed Image ====&gt; 391.IMG_0834-1024x683.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 392.lambsquarters1.jpg
Completed Image ====&gt; 393.arugula.png
Invalid or missing image format. Skipping...
Completed Image ====&gt; 394.lambs-quarters-chenopodium-album-02.jpg
Completed Image ====&gt; 395.dscf2809.jpg
Completed Image ====&gt; 396.DSC_8497.jpg
Completed Image ====&gt; 397.20160318_182905-e1512781546433.jpg
Completed Image ====&gt; 398.lambs-quarters-young2-300x400.jpg
Completed Image ====&gt; 399.Lambs-Quarters-7463-v3.jpg
Completed Image ====&gt; 400.0c223495de044641f69e4dd7e87898dfl-m0xd-w1020_h770_q80.jpg
Completed Image ====&gt; 401.lambs-quarters-1.png
Completed Image ====&gt; 402.LambsQtrs70401.jpg
Completed Image ====&gt; 403.lambs-quarters-growing-field-450w-709031728.jpg
Completed Image ====&gt; 404.62248047_321635882113949_8191980519779484094_n.jpg
Completed Image ====&gt; 405.file.jpg
Completed Image ====&gt; 406.lambs-quarters-pan-600x399.jpg
Completed Image ====&gt; 407.chenopodium_album.jpg
Completed Image ====&gt; 408.lambs-quarters-1024x735.jpg
Completed Image ====&gt; 409.14020548738_25a46aefdf_b.jpg
Completed Image ====&gt; 410.index.jpg
Completed Image ====&gt; 411.main_image.jpg
Completed Image ====&gt; 412.lambs-quarters-hummus.jpg
Completed Image ====&gt; 413.large.jpeg
Completed Image ====&gt; 414.Lambsquarter_flower_edited_300.jpg
Completed Image ====&gt; 415.23_LambsQuarters140929.jpg
Completed Image ====&gt; 416.lq-1.jpg
Completed Image ====&gt; 417.june08-lambs-quarter.jpg
Completed Image ====&gt; 418.album9a.jpg
Completed Image ====&gt; 419.lambs-quarters.jpg
Completed Image ====&gt; 420.IMG_1472-e1437761905931.jpg
Completed Image ====&gt; 421.Quinoa-681x1024.jpg
Completed Image ====&gt; 422.lamquart.jpg
Completed Image ====&gt; 423.Indian-Spinach-well-watered-300.jpg
Completed Image ====&gt; 424.I0000kRXgiO0J8Vg.jpg
Completed Image ====&gt; 425.DSCN4478.JPG
Completed Image ====&gt; 426.v4-460px-Eat-Lamb%27s-Quarters-Step-2.jpg.webp
Completed Image ====&gt; 427.42292471122_9a111fa888_b.jpg
Completed Image ====&gt; 428.Santiago%20Oaks%20Regional%20Park,%20Orange,%20CA%207-3-11%20223.jpg
Completed Image ====&gt; 429.img-1365-orig.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 430.lambs-quarters-gnocchi-600x300.jpg
Completed Image ====&gt; 431.500_F_239866358_ZohBH2rCvDnmOlHC3PIYr5qXDzVAPJep.jpg
Completed Image ====&gt; 432.Lambs-quarters-Herbicide-Agriculture-Canada.jpg
Completed Image ====&gt; 433.lambs-quarters2.jpg
Completed Image ====&gt; 434.0013.jpg
Completed Image ====&gt; 435.bwi-bs267731.jpg
Completed Image ====&gt; 436.58440207_2230362707025473_5812130904905772992_n.jpg
Completed Image ====&gt; 437.Lambs_Quarters_iStockphoto_com_MIMOHE_44052526_banner_2.jpg
Completed Image ====&gt; 438.epazote_eggs.jpg
Completed Image ====&gt; 439.maxresdefault.jpg
Completed Image ====&gt; 440.500_F_193778444_FM5D0TJyIlhuHzKnQ2n8TEB0rU1a1gC6.jpg
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
Completed Image ====&gt; 441.lambs-quarters-chenopodium-album-05.jpg
Completed Image ====&gt; 442.Chenopodium%20album%20seeds.jpg
Completed Image ====&gt; 443.img_0301.jpg
Completed Image ====&gt; 444.5160112544_8af1fd7c36_b.jpg
Completed Image ====&gt; 445.Chenopodium-LB0805-6354.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 446.LambsQuarters.jpg
Completed Image ====&gt; 447.lambq-2leaf-zoom.jpg
Completed Image ====&gt; 448.trim+tender+lambs+quarters+010+%282%29.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 449.My-handful-of-miscella_opt.jpeg
Completed Image ====&gt; 450.Lambs-Quarters.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 451.jsc%209908%20lambs%20quarters.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 452.imnages.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 453.Santiago%20Oaks%20Regional%20Park,%20Orange,%20CA%207-3-11%20225.jpg
Completed Image ====&gt; 454.14.jpg
Completed Image ====&gt; 455.Lambs-Quarter-Chip-Dip.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 456.fab09s00e.jpg
IOError on an image...trying next one... Error: timed out
Completed Image ====&gt; 457.IMG_6609-1-750x562.jpg
Completed Image ====&gt; 458.millet-marigolds-buckwheat-and-lambs-quarters.jpg
Completed Image ====&gt; 459.Chenopodium-LB0805-6685.jpg
Completed Image ====&gt; 460.ssj-176139.jpg
Completed Image ====&gt; 461.shutterstock_1084658240Optimized.jpg
Completed Image ====&gt; 462.lambs_quarters_10sh25_083110_640x480.jpg
Completed Image ====&gt; 463.lambs-quarters-small-3.jpg
Completed Image ====&gt; 464.lambs-quarters-1024x735.jpg
Completed Image ====&gt; 465.images-2.jpeg
Completed Image ====&gt; 466.lambs-quarters-maturing-300x400.jpg
IOError on an image...trying next one... Error: timed out
Completed Image ====&gt; 467.poison-ivy.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 468.lambs-quarters-for-sale.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 469.lambs-quarters-leaves.jpg
Completed Image ====&gt; 470.11.jpg
Completed Image ====&gt; 471.aid8858767-v4-728px-Harvest-Lamb%27s-Quarters-Step-8.jpg
Completed Image ====&gt; 472.Lambs-Quarters.jpg
Completed Image ====&gt; 473.0004.jpg
Completed Image ====&gt; 474.Lambs-Quarters-4.jpg
Completed Image ====&gt; 475.lambs-quarters-jpg.jpg
Completed Image ====&gt; 476.DSC_0139.jpg
Completed Image ====&gt; 477.lambsquarters3.JPG
Completed Image ====&gt; 478.lambs-quarters.jpg
Completed Image ====&gt; 479.Dollarphotoclub_86952436-e1437756397736.jpg
Completed Image ====&gt; 480.ssj-176141.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 481.P9090004.jpg
Completed Image ====&gt; 482.lambs-quarters_w_pigweed_seedlings.jpg
Completed Image ====&gt; 483.27208305643_cef0fb4f48_b.jpg
Completed Image ====&gt; 484.lambsquarter1.jpg
Completed Image ====&gt; 485.Chenopodium%20album%20L,%20Lamb%27s%20quarters-1-2008.jpg
Completed Image ====&gt; 486.foraged-lambs-quarter.jpg
Completed Image ====&gt; 487.Chenopodium-album-25101.jpg
Completed Image ====&gt; 488.d832eb92-b87a-4188-9383-6de54c337236.jpg
Completed Image ====&gt; 489.lambs-quarter.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 490.chenopodium_album_x2.jpg
Completed Image ====&gt; 491.imoages.jpg
Completed Image ====&gt; 492.IMG_0184.jpg
Completed Image ====&gt; 493.2404.jpeg
Completed Image ====&gt; 494.5471422_5565dba2.jpg
Completed Image ====&gt; 495.lambs-quarters-leaves.jpg
Completed Image ====&gt; 496.tn0037.jpg
Completed Image ====&gt; 497.meadow-300x208.jpg
Completed Image ====&gt; 498.lambs-quarters.jpg
URLError on an image...trying next one... Error: HTTP Error 500: Internal Server Error
Completed Image ====&gt; 499.lamb-quarters-foliage.jpg
Completed Image ====&gt; 500.IMG_0829-575x1024.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 501.bwi-blw034033.jpg
Completed Image ====&gt; 502.lambs-quarters.jpg
Completed Image ====&gt; 503.lamb2527s_quarters1.jpg
Completed Image ====&gt; 504.9053669388_3aaefc08fc_b.jpg
Completed Image ====&gt; 505.july22-lambs%20quarters.jpg
Completed Image ====&gt; 506.4675256167_f1193381b4_b.jpg
Completed Image ====&gt; 507.920x920.jpg
Completed Image ====&gt; 508.pizza4-710x440.jpg
Completed Image ====&gt; 509.20.jpg
Completed Image ====&gt; 510.lambs-quarters.jpg
Completed Image ====&gt; 511.8010662798_87ccfd823e_b.jpg
Completed Image ====&gt; 512.lambsquarters2150.jpg
Completed Image ====&gt; 513.trim+tender+lambs+quarters+014+%282%29.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 514.lambs-quarters-final.jpg
Completed Image ====&gt; 515.140720_0174.jpg
Completed Image ====&gt; 516.jsc%20980718%20lamb's%20quarters.jpg
Completed Image ====&gt; 517.lambs-quarters-seed-2-comments-eating-lambsquarters-seeds.jpg
Completed Image ====&gt; 518.lambs-quarters-chenopodium-album-michael-earney.jpg
Completed Image ====&gt; 519.LQ1.png
Completed Image ====&gt; 520.chenopodium_album_2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 521.Chenopodium_album__Fathen-003.JPG
Completed Image ====&gt; 522.fc01d50c0c5a5d7de95e9898f78a21c8l-m0xd-w1020_h770_q80.jpg
Completed Image ====&gt; 523.blanched-myeongaju.jpg
Completed Image ====&gt; 524.0014.jpg
Completed Image ====&gt; 525.IMG_1468-e1437792278349.jpg
Completed Image ====&gt; 526.lambsquarters.jpg
Completed Image ====&gt; 527.lambq-leaf-zoom.jpg
Completed Image ====&gt; 528.lambs-quarters-plate-600x400.jpg
Completed Image ====&gt; 529.Lambsquarters%20seedling.jpg
Completed Image ====&gt; 530.stock-photo-plant-lamb-s-quarters-fan-hen-chenopodium-album-1147154342.jpg
Completed Image ====&gt; 531.lambs-quarters.jpg
Completed Image ====&gt; 532.Chenopodium-LB0806-7371.jpg
Completed Image ====&gt; 533.CHEalbum1JAH.jpg
Completed Image ====&gt; 534.14787102649_b23f306305_z.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 535.Chenopodium_giganteum-5529.jpg
Completed Image ====&gt; 536.daylilies.jpg
Completed Image ====&gt; 537.bwi-blws143109.jpg
Completed Image ====&gt; 538.purslane-180x180.jpg
Completed Image ====&gt; 539.lambsquarters1.jpg
Completed Image ====&gt; 540.Pest-Patrol-March-I_opt4-660x420.jpg
Completed Image ====&gt; 541.800px-Chenopodium_berlandieri_(3767482897)_(2).jpg
Completed Image ====&gt; 542.lambsquarters_098.jpg
Completed Image ====&gt; 543.cooking-lambs-quarters.jpg
Completed Image ====&gt; 544.what_is_this_plant_1_m7.jpg
Completed Image ====&gt; 545.lambs-quarters-weed.jpg
Completed Image ====&gt; 546.jsc%209810%20lamb's%20quarters%202.jpg
Completed Image ====&gt; 547.lambs-quarters.jpg
Completed Image ====&gt; 548.4.jpg
Completed Image ====&gt; 549.lambqunn.jpg
Completed Image ====&gt; 550.3-Common-Edible-Weeds-Traditional-Cooking-School-GNOWFGLINS-lambs-quarter.jpg
Completed Image ====&gt; 551.chenopodium_album_2.jpg
Completed Image ====&gt; 552.23ee.jpg
Completed Image ====&gt; 553.lamb_s_quarters_in_los_angeles_vacant_lot.jpg
Completed Image ====&gt; 554.Lambs-quarters-Chenopodium-album.jpg
Completed Image ====&gt; 555.Chenopodium_album.4.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 556.lambs-quarters-chenopodium-album-04.jpg
Completed Image ====&gt; 557.i283163839594790006._szw1280h1280_.jpg
IOError on an image...trying next one... Error: timed out
Completed Image ====&gt; 558.lambquartersbeans.jpg
Completed Image ====&gt; 559.chal_fl.jpg
Completed Image ====&gt; 560.t600-Lamb's%20quarters.jpg
Completed Image ====&gt; 561.lambs-quarters-cookstown-greens-edible-weeds.jpg
Completed Image ====&gt; 562.chenopodiumalbumandchenopodiummurale2.jpg
Completed Image ====&gt; 563.img_2149.jpg
Completed Image ====&gt; 564.Chenopodium_album__Fathen-001.JPG
Invalid or missing image format. Skipping...
Completed Image ====&gt; 565.lambs_quarters_magenta_spreen.jpg
Completed Image ====&gt; 566.P9090002.jpg
Completed Image ====&gt; 567.500_F_239866380_yFIUIz8lIXN1mQVYci5w0oYq9GrOTsJH.jpg
Completed Image ====&gt; 568.lambs-quarters-e1465160106881.jpg
Completed Image ====&gt; 569.0004.jpg
Completed Image ====&gt; 570.Wild_Vegetables-Pets-Lambs_Quarters.jpg
Completed Image ====&gt; 571.stock-photo-bathua-lambs-quarters-kathmandu-nepal-may-1400533223.jpg
Completed Image ====&gt; 572.fremontii1a.jpg
Completed Image ====&gt; 573.DSC_0005-001.JPG
Completed Image ====&gt; 574.img_2113.jpg
Completed Image ====&gt; 575.bwi-blws180789.jpg
Completed Image ====&gt; 576.weeds_lq_seedling_zoom.jpg
Completed Image ====&gt; 577.trim+tender+lambs+quarters+017+%282%29.JPG
Completed Image ====&gt; 578.lambs_quarters_9sh25_083110_640x480.jpg
Completed Image ====&gt; 579.IMG_1697.JPG
Completed Image ====&gt; 580.Fat-Hen-Garden-Weeds-G017706.jpg
Completed Image ====&gt; 581.lambs-quarters-seed-the-weed-that-wasnt-lambsquarters-image-of-lambsquarters-plant-and-flower.jpg
Completed Image ====&gt; 582.jsc%209810%20lamb's%20quarters%201.jpg
Completed Image ====&gt; 583.Lambs-quarters.jpg
Completed Image ====&gt; 584.lambs_quarters_5sh25_091310_640x480.jpg
Completed Image ====&gt; 585.105824014_lambs-quarters---fat-hen-chenopodium-album-x-50-seeds-.jpg
Completed Image ====&gt; 586.6888226697_9568cd21e0_o.jpg
IOError on an image...trying next one... Error: timed out
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
Invalid or missing image format. Skipping...
IOError on an image...trying next one... Error: timed out
Completed Image ====&gt; 587.lambs-quarters-seed-lambs-quarter-seeds-are-totally-safe-to-eat-but-there-are-two-cautions-to-keep-image-of-lambsquarters-plant-and-flower.jpg
Completed Image ====&gt; 588.aid8858777-v4-728px-Eat-Lamb%27s-Quarters-Step-10.jpg


Unfortunately all 1000 could not be downloaded because some images were not downloadable. 588 is all we got for this search filter!

Errors: 53

</pre></div>
</div>
<div class="outline-4" id="outline-container-org8742818">
<h4 id="org8742818">London Rocket</h4>
<div class="outline-text-4" id="text-org8742818">
<div class="highlight">
<pre><span></span>keywords["keywords"] = "london rocket"
london_rocket_paths = google_images.download(keywords)
</pre></div>
<pre class="example">

Item no.: 1 --&gt; Item name = london rocket
Evaluating...
Getting you a lot of images. This may take a few moments...
Reached end of Page.
Starting Download...
Completed Image ====&gt; 1.220px-Sisymbrium_irio_flower.JPG
Completed Image ====&gt; 2.DSC_0085_-_Sisymbrium_irio_London_rocket_large.jpg
Completed Image ====&gt; 3.IMG_4245_-_London_rocket_in_urban_environment_large.jpg
Completed Image ====&gt; 4.london-form2.jpg
Completed Image ====&gt; 5.london_rocket.jpg
Completed Image ====&gt; 6.london-rocket-flower.jpg
Completed Image ====&gt; 7.o_19ogl35m815objf016ih6ra4238.jpg
Completed Image ====&gt; 8.494.jpg
Completed Image ====&gt; 9.Sisymbrium_ir_300.jpg
Completed Image ====&gt; 10.londonrocket1.jpg
Completed Image ====&gt; 11.sisymbrium-irio1.jpg
Completed Image ====&gt; 12.london-rocket-leaf.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 13.51P9kTHuD%2BL._SR600%2C315_PIWhiteStrip%2CBottomLeft%2C0%2C35_SCLZZZZZZZ_.jpg
Completed Image ====&gt; 14.3982Sisymbrium-irio600x375.jpg
Completed Image ====&gt; 15.William%20Mason%20Regional%20Park,%20Irvine,%20CA%202-17-08%20008.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 16.london-rocket-2.jpg
Completed Image ====&gt; 17.london-rocket.jpg
Completed Image ====&gt; 18.londonrocketDSCN5624.jpg
Completed Image ====&gt; 19.g-london-rocket-plant-2.jpg
Completed Image ====&gt; 20.DSC_0010_2_-_London_rocket_greens_large.jpg
Completed Image ====&gt; 21.51P9kTHuD%2BL._AC_SY400_.jpg
Completed Image ====&gt; 22.Huntington%20Central%20Park,%20Huntington%20Beach,%20CA%202-15-09%20017.jpg
Completed Image ====&gt; 23.day-8-london-rocket-in-my-yard-1-8-19-1.jpg
Completed Image ====&gt; 24.1043.jpeg
Completed Image ====&gt; 25.Sisymbrium_ir_400.jpg
Completed Image ====&gt; 26.Sisymbrium_irio_[IMG_2592].jpg
Completed Image ====&gt; 27.3860Sisymbrium-irio600x375.jpg
Completed Image ====&gt; 28.London-Rocket.jpg
Completed Image ====&gt; 29.140309sv.jpg
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1056)&gt;
Completed Image ====&gt; 30.38639.jpg
Completed Image ====&gt; 31.o_19ogl3ape1f4f1knlnc48ik1a98h.jpg
Completed Image ====&gt; 32.maxresdefault.jpg
Completed Image ====&gt; 33.londonrocket3.jpg
Completed Image ====&gt; 34.london_rocket_bloom.jpg
Completed Image ====&gt; 35.london-rocket1.jpg
Completed Image ====&gt; 36.london_rocket_group.jpg
Completed Image ====&gt; 37.f14605.jpg
Completed Image ====&gt; 38.S120_29206a.jpg
Completed Image ====&gt; 39.day-8-london-rocket-in-my-yard-1-8-19-2.jpg
Completed Image ====&gt; 40.5c86b5627f629.image.jpg
Completed Image ====&gt; 41.c86d9c.jpg
Completed Image ====&gt; 42.1044.jpeg
Completed Image ====&gt; 43.day-8-london-rocket-in-my-yard-1-8-19-3.jpg
Completed Image ====&gt; 44.IMG_20180324_102901.jpg
Completed Image ====&gt; 45.londonrocket4.jpg
Completed Image ====&gt; 46.il_794xN.1506577530_kluz.jpg
Completed Image ====&gt; 47.false-london-rocket-sisymbrium-loeselii-brassicaceae-CTMHBW.jpg
Completed Image ====&gt; 48.cb_londrkt03f.jpg
Completed Image ====&gt; 49.London%20Rocket.jpg
Completed Image ====&gt; 50.London-Rocket-Kramer-Junction-Feb-2014_0.jpg
Completed Image ====&gt; 51.3654Sisymbrium-irio600x377.jpg
Completed Image ====&gt; 52.140309ss.jpg
Completed Image ====&gt; 53.il_794xN.1227097048_e0cv.jpg
Completed Image ====&gt; 54.5601383082_859b2daa06_b.jpg
Completed Image ====&gt; 55.london-fruit.jpg
Completed Image ====&gt; 56.DSC_0157_-_London_rocket_Pesto_on_pork_chop_breaded_with_toasted_ground_London_rocket_seed_large.jpg
Completed Image ====&gt; 57.londonrocket.jpg
Completed Image ====&gt; 58.original.jpeg
Completed Image ====&gt; 59.3850Sisymbrium-irio600x375.jpg
Completed Image ====&gt; 60.15FU4685o.jpg
Completed Image ====&gt; 61.large.jpg
Completed Image ====&gt; 62.4341089426_5707f36f5f_z.jpg
Completed Image ====&gt; 63.da6811590f132add2ddcdb28404f5341.jpg
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 64.vd7-2989633.jpg
Completed Image ====&gt; 65.SSYIR-Sisymbrium_irio_t.jpg
Completed Image ====&gt; 66.London%20Rocket%2C%20Sisymbrium%20irio-L.jpg
Completed Image ====&gt; 67.weed-LondonRocket1.jpg
Completed Image ====&gt; 68.IMG_20180325_094411-1.jpg
Completed Image ====&gt; 69.Sisymbrium-irio_London-rocket_JM-DiTomaso.jpg
Completed Image ====&gt; 70.S120_29654a.jpg
Completed Image ====&gt; 71.London-rocket-Sisymbrium-irio.jpg
Completed Image ====&gt; 72.Sisymbrium-irio-20080320_600.JPG
Completed Image ====&gt; 73.londonrocketplant.jpg
Completed Image ====&gt; 74.London_Rocket001_RMueller.jpg
Completed Image ====&gt; 75.24831956541_9dd9b2395a_b.jpg
Completed Image ====&gt; 76.londonrock.jpg
Completed Image ====&gt; 77.London%20Rocket%2C%20Sisymbrium%20irio-L.jpg
Completed Image ====&gt; 78.London_Rocket002_RMueller.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 79.weed-london-rocket-2-edited-for-book.jpg
Completed Image ====&gt; 80.Sisymbrium%20loeselii%20Sagaredzjo%2C%20Imeretien%2C%20Georgia%2020180428_3135.jpg
Completed Image ====&gt; 81.london-rocket-sisymbrium-irio-growing-in-sand-in-umm-al-quwayn-uae-H29K4J.jpg
Completed Image ====&gt; 82.London%20Rocket.jpg
Completed Image ====&gt; 83.409a41.jpg
Completed Image ====&gt; 84.Sisymbrium%20loeselii%20David%20Gareji%20Monastery%2C%20Kakheti%2C%20Georgia%2020180429_2973.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 85.Sisymbrium%20irio.jpg
Completed Image ====&gt; 86.00574751.jpg
Completed Image ====&gt; 87.London%20Rocket%2C%20Sisymbrium%20irio-L.jpg
Completed Image ====&gt; 88.Sisymbrium_iriofebruary2.jpg
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 89.large.JPG
Completed Image ====&gt; 90.5498127211_1d5cba6d3b_b.jpg
Completed Image ====&gt; 91.o_19ogl3guf1hi8175r13441cdg13dpq.jpg
Completed Image ====&gt; 92.Sisymbrium%20loeselii%20Sagaredzjo%2C%20Imeretien%2C%20Georgia%2020180428_3134.jpg
Completed Image ====&gt; 93.0415.jpeg
Completed Image ====&gt; 94.S120_29205a.jpg
Completed Image ====&gt; 95.0e9b64.jpg
Completed Image ====&gt; 96.2510.jpeg
Completed Image ====&gt; 97.DSC_0008_-_London_rocket_seeds_large.jpg
Completed Image ====&gt; 98.Sisiri01.jpg
Completed Image ====&gt; 99.default.jpg
Completed Image ====&gt; 100.index.jpg
Completed Image ====&gt; 101.o_19ogl3l80166gv11h0r18os12bt13.jpg
Completed Image ====&gt; 102.s-l300.jpg
Completed Image ====&gt; 103.londonrocket..jpg
Completed Image ====&gt; 104.S120_29656a.jpg
Completed Image ====&gt; 105.flora168a.jpg
Completed Image ====&gt; 106.Dimmit%20County,%20Texas-004.JPG
Completed Image ====&gt; 107.sisymbriumirio12.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 108.ESRP-biologist-Justine-Kokx-in-a-dense-stand-of-London-rocket-Sisymbrium-irio-The-gray.png
Completed Image ====&gt; 109.S120_29212a.jpg
Completed Image ====&gt; 110.771abeac6cf01a13ad970c3b92be4aa5.jpg
Completed Image ====&gt; 111.15FUC1433x.jpg
Completed Image ====&gt; 112.79813.jpg
Completed Image ====&gt; 113.IMG_20180325_094349-1-768x1024.jpg
Completed Image ====&gt; 114.londonrocket2.jpg
Completed Image ====&gt; 115.common-southeast-new-mexico-weed-london-rocket-mustard-e1547857102350.jpg
Completed Image ====&gt; 116.sisymbriumirio2.jpg
Completed Image ====&gt; 117.84610.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 118.Sisymbrium-irio01-tn.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 119.sisymbrium_irio4.jpg
Completed Image ====&gt; 120.S120_29658a.jpg
Completed Image ====&gt; 121.London-Rocket-blog.jpg
Completed Image ====&gt; 122.4438178937_a11999137a_z.jpg
Completed Image ====&gt; 123.Sisymbrium_irio_[IMG_4442].jpg
Completed Image ====&gt; 124.Sisymbrium%20loeselii%20David%20Gareji%20Monastery%2C%20Kakheti%2C%20Georgia%2020180429_2971.jpg
Completed Image ====&gt; 125.0188.jpeg
Completed Image ====&gt; 126.londonrocket4b.jpg
Completed Image ====&gt; 127.londonrocketleaves.jpg
Completed Image ====&gt; 128.LondonRocket51501.jpg
Completed Image ====&gt; 129.2347778923_8bc09e4a59_z.jpg
Completed Image ====&gt; 130.Sisymbrium-irio02.jpg
Completed Image ====&gt; 131.London%20Rocket,%20Sisymbrium%20irio%20(3)_small.jpg
Completed Image ====&gt; 132.Clock-Tower-Rocket-Entrance.jpg
Completed Image ====&gt; 133.sisymbrium_irio.jpg
Completed Image ====&gt; 134.large.JPG
Completed Image ====&gt; 135.JON-LONDON-Rocket-Factory.jpg
Completed Image ====&gt; 136.S120_29657a.jpg
Completed Image ====&gt; 137.16401121689_6910900ea9_b.jpg
Completed Image ====&gt; 138.mustard-london-rocket-weed-e1554082015485.jpg
Completed Image ====&gt; 139.figure-736-london-rocket-is-a-difficult-to-control-annual-winter-weed-Copy.jpg
Completed Image ====&gt; 140.d013d5bfded05925b70bd40deed34cf1.jpg
Completed Image ====&gt; 141.London%20Rocket,%20Sisymbrium%20irio%20(4)_small.jpg
Completed Image ====&gt; 142.maxresdefault.jpg
Completed Image ====&gt; 143.siiri2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 144.sisymbrium_irio2.jpg
Completed Image ====&gt; 145.0WsbPw47_400x400.jpg
Completed Image ====&gt; 146.IMG_20180325_094349-1-2000x1200.jpg
Completed Image ====&gt; 147.1551.jpeg
Completed Image ====&gt; 148.5374776.jpg
Completed Image ====&gt; 149.56a067119f967.image.jpg
Completed Image ====&gt; 150.image005.jpg
Completed Image ====&gt; 151.e753e3.jpg
Completed Image ====&gt; 152.16422275435_5da4a8000a_b.jpg
Completed Image ====&gt; 153.LondonRocketDet51501.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 154.large.jpg
Completed Image ====&gt; 155.jcs-sisymbrium-irio-25532.jpg
Completed Image ====&gt; 156.london_rocket_leaf.jpg
Completed Image ====&gt; 157.sisymbrium_irio3.jpg
Completed Image ====&gt; 158.sisymbriumirio1.jpg
Completed Image ====&gt; 159.36624881265_41779ab594_b.jpg
Completed Image ====&gt; 160.sisymbrium-irio2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 161.LDN_Rocket_Rare_Beef_and_Chip_Salad_2_CROP.jpg
Completed Image ====&gt; 162.sisymbrium_irio1.jpg
Completed Image ====&gt; 163.38640.jpg
Completed Image ====&gt; 164.londonrocket.jpg
Completed Image ====&gt; 165.IMG_4536.JPG
Completed Image ====&gt; 166.59e68d196fc1e8472fabf807b1e0268c.jpg
Completed Image ====&gt; 167.25036081001_323725b280_m.jpg
Completed Image ====&gt; 168.5374777.jpg
Completed Image ====&gt; 169.IMG_20180324_102853-1-768x1024.jpg
Completed Image ====&gt; 170.04.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 171.1554.jpeg
Completed Image ====&gt; 172.Santiago%20Oaks%20Regional%20Park,%20Orange,%20CA%201-20-08%20021.jpg
Completed Image ====&gt; 173.sisymbrium-irio-2-672x372.jpg
Completed Image ====&gt; 174.09ec06.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 175.Sisymbrium-irio03-tn.jpg
Completed Image ====&gt; 176.9R3KVRJKYRI0S0W0Q090H070CQ703Q70ARLQNRZQYRXQCR90K0XQK0503Q40JQJKOR0QURFKTQ503QZQYRMQFR60K0U0.jpg
Completed Image ====&gt; 177.londonrocket4c.jpg
Completed Image ====&gt; 178.140309su.jpg
Completed Image ====&gt; 179.jcs-sisymbrium-irio-26138.jpg
Completed Image ====&gt; 180.water-rocket-eruca-aquatica-and-london-rocket-sisymbrium-irio-handcoloured-woodblock-engraving-of-a-botanical-illustration-from-adam-lonicers-krauterbuch-or-herbal-frankfurt-1557-this-from-a-17th-century-pirate-edition-or-atlas-of-illustrations-only-with-captions-in-latin-greek-french-italian-german-and-in-english-manuscript-P9G7KB.jpg
Completed Image ====&gt; 181.IMG_1273_Watermark.jpg
Completed Image ====&gt; 182.Sisymbrium_irio_[IMG_2487].jpg
Completed Image ====&gt; 183.thames-rockets-detail.jpg
Completed Image ====&gt; 184.maxresdefault.jpg
Completed Image ====&gt; 185.wall-street-and-london-rocket-after-us-bailout-415x275.jpg
Completed Image ====&gt; 186.IMG_4534.JPG
Completed Image ====&gt; 187.13500499343_7033192b2f_b.jpg
Completed Image ====&gt; 188.Sisymbrium%20loeselii%20F%C3%A5r%C3%B6gatan%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160613_0053.jpg
Completed Image ====&gt; 189.londonrocketplant2.jpg
Completed Image ====&gt; 190.image003.jpg
Completed Image ====&gt; 191.26b.jpg
Completed Image ====&gt; 192.rocket-in-royal-air-force-museum-london-uk-united-kingdom-england-F3H35B.jpg
Completed Image ====&gt; 193.Santiago%20Oaks%20Regional%20Park,%20Orange,%20CA%201-20-08%20019.jpg
Completed Image ====&gt; 194.sisymbrium-irio3.jpg
Completed Image ====&gt; 195.zh4-3049794.jpg
Completed Image ====&gt; 196.0844.jpeg
Completed Image ====&gt; 197.33269439368_a2b76c83f1_m.jpg
Completed Image ====&gt; 198.London%20Rocket,%20Sisymbrium%20irio%20(1)_small.jpg
Completed Image ====&gt; 199.412Y4nzcXXL._SX425_.jpg
Completed Image ====&gt; 200.5374779.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 201.356630.jpg
Completed Image ====&gt; 202.S120_29211a.jpg
Completed Image ====&gt; 203.weeds-header.jpg
Completed Image ====&gt; 204.londonrocket3x450.jpg
Completed Image ====&gt; 205.a4668185-c05a-4753-a802-1c0f519834d8.jpg
Completed Image ====&gt; 206.11_2_Biofuel.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 207.26779570281_e6b72f5b28_b.jpg
Completed Image ====&gt; 208.cropped-resize-13.jpg
Completed Image ====&gt; 209.140309st.jpg
Completed Image ====&gt; 210.S120_29204a.jpg
Completed Image ====&gt; 211.sisymbrium_irio_fr.jpg
Completed Image ====&gt; 212.3907.jpeg
Completed Image ====&gt; 213.Sisymbrium%20irio2.jpg
Completed Image ====&gt; 214.sisymbrium-irio-london-rocket-p69b3p.jpg
Completed Image ====&gt; 215.309e0d.jpg
Completed Image ====&gt; 216.thames-rockets.jpg
Completed Image ====&gt; 217.leptosphaeria_maculans.jpg
Completed Image ====&gt; 218.AE-3475-45282.jpg
Completed Image ====&gt; 219.0a91f29801264c07a04aac89ef4730fb.jpg
Completed Image ====&gt; 220.Hedge-Mustard-Sisymbrium-Irio-London-Rocket-Khubhkala.jpg
Completed Image ====&gt; 221.weed-LondonRocket2.jpg
Completed Image ====&gt; 222.Sisymbrium_irio_[IMG_2482].jpg
Completed Image ====&gt; 223.siiri4.jpg
Completed Image ====&gt; 224.6997895151_fb8a602b66_b.jpg
Completed Image ====&gt; 225.5374780.jpg
Completed Image ====&gt; 226.default.jpg
Completed Image ====&gt; 227.mustard%2Bin%2Balfalfa.jpg
Completed Image ====&gt; 228.londonrocketstem.jpg
Completed Image ====&gt; 229.022805-VE-Renz-Rocket-1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 230.5f1d4d.jpg
Completed Image ====&gt; 231.1553.jpeg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 232.milk-thistle.jpg
Completed Image ====&gt; 233.NuMex-Twilight-1-e1530377622654.jpg
Completed Image ====&gt; 234.rocket-league-finals-london-copperbox.jpg
Completed Image ====&gt; 235.Bratou20.jpg
Completed Image ====&gt; 236.London-Rocket.jpg
Completed Image ====&gt; 237.resize-IMG_0709.jpg
Completed Image ====&gt; 238.Picture1.png
Completed Image ====&gt; 239.7426f8c79812f86d44b6c77bfee6b48d.jpg
Completed Image ====&gt; 240.London%20Rocket,%20Sisymbrium%20irio_small.jpg
Completed Image ====&gt; 241.KHUBKALAN_4.jpg
Completed Image ====&gt; 242.london-rocket-flix-weld-sisymbrium-irio-l.jpg
Completed Image ====&gt; 243.S120_29203a.jpg
Completed Image ====&gt; 244.ArugulaandAppleSalad.jpg
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 245.ce4b06.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 246.2656.jpeg
Completed Image ====&gt; 247.sisymbrium-irio-a7d83edf-7454-4761-8354-eb771d3757e-resize-750.jpeg
Completed Image ====&gt; 248.Spiny-Sowthistle.jpg
Completed Image ====&gt; 249.78f89db8faa36a766811ff3d1db41075.jpg
Completed Image ====&gt; 250.51wJnBTdO3L._SX425_.jpg
Completed Image ====&gt; 251.london-rocket-aaron-burrows.jpg
Completed Image ====&gt; 252.rocket-food-the-luxury-london-catering-company-with-a-conscience.jpg
Completed Image ====&gt; 253.S120_29207a.jpg
Completed Image ====&gt; 254.rocket.png
Completed Image ====&gt; 255.s_irio.jpg
Completed Image ====&gt; 256.Sisymbrium%2Birio%2BL%2B%252811%2529.JPG
Completed Image ====&gt; 257.I-15.mustard1.JPG
Completed Image ====&gt; 258.15FU4689o.jpg
Completed Image ====&gt; 259.86866.jpg
Completed Image ====&gt; 260.Sisymbrium%20loeselii%20Sagaredzjo%2C%20Imeretien%2C%20Georgia%2020180428_3133.jpg
Completed Image ====&gt; 261.sisymbriumirio.jpg
Completed Image ====&gt; 262.s_irio2.jpg
Completed Image ====&gt; 263.4493a2.jpg
Completed Image ====&gt; 264.siiri3.jpg
Completed Image ====&gt; 265.S120_29655a.jpg
Completed Image ====&gt; 266.IMG_3681_large.jpg
Completed Image ====&gt; 267.56344614_397036497516085_1450132965202685348_n.jpg
Completed Image ====&gt; 268.CKGKVK8KPKVQB02QD0PQV0WQY0WQV0PQT0GQC0HKAKMKVK1QTKQKTKKKOKVQZSNQ1K8K1K9QF0GKTKAQVKVQOKGKTK5K.jpg
Completed Image ====&gt; 269.Sisymbrium%20irio%204065.JPG
Completed Image ====&gt; 270.rocket-boat-header.jpg
Completed Image ====&gt; 271.226100.jpg
Completed Image ====&gt; 272.rocket-holborn.jpg
Completed Image ====&gt; 273.Salad-rocket940x627.jpg
Completed Image ====&gt; 274.london_rocket_3-1624447C9AB1D00A0D0-thumb400.jpg
Completed Image ====&gt; 275.0320.jpeg
Completed Image ====&gt; 276.S120_29215a.jpg
Completed Image ====&gt; 277.Sisymbrium%20loeselii%20F%C3%A5r%C3%B6gatan%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160613_0041.jpg
Completed Image ====&gt; 278.london-england-uk-thames-rockets-tourist-speedboat-on-the-river-thames-passing-under-blackfriars-bridge-st-pauls-cathedral-in-the-background-RP452H.jpg
Completed Image ====&gt; 279.rocket-backgrund.jpg
Completed Image ====&gt; 280.24367603.jpg
Completed Image ====&gt; 281.DSCN0425.JPG
Completed Image ====&gt; 282.s_irio1.jpg
Completed Image ====&gt; 283.londonrocketplt6x500.jpg
Completed Image ====&gt; 284.5459957.jpg
Completed Image ====&gt; 285.new-rocket-engine-london-sydney-768x659.jpg
Completed Image ====&gt; 286.Sisymbrium_irio_[IMG_4445].jpg
Completed Image ====&gt; 287.khubkala-london-rocket-sisymbrium-irio.jpg
Completed Image ====&gt; 288.RocketSpace_Top-London-Event-Planners.png
Completed Image ====&gt; 289.siiri0.jpg
Completed Image ====&gt; 290.London+Rocket%2C+Sisymbrium+irio%2C+nitrate.jpg
Completed Image ====&gt; 291.KHUBKALAN_10.jpg
Completed Image ====&gt; 292.54447300_997537700439525_4130224835163473728_n.jpg
Completed Image ====&gt; 293.london-rocket-copyright-lynda-terrill.jpg
Completed Image ====&gt; 294.rocket-city-signature.jpg
Completed Image ====&gt; 295.stock-photo-texas-wildflower-rapistrum-rugosum-london-rocket-bastardcabbage-1376555177.jpg
Completed Image ====&gt; 296.226102.jpg
Completed Image ====&gt; 297.131eedb9d220f7840a9e8f3d43839f07.jpg
Completed Image ====&gt; 298.ddsao_commercial_Capco-London-2_008a-700x525.jpg
Completed Image ====&gt; 299.maxresdefault.jpg
Completed Image ====&gt; 300.ww2-air-raid-damage-brockley-london-rocket-raid-at-brockley-rescue-B3P47B.jpg
Completed Image ====&gt; 301.LONDON+ROCKET.jpg
Completed Image ====&gt; 302.Sisymbrium%20loeselii%20F%C3%A5r%C3%B6gatan%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160613_0047.jpg
Completed Image ====&gt; 303.image.jpg
Completed Image ====&gt; 304.19439045138_19f3a0d18e_m.jpg
Completed Image ====&gt; 305.siir_002_lhp.jpg
Completed Image ====&gt; 306.il_570xN.1576686148_4fk8.jpg
Completed Image ====&gt; 307.plond3003110188_q1_2-0._UX357_QL90_.jpg
Completed Image ====&gt; 308.maxresdefault.jpg
Completed Image ====&gt; 309.50956118_377358896149576_3788801874683841679_n.jpg
Completed Image ====&gt; 310.the-rocket-in-euston.jpg
Completed Image ====&gt; 311.S120_29210a.jpg
Completed Image ====&gt; 312.sisymbrium_irio_w.jpg
Completed Image ====&gt; 313.Sisymbrium%20loeselii%20Sagaredzjo%2C%20Imeretien%2C%20Georgia%2020180428_3133.jpg
Completed Image ====&gt; 314.KHUBKALAN_3.jpg
Completed Image ====&gt; 315.rocket-bishopsgate-sep15.jpg
Completed Image ====&gt; 316.v2damage_10.jpg
Completed Image ====&gt; 317.Rocket-Restaurant-3-1200x800-optimised.jpg
Completed Image ====&gt; 318.46421368874_7120d3f903_b.jpg
URLError on an image...trying next one... Error: HTTP Error 403: Forbidden
Completed Image ====&gt; 319.New_GettyImagesSubs-531752444_trans_NvBQzQNjv4BqZgEkZX3M936N5BQK4Va8RT0aesusvN1TE7a0ddd_esI.jpg
Completed Image ====&gt; 320.15FU4686o.jpg
Completed Image ====&gt; 321..jpg
Completed Image ====&gt; 322.226101.jpg
Completed Image ====&gt; 323.46597159_324898131443324_8266813337300077069_n.jpg
Completed Image ====&gt; 324.gwrfilmtile-2-1-1024x427-768x320.jpg
Completed Image ====&gt; 325.pizza-with-rocket.jpg
Completed Image ====&gt; 326.img-7641.jpg
Completed Image ====&gt; 327.good_energy_gu_15-small.jpg
Completed Image ====&gt; 328.Dx2x_1uVsAAqHP4.jpg
Completed Image ====&gt; 329.sisymbrium_irio.jpg
Completed Image ====&gt; 330.the-rocket-pub-in-euston-road-london-uk-DXP6JY.jpg
Completed Image ====&gt; 331.london_rocket_2.jpg
Completed Image ====&gt; 332.khubkalan-500x500.jpg
Completed Image ====&gt; 333.hqdefault.jpg
Completed Image ====&gt; 334.44E71EEE-1DD8-B71B-0B20A4ED31C2094E.jpg
Completed Image ====&gt; 335.RocketSpace_Raising-Venture-Capital-in-San-Francisco-vs-London.png
Completed Image ====&gt; 336.London-Rocket-4BCTV-Host.jpg
Completed Image ====&gt; 337.240615.jpg
Completed Image ====&gt; 338.54447152_381205215798386_7606656965033509534_n.jpg
Completed Image ====&gt; 339.19006093973_c63196300b_b.jpg
Completed Image ====&gt; 340.Sisymbrium%20loeselii%20F%C3%A5r%C3%B6gatan%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160613_0052.jpg
Completed Image ====&gt; 341.Greenwich-Peninsula-775x270.jpg
Completed Image ====&gt; 342.0000684_rocket-revolution-50-mins-london-eye_415.jpeg
Completed Image ====&gt; 343.Sisymbrium_irio_[IMG_4446].jpg
Completed Image ====&gt; 344._7394966.jpg
Completed Image ====&gt; 345.3070ic1.jpg
Completed Image ====&gt; 346.outdoor-dining-area-in-adams-court-of-rocket-restaurant-old-broad-JF68WM.jpg
Completed Image ====&gt; 347.p2045519912-3.jpg
Completed Image ====&gt; 348.London+Rocket.jpg
Completed Image ====&gt; 349.ROCKET_PLANTER_0.jpg
Completed Image ====&gt; 350.londonrocket.jpg
Completed Image ====&gt; 351.tansymustard_post.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 352.Sisymbriom_Irio.jpg
Completed Image ====&gt; 353.london-r-must09-073s.jpg
Completed Image ====&gt; 354.023AnnualMercuryLimehoBasinLondSep14red.JPG
Completed Image ====&gt; 355.4-16-19-thumbnail-description-london-rocket.png
Completed Image ====&gt; 356.london-events_0.jpg
Completed Image ====&gt; 357.KHUBKALAN_9.jpg
Completed Image ====&gt; 358.03-Rocket-Catering-Branding-Van-Livery-Here-Design-UK-BPO.jpg
Completed Image ====&gt; 359.BZ4LWZ5L8ZWHAHMH1HXHCHUHHRUHAZ4LNZNHHR4HHRUHZR9HFHNHJHIHAHKLOHWHHR8LNZZLDH4HDH9HDHRL2Z0LEZLL.jpg
Completed Image ====&gt; 360.e5aaab2e503952d8b1949ecdf84c2d35.jpg
Completed Image ====&gt; 361.Lyles-lamb-720x480.jpg
Completed Image ====&gt; 362.SultanStoryRocket.jpg
Completed Image ====&gt; 363.London%20Rocket,%20Sisymbrium%20irio%20(2)_small.jpg
IOError on an image...trying next one... Error: [Errno 104] Connection reset by peer
Completed Image ====&gt; 364.London_Metropolitan_University%2C_Rocket_Complex%2C_Holloway_Road.jpg
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 365.boyrocketsmallblack.jpg
Completed Image ====&gt; 366.226103.jpg
Completed Image ====&gt; 367.S120_29216a.jpg
Completed Image ====&gt; 368.TA-TA-small-plates-poussin-aubergine-jack1-720x480.jpg
Completed Image ====&gt; 369.lr_rosette.jpg
Completed Image ====&gt; 370.1103161.jpg
Completed Image ====&gt; 371.tansy_mustard_descurainia_pinnata_walt_britt_003.jpg
Completed Image ====&gt; 372.london-explodes-sea-fireworks-over-ben-london-eye-new_cg1p18020635c_th.jpg
Completed Image ====&gt; 373.lr.jpg
Completed Image ====&gt; 374.Sisymbrium_irio_flower2.jpg
Completed Image ====&gt; 375.londonrocket.jpg
Completed Image ====&gt; 376.tower-of-london-yann-lazarus-canvas-print.jpg
Completed Image ====&gt; 377.s-l1000.jpg
Completed Image ====&gt; 378.Sisymbrium_irio_[IMG_4447].jpg
Completed Image ====&gt; 379.sisymbriumfull.jpg
Completed Image ====&gt; 380.5459955.jpg
Completed Image ====&gt; 381.maxresdefault.jpg
Completed Image ====&gt; 382.RLCS-Season-5-Announcement-02_1080.309bf22bd29c2e411e9dd8eb07575bb1.jpg
Completed Image ====&gt; 383.33141801252_b7d99a209d_b.jpg
Completed Image ====&gt; 384.rocket-and-prosciutto.jpg
Completed Image ====&gt; 385.london_rocket_by_patgoltz_d1ccww0-250t.jpg
Completed Image ====&gt; 386.1-nocturne-in-black-and-gold-james-a-m-whistler-canvas-print.jpg
Completed Image ====&gt; 387.retro-graffiti-rocket-ship-art-brick-lane-london-61414437.jpg
Completed Image ====&gt; 388.el-pastor_trans_NvBQzQNjv4Bqeo_i_u9APj8RuoebjoAHt0k9u7HhRJvuo-ZLenGRumA.jpg
Completed Image ====&gt; 389.SegaWorld_London_Rocket_Entrance_3.png
Completed Image ====&gt; 390.tansy_mustard_field_post.jpg
Completed Image ====&gt; 391.rocket-complex-london-metropolitan-university-holloway-road-islington-BF60EE.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 392._1459074.jpg
Completed Image ====&gt; 393.86865.jpg
Completed Image ====&gt; 394.il_340x270.1808318442_d7m2.jpg
Completed Image ====&gt; 395.V2-launch.jpg
Completed Image ====&gt; 396.BBC-Weather-forecast-news-London-Met-Office-UK-947465.jpg
Completed Image ====&gt; 397.pima-canyon-hiking-trail-small-260nw-1380027323.jpg
Completed Image ====&gt; 398.Sisymbrium_irio_[IMG_4444].jpg
Completed Image ====&gt; 399.new-year-bigalbaloo-stock-canvas-print.jpg
Completed Image ====&gt; 400.siir_001_lhp.jpg
Completed Image ====&gt; 401.London-Rocket.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 402.SpaceX-plans-rocket-flights-from-London-to-New-York-in-29-minutes-660x330.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 403.rocket.jpg
Completed Image ====&gt; 404.RECP-130900-SHTF-08-EDITED.jpg
Completed Image ====&gt; 405.Dalston-Library-4th-January-1945.jpg
Completed Image ====&gt; 406.Dubai-London-Elon-Musk.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 407.https%3A%2F%2Fblogs-images.forbes.com%2Fbridaineparnell%2Ffiles%2F2017%2F09%2FElon-Musk-Giant-Rocket-Could-Take-Us-To-Mars-In-Just-7-Years-And-London-In-29-Minutes.jpg
Completed Image ====&gt; 408.new-year-london-11499911.jpg
Completed Image ====&gt; 409.folderthumb.jpg
Completed Image ====&gt; 410.05b4d31ca93e3ad36ec015064bd6ff07.jpg
Completed Image ====&gt; 411.Sisymbrium_loeselii,I_MEL3468.jpg
Completed Image ====&gt; 412.london-house-prices.jpg
Completed Image ====&gt; 413.Gagarin-Sqaure-artists-impression-from-38-Southwark-Street-Photo-Lees-Associates-700x455.jpg
Completed Image ====&gt; 414.il_340x270.1901271951_25j8.jpg
Completed Image ====&gt; 415.Himalayan-Balsam_resized-225x300.jpg
Completed Image ====&gt; 416.d731f365745629827fed3ade91155985.jpg
Completed Image ====&gt; 417.file.jpg
Completed Image ====&gt; 418.Dimmit%20County,%20Texas.JPG
Completed Image ====&gt; 419.file.jpg
Completed Image ====&gt; 420.m_5b377e73baebf689a7de2285.jpg
Completed Image ====&gt; 421.The-Ethicurean-at-the-Barley-Wood-Walled-Garden-720x480.jpg
Completed Image ====&gt; 422.paper-london-WhiteBlack-Rocket-Dot-Sweater.jpeg
Completed Image ====&gt; 423.IMG_2059_600x.jpg
Completed Image ====&gt; 424.siiri5.jpg
Completed Image ====&gt; 425.salami-rocket-parmesan.jpg
Completed Image ====&gt; 426.1031069-smurfslostvillage.jpg
Completed Image ====&gt; 427.9464140.png
Completed Image ====&gt; 428.SegaWorld_London_Rocket_Entrance_2.png
Completed Image ====&gt; 429.5498126289_e4c8595bcd_b.jpg
Completed Image ====&gt; 430.16641874958_af3efa301e_m.jpg
Completed Image ====&gt; 431.3574411866_717f8d2b91_b-700x525.jpg
Completed Image ====&gt; 432.5459956.jpg
Completed Image ====&gt; 433.Imgf1053.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 434.siir_004_lhp.jpg
Completed Image ====&gt; 435.24831958631_e18617f41e.jpg
Completed Image ====&gt; 436.V2-Rocket-small1.jpg
Completed Image ====&gt; 437.fe0eb763be438e422d675770d2a49f16.image.310x550.jpg
Completed Image ====&gt; 438.pic817.jpg
Completed Image ====&gt; 439.cd4071c72b2f25ead18518b2d74e9390.jpg
Completed Image ====&gt; 440.e9662b_6cbaa7225c2d4cf98879010a7c5e1197~mv2.webp
Completed Image ====&gt; 441.NINTCHDBPICT000481640683.jpg
Completed Image ====&gt; 442.large_paper-london-blue-rocket-pleated-sleeve-jumper.jpg
Completed Image ====&gt; 443.sisymbrium-irio15.jpg
Completed Image ====&gt; 444.bobby_london_rocket.jpg
Completed Image ====&gt; 445.$_86.JPG
Completed Image ====&gt; 446.gettyimages-855370170.jpg
Completed Image ====&gt; 447.Faviken1-720x480.jpg
Completed Image ====&gt; 448.rocket-complex.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 449.SpaceX-to-SLASH-travel-times-Elon-Musk-will-rocket-passengers-from-London-to-New-York-1791179.jpg
Completed Image ====&gt; 450.Sisymbrium%20loeselii%20-%20False%20London%20Rocket%20-%20borstsenap_Sisymbrium_loeselii-8712.jpg
Completed Image ====&gt; 451.Skinnydip_iPhone_6_Rocket_Glitter_Case_3_5a03b09f-3076-4ea6-a912-b6b5f82cd463.jpg
Completed Image ====&gt; 452.20daceff-7adb-421b-9c82-51aa53cb9c30.jpeg
Completed Image ====&gt; 453.weed-LondonRocket3.jpg
Completed Image ====&gt; 454.burrata-rocket-and-proscuitto.jpg
Completed Image ====&gt; 455.7922399e-995f-4f51-a2ee-6bff2cd9d248.jpg
Completed Image ====&gt; 456.london-united-kingdom-april-12-450w-75306139.jpg
Completed Image ====&gt; 457.BottleRocketLondon-300x225.jpeg
Completed Image ====&gt; 458.stephenson-s-rocket-locomotive-science-museum-london-uk-was-preserved-now-display-53493967.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 459.Sisymbrium_irio,_seed,I_USID257.jpg
Completed Image ====&gt; 460.supersonic-plane.jpg
Completed Image ====&gt; 461.il_340x270.1139711024_5sj5.jpg
Completed Image ====&gt; 462.elton-john--rocket-man-lesley-giles-canvas-print.jpg
Completed Image ====&gt; 463.7d6e8d3df8990e9b826c3719b65a00fd.jpg
Completed Image ====&gt; 464.IMG_6979-910x1024.jpg
Completed Image ====&gt; 465.beef-3-860x348.jpg
Completed Image ====&gt; 466.SpaceX0512.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 467.spacex-rocket_md.jpg
Completed Image ====&gt; 468.rocket-tomato-salad.jpg
Completed Image ====&gt; 469.1798575_cheesegrater.jpg
Completed Image ====&gt; 470.1410342683916_wps_2_V2_map_3_jpg.jpg
Completed Image ====&gt; 471.rocket_restaurant_bar_city_london_photo_4.jpg
Completed Image ====&gt; 472.SegaWorld_London_Rocket_Entrance_1.png
Completed Image ====&gt; 473.space-rocket-cup-and-straw-28567-lifestyle.jpg
Completed Image ====&gt; 474.24367604.jpg
Completed Image ====&gt; 475.file.jpg
Completed Image ====&gt; 476.rocket-league-wheels.jpg
Completed Image ====&gt; 477.Sisymbrium_loeselii,I_MEL3469.jpg
Completed Image ====&gt; 478.404-restaurant.jpg
Completed Image ====&gt; 479.large_000000.jpg
Completed Image ====&gt; 480.4py55lifhzj21.jpg
Completed Image ====&gt; 481.london2018-970x970_1200x1200.jpg
Completed Image ====&gt; 482.item_XL_31752380_0d28a22b0bcfb.jpg
Completed Image ====&gt; 483.london-uk-06th-june-2019-celebs-attend-cash-rocket-photocall-at-wellington-arch-on-6-june-2019-london-uk-credit-picture-capitalalamy-live-news-TC6PKA.jpg
Completed Image ====&gt; 484.weedsladybug.jpg
Completed Image ====&gt; 485.DB-photo-by-Miriam-Preis-culinary-academy-of-sweden-720x480.jpg
Completed Image ====&gt; 486.rocket-jump-london-1560x1560.jpg
Completed Image ====&gt; 487.MB915210_942long.jpg
Completed Image ====&gt; 488.londons-flat-iron-lenny-carter-canvas-print.jpg
Completed Image ====&gt; 489.13395371_f1024.jpg
Completed Image ====&gt; 490.Rocket-Restaurants-Holborn-London-Interior-Design-5.jpg
Completed Image ====&gt; 491.ligularia-the-rocket-1024x681.jpg
Completed Image ====&gt; 492.consultancy.jpg
Completed Image ====&gt; 493.10320809.jpg
Completed Image ====&gt; 494.UK-weather-forecast-August-2017-summer-Met-Office-Britain-heatwave-Lucifer-Europe-837552.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 495.74393.jpg
Completed Image ====&gt; 496.rocket-food-home_slide-03413210015106607188113618863.jpg
Completed Image ====&gt; 497.p3229209331-3.jpg
Completed Image ====&gt; 498.81132-tomato-and-rosemary-london-rocket-smoothie.jpg
Completed Image ====&gt; 499.64659_creative_1515578815583.jpg
Completed Image ====&gt; 500.IMG_20190117_142023-01-500x500.jpeg
Completed Image ====&gt; 501.Market-Hall-4-1320x880.jpg
Completed Image ====&gt; 502.012EchiumPlantagineumLondFldsAug15red.JPG
Completed Image ====&gt; 503.bar-ingenious-sign-funny.jpg
Completed Image ====&gt; 504.pool-sharks-from-the-london-office.jpg
Completed Image ====&gt; 505.MUS-FAPC1114_405.jpg
Completed Image ====&gt; 506.powerboating%20and%20London%20Eye%20320.jpg
Completed Image ====&gt; 507.MUS-FAFP1114_black_622.jpg
Completed Image ====&gt; 508.145221.jpg
Completed Image ====&gt; 509.thames-rockets-london-speed-14101327.jpg
Completed Image ====&gt; 510.UK-009916_large.jpg
Completed Image ====&gt; 511.people-cars-front-rocket-pub-king-s-cross-london-uk-july-one-busiest-pubs-euston-126558552.jpg
Completed Image ====&gt; 512.wild_rocket.jpg
Completed Image ====&gt; 513.img-7639.jpg
Completed Image ====&gt; 514.PAPER%20London%20Rocket%20Wool%20Jumper%20Sweaters%20%20Knits%20Sapphire%20FQLEWI_3.jpg
Completed Image ====&gt; 515.7649196.jpg
Completed Image ====&gt; 516.hqdefault.jpg
URLError on an image...trying next one... Error: HTTP Error 503: Service Unavailable
Completed Image ====&gt; 517.sisymbrium_irio.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 518.img_20190324_130321824.jpg
Completed Image ====&gt; 519.mev-11113199.jpg
Completed Image ====&gt; 520.london_rocket_sisymbrium_irio_l_007.jpg
Completed Image ====&gt; 521.310558d8342a5d918d137fafe1094de5_featured_v2.jpg
Completed Image ====&gt; 522.gherkinrocket.jpg
Completed Image ====&gt; 523.rocket_restaurant_bar_city_london_photo_2.jpg
Completed Image ====&gt; 524.7QFRQQYRJKQ0X0DQ70TQ50Q0N0Q080BR7QYRQQCR90YRZQNRM0FQ90R060CQ20DQ20Q0U0JR0Q00P0ORMQDRKQWRQQ3R.jpg
Completed Image ====&gt; 525.Rocket-by-Balls-Brothers-1-optimised.jpg
Completed Image ====&gt; 526.London-Rocket-flower-Sisymbrium-irio-jpg.jpg
Completed Image ====&gt; 527.ea9d42f9-da0e-46c3-b268-105543074d79.jpeg
Completed Image ====&gt; 528.37568262_2222731437743083_622871120931979264_n-Copy-1.jpg
Completed Image ====&gt; 529.001-houses-for-sale-11-57ed5317f264d-57ed53180e718.jpg
Completed Image ====&gt; 530.clifton-nurseries-london-banner-double.jpg
Completed Image ====&gt; 531.43722581-london-england-may-31-stephenson-s-rocket-locomotive-science-museum-in-london-on-may-31-2015-in-lond.jpg
Completed Image ====&gt; 532.the-rocket-in-euston.jpg
Completed Image ====&gt; 533.Saltimporten-720x480.jpg
Completed Image ====&gt; 534.north-korea-london-center.jpg
Completed Image ====&gt; 535.98327919_Supersonic_rocket_trial_trans_NvBQzQNjv4BqZgEkZX3M936N5BQK4Va8RWtT0gK_6EfZT336f62EI5U.jpg
Completed Image ====&gt; 536.Legends-of-Gaming-2015-main_tcm25-395616.jpg
Completed Image ====&gt; 537.team-dignitas-win-rocket-league-champs.jpg
Completed Image ====&gt; 538.kiss-peter-cade-canvas-print.jpg
Completed Image ====&gt; 539.p979539651-3.jpg
Completed Image ====&gt; 540.Rocket%2C_Science_Museum%2C_London_-_DSC05416.JPG
Completed Image ====&gt; 541.5b8ff137dda4c8452c8b45b3.jpg
Completed Image ====&gt; 542._2dc285ae-49b3-11e7-942b-1b07039b2a8c.jpg
Completed Image ====&gt; 543.85224.jpg
Completed Image ====&gt; 544.Startupbootcamp_Insurtech_RocketSpace_Partnership_London.jpg
Completed Image ====&gt; 545.s-l300.jpg
Completed Image ====&gt; 546.pyongyangsatellite0903.jpg
Completed Image ====&gt; 547.027008bd-f3a9-4346-ba95-8841adc5daf2.jpeg
Completed Image ====&gt; 548.Stephenson%27s_Rocket.jpg
Completed Image ====&gt; 549.25035770948_99f2d2f570_b.jpg
Completed Image ====&gt; 550.zpg_agent_static_agent_profile_images_(18623590).jpg
Completed Image ====&gt; 551.med_1418105beac739472d8b5cc13671d4cc.jpg
Completed Image ====&gt; 552.green-machine-avocado.jpg
Completed Image ====&gt; 553.7d7f721e-ad3b-444f-9a46-928d265c9646.jpg
Completed Image ====&gt; 554.50883754_1997344140302270_3575933874234229939_n.jpg
Completed Image ====&gt; 555.First-V2-Rocket-13.jpg
Completed Image ====&gt; 556.rocket%20man%20at%20call%20me%20mr%20lucky.png
Completed Image ====&gt; 557.30_St_Mary_Axe_from_Leadenhall_Street.jpg
Completed Image ====&gt; 558.p942494144-3.jpg
Completed Image ====&gt; 559.1800.jpg
Completed Image ====&gt; 560.londonrocket2.jpg
Completed Image ====&gt; 561.londonrocket6874.jpg
Completed Image ====&gt; 562.Leon-Leon-London_Rocket_12-2_15th-June-1.jpg
Completed Image ====&gt; 563.JON-LONDON-Paolo-Rocket-Factory.jpg
Completed Image ====&gt; 564.Morito-breakfast-1320x880.jpg
Completed Image ====&gt; 565.29d33e06-093b-4ec7-b448-64b2127f8a17.jpeg
Completed Image ====&gt; 566.sisymbrium-610773b6-adb9-4595-9c4c-e425df6e5c3-resize-750.jpeg
Completed Image ====&gt; 567.627.jpg
Completed Image ====&gt; 568.davidminn2.jpg
Completed Image ====&gt; 569.V2-rocket-remains-st-stephens-rd-sept-17-1944-c.jpg
Completed Image ====&gt; 570.24629827090_4b0daf81b2_b.jpg
Completed Image ====&gt; 571.p935073872-3.jpg
Completed Image ====&gt; 572.2_4_d5.jpg
Completed Image ====&gt; 573.Space_Shuttle_Columbia_launching-808x454.jpg
Completed Image ====&gt; 574.pic1.jpg
Completed Image ====&gt; 575.saved-london-monument-shape-v-rocket-inscription-sarnaki-poland-commemorating-world-war-ii-polish-heroes-71868054.jpg
Completed Image ====&gt; 576.DTFXLB.jpg
Completed Image ====&gt; 577.54447169_337552116881558_1489561345650094779_n.jpg
Completed Image ====&gt; 578.formosat.jpg
Completed Image ====&gt; 579.metro-piazza-pizza.jpg
Completed Image ====&gt; 580.Lambeth-baths-bombed.jpg
Completed Image ====&gt; 581.rocket-league-rumble.jpg
Completed Image ====&gt; 582.maxresdefault.jpg
Completed Image ====&gt; 583.image_90004.jpeg
Completed Image ====&gt; 584.Santa-Bufalina-pizza-720x480.jpg
Completed Image ====&gt; 585.7836309_f520.jpg
Completed Image ====&gt; 586.dsc05409.jpg
Completed Image ====&gt; 587.rocketML010803_100x110.jpg
Completed Image ====&gt; 588.682074327.jpg
Completed Image ====&gt; 589.Thames%2BRockets.jpg
Completed Image ====&gt; 590.Diamondback-Moth-on-London-.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 591.29604074145_8b48c4315e_b.jpg
Completed Image ====&gt; 592.londonRocketSm.jpg
Completed Image ====&gt; 593.lh_3.jpg
Completed Image ====&gt; 594.20190216_170313-e1550625559355-768x1024.jpg
Completed Image ====&gt; 595.2_4_d6.jpg
Completed Image ====&gt; 596.Estimated-lower-threshold-temperatures-and-times-for-isothermal-inactivation-of-seed-of.png
Completed Image ====&gt; 597.space-rockets-at-london-science-museum.jpg
Completed Image ====&gt; 598.londonrocket1.jpg
Completed Image ====&gt; 599.Frame_Black-Arrow1.jpg
Completed Image ====&gt; 600.bresaola-parmesan-rocket.jpg
Completed Image ====&gt; 601._MG_3861%20copy%202.jpg
Completed Image ====&gt; 602.IMG_2510.jpg
Completed Image ====&gt; 603.Teff.jpg
Completed Image ====&gt; 604.D6sLquIX4AAFw9y.jpg
Completed Image ====&gt; 605.78683e_7027722c38d74cc0b513ee43b32e4aa2~mv2.webp
Completed Image ====&gt; 606.hqdefault.jpg
Completed Image ====&gt; 607.54428676_362798810994767_5988585013693480279_n.jpg
Completed Image ====&gt; 608.p1220343083-3.jpg
Completed Image ====&gt; 609.stephensons-rocket-locomotive-science-museum-london-uk-avante-garde-template-steam-powered-passenger-locomotives-53493961.jpg
Completed Image ====&gt; 610.PAPER%20London%20Rocket%20Wool%20Jumper%20Sweaters%20%20Knits%20Sapphire%20FQLEWI_1.jpg
Completed Image ====&gt; 611.316120_1.jpg
Completed Image ====&gt; 612.IMG_0641.jpg
Completed Image ====&gt; 613.Stripped-Back-tomato-salad.jpg
Completed Image ====&gt; 614.hqdefault.jpg
Completed Image ====&gt; 615.property.jpg
Completed Image ====&gt; 616.c6461645-1a13-48bb-a5b1-6d7661712435.jpeg
Completed Image ====&gt; 617.p196041756-3.jpg
Completed Image ====&gt; 618.53419775_660699761016397_2026533198008089050_n.jpg
Completed Image ====&gt; 619.vintage-street-style-london-rocket-originals-sophia-blue-wedge-sandals-navy-1940s-1950s-handbag-hat-chiffon-scarf.jpg
Completed Image ====&gt; 620.The-Proud-Archivist-cauliflower-720x480.jpg
Completed Image ====&gt; 621.maxresdefault.jpg
Completed Image ====&gt; 622.p411390444-3.jpg
Completed Image ====&gt; 623.tansy.jpg
Completed Image ====&gt; 624.p1220347285-3.jpg
Completed Image ====&gt; 625.20131022Rauke2.jpg
Completed Image ====&gt; 626.snapdragon%2Bin%2Bgarden.jpg
Completed Image ====&gt; 627.p813812566-3.jpg
Completed Image ====&gt; 628.priya-guha-rocketspace-uk-london-general-manager.jpg
Completed Image ====&gt; 629.tOMwMEu2Dcqfr2PxVKu0BlLz6FBUIamZsQRQhDSX1Kg.jpg


Unfortunately all 1000 could not be downloaded because some images were not downloadable. 629 is all we got for this search filter!

Errors: 37

</pre></div>
</div>
<div class="outline-4" id="outline-container-org163441e">
<h4 id="org163441e">Sow Thistle</h4>
<div class="outline-text-4" id="text-org163441e">
<div class="highlight">
<pre><span></span>keywords["keywords"] = "smooth sow thistle"
sow_thistle_paths = google_images.download(keywords)
</pre></div>
<pre class="example">

Item no.: 1 --&gt; Item name = smooth sow thistle
Evaluating...
Getting you a lot of images. This may take a few moments...
Reached end of Page.
Starting Download...
Completed Image ====&gt; 1.sowthistle_smooth.jpg
Completed Image ====&gt; 2.SowThistle(Smooth)_DSC07766p1.JPG
Completed Image ====&gt; 3.9652.jpg
Completed Image ====&gt; 4.SowThistle(Smooth)_eastLancsRd_2010_09_21_003p9.jpg
Completed Image ====&gt; 5.Sow-thistle,%20Smooth%20(Sonchus%20oleraceus)%20Church%20Walk%20Sapcote%20SP%204894%209320%20(taken%2011.10.2008).JPG
Completed Image ====&gt; 6.Smooth_Sow_Thistle_sw_080716_60983c.jpg
Completed Image ====&gt; 7.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_018p2.jpg
Completed Image ====&gt; 8.sonch_oler.jpg
Completed Image ====&gt; 9.large_Sowthistle1.jpg
Completed Image ====&gt; 10.SowThistle(Smooth)_2009_04_03_BoatCrawl_LancasterCanal_KenBirchs_540p6.jpg
Completed Image ====&gt; 11.sonchus_oleraceus_smooth_sow_thistle.jpg
Completed Image ====&gt; 12.1200px-Sonchus_February_2008-1.jpg
Completed Image ====&gt; 13.SowThistle(Smooth)_2009_04_03_BoatCrawl_LancasterCanal_KenBirchs_542p6.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 14.web%208.jpg
Completed Image ====&gt; 15.5374204_8c2e7bdd.jpg
Completed Image ====&gt; 16.Sow-Thistle-8.jpg
Completed Image ====&gt; 17.common_sow_thistle_plant1.jpg
Completed Image ====&gt; 18.Sow-thistle,%20Prickly%20(Sonchus%20asper)%20Old%20Fosse%20Sapcote%20SP%204909%209166%20(taken%202.6.2006)..JPG
Completed Image ====&gt; 19.web%202.jpg
Completed Image ====&gt; 20.flowering-tops-of-smooth-sow-thistle-sonchus-oleraceus-the-leaves-J4Y65Y.jpg
Completed Image ====&gt; 21.Sow-Thistle-4.jpg
Completed Image ====&gt; 22.ece0de.jpg
Completed Image ====&gt; 23.Sow-thistle-Prickly-1.jpg
Completed Image ====&gt; 24.Sow-thistle-Prickly-2.jpg
Completed Image ====&gt; 25.p18mjkdkkn9251qh3lht1n8m13sv3.jpg
Completed Image ====&gt; 26.flowering-top-of-smooth-sow-thistle-sonchus-oleraceus-young-leaves-edible-as-a-foraged-food-common-uk-european-weed-T5KTH3.jpg
Completed Image ====&gt; 27.Smooth%20Sowthistle.jpeg
Completed Image ====&gt; 28.IMG_20190528_103650946.jpg
Completed Image ====&gt; 29.sonchus_oleraceus_smooth_sow_thistle_common_flower_plant_side_view_19-09-08.jpg
Completed Image ====&gt; 30.2011-06-23%20at%2012-41-40.jpeg
Completed Image ====&gt; 31.ecf0a7.jpg
Completed Image ====&gt; 32.flowering-top-of-smooth-sow-thistle-sonchus-oleraceus-young-leaves-edible-as-a-foraged-food-common-uk-european-weed-T5KTHD.jpg
Completed Image ====&gt; 33.smooth_sowthistle_IMGP0261.jpg
Completed Image ====&gt; 34.p179q2ticb1lro1rlg1koq1j3v18pf3l.jpg
Completed Image ====&gt; 35.yellow-flowered-smooth-sow-thistle-sonchus-oleraceus-is-a-member-of-J0NPFP.jpg
Completed Image ====&gt; 36.Common_sowthistle___Sonchus_oleraceus-005.JPG
URLError on an image...trying next one... Error: HTTP Error 404: Not Found
Completed Image ====&gt; 37.IMG_1747.JPG
Completed Image ====&gt; 38.yellow-flowers-flowering-top-of-smooth-sow-thistle-sonchus-oleraceus-young-leaves-edible-as-a-foraged-food-common-uk-european-weed-T7A95H.jpg
Completed Image ====&gt; 39.sonchus_oleraceus_smooth_sow_thistle_close.jpg
Completed Image ====&gt; 40.sonchus-oleraceus1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 41.SS2521204.jpg
Completed Image ====&gt; 42.Smooth-sow-thistle-seedling.jpg
Completed Image ====&gt; 43.FOOD_sowthistle-1024x673.jpg
Completed Image ====&gt; 44.prickly_sowthistle.jpg
Completed Image ====&gt; 45.smooth_sowthistle_2907t_r20.jpg
Completed Image ====&gt; 46.maxresdefault.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 47.85b24d.jpg
Completed Image ====&gt; 48.80115760.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 49.smooth-sow-thistle-sonchus-oleraceus-flowers-XE1RR3.jpg
Completed Image ====&gt; 50.Sow-thistle-Smooth-1.jpg
Completed Image ====&gt; 51.smooth-sow-thistle-sonchus-oleraceus-yellow-soft-79333227.jpg
Completed Image ====&gt; 52.Common%20Sowthistle.jpg
Completed Image ====&gt; 53.smooth_sow_thistle.jpg
Completed Image ====&gt; 54.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_017p1.jpg
Completed Image ====&gt; 55.29139600124_115d1a9af8_b.jpg
Completed Image ====&gt; 56.yellow-flowered-smooth-sow-thistle-sonchus-oleraceus-is-a-member-of-J0NPG2.jpg
Completed Image ====&gt; 57.common-sow-thistle-leaves.jpg
Completed Image ====&gt; 58.5374202_0b7ad895.jpg
Completed Image ====&gt; 59.common-sow-thistle-plant.jpg
Completed Image ====&gt; 60.72225205.jpg
Completed Image ====&gt; 61.SNCOL-Sonchus_oleraceus_t.jpg
Completed Image ====&gt; 62.80116088.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 63.IMG_1917.JPG
Completed Image ====&gt; 64.Pricklysow-croprotect.jpg
Completed Image ====&gt; 65.Smooth%20Sowthistle_P1020431.jpeg
Completed Image ====&gt; 66.bd78cc.jpg
Completed Image ====&gt; 67.annual-sowthistle-sonchus-oleraceus-common-450w-1166678155.jpg
Completed Image ====&gt; 68.329121.jpg
Completed Image ====&gt; 69.sowthistle_large.jpg
Completed Image ====&gt; 70.ed85f8.jpg
Completed Image ====&gt; 71.smooth_sowthistle_2909t_r22.jpg
Completed Image ====&gt; 72.24.jpg
Completed Image ====&gt; 73.29010992-smooth-sow-thistle-conchus-oleraceus-inflorescence.jpg
Completed Image ====&gt; 74.Sonchus%20oleraceus%20Chersonesos%2C%20Sevastopol%2C%20Crimea%2C%20Russia%2020150914_0096.jpg
Completed Image ====&gt; 75.p16v168dm2mla19ejvf198v7v57.jpg
Completed Image ====&gt; 76.3535847370_6391db8170_b.jpg
Completed Image ====&gt; 77.80125617.jpg
Completed Image ====&gt; 78.Smooth-Sowthistle2.jpg
Completed Image ====&gt; 79.sonchus-oleraceus_560x315.jpg
Completed Image ====&gt; 80.Common_sowthistle___Sonchus_oleraceus-007.JPG
Completed Image ====&gt; 81.young-sonchus-oleraceus-common-sowthistle-sow-thistle-smooth-annual-hare-s-colwort-other-names-milky-tassel-milk-soft-swinies-117936556.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 82.IMG_20190605_122936493.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 83.IMG_1964.JPG
Completed Image ====&gt; 84.sonchus-oleraceus1.jpg
Completed Image ====&gt; 85.jcs-sonchus-oleraceus-63325.jpg
Completed Image ====&gt; 86.sowthistle_perennial_thumb_410.jpg
Completed Image ====&gt; 87.gwg-sch661.jpg
Completed Image ====&gt; 88.stock-photo-sonchus-oleraceus-or-annual-sowthistle-common-sow-thistle-smooth-sow-thistle-1123582856.jpg
Completed Image ====&gt; 89.annual-sowthistle-sonchus-oleraceus-common-260nw-1328571110.jpg
Completed Image ====&gt; 90.il_794xN.1614660773_px89.jpg
Completed Image ====&gt; 91.smooth-sowthistle-salsa-recipe-750x420.png
Completed Image ====&gt; 92.European_Goldfinch_%28Carduelis_carduelis%29_eating_seeds_of_Smooth_Sow_Thistle_%28Sonchus_oleraceus%29_%2826067225674%29.jpg
Completed Image ====&gt; 93.sow-thistle-flowers.jpg
Completed Image ====&gt; 94.sonchus_oleraceus_smooth_sow_thistle_02-02-13_1.jpg
Completed Image ====&gt; 95.smooth_sow_thistle3_5-4-2014_th.JPG
Completed Image ====&gt; 96.sow-thistle-full-view.jpg
Completed Image ====&gt; 97.Sonchus_oleraceus_flower2.jpg
Completed Image ====&gt; 98.17789.jpg
Completed Image ====&gt; 99.Sow-Thistle-Smooth-2.jpg
Completed Image ====&gt; 100.sonchus-oleraceus-Smooth-Sow-thistle-J.R.Crellin-Floralimages.co.uk.jpg
Completed Image ====&gt; 101.fromother_077_mid.jpg
Completed Image ====&gt; 102.4692982753_46fcb46493_b.jpg
Completed Image ====&gt; 103.83ec77.jpg
Completed Image ====&gt; 104.5374208_158efadd.jpg
Completed Image ====&gt; 105.20.jpg
Completed Image ====&gt; 106.SONOL-leaf-sideW_1344580907.jpg
Completed Image ====&gt; 107.ccb53cb0208a03a5a557396b9c24917e.jpg
Completed Image ====&gt; 108.videoblocks-many-dry-common-sowthistle-flowers-with-fluff-swaying-in-wind-in-late-summer-or-early-autumn-also-called-sow-thistle-smooth-sow-thistle-annual-sow-thistle-hares-colwort-sonchus-oleraceus_rdg29jqnqg_thumbnail-full01.png
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1056)&gt;
Invalid or missing image format. Skipping...
Completed Image ====&gt; 109.annual-sowthistle-sonchus-oleraceus-common-260nw-1328571026.jpg
Completed Image ====&gt; 110.sonchus-oleraceus-smooth-sow-thistle-seed-head-and-flowers-on-the-end-of-a-tall-stem-PFR2BJ.jpg
Completed Image ====&gt; 111.rdc-ad_135126.jpg
Completed Image ====&gt; 112.SowthistleE.jpg
Completed Image ====&gt; 113.beautiful-dry-common-sowthistle-flower-with-fluff-swaying-in-wind-in-late-summer-or-early-autumn-also-called-sow-thistle-smooth-sow-thistle-annual-sow-thistle-hares-colwort-sonchus-oleraceus_sixajmgbil_thumbnail-full01.png
Completed Image ====&gt; 114.142a5.jpg
Completed Image ====&gt; 115.a5aa6c.jpg
Completed Image ====&gt; 116.Common_sowthistle___Sonchus_oleraceus-004.JPG
Completed Image ====&gt; 117.76138.jpg
Completed Image ====&gt; 118.Sonchus_oleraceus.jpg
Completed Image ====&gt; 119.Sonchus_oleraceus_flower3.jpg
Completed Image ====&gt; 120.web%209.jpg
Completed Image ====&gt; 121.5374207_ad55345e.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 122.Sonchus%20oleraceus%202%2C%20Gewone%20melkdistel%2C%20Saxifraga-Jan%20van%20der%20Straaten.jpg
Completed Image ====&gt; 123.Sonchus%20asper%20Jordh%C3%B6gar%20Hyllie%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020180604_0035.jpg
Completed Image ====&gt; 124.475ded.jpg
Completed Image ====&gt; 125.sonchus-oleraceus2.jpg
Completed Image ====&gt; 126.Sonchus%20oleraceus%205%2C%20Gewone%20melkdistel%2C%20Saxifraga-Peter%20Meininger.JPG
Completed Image ====&gt; 127.655196.jpg
Completed Image ====&gt; 128.5455851254_fa04765b5d_b.jpg
IOError on an image...trying next one... Error: The read operation timed out
Completed Image ====&gt; 129.sonchus_oleraceus_smooth_sow_thistle_common_flower_01-05-04.jpg
Completed Image ====&gt; 130.sonchus-asper-juvenile-plant-in-nature1.jpg
Completed Image ====&gt; 131.smooth-sow-thistle-sonchus-oleraceus-flower-bud-and-seedheads-forming-BR6A78.jpg
Completed Image ====&gt; 132.plant_Smooth_Sow_thistle_wf_080614_60264c.jpg
Completed Image ====&gt; 133.46662533232_ccfe6335a7_b.jpg
Completed Image ====&gt; 134.23.jpg
Completed Image ====&gt; 135.Sonchus_oleraceus_-_Smooth_Sow-thistle.JPG
URLError on an image...trying next one... Error: &lt;urlopen error [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1056)&gt;
Completed Image ====&gt; 136.sow_thistle_360x203.png
Completed Image ====&gt; 137.8158769_orig.jpg
Completed Image ====&gt; 138.sonchus-oleraceus-beautiful-dry-common-sowthistle-flower-with-fluff-swaying-in-wind-in-late-summer-or-early-autumn-also-called-sow-thistle-smooth-sow-thistle-annual-sow-thistle-hares-colwort_setyznjh_thumbnail-full01.png
Completed Image ====&gt; 139.sow-thistle-flower-2.jpg
Completed Image ====&gt; 140.aam-aaes91799.jpg
Completed Image ====&gt; 141.67916.jpg
Completed Image ====&gt; 142.3097063_orig.jpg
Completed Image ====&gt; 143.SNCOL-Flower20.jpg
Completed Image ====&gt; 144.01321434.jpg
Completed Image ====&gt; 145.Weed178.jpg
Completed Image ====&gt; 146.Sonchus%20oleraceus%20Ridhuset%2C%20Klagshamns%20udde%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020150609_0016.jpg
Completed Image ====&gt; 147.3170025235_c0fa8a4ea5_b.jpg
Completed Image ====&gt; 148.SowThistle2.jpg
Completed Image ====&gt; 149.smooth-sow-thistle-sonchus-oleraceus-young-plant-leaf-rosette-B4YA1A.jpg
Completed Image ====&gt; 150.smooth_sow_thistle2_5-4-2014_th.JPG
Completed Image ====&gt; 151.sowthistle_plant1.jpg
Completed Image ====&gt; 152.smooth-sow-thistle-sonchus-oleraceus-260nw-1097605763.jpg
Completed Image ====&gt; 153.smooth-sow-thistle.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 154.b112d2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 155.2012-01-24%20at%2012-12-40.jpeg
Completed Image ====&gt; 156.rosette_smooth_sow_thistle_21-2-2018_th.JPG
Completed Image ====&gt; 157.Smooth-Sow-Thistle-Sonchus-oleraceus-POPUP.jpg
Completed Image ====&gt; 158.500_F_82043410_9WuvLcouY72SO2MIP35u8pUt0M3HSRZS.jpg
Completed Image ====&gt; 159.IMG_20190609_145833225.jpg
Completed Image ====&gt; 160.stock-photo-sonchus-oleraceus-or-annual-sowthistle-common-sow-thistle-smooth-sow-thistle-1125654875.jpg
Completed Image ====&gt; 161.53372.jpg
Completed Image ====&gt; 162.90361106.jpg
Completed Image ====&gt; 163.96b547.jpg
Completed Image ====&gt; 164.Sonchus%20oleraceus%203%2C%20Gewone%20melkdistel%2C%20Saxifraga-Jan%20van%20der%20Straaten.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 165.fhr-88888-12309-686.jpg
Completed Image ====&gt; 166.videoblocks-scenic-dry-common-sowthistle-flower-with-fluff-swaying-in-wind-in-late-summer-or-early-autumn-also-called-sow-thistle-smooth-sow-thistle-annual-sow-thistle-hares-colwort-sonchus-oleraceus_sdaio7hcg_thumbnail-full01.png
Completed Image ====&gt; 167.Common_sowthistle___Sonchus_oleraceus-003.JPG
Completed Image ====&gt; 168.142a3.jpg
Completed Image ====&gt; 169.yellow-flowered-smooth-sow-thistle-sonchus-oleraceus-is-a-member-of-J0NPFG.jpg
Completed Image ====&gt; 170.SONSS-EAR-700.jpg
Completed Image ====&gt; 171.scenic-dry-common-sowthistle-flower-fluff-swaying-wind-late-summer-early-autumn-also-called-sow-thistle-smooth-annual-113403593.jpg
Completed Image ====&gt; 172.sonchus-oleraceus-smooth-sow-thistle-english-school.jpg
Completed Image ====&gt; 173.p661350765-3.jpg
Completed Image ====&gt; 174.27445a.jpg
Completed Image ====&gt; 175.sow-thistle-2.jpg
Completed Image ====&gt; 176.sonchus_oleraceus_smooth_sow_thistle_common_00_flower_03-06-08_1.jpg
Completed Image ====&gt; 177.possible_smooth_sow_thistle_4-4-2014_th.JPG
Completed Image ====&gt; 178.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_020p3.jpg
Completed Image ====&gt; 179.perennial_sowthistle-young.jpg
Completed Image ====&gt; 180.3373645632_ffe48fe31a_b.jpg
Completed Image ====&gt; 181.4f36b5.jpg
Completed Image ====&gt; 182.18b.jpg
Completed Image ====&gt; 183.IMG_7500-Smooth-Sow-thistle-Sonchus-oleraceus-Old-croft-house-NC044306-6-12-16-2.jpg
Completed Image ====&gt; 184.14033.jpg
Completed Image ====&gt; 185.sonchus-oleraceus2.jpg
Completed Image ====&gt; 186.stock-photo-annual-sowthistle-or-sonchus-oleraceus-common-sow-thistle-smooth-sow-thistle-hare-s-colwort-1170548473.jpg
Completed Image ====&gt; 187.field-sowthistle-seedhead.jpg
Completed Image ====&gt; 188.IMG_4692.JPG
Completed Image ====&gt; 189.2013-07-02%20at%2015-23-58.jpeg
Completed Image ====&gt; 190.web%204.jpg
Completed Image ====&gt; 191.plants_484_mid.jpg
Completed Image ====&gt; 192.smooth-sow-thistle-sonchus-oleraceus-flowering-plants-a1w22m.jpg
Completed Image ====&gt; 193.SNCOL-Flower5.jpg
Completed Image ====&gt; 194.rdc-ad-175924.jpg
Completed Image ====&gt; 195.sow-thistle-pulled.jpg
Completed Image ====&gt; 196.SowThistle(Smooth)_2009_04_03_BoatCrawl_LancasterCanal_KenBirchs_540p7.jpg
Completed Image ====&gt; 197.Sow-thistle-Perennial-2.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 198.fab10s00f.jpg
Completed Image ====&gt; 199.sonchus_oleraceus_smooth_sow_thistle_common_flower_19-09-08.jpg
Completed Image ====&gt; 200.Sonchus_oleraceus__Smooth_Sow_Thistle_.JPG
Completed Image ====&gt; 201.c5f7d7.jpg
Completed Image ====&gt; 202.sow-thistle.jpg
Completed Image ====&gt; 203.142a1.jpg
Completed Image ====&gt; 204.3244d2.jpg
Completed Image ====&gt; 205.3321766617_fd28c26175_b.jpg
Completed Image ====&gt; 206.smooth-sow-thistle-sonchus-oleraceus-bob-gibbons-canvas-print.jpg
Completed Image ====&gt; 207.web%203.jpg
Completed Image ====&gt; 208.plants_485_mid.jpg
Completed Image ====&gt; 209.80110235.jpg
Completed Image ====&gt; 210.329126.jpg
Completed Image ====&gt; 211.SNCOL-Plant5.jpg
Completed Image ====&gt; 212.field-sow-thistle.jpg
Completed Image ====&gt; 213.stock-photo-annual-sowthistle-or-sonchus-oleraceus-common-sow-thistle-smooth-sow-thistle-hare-s-colwort-1170546952.jpg
Completed Image ====&gt; 214.4543s.jpg
Completed Image ====&gt; 215.Sonchus-Oleraceus-Smooth-Sowthistle.jpg
Completed Image ====&gt; 216.08757-Sonchus-oleraceus.jpg
Completed Image ====&gt; 217.smooth-sowthistle.jpg
Completed Image ====&gt; 218.rdc-ad_135097.jpg
Completed Image ====&gt; 219.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_027p5.jpg
Completed Image ====&gt; 220.smooth_sow_thistle4_5-4-2014_th.JPG
Completed Image ====&gt; 221.Common_sowthistle___Sonchus_oleraceus-001.JPG
Completed Image ====&gt; 222.stock-photo-annual-sowthistle-or-sonchus-oleraceus-common-sow-thistle-smooth-sow-thistle-hare-s-colwort-1163731474.jpg
Completed Image ====&gt; 223.13.jpg
Completed Image ====&gt; 224.Leaves151.jpg
Completed Image ====&gt; 225.c72dca.jpg
Completed Image ====&gt; 226.smooth-sow-thistle-sonchus-oleraceus-bob-gibbonsscience-photo-library.jpg
Completed Image ====&gt; 227.sow-thistle.jpg
Completed Image ====&gt; 228.103166.jpg
Completed Image ====&gt; 229.Smooth-Sow-Thistle-Sonchus-oleraceus-grubbed-out-popup.jpg
Completed Image ====&gt; 230.smooth-sow-thistle-leaf-detail.jpg
Completed Image ====&gt; 231.IMG_20190605_102911324.jpg
Completed Image ====&gt; 232.sonchus_oleraceus_smooth_sow_thistle_common_flower_leaf_18-06-04.jpg
Completed Image ====&gt; 233.Sonchus%20oleraceus%20P-pl%20Kloster%C3%A4ngsv%C3%A4gen%2C%20Lund%2C%20Sk%C3%A5ne%2C%20Sweden%2020150608_0097.jpg
Completed Image ====&gt; 234.Sonchus%20oleraceus%201%2C%20Gewone%20melkdistel%2C%20Saxifraga-Jan%20van%20der%20Straaten.jpg
Completed Image ====&gt; 235.smooth-sow-thistle.jpg
Completed Image ====&gt; 236.sonchus_oleraceus_564.jpg
Completed Image ====&gt; 237.Sonchus_oleraceus,I_TQBH4670.jpg
Completed Image ====&gt; 238.SONOL-from-aboveW_1344580830.jpg
Completed Image ====&gt; 239.weed_dandelionflower-e1401844344375.jpg
Completed Image ====&gt; 240.Sow-thistle-Perennial-1.jpg
Completed Image ====&gt; 241.SNCOL-Flower02_L.jpg
Completed Image ====&gt; 242.25343015684_f8d326024c.jpg
Completed Image ====&gt; 243.SowThistle.jpg
Completed Image ====&gt; 244.54317.jpg
Completed Image ====&gt; 245.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_019p09.jpg
Completed Image ====&gt; 246.IMG_02091.jpg
Completed Image ====&gt; 247.SONoler3b.JPG
Completed Image ====&gt; 248.11053300674_eca626ca2a_b.jpg
Completed Image ====&gt; 249.2012-07-04%20at%2010-26-44.jpeg
Completed Image ====&gt; 250.fhr-88888-12441-686.jpg
Completed Image ====&gt; 251.Smooth_Sow-thistle.jpg
Completed Image ====&gt; 252.032.jpg
Completed Image ====&gt; 253.sonchus_oleraceus_smooth_sow_thistle_close_large.jpg
Completed Image ====&gt; 254.a2449d.jpg
Completed Image ====&gt; 255.sow-thistle-bud.jpg
Completed Image ====&gt; 256.24982479211_9bb743b51e.jpg
Completed Image ====&gt; 257.80122105.jpg
Completed Image ====&gt; 258.may17SmSowThFl.jpg
Completed Image ====&gt; 259.smoothsowthistle.JPG
Completed Image ====&gt; 260.SNCOL-Inflorescences.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 261.roughsowthistle2.jpg
Completed Image ====&gt; 262.jjj%2B%25281%2529.JPG
Completed Image ====&gt; 263.weed_sowthistle.jpg
Completed Image ====&gt; 264.Warren_St_smooth_sow_thistle_12-2-2019_th.JPG
Completed Image ====&gt; 265.SST-271016.jpg
Completed Image ====&gt; 266.67917.jpg
Completed Image ====&gt; 267.SNCOL-Flower21.jpg
Completed Image ====&gt; 268.sow_thistle3_560x315.png
Completed Image ====&gt; 269.S_oleraceus_IMGP0259.jpg
Completed Image ====&gt; 270.unknown_weed2_27-3-2014_th.JPG
Completed Image ====&gt; 271.tn_Smooth%20sowthistle.jpg
Completed Image ====&gt; 272.Warren_St_weeds_12-2-2019_th.JPG
Completed Image ====&gt; 273.a1487740-7171-4c80-8e09-70db9825bd35.jpg
Completed Image ====&gt; 274.7e15d8.jpg
Completed Image ====&gt; 275.sonchus_oleraceus_smooth_sow_thistle_common_leaf_19-09-08.jpg
Completed Image ====&gt; 276.hqdefault.jpg
Completed Image ====&gt; 277.sow-thistle-stem.jpg
Completed Image ====&gt; 278.2012-12-04%20at%2012-26-56.jpeg
Completed Image ====&gt; 279.Sonchus_oleraceus__Sow_thistle_6.JPG
Completed Image ====&gt; 280.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_044p7.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 281.440463301_09a2660f39_b.jpg
Completed Image ====&gt; 282.002840-sonchus-oleraceus.jpg
Completed Image ====&gt; 283.dscn1101_orig.jpg
Completed Image ====&gt; 284.sonchus_oleraceus_19e1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 285.TFIEF+02.jpg
Completed Image ====&gt; 286.15.jpg
Completed Image ====&gt; 287.SONSS-FLO-700.jpg
Completed Image ====&gt; 288.il_340x270.1614660773_px89.jpg
Completed Image ====&gt; 289.puha...jpg
Completed Image ====&gt; 290.318097.jpg
Completed Image ====&gt; 291.hqdefault.jpg
Completed Image ====&gt; 292.pre-rm01936270351.jpg
Completed Image ====&gt; 293.SST230.jpg
Completed Image ====&gt; 294.SmoothSowThistle.jpg
Completed Image ====&gt; 295.SONOL-adultW_1344580654.jpg
Completed Image ====&gt; 296.SNCOL-Leaf07.jpg
Completed Image ====&gt; 297.Sonchus%20oleraceus%206%2C%20Gewone%20melkdistel%2C%20Saxifraga-Willem%20van%20Kruijsbergen.jpg
Completed Image ====&gt; 298.f9fa3a.jpg
Completed Image ====&gt; 299.44738367760_7413aa0788_b.jpg
Completed Image ====&gt; 300.IMG_02091-e1359058715293-764x1024.jpg
Completed Image ====&gt; 301.smooth-sow-thistle-sonchus-oleraceus-bob-gibbonsscience-photo-library.jpg
Completed Image ====&gt; 302.sonchus_oleraceus_smooth_sow_thistle_common_flower_13-08-05.jpg
Completed Image ====&gt; 303.smooth-sow-thistle.JPG
Completed Image ====&gt; 304.194189_w_300.jpg
Completed Image ====&gt; 305.53310.jpg
Completed Image ====&gt; 306.smooth_sow_thistle_buds_21-4-2017.JPG
Completed Image ====&gt; 307.IMG_20190603_102602098.jpg
Completed Image ====&gt; 308.2013-06-07%20at%2009-01-57.jpeg
Completed Image ====&gt; 309.3147587535_27cc95929d_b.jpg
Completed Image ====&gt; 310.il_570xN.1567199632_psuv.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 311.0181be.jpg
Completed Image ====&gt; 312.sonchus_oleraceus_01.jpg
Completed Image ====&gt; 313.sonchus_oleraceus_1.jpg
Completed Image ====&gt; 314.15jun004.jpg
Completed Image ====&gt; 315.sow-thistle-seedlings.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 316.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_045p99.jpg
Completed Image ====&gt; 317.93a92f.jpg
Completed Image ====&gt; 318.SNCOL-Plant2.jpg
Completed Image ====&gt; 319.5711750775_4336bc77a6_b.jpg
Completed Image ====&gt; 320.p821331182-3.jpg
Completed Image ====&gt; 321.D00DTmiX4AUMiGb.jpg
Completed Image ====&gt; 322.SONSS-COT-700.jpg
Completed Image ====&gt; 323.5871.jpg
Completed Image ====&gt; 324.Common_sowthistle___Sonchus_oleraceus-006.JPG
Completed Image ====&gt; 325.sow-thistle-flower.jpg
Completed Image ====&gt; 326.sonchus%20oleraceus%207172.JPG
Completed Image ====&gt; 327.v-cardoon-large-smooth_620x.jpg
Completed Image ====&gt; 328.SowThistle154.jpg
Completed Image ====&gt; 329.Sonchus_oleraceus_flower.jpg
Completed Image ====&gt; 330.sonchus_oleraceus_smooth_sow_thistle_common_flowering_plant_19-09-08.jpg
Completed Image ====&gt; 331.Cicerbita+macrophylla+NT0035+17June2016+PW+2.jpg
Completed Image ====&gt; 332.80103630.jpg
Completed Image ====&gt; 333.sonchus-oleraceus15412.jpg
Completed Image ====&gt; 334.smooth_sow_thistles_24-2-2018_th.JPG
Completed Image ====&gt; 335.20278481668_566392b427_b.jpg
Completed Image ====&gt; 336.Sonchus%20oleraceus%207%2C%20Gewone%20melkdistel%2C%20Saxifraga-Rutger%20Barendse.jpg
Completed Image ====&gt; 337.8a6ba5.jpg
Completed Image ====&gt; 338.Spray-Application-Advice.jpg
Completed Image ====&gt; 339.2012-07-04%20at%2010-26-31.jpeg
Completed Image ====&gt; 340.16jun016.jpg
Completed Image ====&gt; 341.6soaru.jpg
Completed Image ====&gt; 342.spiny-sow-thistle-1.JPG
Completed Image ====&gt; 343.smooth-sow-thistle-sonchus-oleraceus-bob-gibbonsscience-photo-library-canvas-print.jpg
Completed Image ====&gt; 344.DSCN1349-Dryad-on-Smooth-Sow-Thistle.jpg
Completed Image ====&gt; 345.smooth-sow-thistle-sonchus-oleraceus_4_orig.jpg
Completed Image ====&gt; 346.25343006054_9d04872569.jpg
Completed Image ====&gt; 347.sow-thistle-seed.jpg
Completed Image ====&gt; 348.TFIEF+01.jpg
Completed Image ====&gt; 349.Dandelion.jpg
Completed Image ====&gt; 350.sonchus_oleraceus_smooth_sow_thistle_common_flower_09-07-04.jpg
Completed Image ====&gt; 351.Weed187.jpg
Completed Image ====&gt; 352.27803f.jpg
Completed Image ====&gt; 353.67915.jpg
Completed Image ====&gt; 354.sowthistle_harvest.jpg
Completed Image ====&gt; 355.sowthistle-root.jpg
Completed Image ====&gt; 356.cultivation_principles_1_560x315.jpg
Completed Image ====&gt; 357.s-l225.jpg
Completed Image ====&gt; 358.smooth-sow-thistle-sonchus-oleraceus_3_orig.jpg
Completed Image ====&gt; 359.4498967791_e25c6d2338_z.jpg
Completed Image ====&gt; 360.map_of_Sonchus_oleraceus.jpg
Completed Image ====&gt; 361.Cystiphora%20sonchi4.jpg
Completed Image ====&gt; 362.Sonchus%20oleraceus%202%2C%20Gewone%20melkdistel%2C%20Saxifraga-Jan%20van%20der%20Straaten.jpg
Completed Image ====&gt; 363.hqdefault.jpg
Completed Image ====&gt; 364.Sonchus%20oleraceus%20Yevpatoria%2C%20Crimea%2C%20Russia%2020150910_0219.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 365.Lactuca-serriola-leaves-900x900.jpg
Completed Image ====&gt; 366.12jul001.jpg
Completed Image ====&gt; 367.Bristly-Ox-Tongue-RM-10_2D00_7_2D00_15-HTV-_2800_23_2900_.jpg
Completed Image ====&gt; 368.sowthistle%2Bflowers.jpg
Completed Image ====&gt; 369.Golovinomyces_sonchicola.jpg
Completed Image ====&gt; 370.smooth-sowthistle.jpg
Completed Image ====&gt; 371.unknown_weed_rosette_30-1-2019_th.JPG
Completed Image ====&gt; 372.PFFT1139_Cicerbita_plumieri.jpg
Completed Image ====&gt; 373.sowthistle_HTN.jpg
Completed Image ====&gt; 374.s-l225.jpg
Completed Image ====&gt; 375.33893850613_ee257ea130_b.jpg
Completed Image ====&gt; 376.15.jpg
Completed Image ====&gt; 377.8583870041_016664b427.jpg
Completed Image ====&gt; 378.91301.jpg
Completed Image ====&gt; 379.1156e6.jpg
Completed Image ====&gt; 380.web%206.jpg
Completed Image ====&gt; 381.41TmZtO7ykL.jpg
Completed Image ====&gt; 382.D00DRAdX0AAYH70.jpg
Completed Image ====&gt; 383.SowThistle(Smooth)_2010_09_05_Wigan_Parbold_BurscoughBridge_025p8.jpg
Completed Image ====&gt; 384.sow%20thistle_spiney%20annual_123.jpeg
Completed Image ====&gt; 385.philip_wright_560x315.jpg
Completed Image ====&gt; 386.SNCOL-Bud3.jpg
Completed Image ====&gt; 387.35101351485_80f0d363aa_m.jpg
Completed Image ====&gt; 388.sonchus_oleraceus_smooth_sow_thistle_common_flower_side_view_13-08-05.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 389.498optimized.jpg
Completed Image ====&gt; 390.200811191415440.smooth_sow-thistle.JPG
Completed Image ====&gt; 391.Warren_St_swine_cress_buds_in_situ_12-2-2019_th.JPG
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 392.Common_sowthistle___Sonchus_oleraceus.JPG
Completed Image ====&gt; 393.rue-leaved-saxifrage-2.jpg
Completed Image ====&gt; 394.20180520_124526.jpg
Completed Image ====&gt; 395.weeds-tsln-060317-5-3-930x1240.jpg
Completed Image ====&gt; 396.smooth-sow-thistle-sonchus-oleraceus_2_orig.jpg
Completed Image ====&gt; 397.sonchus-oleraceus-smooth-sow-thistle_u-l-pvu2820.jpg
Completed Image ====&gt; 398.Smooth-Hawk_2700_s_2D00_beard-RM-10_2D00_7_2D00_15-HTV-_2800_39_2900_.jpg
Completed Image ====&gt; 399.08f7b527f01601ccc032f34d1eae84ee.jpg
Completed Image ====&gt; 400.SONoler2b.JPG
Completed Image ====&gt; 401.sonchus_oleraceus_smooth_sow_thistle_common_flower_03-06-08_2.jpg
Completed Image ====&gt; 402.Thsmthsowthistle.jpg
Completed Image ====&gt; 403.large.jpg
Completed Image ====&gt; 404.SNCOL-Flower03_L.jpg
Completed Image ====&gt; 405.9593b5130ef023a7ec2aee16f0a5e3c6.jpg
Completed Image ====&gt; 406.rosette_verbascum_20-3-2018.JPG
Completed Image ====&gt; 407.habit_750.jpg
Completed Image ====&gt; 408.Sonchus_oleraceus_leaf.png
Completed Image ====&gt; 409.25.jpg
Completed Image ====&gt; 410.SNCOL-Flower01.jpg
Completed Image ====&gt; 411.puha-2.jpg
Completed Image ====&gt; 412.Sonchus%20oleraceus%20Yevpatoria%2C%20Crimea%2C%20Russia%2020150910_0219.jpg
Completed Image ====&gt; 413.CIMG4907.jpg
Completed Image ====&gt; 414.bee.jpg
Completed Image ====&gt; 415.c0342f.jpg
Completed Image ====&gt; 416.Sonchus_arvensis,I_MWS28869.jpg
Completed Image ====&gt; 417.p18qhkg196uos1tgc1mmr2c9ahd4.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 418.Gall_on_SonchusLeaves_2018_07_21_Ainsdale_GreenBeach_Botanisin_262p1.jpg
Completed Image ====&gt; 419.red-sorrel-11621-p1010765.jpg
Completed Image ====&gt; 420.Cats-ear-and-dandelion.jpg
Completed Image ====&gt; 421.S_Sowthistle1.jpg
Completed Image ====&gt; 422.19deb0f654eff1f8b3297ce938098d492efefc43.jpg
Completed Image ====&gt; 423.geranium_molle_rosette_centre_close-up_30-1-2019_th.JPG
Completed Image ====&gt; 424.il_340x270.1664549223_hfgq.jpg
Completed Image ====&gt; 425.sonchus_oleraceus.jpg
Completed Image ====&gt; 426.24.jpg
Completed Image ====&gt; 427.Prickly%20sow%20thistle_LR_29.jpeg
Completed Image ====&gt; 428.sow-thistle.jpg
Completed Image ====&gt; 429.MUS-CS1212_622.jpg
Completed Image ====&gt; 430.ssthistle.png
Completed Image ====&gt; 431.Sonchus%20oleraceus%20Smooth%20Sow-thistle%20p8200764%20thumb.jpg
Completed Image ====&gt; 432.SONSS-COT-200.jpg
Completed Image ====&gt; 433.P1590845.jpg
Completed Image ====&gt; 434.IMG_8129.JPG
Completed Image ====&gt; 435.weed_dandelion.jpg
Completed Image ====&gt; 436.Smooth_Hawksbeard12.JPG
Completed Image ====&gt; 437.SowThistle157.jpg
Completed Image ====&gt; 438.Sonchus%20palustris%20Lagunens%20sm%C3%A5b%C3%A5tshamn%2C%20Ribersborg%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160725_0032.jpg
Completed Image ====&gt; 439.img_1458.jpg
Completed Image ====&gt; 440.SmoothHawksbeard.jpg
Completed Image ====&gt; 441.87186da60d4d275c993d6bf2e3614439--wild-edibles-medicinal-herbs.jpg
Completed Image ====&gt; 442.winterhel-1.jpeg
Completed Image ====&gt; 443.06jun041.jpg
Completed Image ====&gt; 444.Hypochaeris-glabra02.jpg
Completed Image ====&gt; 445.rosette_smooth_sow_thistle_2-12-2017_th.JPG
Completed Image ====&gt; 446.crepis-capillaris-Smooth-Hawk_s-beard-J.-R.-Crellin-Floralimages.co.uk.jpg
Completed Image ====&gt; 447.sonchus-arvensis.jpg
Completed Image ====&gt; 448.Majjistral%20June%202014%20(27).jpg
Completed Image ====&gt; 449.SowThistle(Perennial)_2007_07_27_HallRoad_Formby_Freshfield_594p7.jpg
Completed Image ====&gt; 450.Sonchus%20oleraceus%204%2C%20Gewone%20melkdistel%2C%20Saxifraga-Jan%20van%20der%20Straaten.jpg
Completed Image ====&gt; 451.Golovinomyces_sonchicola_mic1.jpg
Completed Image ====&gt; 452.3598637700_77b4e28e18_z.jpg
Completed Image ====&gt; 453.SNCOL-SeedsRipe.jpg
Completed Image ====&gt; 454.181208.jpg
Completed Image ====&gt; 455.nbnr_primrose_100423_1.jpg
Completed Image ====&gt; 456.o_1d8ghjvl51ovq1o8nhgb1aq53jo29.jpg
Completed Image ====&gt; 457.19.jpg
Completed Image ====&gt; 458.181202-smooth-sowthistle-maybe.jpg
Completed Image ====&gt; 459.smooth-sow-thistle-sonchus-oleraceus-plant-leaf-rosette-X7YXKW.jpg
Completed Image ====&gt; 460.SowThistle11051.jpg
Completed Image ====&gt; 461.DSCN2567-001.jpg
Completed Image ====&gt; 462.DSC00078-768x432.jpg
Completed Image ====&gt; 463.Creeping-Thistle-RM-10_2D00_7_2D00_15-HTV-_2800_30_2900_.jpg
Completed Image ====&gt; 464.19843886014_51131b7986_b.jpg
Completed Image ====&gt; 465.f43f85.jpg
Completed Image ====&gt; 466.nbnr_teasel_477x670.jpg
Completed Image ====&gt; 467.fab10s00h.jpg
Completed Image ====&gt; 468.SONSS-FLO-700.jpg
Completed Image ====&gt; 469.sasperleaf.jpg
Completed Image ====&gt; 470.creeping-thistle.jpg
Completed Image ====&gt; 471.SowThistle(Rough)_2011_04_28_EyeHosp_KnottBar_BridgewaterCanal_Home_222p2.jpg
Completed Image ====&gt; 472.41TmZtO7ykL.jpg
Completed Image ====&gt; 473.Sonchus%20oleraceus%20Yevpatoria%2C%20Crimea%2C%20Russia%2020150910_0219.jpg
Completed Image ====&gt; 474.sonchus-oleraceus-2.jpg
Completed Image ====&gt; 475.D00DRAdX0AAYH70.jpg
Completed Image ====&gt; 476.sowthistle-root.jpg
Completed Image ====&gt; 477.o_1aq2pu1kt1uc31dhokcl1s4csms3m.jpg
Completed Image ====&gt; 478.map_of_Sonchus_oleraceus.jpg
Completed Image ====&gt; 479.91301.jpg
Completed Image ====&gt; 480.smooth-sowthistle.jpg
Completed Image ====&gt; 481.35101351485_80f0d363aa_m.jpg
Completed Image ====&gt; 482.fieldsowthistbracth.jpg
Completed Image ====&gt; 483.unknown_weed_rosette_30-1-2019_th.JPG
Completed Image ====&gt; 484.SONOL-flower-bud-L-61_1398180290.jpg
Completed Image ====&gt; 485.sow%20thistle_spiney%20annual_123.jpeg
Completed Image ====&gt; 486.1156e6.jpg
Completed Image ====&gt; 487.498optimized.jpg
Completed Image ====&gt; 488.200811191415440.smooth_sow-thistle.JPG
Completed Image ====&gt; 489.SNCOL-Bud3.jpg
Completed Image ====&gt; 490.sowthistle%2Bflowers.jpg
Completed Image ====&gt; 491.61152677_930201003978159_5940430441820228445_n.jpg
Completed Image ====&gt; 492.8583870041_016664b427.jpg
Completed Image ====&gt; 493.sonchus_oleraceus_smooth_sow_thistle_common_flower_side_view_13-08-05.jpg
Completed Image ====&gt; 494.15.jpg
URLError on an image...trying next one... Error: &lt;urlopen error unknown url type: x-raw-image&gt;
Completed Image ====&gt; 495.SowThistle(Prickly)_2010_09_05_Wigan_Parbold_BurscoughBridge_040p3.jpg
Completed Image ====&gt; 496.opium-lettuce-Lactuca-Serriola.jpg
Completed Image ====&gt; 497.rue-leaved-saxifrage-2.jpg
Completed Image ====&gt; 498.20180520_124526.jpg
Completed Image ====&gt; 499.Sow%2BThistle%2BI.JPG
Completed Image ====&gt; 500.weeds-tsln-060317-5-3-930x1240.jpg
Completed Image ====&gt; 501.sonchus-oleraceus-smooth-sow-thistle_u-l-pvu2820.jpg
Completed Image ====&gt; 502.smooth-sow-thistle-sonchus-oleraceus_2_orig.jpg
Completed Image ====&gt; 503.1050psowthistlepamp.jpg
Completed Image ====&gt; 504.red-sorrel-11621-p1010765.jpg
Completed Image ====&gt; 505.web%208.jpg
Completed Image ====&gt; 506.SONoler2b.JPG
Completed Image ====&gt; 507.Smooth-Hawk_2700_s_2D00_beard-RM-10_2D00_7_2D00_15-HTV-_2800_39_2900_.jpg
Completed Image ====&gt; 508.08f7b527f01601ccc032f34d1eae84ee.jpg
Completed Image ====&gt; 509.common-sow-thistle-stem.jpg
Completed Image ====&gt; 510.senecio2-453x573.jpg
Completed Image ====&gt; 511.sow%20thistle%20N1.jpg
Completed Image ====&gt; 512.1452646619101.jpeg
Completed Image ====&gt; 513.large.jpg
Completed Image ====&gt; 514.fieldsowthistflwh.jpg
Completed Image ====&gt; 515.cultivation_principles_1_560x315.jpg
Completed Image ====&gt; 516.PerennialSowThistle2_500_rdax_333x311_80.jpg
Completed Image ====&gt; 517.Sonchus_asper,I_TQBH14676.jpg
Completed Image ====&gt; 518.Warren_St_swine_cress_buds_in_situ_12-2-2019_th.JPG
Completed Image ====&gt; 519.Flower-and-flowerbuds-of-Prickly-sow-thistle.jpg
Completed Image ====&gt; 520.20100326135648e12.jpg
Completed Image ====&gt; 521.9593b5130ef023a7ec2aee16f0a5e3c6.jpg
Completed Image ====&gt; 522.habit_750.jpg
Completed Image ====&gt; 523.Sonchus_oleraceus_leaf.png
Completed Image ====&gt; 524.p1645ncekam3qkq418nb1cjv1dkji.jpg
Completed Image ====&gt; 525.7278637248_1b14b80755_m.jpg
Completed Image ====&gt; 526.SNCOL-Flower01.jpg
Completed Image ====&gt; 527.nipplewort.lf.jpg
Completed Image ====&gt; 528.puha-2.jpg
Completed Image ====&gt; 529.CIMG4907.jpg
Completed Image ====&gt; 530.SONSS-COT-700.jpg
Completed Image ====&gt; 531.SNCOL-Flower03_L.jpg
URLError on an image...trying next one... Error: HTTP Error 403: Forbidden
Completed Image ====&gt; 532.bee.jpg
Completed Image ====&gt; 533.up09.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 534.sonchus_oleraceus9.jpg
Completed Image ====&gt; 535.c0342f.jpg
Completed Image ====&gt; 536.Cats-ear-and-dandelion.jpg
Completed Image ====&gt; 537.S_Sowthistle1.jpg
Completed Image ====&gt; 538.Sonchus%20oleraceus%20flower1.JPG
Completed Image ====&gt; 539.Sow%2BIII.JPG
Completed Image ====&gt; 540.common_sow_thistle_leaf_margin1.jpg
Completed Image ====&gt; 541.Plant7135e2.jpg
Completed Image ====&gt; 542.19deb0f654eff1f8b3297ce938098d492efefc43.jpg
Completed Image ====&gt; 543.fab10s00g.jpg
Completed Image ====&gt; 544.sonchus_oleraceus.jpg
Completed Image ====&gt; 545.25075819075_a0c66db222.jpg
Completed Image ====&gt; 546.06jun041.jpg
Completed Image ====&gt; 547.greater-knapweed-4.JPG
Completed Image ====&gt; 548.frankenstein_weed_30-4-2017.JPG
Completed Image ====&gt; 549.25.jpg
Completed Image ====&gt; 550.sow-thistle.jpg
Completed Image ====&gt; 551.Sonchus%20oleraceus%20Yevpatoria%2C%20Crimea%2C%20Russia%2020150910_0219.jpg
Completed Image ====&gt; 552.MUS-FAPC1114_405.jpg
Completed Image ====&gt; 553.ssthistle.png
Completed Image ====&gt; 554.Sonchus%20oleraceus%20Smooth%20Sow-thistle%20p8200764%20thumb.jpg
Completed Image ====&gt; 555.P1590845.jpg
Completed Image ====&gt; 556.common-sow-thistle-top.jpg
Completed Image ====&gt; 557.weed_dandelion.jpg
Completed Image ====&gt; 558.fab10s00p.jpg
Completed Image ====&gt; 559.web%201.jpg
Completed Image ====&gt; 560.136917.JPG
Completed Image ====&gt; 561.5871.jpg
Completed Image ====&gt; 562.Prickly%20sow%20thistle_LR_29.jpeg
Completed Image ====&gt; 563.Closer-view-of-flower-of-Prickly-sow-thistle.jpg
Completed Image ====&gt; 564.img_1458.jpg
Completed Image ====&gt; 565.SmoothHawksbeard.jpg
Completed Image ====&gt; 566.87186da60d4d275c993d6bf2e3614439--wild-edibles-medicinal-herbs.jpg
Completed Image ====&gt; 567.winterhel-1.jpeg
Completed Image ====&gt; 568.p17642kd5g1gmu1e3iuaj1klp12qn14.jpg
Completed Image ====&gt; 569.Hypochaeris-glabra02.jpg
Completed Image ====&gt; 570.rosette_verbascum_20-3-2018.JPG
Completed Image ====&gt; 571.19843886014_51131b7986_b.jpg
Completed Image ====&gt; 572.crepis-capillaris-Smooth-Hawk_s-beard-J.-R.-Crellin-Floralimages.co.uk.jpg
Completed Image ====&gt; 573.Screen-Shot-2017-10-24-at-2.12.14-pm-306x400.png
Completed Image ====&gt; 574.Golovinomyces_sonchicola_mic1.jpg
Completed Image ====&gt; 575.Majjistral%20June%202014%20(27).jpg
Completed Image ====&gt; 576.24.jpg
Completed Image ====&gt; 577.fieldsowthistleflw600sq.jpg
Completed Image ====&gt; 578.Sonchus_asper,I_TQBH14672.jpg
Completed Image ====&gt; 579.3598637700_77b4e28e18_z.jpg
Completed Image ====&gt; 580.nbnr_primrose_100423_1.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 581.smooth-sowthistle-seeds.JPG
Completed Image ====&gt; 582.Sonchus%20oleraceus%204%2C%20Gewone%20melkdistel%2C%20Saxifraga-Jan%20van%20der%20Straaten.jpg
Completed Image ====&gt; 583.21446.jpg
Completed Image ====&gt; 584.181202-smooth-sowthistle-maybe.jpg
Completed Image ====&gt; 585.Leaves-of-Prickly-sow-thistle.jpg
Completed Image ====&gt; 586.SowThistle157.jpg
Completed Image ====&gt; 587.web%206.jpg
Completed Image ====&gt; 588.SNCOL-SeedsRipe.jpg
Completed Image ====&gt; 589.IMG_8129.JPG
Completed Image ====&gt; 590.DSC00078-768x432.jpg
Completed Image ====&gt; 591.p17v9mb9oi1qd1jk61bk4efr1ifl3.jpg
Completed Image ====&gt; 592.DSCN2567-001.jpg
Completed Image ====&gt; 593.Creeping-Thistle-RM-10_2D00_7_2D00_15-HTV-_2800_30_2900_.jpg
Completed Image ====&gt; 594.nbnr_teasel_477x670.jpg
Completed Image ====&gt; 595.geranium_molle_rosette_centre_close-up_30-1-2019_th.JPG
Completed Image ====&gt; 596.Sonchus%20palustris%20Lagunens%20sm%C3%A5b%C3%A5tshamn%2C%20Ribersborg%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160725_0026.jpg
Completed Image ====&gt; 597.rosette_750.jpg
Completed Image ====&gt; 598.IMG_4393-Prickly-Sow-thistle-Sonchus-asper-at-post-box-Drumbeg-Stores-9-6-17.jpg
Completed Image ====&gt; 599.5985044b-67df-48ad-bc53-5f253f0672ad.jpg
Completed Image ====&gt; 600.3170025235_c0fa8a4ea5_b.jpg
Completed Image ====&gt; 601.shutterstock_1080645086.jpg
Completed Image ====&gt; 602.f43f85.jpg
Completed Image ====&gt; 603.prod500134.jpg
Completed Image ====&gt; 604.sow_zpsd1hhu45z.JPG
Completed Image ====&gt; 605.ThistleWeedWeaknessExposed.jpg
Completed Image ====&gt; 606.1050psowthistleleaf.jpg
Completed Image ====&gt; 607.common-sow-thistle-buds.jpg
Completed Image ====&gt; 608.19.jpg
Completed Image ====&gt; 609.432612_1_En_7_Figg_HTML.jpg
Completed Image ====&gt; 610.SowThistle11051.jpg
Completed Image ====&gt; 611.Sonchus_arvensis,I_MWS28869.jpg
Completed Image ====&gt; 612.22933.jpg
Completed Image ====&gt; 613.Galium_mollugo-7A650B2644.jpg
Completed Image ====&gt; 614.Kerr-PoisonousPlants1007-2005-13.jpg
Completed Image ====&gt; 615.Sonchus%20palustris%20Lagunens%20sm%C3%A5b%C3%A5tshamn%2C%20Ribersborg%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020160725_0032.jpg
Completed Image ====&gt; 616.rosette_smooth_sow_thistle_2-12-2017_th.JPG
Completed Image ====&gt; 617.SNCOL-Leaf03b.jpg
Completed Image ====&gt; 618.DXeKiJ7WsAEmhCy.jpg
Completed Image ====&gt; 619.Malacothrix_glabrata_1_600.jpg
Completed Image ====&gt; 620.DSCN0963-001.jpg
Completed Image ====&gt; 621.IMG_0031_zps7zwydx6x.JPG
Completed Image ====&gt; 622.fab10s00c.jpg
Completed Image ====&gt; 623.5f3320be1a771c9211b4f9baeb6a631c.jpg
Completed Image ====&gt; 624.sowthistle.jpg
Completed Image ====&gt; 625.1050psowthistleplant.jpg
Completed Image ====&gt; 626.Chemical.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 627.wall-group-web.jpg
Completed Image ====&gt; 628.hmustard.jpg
Completed Image ====&gt; 629.web%205.jpg
Completed Image ====&gt; 630.fieldsowthistseedhd300.jpg
Completed Image ====&gt; 631.Leaf158.jpg
Completed Image ====&gt; 632.Lactuca%20macrophylla%20Banvallen%2C%20Ribersborg%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020180612_5.jpg
Completed Image ====&gt; 633.50716178_245205593069909_667013002427659958_n.jpg
Completed Image ====&gt; 634.15056529_1841355912759707_1091743041254850560_n.jpg
Completed Image ====&gt; 635.201011081438260.smooth_sow_thistle.JPG
Completed Image ====&gt; 636.34137.jpg
Completed Image ====&gt; 637.sonchus_oleraceus_smooth_sow-thistle_055891c66.jpg
Completed Image ====&gt; 638.sonchus-arvensis.jpg
Completed Image ====&gt; 639.4067033308_4a6ba8a601.jpg
Completed Image ====&gt; 640.12.jpg
Completed Image ====&gt; 641.71Xd5wy8TAL._SL1141_.jpg
Completed Image ====&gt; 642.comparison_of_weed_roots_25-4-2015.jpg
Completed Image ====&gt; 643.Sonchus%20palustris%20Lertagsdammen%2C%20Klagshamns%20udde%2C%20Malm%C3%B6%2C%20Sk%C3%A5ne%2C%20Sweden%2020140808_0109.jpg
Completed Image ====&gt; 644.DXeKiImWsAArMaF.jpg
Completed Image ====&gt; 645.d356c865bea0667d6be27f8f5cbc1396--smooth-thistles.jpg
Completed Image ====&gt; 646.t_Sow%20thistle_nipplewort_lr.jpg
Completed Image ====&gt; 647.sonchus_arvensis_perennial_sow_thistle_corn_leaf_06-07-04.jpg
Completed Image ====&gt; 648.22934.jpg
Completed Image ====&gt; 649.5390077_a3fe0cc6.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 650.Weed-182.jpg
Completed Image ====&gt; 651.sow4_zpsceitoega.JPG
Completed Image ====&gt; 652.fab10s00m.jpg
Completed Image ====&gt; 653.27113.jpg
Completed Image ====&gt; 654.SmoothSowThistle229.jpg
Completed Image ====&gt; 655.Dj27c9xW4AA0vXG.jpg
Invalid or missing image format. Skipping...
Completed Image ====&gt; 656.hounds_tongue_mature.jpg
Completed Image ====&gt; 657.web%203.jpg
Completed Image ====&gt; 658.Yellow147.jpg
Completed Image ====&gt; 659.s-l300.jpg
Completed Image ====&gt; 660.RockSamphire083.jpg
Completed Image ====&gt; 661.web%2013.jpg


Unfortunately all 1000 could not be downloaded because some images were not downloadable. 661 is all we got for this search filter!

Errors: 33

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc05495e">
<h3 id="orgc05495e">Checking the Images</h3>
<div class="outline-text-3" id="text-orgc05495e">
<div class="highlight">
<pre><span></span>for classification in weed_path.iterdir():
    verify_images(classification, delete=True, max_size=500)
</pre></div>
<pre class="example">
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/lambs-quarters/188.crop_common_lambsquarters_2_robert_videki_doronicum_kft_bugwood.jpg'&gt;
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/lambs-quarters/111.crop_common_lambsquarters_robert_videki_doronicum_kft_bugwood.jpg'&gt;
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/purslane/61.VELEA19595_3.jpg'&gt;
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. 
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/dandelion/568.775759.jpg'&gt;
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:965: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images
  ' expressed in bytes should be converted ' +
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
/home/athena/data/datasets/images/weeds/cats-ear/298.Ammi-majus.jpg: Removing corrupt EXIF data
/home/athena/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/PIL/Image.py:1018: UserWarning: Couldn't allocate palette entry for transparency
  warnings.warn("Couldn't allocate palette entry " +
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/smooth-sow-thistle/554.Sonchus%20oleraceus%20Smooth%20Sow-thistle%20p8200764%20thumb.jpg'&gt;
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/smooth-sow-thistle/431.Sonchus%20oleraceus%20Smooth%20Sow-thistle%20p8200764%20thumb.jpg'&gt;
cannot identify image file &lt;_io.BufferedReader name='/home/athena/data/datasets/images/weeds/london-rocket/510.UK-009916_large.jpg'&gt;
</pre></div>
</div>
<div class="outline-3" id="outline-container-org8d13767">
<h3 id="org8d13767">View the Data</h3>
<div class="outline-text-3" id="text-org8d13767">
<div class="highlight">
<pre><span></span>numpy.random.seed(42)
data = ImageDataBunch.from_folder(weed_path, train=".", valid_pct=0.2,
        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)

print(data.classes)
</pre></div>
<pre class="example">
['cats-ear', 'dandelion', 'lambs-quarters', 'london-rocket', 'purslane', 'smooth-sow-thistle']

</pre>
<div class="highlight">
<pre><span></span>data.show_batch(rows=3, figsize=(7, 8))
</pre></div>
<div class="figure">
<p><img alt="show_batch.png" src="/posts/files/posts/fastai/building-an-image-dataset/show_batch.png"></p>
</div>
<div class="figure">
<p><img alt="show_batch.png" src="/posts/fastai/building-an-image-dataset/show_batch.png"></p>
</div>
<div class="highlight">
<pre><span></span>print("Classes:")
for classification in data.classes:
    print(f" - {classification}")
print(f"\nNumber of Classes: {data.c}"
      "\nSize of Training"
      f" Set: {len(data.train_ds):,}\nSize of validation set: "
      f"{len(data.valid_ds):,}")
</pre></div>
<p>Classes:</p>
<ul class="org-ul">
<li>cats-ear</li>
<li>dandelion</li>
<li>lambs-quarters</li>
<li>london-rocket</li>
<li>purslane</li>
<li>smooth-sow-thistle</li>
</ul>
<p>Number of Classes: 6 Size of Training Set: 3,112 Size of validation set: 777</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgad583a0">
<h3 id="orgad583a0">The Resnet 34 Model</h3>
<div class="outline-text-3" id="text-orgad583a0">
<div class="highlight">
<pre><span></span>model = cnn_learner(data, models.resnet34, metrics=error_rate)
</pre></div>
<div class="highlight">
<pre><span></span>model.fit_one_cycle(4)
</pre></div>
<div class="highlight">
<pre><span></span>model.save('stage-1')
</pre></div>
<div class="highlight">
<pre><span></span>model.unfreeze()
</pre></div>
<div class="highlight">
<pre><span></span>print(model.lr_find())
</pre></div>
<pre class="example">
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
None

</pre>
<div class="highlight">
<pre><span></span>model.recorder.plot()
</pre></div>
<div class="figure">
<p><img alt="learning.png" src="/posts/files/posts/fastai/building-an-image-dataset/learning.png"></p>
</div>
<div class="figure">
<p><img alt="learning.png" src="/posts/fastai/building-an-image-dataset/learning.png"></p>
</div>
<div class="highlight">
<pre><span></span>model.fit_one_cycle(2, max_lr=slice(3e-5,3e-4))
model.save('stage-2')
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgebd738f">
<h3 id="orgebd738f">Interpretation</h3>
<div class="outline-text-3" id="text-orgebd738f">
<div class="highlight">
<pre><span></span>interp = ClassificationInterpretation.from_learner(model)
</pre></div>
<div class="highlight">
<pre><span></span>interp.plot_confusion_matrix()
</pre></div>
<div class="figure">
<p><img alt="confusion_matrix.png" src="/posts/files/posts/fastai/building-an-image-dataset/confusion_matrix.png"></p>
</div>
<div class="figure">
<p><img alt="confusion_matrix.png" src="/posts/fastai/building-an-image-dataset/confusion_matrix.png"></p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org3f6c534">
<h3 id="org3f6c534">Looking at the mistakes</h3>
<div class="outline-text-3" id="text-org3f6c534">
<p>If you go and look at the actual images, you'll find that despite our reliance on google as the arbiter of search, there's a pretty large number of images that are wrong (for Cat's Ear this is a place where the prevelance of images of cats becomes a particular problem).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org3c1821a">
<h3 id="org3c1821a">Take Two</h3>
<div class="outline-text-3" id="text-org3c1821a">
<p>It seems to struggle with <a href="https://en.wikipedia.org/wiki/Hypochaeris_radicata?oldformat=true">Cat's Ear</a>, which might not be surprising since it is one of the "false dandelions", although that fact would suggest that it would be misidentified as a dandelion, which wasn't generally the case. For dandelions it did provide the most false positives, but for the other plants "Smooth Sow Thistle" seems to have been the most problematic.</p>
<div class="highlight">
<pre><span></span>data = ImageDataBunch.from_folder(weed_path, train=".", valid_pct=0.2,
        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)

model = cnn_learner(data, models.resnet34, metrics=error_rate)

model.fit_one_cycle(4)

model.save('stage-1')

model.unfreeze()
</pre></div>
<div class="highlight">
<pre><span></span>print(model.lr_find())
</pre></div>
<pre class="example">
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
None

</pre>
<div class="highlight">
<pre><span></span>model.recorder.plot()
</pre></div>
<div class="figure">
<p><img alt="learning_2.png" src="/posts/files/posts/fastai/building-an-image-dataset/learning_2.png"></p>
</div>
<div class="highlight">
<pre><span></span>model.fit_one_cycle(2, max_lr=slice(3e-5,3e-4))
model.save('stage-2')
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgae10795">
<h3 id="orgae10795">Interpretation</h3>
<div class="outline-text-3" id="text-orgae10795">
<div class="highlight">
<pre><span></span>interp = ClassificationInterpretation.from_learner(model)
</pre></div>
<div class="highlight">
<pre><span></span>interp.plot_confusion_matrix()
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgbd093ef">
<h2 id="orgbd093ef">End</h2>
<div class="outline-text-2" id="text-orgbd093ef"></div>
<div class="outline-3" id="outline-container-org6ab2e05">
<h3 id="org6ab2e05">Source</h3>
<div class="outline-text-3" id="text-org6ab2e05"></div>
<div class="outline-4" id="outline-container-org0483587">
<h4 id="org0483587">The original lesson was created by Francisco Ingham and Jeremy Howard. Inspired by <a href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/">Adrian Rosebrock</a>. It accompanies <a href="https://course.fast.ai/videos/?lesson=2">Fast Ai Lesson 2</a>.</h4>
<div class="outline-text-4" id="text-org0483587">
<p>from fastai.widgets import *</p>
<p>db = (ImageList.from_folder(path) .no_split() .label_from_folder() .transform(get_transforms(), size=224) .databunch() )</p>
<p>learn_cln = cnn_learner(db, models.resnet34, metrics=error_rate)</p>
<p>learn_cln.load('stage-2');</p>
<p>ds, idxs = DatasetFormatter().from_toplosses(learn_cln)</p>
<p>ImageCleaner(ds, idxs, path)</p>
<p>ds, idxs = DatasetFormatter().from_similars(learn_cln)</p>
<p>ImageCleaner(ds, idxs, path, duplicates=True)</p>
<p>learn.export()</p>
<p>defaults.device = torch.device('cpu')</p>
<p>img = open_image(path/'black'/'00000021.jpg') img</p>
<p>learn = load_learner(path)</p>
<p>pred_class,pred_idx,outputs = learn.predict(img) pred_class</p>
<p>learn = cnn_learner(data, models.resnet34, metrics=error_rate)</p>
<p>learn.fit_one_cycle(1, max_lr=0.5)</p>
<p>learn = cnn_learner(data, models.resnet34, metrics=error_rate)</p>
<p>learn.fit_one_cycle(5, max_lr=1e-5)</p>
<p>learn.recorder.plot_losses()</p>
<p>learn = cnn_learner(data, models.resnet34, metrics=error_rate, pretrained=False)</p>
<p>learn.fit_one_cycle(1)</p>
<p>np.random.seed(42) data = ImageDataBunch.from_folder(path, train=".", valid_pct=0.9, bs=32, ds_tfms=get_transforms(do_flip=False, max_rotate=0, max_zoom=1, max_lighting=0, max_warp=0 ),size=224, num_workers=4).normalize(imagenet_stats)</p>
<p>learn = cnn_learner(data, models.resnet50, metrics=error_rate, ps=0, wd=0) learn.unfreeze()</p>
<p>learn.fit_one_cycle(40, slice(1e-6,1e-4))</p>
</div>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/fastai/dog-and-cat-breed-classification/">Dog and Cat Breed Classification (What's Your Pet?)</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/fastai/dog-and-cat-breed-classification/" rel="bookmark"><time class="published dt-published" datetime="2019-04-13T16:14:46-07:00" itemprop="datePublished" title="2019-04-13 16:14">2019-04-13 16:14</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgefb70a6">Departure</a>
<ul>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgd9600d6">Imports</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgb6c7903">Some Setup</a></li>
</ul>
</li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgda30b93">Initiation</a>
<ul>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org3441b8c">Downloading the Data</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org5163c29">Looking At the Data</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgc4cb294">Training: resnet34</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org2d50b61">Results</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgc72f515">Unfreezing, fine-tuning, and learning rates</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org0041cc0">Training: resnet50</a></li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#orgf58c162">Other Data Formats</a></li>
</ul>
</li>
<li><a href="/posts/fastai/dog-and-cat-breed-classification/#org74d91ee">Return</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgefb70a6">
<h2 id="orgefb70a6">Departure</h2>
<div class="outline-text-2" id="text-orgefb70a6">
<p>This is lesson one from the <a href="https://www.fast.ai">fastai</a> course <a href="https://course.fast.ai/index.html">Practical Deep Learning for Coders, v3</a>, which I assume is the third version of the course, and not a reference to a <a href="https://www.wikiwand.com/en/Kamen_Rider_V3">Japanese television show</a>. It uses the <a href="http://www.fast.ai/2018/10/02/fastai-ai/">fastai V1 library</a> which uses <a href="https://hackernoon.com/pytorch-1-0-468332ba5163">Pytorch 1.0</a> but is an <a href="https://www.wikiwand.com/en/Convention_over_configuration">opinionated framework</a> that bundles some sensible defaults so you don't have to spend as much time building the networks.</p>
<p>The goal is to train a neural network to identify the breeds of cats and dogs based of photos of them. It uses the <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford-IIT Pet Dataset</a> which was created by researchers at Oxford University's <a href="http://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group</a>.</p>
</div>
<div class="outline-3" id="outline-container-orgd9600d6">
<h3 id="orgd9600d6">Imports</h3>
<div class="outline-text-3" id="text-orgd9600d6"></div>
<div class="outline-4" id="outline-container-org61b175c">
<h4 id="org61b175c">Python</h4>
<div class="outline-text-4" id="text-org61b175c">
<p>Other than the <a href="https://docs.python.org/3.4/library/re.html"><code>re</code></a> none of the python imports were part of the original lesson. I'm importing <a href="https://docs.python.org/3/library/gc.html">gc</a> to do garbage collection because the lesson starts with a smaller network and then changes to a larger one which caused my machine to run out of memory on the GPU. The rest of the imports are for settings and setup.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb80a7c6">
<h4 id="orgb80a7c6">PyPi</h4>
<div class="outline-text-4" id="text-orgb80a7c6">
<p><code>fastai</code> recommends using <code>*</code> to import everything, but I'd like to know where everything comes from and not import something that might conflict with my naming conventions so I'm going to (at least try to) import things individually. Luckily, unlike some projects (I'm looking at you, <a href="https://bokeh.pydata.org/en/latest/">bokeh</a>), their site has a search feature so you can look things up to see which module they come from.</p>
<p>I'll keep the <code>fast.ai</code> stuff separate to maybe make it easier to reference what comes from where.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">fastai.datasets</span> <span class="kn">import</span> <span class="n">untar_data</span><span class="p">,</span> <span class="n">URLs</span>
<span class="kn">from</span> <span class="nn">fastai.metrics</span> <span class="kn">import</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">error_rate</span>
<span class="kn">from</span> <span class="nn">fastai.train</span> <span class="kn">import</span> <span class="n">ClassificationInterpretation</span>
<span class="kn">from</span> <span class="nn">fastai.vision.data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_image_files</span><span class="p">,</span> 
    <span class="n">imagenet_stats</span><span class="p">,</span> 
    <span class="n">ImageDataBunch</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">fastai.vision.learner</span> <span class="kn">import</span> <span class="n">cnn_learner</span>
<span class="kn">from</span> <span class="nn">fastai.vision.models</span> <span class="kn">import</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">resnet50</span>
<span class="kn">from</span> <span class="nn">fastai.vision.transform</span> <span class="kn">import</span> <span class="n">get_transforms</span>
</pre></div>
<p>And the rest…</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">ipyexperiments</span> <span class="kn">import</span> <span class="n">IPyExperimentsPytorch</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">import</span> <span class="nn">holoviews</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge634059">
<h4 id="orge634059">My Stuff</h4>
<div class="outline-text-4" id="text-orge634059">
<p>This is just some convenience stuff wrapped around other people's code (my lite-version of opinionated code).</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae.tables</span> <span class="kn">import</span> <span class="n">CountPercentage</span>
<span class="kn">from</span> <span class="nn">graeae.timers</span> <span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">from</span> <span class="nn">graeae.visualization</span> <span class="kn">import</span> <span class="n">EmbedHoloview</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb6c7903">
<h3 id="orgb6c7903">Some Setup</h3>
<div class="outline-text-3" id="text-orgb6c7903"></div>
<div class="outline-4" id="outline-container-org1eba125">
<h4 id="org1eba125">Some Constants</h4>
<div class="outline-text-4" id="text-org1eba125">
<p>There's a lot of values scattered all over the place and I just wanted one place to keep track of them and maybe change them if needed.</p>
<div class="highlight">
<pre><span></span><span class="n">Net</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">low_memory_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2a4341d">
<h4 id="org2a4341d">The Random Seed</h4>
<div class="outline-text-4" id="text-org2a4341d">
<p>To make this reproducible I'll set the random seed in numpy.</p>
<div class="highlight">
<pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">Net</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8d8588b">
<h4 id="org8d8588b">The Path</h4>
<div class="outline-text-4" id="text-org8d8588b">
<p>This loads where I put the image data-set.</p>
<div class="highlight">
<pre><span></span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">".env"</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"OXFORD_PET_DATASET"</span><span class="p">))</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4d6d389">
<h4 id="org4d6d389">Plotting</h4>
<div class="outline-text-4" id="text-org4d6d389">
<p>Although I'd prefer to plot things in HoloViews/bokeh, some of their stuff is too tightly bundled to make it easy (and the image plots maybe don't need to be interactive) so this sets up some formatting for the matplotlib plots.</p>
</div>
<div class="outline-5" id="outline-container-org4d33b24">
<h5 id="org4d33b24">Matplotlib</h5>
<div class="outline-text-5" id="text-org4d33b24">
<div class="highlight">
<pre><span></span><span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'matplotlib'</span><span class="p">,</span> <span class="s1">'inline'</span><span class="p">)</span>
<span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">'config'</span><span class="p">,</span> <span class="s2">"InlineBackend.figure_format = 'retina'"</span><span class="p">)</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">"whitegrid"</span><span class="p">,</span>
            <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">"axes.grid"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
                <span class="s2">"font.family"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"sans-serif"</span><span class="p">],</span>
                <span class="s2">"font.sans-serif"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"Open Sans"</span><span class="p">,</span> <span class="s2">"Latin Modern Sans"</span><span class="p">,</span> <span class="s2">"Lato"</span><span class="p">],</span>
                <span class="s2">"figure.figsize"</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">)},</span>
            <span class="n">font_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-5" id="outline-container-org5e0c97d">
<h5 id="org5e0c97d">The Bokeh</h5>
<div class="outline-text-5" id="text-org5e0c97d">
<p>This sets up some stuff for the javascript-based plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">holoviews</span><span class="o">.</span><span class="n">extension</span><span class="p">(</span><span class="s2">"bokeh"</span><span class="p">)</span>
<span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"dog-and-cat-breed-classification"</span>
<span class="n">OUTPUT_FOLDER</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/fastai/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloview</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_FOLDER</span><span class="p">)</span>
</pre></div>
<p>This is where I'm going to put the settings for the javascript-based plotting.</p>
<div class="highlight">
<pre><span></span><span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">height</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf22fa9a">
<h4 id="orgf22fa9a">The Timer</h4>
<div class="outline-text-4" id="text-orgf22fa9a">
<p>This times how long things take so I can estimate how long it will take if I re-run cells. It also speaks a message so I can do something else and will know that the code is done running without having to watch the messages.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0b0b056">
<h4 id="org0b0b056">Tabulate</h4>
<div class="outline-text-4" id="text-org0b0b056">
<p>This is to format tables in the org-mode format (since I'm running this in emacs org-babel).</p>
<div class="highlight">
<pre><span></span><span class="n">ORG_TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">,</span> 
                    <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                    <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgda30b93">
<h2 id="orgda30b93">Initiation</h2>
<div class="outline-text-2" id="text-orgda30b93"></div>
<div class="outline-3" id="outline-container-org3441b8c">
<h3 id="org3441b8c">Downloading the Data</h3>
<div class="outline-text-3" id="text-org3441b8c">
<p>As I mentioned before, the data will be the <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/">Oxford-IIIT Pet Dataset</a> by <a href="http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf">O. M. Parkhi et al., 2012</a>. In the dataset there are twelve breeds of cat and twenty-five breeds of dog. When the researchers performed their experiments in 2012 the best accuracy they got was 59.21 %.</p>
<p>The original lesson uses the <a href="https://docs.fast.ai/datasets.html#untar_data">untar_data</a> function to download the data-set.</p>
<div class="highlight">
<pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">untar_data</span><span class="p">)</span>
</pre></div>
<pre class="example">
Help on function untar_data in module fastai.datasets:

untar_data(url: str, fname: Union[pathlib.Path, str] = None, dest: Union[pathlib.Path, str] = None, data=True, force_download=False) -&gt; pathlib.Path
    Download `url` to `fname` if it doesn't exist, and un-tgz to folder `dest`.


</pre>
<p>This data set is 774 Megabytes and given my over-priced yet still incredibly slow CenturyLink speeds I found downloading it directly from the <a href="https://course.fast.ai/datasets#image-classification">fastai datasets page</a> a little more satisfactory, since the progress widget that runs during the download when <code>untar_data</code> downloads the dataset doesn't show up in emacs.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="n">DATA_PATH</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">)</span>
</pre></div>
<pre class="example">
/home/athena/data/datasets/images/oxford-iiit-pet

</pre>
<p>I didn't know it, but <code>Paths</code> have an <code>ls</code> method (so far as I could see this isn't in <a href="https://docs.python.org/3/library/pathlib.html">python's documentation</a>) which I mention because I found out because it was in the original lesson. This is nice because, well, it's easy to remember, but the way I'm using it <code>iterdir</code> makes more sense.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">DATA_PATH</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {path}"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>/home/athena/data/datasets/images/oxford-iiit-pet/images_backup</li>
<li>/home/athena/data/datasets/images/oxford-iiit-pet/README.org</li>
<li>/home/athena/data/datasets/images/oxford-iiit-pet/images</li>
<li>/home/athena/data/datasets/images/oxford-iiit-pet/annotations</li>
</ul>
<p>Here's another trick I didn't know about, but learned from the lesson - instead of using the <code>joinpath</code> method you can just use a forward-slash.</p>
<div class="highlight">
<pre><span></span><span class="n">path_to_annotations</span> <span class="o">=</span> <span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'annotations'</span>
<span class="n">path_to_images</span> <span class="o">=</span> <span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'images'</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5163c29">
<h3 id="org5163c29">Looking At the Data</h3>
<div class="outline-text-3" id="text-org5163c29"></div>
<div class="outline-4" id="outline-container-orge182925">
<h4 id="orge182925">Getting the Labels</h4>
<div class="outline-text-4" id="text-orge182925">
<p>Here's where we peek at our data set. The dataset is set up so that the breeds are used in the names of the image files. <code>fast.ai</code> has a convenient classmethod named <a href="https://docs.fast.ai/vision.data.html#ImageDataBunch.from_name_re">ImageDataBunch.from_name_re</a> that will extract the labels from the filenames using a <a href="https://docs.python.org/3.6/library/re.html">regular expression</a>.</p>
<p>Before we get to that, though, we can take a look at some file names using <a href="https://docs.fast.ai/vision.data.html#get_image_files">get_image_files</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">file_names</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_to_images</span><span class="p">)</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {path.name}"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>Boxer_20.jpg</li>
<li>Saint_Bernard_195.jpg</li>
<li>Saint_Bernard_133.jpg</li>
<li>English_Cocker_Spaniel_43.jpg</li>
<li>Pug_51.jpg</li>
</ul>
<p>So it looks like the format is <code>&lt;breed&gt;_&lt;index&gt;.jpg</code>. Later on we're going to use the labels when we inspect the model so next I'm going to make the standardize the file-name cases to be title-cased.</p>
<div class="highlight">
<pre><span></span><span class="n">UNDERSCORE</span><span class="p">,</span> <span class="n">SPACE</span> <span class="o">=</span> <span class="s2">"_"</span><span class="p">,</span> <span class="s2">" "</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">:</span>
    <span class="n">name</span><span class="p">,</span> <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">UNDERSCORE</span><span class="p">,</span> <span class="n">SPACE</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="n">extension</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">SPACE</span><span class="p">,</span> <span class="n">UNDERSCORE</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
    <span class="n">path</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<span class="n">file_names</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_to_images</span><span class="p">)</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">file_names</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {path.name}"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>Boxer_20.jpg</li>
<li>Saint_Bernard_195.jpg</li>
</ul>
<p>Now I'll construct the pattern to match the file-name.</p>
<div class="highlight">
<pre><span></span><span class="n">is_not_a</span> <span class="o">=</span> <span class="s2">"^"</span>
<span class="n">end_of_line</span> <span class="o">=</span> <span class="s2">"$"</span>
<span class="n">one_or_more</span> <span class="o">=</span> <span class="s2">"+"</span>
<span class="n">digit</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"\d"</span>
<span class="n">forward_slash</span> <span class="o">=</span> <span class="s2">"/"</span>
<span class="n">character_class</span> <span class="o">=</span> <span class="s2">"[{}]"</span>
<span class="n">group</span> <span class="o">=</span> <span class="s2">"({})"</span>

<span class="n">anything_but_a_slash</span> <span class="o">=</span> <span class="n">character_class</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="s2">"{is_not_a}{forward_slash}"</span><span class="p">)</span>

<span class="n">index</span> <span class="o">=</span> <span class="n">rf</span><span class="s2">"{digit}{one_or_more}"</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="s1">'{anything_but_a_slash}{one_or_more}'</span><span class="p">)</span>
<span class="n">file_extension</span> <span class="o">=</span> <span class="s2">".jpg"</span>

<span class="n">expression</span> <span class="o">=</span> <span class="n">rf</span><span class="s1">'{forward_slash}{label}{UNDERSCORE}{index}{file_extension}{end_of_line}'</span>
<span class="n">test</span> <span class="o">=</span> <span class="s2">"/home/athena/data/datasets/images/oxford-iiit-pet/images/Saint_Bernard_195.jpg"</span>
<span class="k">assert</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">expression</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span><span class="o">.</span><span class="n">groups</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"Saint_Bernard"</span>
</pre></div>
<p>The reason for the forward slash at the beginning of the expression is that we're passing in the entire path to each image, not just the name of the image.</p>
<p>Now on to the <code>ImageDataBunch</code>. Here's the arguments we need to pass in.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on method from_name_re in module fastai.vision.data:

from_name_re(path: Union[pathlib.Path, str], fnames: Collection[pathlib.Path], pat: str, valid_pct: float = 0.2, **kwargs) method of builtins.type instance
    Create from list of `fnames` in `path` with re expression `pat`.

None

</pre>
<p>Okay, so let's get the labels.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span><span class="n">path_to_images</span><span class="p">,</span> 
                                   <span class="n">file_names</span><span class="p">,</span> 
                                   <span class="n">expression</span><span class="p">,</span> 
                                   <span class="n">ds_tfms</span><span class="o">=</span><span class="n">get_transforms</span><span class="p">(),</span> 
                                   <span class="n">size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> 
                                   <span class="n">bs</span><span class="o">=</span><span class="n">Net</span><span class="o">.</span><span class="n">batch_size</span>
                                  <span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">)</span>
</pre></div>
<p>One of the arguments we passed in (<code>ds_tfms</code>?) isn't particularly obviously named, unless you already know about applying transforms to images, but here's what we passed to it.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">get_transforms</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on function get_transforms in module fastai.vision.transform:

get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10.0, max_zoom:float=1.1, max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75, p_lighting:float=0.75, xtra_tfms:Union[Collection[fastai.vision.image.Transform], NoneType]=None) -&gt; Collection[fastai.vision.image.Transform]
    Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.

None

</pre>
<p><a href="https://docs.fast.ai/vision.transform.html#get_transforms">get_transforms</a> adds random changes to the images to augment the datasets for our training.</p>
<p>We also added a call to <a href="https://docs.fast.ai/vision.data.html#normalize">normalize</a> which sets the mean and standard deviation of the images to match those of the images used to train the model that we're going to use (<a href="https://arxiv.org/abs/1512.03385">ResNet</a>).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org6fdd217">
<h4 id="org6fdd217">Looking at Some of the Images</h4>
<div class="outline-text-4" id="text-org6fdd217">
<p>The <a href="https://docs.fast.ai/basic_data.html#DataBunch.show_batch">show_batch</a> method will plot some of the images in matplotlib. It retrieves them randomly so calling the method repeatedly will pull up different images. Unfortunately you can't pass in a figure or axes so it isn't easily configurable.</p>
<div class="highlight">
<pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">)</span>
</pre></div>
<pre class="example">
Help on method show_batch in module fastai.basic_data:

show_batch(rows:int=5, ds_type:fastai.basic_data.DatasetType=&lt;DatasetType.Train: 1&gt;, reverse:bool=False, **kwargs) -&gt; None method of fastai.vision.data.ImageDataBunch instance
    Show a batch of data in `ds_type` on a few `rows`.


</pre>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
<div class="figure">
<p><img alt="show_batch.png" src="/posts/fastai/dog-and-cat-breed-classification/show_batch.png"></p>
</div>
<p>I'm guessing that the reason why so many images look "off" is because the of the data-transforms being added, and not that the photographers were horrible (or drunk). Why don't we look at the representation of the data bunch?</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
<pre class="example">
ImageDataBunch;

Train: LabelList (5912 items)
x: ImageList
Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
y: CategoryList
Boxer,Saint_Bernard,Saint_Bernard,Ragdoll,Birman
Path: /home/athena/data/datasets/images/oxford-iiit-pet/images;

Valid: LabelList (1478 items)
x: ImageList
Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
y: CategoryList
Siamese,British_Shorthair,English_Cocker_Spaniel,Newfoundland,Russian_Blue
Path: /home/athena/data/datasets/images/oxford-iiit-pet/images;

Test: None
</pre>
<p>So it looks like the <code>ImageDataBunch</code> created a training and a validation set and each of the images has three channels and is 224 x 224 pixels.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc4cb294">
<h3 id="orgc4cb294">Training: resnet34</h3>
<div class="outline-text-3" id="text-orgc4cb294">
<p>Here's where we train the model, a <a href="http://cs231n.github.io/convolutional-networks/">convolutional neural network</a> in the back with a fully-connected network at the end.</p>
<p>I'll use <code>fast.ai's</code> <a href="https://docs.fast.ai/vision.learner.html#cnn_learner">cnn_learner</a> to load the data, pre-trained model (<code>resnet34</code>), and the metric to use when training (<a href="https://docs.fast.ai/metrics.html#error_rate">error_rate</a>). If you look at the <a href="https://github.com/fastai/fastai/blob/master/fastai/vision/models/__init__.py">fast ai code</a> they are importing the <code>resnet34</code> model from <a href="https://pytorch.org/docs/stable/torchvision/models.html#id3">pytorch's torchvision</a>.</p>
<p>This next block sets up the <a href="https://github.com/stas00/ipyexperiments/blob/master/docs/ipyexperiments.md">IPyExperiments</a> which will delete all the variables that were created after it was created when it is deleted. This is to free up memory because the <code>resnet</code> architecture takes up a lot of memory on the GPU.</p>
<div class="highlight">
<pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">IPyExperimentsPytorch</span><span class="p">()</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgfc87c2b">
<h4 id="orgfc87c2b">Experiment started with the Pytorch backend</h4>
<div class="outline-text-4" id="text-orgfc87c2b">
<p>Device: ID 0, GeForce GTX 1060 6GB (6069 RAM)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org2751a9c">
<h4 id="org2751a9c">Current state:</h4>
<div class="outline-text-4" id="text-org2751a9c">
<p>RAM: Used Free Total Util CPU: 2,375 58,710 64,336 MB 3.69% GPU: 916 5,153 6,069 MB 15.10%</p>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.000 ･ CPU: 0 0 2,375 MB | ･ GPU: 0 0 916 MB |</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</pre></div>
<pre class="example">
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:01.758
･ CPU:          0          0      2,551 MB |
･ GPU:        114          0      1,030 MB |

</pre>
<pre class="example">
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /home/athena/.torch/models/resnet34-333f7ec4.pth
87306240it [00:26, 3321153.99it/s]
</pre>
<p>As you can see, it downloaded the stored model parameters from pytorch. This is because I've never downloaded this particular model before - if you run it again it shouldn't need to re-download it. Since this is a <a href="https://pytorch.org">pytorch</a> model we can look at it's represetantion to see the architecture of the network.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>
<pre class="example">
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (1): Sequential(
    (0): AdaptiveConcatPool2d(
      (ap): AdaptiveAvgPool2d(output_size=1)
      (mp): AdaptiveMaxPool2d(output_size=1)
    )
    (1): Flatten()
    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.25)
    (4): Linear(in_features=1024, out_features=512, bias=True)
    (5): ReLU(inplace)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): Dropout(p=0.5)
    (8): Linear(in_features=512, out_features=37, bias=True)
  )
)
</pre>
<p>That's a pretty big network, but the main thing to notice is the last layer, which has 37 <code>out_features</code> which corresponds to the number of breeds we have in our data-set. If you were working directly with pytorch you'd have to remove the last layer and add it back yourself, but <code>fast.ai</code> has done this for us.</p>
<p>Now we need to train it using the <a href="https://docs.fast.ai/train.html#fit_one_cycle">fit_one_cycle</a> method. At first I thought 'one cycle' meant just one pass through the batches but according to the <a href="https://docs.fast.ai/callbacks.one_cycle.html">documentation</a>, this is a reference to a training method called the <a href="https://sgugger.github.io/the-1cycle-policy.html">1Cycle Policy</a> proposed by <a href="https://arxiv.org/abs/1803.09820">Leslie N. Smith</a> that changes the hyperparameters to make the model train faster.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">mesasge</span> <span class="o">=</span> <span class="s2">"Finished fitting the ResNet 34 Model."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:18:45.894630
Ended: 2019-04-21 18:22:09.988508
Elapsed: 0:03:24.093878
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:03:24.095
･ CPU:          0          0      2,999 MB |
･ GPU:        151      3,322      1,182 MB |

</pre>
<p>Depending on how busy the computer is this takes two to three minutes when I run it. Next let's store the parameters for the trained model to disk.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'stage-1'</span><span class="p">)</span>
</pre></div>
<pre class="example">
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.145
･ CPU:          0          0      3,000 MB |
･ GPU:         -1          0      1,181 MB |

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org2d50b61">
<h3 id="org2d50b61">Results</h3>
<div class="outline-text-3" id="text-org2d50b61">
<p>Let's look at how the model did. If I was running this in a jupyter notebook there would be a table output of the accuracy, but I'm not, and I can't find any documentation on how to get that myself, so, tough luck, then. We can look at some things after the fact, though - the <a href="https://docs.fast.ai/train.html#ClassificationInterpretation">ClassificationInterpretation</a> class contains methods to help look at how the model did.</p>
<div class="highlight">
<pre><span></span><span class="n">interpreter</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</pre></div>
<p>The <a href="https://docs.fast.ai/vision.learner.html#ClassificationInterpretation.top_losses">top_losses</a> method returns a tuple of the highest losses along with the indices of the data that gave those losses. By default it actually gives all the losses sorted from largest to smallest, but you could pass in an integer to limit how much it returns.</p>
<div class="highlight">
<pre><span></span><span class="n">losses</span><span class="p">,</span> <span class="n">indexes</span> <span class="o">=</span> <span class="n">interpreter</span><span class="o">.</span><span class="n">top_losses</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">valid_ds</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>
</pre></div>
<pre class="example">
tensor([7.1777e+00, 6.8882e+00, 5.8577e+00,  ..., 3.8147e-06, 3.8147e-06,
        1.9073e-06])
tensor([1298, 1418,  166,  ...,  735,  404,  291])
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.002
･ CPU:          0          0      3,000 MB |
･ GPU:          0          0      1,181 MB |

</pre>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">holoviews</span><span class="o">.</span><span class="n">Distribution</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Loss Distribution"</span><span class="p">,</span> 
                                           <span class="n">xlabel</span><span class="o">=</span><span class="s2">"Loss"</span><span class="p">,</span> 
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> 
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"loss_distribution"</span><span class="p">)()</span>
</pre></div>
<object data="/posts/fastai/dog-and-cat-breed-classification/loss_distribution.html" height="800" style="width:100%" type="text/html">
<p>Figure Missing</p>
</object>
<p>Although it looks like there are negative losses, that's just the way the distribution works out, it looks like most of the losses are around zero.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</pre></div>
<pre class="example">
tensor(7.1777)
tensor(1.9073e-06)
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001
･ CPU:          0          0      3,000 MB |
･ GPU:          7          0      1,188 MB |

</pre>
<p>Here's a count of the losses when they are broken up into ten bins.</p>
<div class="highlight">
<pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">losses</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">percentage</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">total</span>
<span class="n">bins</span><span class="p">[</span><span class="s2">"percent"</span><span class="p">]</span> <span class="o">=</span> <span class="n">percentage</span>
<span class="k">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"Range Count Percent(%)"</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Range</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent(%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">(-0.00718, 0.718]</td>
<td class="org-right">1349</td>
<td class="org-right">91.272</td>
</tr>
<tr>
<td class="org-left">(0.718, 1.436]</td>
<td class="org-right">61</td>
<td class="org-right">4.1272</td>
</tr>
<tr>
<td class="org-left">(1.436, 2.153]</td>
<td class="org-right">31</td>
<td class="org-right">2.09743</td>
</tr>
<tr>
<td class="org-left">(2.153, 2.871]</td>
<td class="org-right">14</td>
<td class="org-right">0.947226</td>
</tr>
<tr>
<td class="org-left">(2.871, 3.589]</td>
<td class="org-right">15</td>
<td class="org-right">1.01488</td>
</tr>
<tr>
<td class="org-left">(3.589, 4.307]</td>
<td class="org-right">3</td>
<td class="org-right">0.202977</td>
</tr>
<tr>
<td class="org-left">(4.307, 5.024]</td>
<td class="org-right">2</td>
<td class="org-right">0.135318</td>
</tr>
<tr>
<td class="org-left">(5.024, 5.742]</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">(5.742, 6.46]</td>
<td class="org-right">1</td>
<td class="org-right">0.067659</td>
</tr>
<tr>
<td class="org-left">(6.46, 7.178]</td>
<td class="org-right">2</td>
<td class="org-right">0.135318</td>
</tr>
</tbody>
</table>
<p>It's not entirely clear to me how to interpret the losses - what does a loss of seven mean, exactly? -0.00744? But, anyway, it looks like the vast majority are less than one.</p>
<p>Another thing we can do is plot the images that had the highest losses.</p>
<div class="highlight">
<pre><span></span><span class="n">interpreter</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">11</span><span class="p">))</span>
</pre></div>
<div class="figure">
<p><img alt="top_losses.png" src="/posts/fastai/dog-and-cat-breed-classification/top_losses.png"></p>
</div>
<p>It looks like the ones that had the most loss had some kind of weird flare effect applied to the image. Now that we've used it, maybe we can see how we're supposed to call <code>plot_top_losses</code>.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">help</span><span class="p">(</span><span class="n">interpreter</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">))</span>
</pre></div>
<pre class="example">
Help on method _cl_int_plot_top_losses in module fastai.vision.learner:

_cl_int_plot_top_losses(k, largest=True, figsize=(12, 12), heatmap:bool=True, heatmap_thresh:int=16, return_fig:bool=None) -&gt; Union[matplotlib.figure.Figure, NoneType] method of fastai.train.ClassificationInterpretation instance
    Show images in `top_losses` along with their prediction, actual, loss, and probability of actual class.

None

</pre>
<p><b>Note:</b> in the original notebook they were using a function called <a href="https://github.com/fastai/fastai/blob/master/fastai/gen_doc/nbdoc.py#L126">doc</a>, which tries to open another window and will thus hang when run in emacs. They <i>really</i> want you to use jupyter.</p>
<p>Next let's look at the <a href="https://www.wikiwand.com/en/Confusion_matrix">confusion matrix</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">interpreter</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="confusion_matrix.png" src="/posts/fastai/dog-and-cat-breed-classification/confusion_matrix.png"></p>
</div>
<p>One way to interpret this is to look at the x-axis (the actual breed) and sweep vertically up to see the counts for the y-axis (what our model predicted it was). The diagonal cells from the top left to the bottom right is where the predicted matched the actual. In this case, the fact that almost all the counts are in the diagonal means our model did pretty well at predicting the breeds in the images.</p>
<p>If you compare the images with the worst losses to the confusion matrix you'll notice that they don't seem to correlate with the worst performances overall - the worst losses were one-offs, probably due to the flare effect. The most confused was the <i>Ragdoll</i> being confused for a <i>Birman</i>, but, as noted in the lecture, <a href="https://pets.thenest.com/birman-vs-ragdoll-cat-11758.html">distinguishing them is hard for people too</a>.</p>
<p>Here's the breeds that were the hardest for the model to predict.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">interpreter</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> 
                <span class="n">headers</span><span class="o">=</span><span class="s2">"Actual Predicted Count"</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Actual</th>
<th class="org-left" scope="col">Predicted</th>
<th class="org-right" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-right">10</td>
</tr>
<tr>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">American_Bulldog</td>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">Bengal</td>
<td class="org-left">Egyptian_Mau</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-left">American_Bulldog</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Miniature_Pinscher</td>
<td class="org-left">Chihuahua</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Ragdoll</td>
<td class="org-left">Birman</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Samoyed</td>
<td class="org-left">Great_Pyrenees</td>
<td class="org-right">3</td>
</tr>
</tbody>
</table>
<p>It doesn't look too bad, actually, other that the first few entries, maybe.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgc72f515">
<h3 id="orgc72f515">Unfreezing, fine-tuning, and learning rates</h3>
<div class="outline-text-3" id="text-orgc72f515">
<p>So, this is what we get with a straight off-the-shelf setup from <code>fast.ai</code>, but we want more, don't we? Let's <a href="https://docs.fast.ai/basic_train.html#Learner.unfreeze"><b>unfreeze</b></a> the model (allow the entire model's weights to be trained) and train some more.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
<p>Since we are using a pre-trained model we normally freeze all but the last layer to do transfer learning, by unfreezing the model we'll train all the layers to our dataset.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Finished training the unfrozen model."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:29:47.149628
Ended: 2019-04-21 18:30:28.689325
Elapsed: 0:00:41.539697
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:41.541
･ CPU:          0          0      3,010 MB |
･ GPU:        694      1,923      1,883 MB |

</pre>
<p>Now we save the parameters to disk again.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'stage-1'</span><span class="p">);</span>
</pre></div>
<p>Now we're going to use the <a href="https://docs.fast.ai/callbacks.lr_finder.html">lr_find</a> method to find the best learning rate.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Finished finding the best learning rate."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:31:02.961941
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Ended: 2019-04-21 18:31:29.892324
Elapsed: 0:00:26.930383
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:26.931
･ CPU:          0          0      3,010 MB |
･ GPU:        339      1,646      2,218 MB |

</pre>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
<div class="figure">
<p><img alt="learning.png" src="/posts/fastai/dog-and-cat-breed-classification/learning.png"></p>
</div>
<p>So, it's kind of hard to see the exact number, but you can see that somewhere around a learning rate of 0.0001 we get a good loss and then after that the loss starts to go way up.</p>
<p>So next we're going to re-train it using an interval that hopefully gives us the best loss.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">1e-4</span><span class="p">)))</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:34:11.748741
None
Ended: 2019-04-21 18:35:34.827655
Elapsed: 0:01:23.078914
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:01:23.083
･ CPU:          0          0      3,011 MB |
･ GPU:          9      1,634      2,231 MB |

</pre>
<p>Now the experiment is over so let's free up some memory.</p>
<div class="highlight">
<pre><span></span><span class="k">del</span> <span class="n">experiment</span>
</pre></div>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.000 ･ CPU: 0 0 3,011 MB | ･ GPU: -17 0 2,214 MB |</p>
<p>IPyExperimentsPytorch: Finishing</p>
</div>
<div class="outline-4" id="outline-container-org8fd340a">
<h4 id="org8fd340a">Experiment finished in 00:20:22 (elapsed wallclock time)</h4>
</div>
<div class="outline-4" id="outline-container-orgb98a06a">
<h4 id="orgb98a06a">Newly defined local variables:</h4>
<div class="outline-text-4" id="text-orgb98a06a">
<p>Deleted: bins, codecs, indexes, interpreter, learn, losses, percentage, total</p>
</div>
</div>
<div class="outline-4" id="outline-container-org0e9ee8f">
<h4 id="org0e9ee8f">Circular ref objects gc collected during the experiment:</h4>
<div class="outline-text-4" id="text-org0e9ee8f">
<p>cleared 12 objects (only temporary leakage)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org3436ed7">
<h4 id="org3436ed7">Experiment memory:</h4>
<div class="outline-text-4" id="text-org3436ed7">
<p>RAM: Consumed Reclaimed CPU: 636 0 MB ( 0.00%) GPU: 1,297 1,308 MB (100.82%)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org260508d">
<h4 id="org260508d">Current state:</h4>
<div class="outline-text-4" id="text-org260508d">
<p>RAM: Used Free Total Util CPU: 3,011 57,984 64,336 MB 4.68% GPU: 906 5,163 6,069 MB 14.93%</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0041cc0">
<h3 id="org0041cc0">Training: resnet50</h3>
<div class="outline-text-3" id="text-org0041cc0">
<p>Okay, so we trained the <code>resnet34</code> model, and although I haven't figured out how to tell exactly how well it's doing, it seems to be doing pretty well. Now it's time to try the <code>resnet50</code> model, which has pretty much the same architecture but more layers. This means it should do better, but it also takes up a lot more memory.</p>
<p>Even after deleting the old model I still run out of memory so I'm going to have to fall back to a smaller batch-size.</p>
<div class="highlight">
<pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">IPyExperimentsPytorch</span><span class="p">()</span>
</pre></div>
<pre class="example">

*** Experiment started with the Pytorch backend
Device: ID 0, GeForce GTX 1060 6GB (6069 RAM)


*** Current state:
RAM:    Used    Free   Total       Util
CPU:   3,011  57,984  64,336 MB   4.68% 
GPU:     906   5,163   6,069 MB  14.93% 


･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000
･ CPU:          0          0      3,011 MB |
･ GPU:          0          0        906 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_name_re</span><span class="p">(</span>
    <span class="n">path_to_images</span><span class="p">,</span> 
    <span class="n">file_names</span><span class="p">,</span> 
    <span class="n">expression</span><span class="p">,</span> 
    <span class="n">ds_tfms</span><span class="o">=</span><span class="n">get_transforms</span><span class="p">(),</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">299</span><span class="p">,</span> 
    <span class="n">bs</span><span class="o">=</span><span class="n">Net</span><span class="o">.</span><span class="n">low_memory_batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">)</span>
</pre></div>
<p>Now I'll re-build the learner with the new pre-trained model.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">resnet50</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
<div class="figure">
<p><img alt="learning_50.png" src="/posts/fastai/dog-and-cat-breed-classification/learning_50.png"></p>
</div>
<p>So with this learner we can see that there's a rapid drop in loss followed by a sudden spike in loss.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Done fitting resnet 50"</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:42:03.987300
Ended: 2019-04-21 18:57:43.628598
Elapsed: 0:15:39.641298
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:15:39.643
･ CPU:          0          0      3,067 MB |
･ GPU:         17      4,474      1,117 MB |

</pre>
<p>Okay, so save the parameters again.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'stage-1-50'</span><span class="p">)</span>
</pre></div>
<p>Now we can try and unfreeze and re-train it.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"Finished training resnet 50 with the optimal learning rate."</span>
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span><span class="mf">1e-4</span><span class="p">))</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 18:58:22.070603
Ended: 2019-04-21 19:06:24.471347
Elapsed: 0:08:02.400744
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:08:02.406
･ CPU:          0          0      3,069 MB |
･ GPU:        259      4,586      1,376 MB |

</pre>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 19:08:37.971400
Ended: 2019-04-21 19:08:49.648814
Elapsed: 0:00:11.677414
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:11.679
･ CPU:          0          0      3,069 MB |
･ GPU:         22        410      1,398 MB |

</pre>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Error Rate: {metrics[0]:.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Error Rate: 0.15

</pre>
<p>Since it didn't improve let's go back to the previous model.</p>
<div class="highlight">
<pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'stage-1-50'</span><span class="p">);</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Error Rate: {metrics[0]:.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 19:09:19.655769
Ended: 2019-04-21 19:09:30.841289
Elapsed: 0:00:11.185520
Error Rate: 0.16
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:16.011
･ CPU:          1          1      3,069 MB |
･ GPU:        308        612      1,706 MB |

</pre></div>
<div class="outline-4" id="outline-container-org6dcabaf">
<h4 id="org6dcabaf">Interpreting the Result</h4>
<div class="outline-text-4" id="text-org6dcabaf">
<div class="highlight">
<pre><span></span><span class="n">interpreter</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-5" id="outline-container-orgaaf7469">
<h5 id="orgaaf7469">The Most Confusing Breeds</h5>
<div class="outline-text-5" id="text-orgaaf7469">
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">interpreter</span><span class="o">.</span><span class="n">most_confused</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
                <span class="n">headers</span><span class="o">=</span><span class="s2">"Actual Predicted Count"</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Actual</th>
<th class="org-left" scope="col">Predicted</th>
<th class="org-right" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Bengal</td>
<td class="org-left">Egyptian_Mau</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">Ragdoll</td>
<td class="org-left">Birman</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">Staffordshire_Bull_Terrier</td>
<td class="org-left">American_Pit_Bull_Terrier</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">Bengal</td>
<td class="org-left">Abyssinian</td>
<td class="org-right">3</td>
</tr>
</tbody>
</table>
<p>It got fewer breeds with more than two wrong than the <code>resnet34</code> model did, but both of them seem to have trouble telling an American Pit Bull Terrier from a Staffordshire Bull Terrier.</p>
<div class="highlight">
<pre><span></span><span class="k">del</span> <span class="n">experiment</span>
</pre></div>
<pre class="example">
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |

</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf58c162">
<h3 id="orgf58c162">Other Data Formats</h3>
<div class="outline-text-3" id="text-orgf58c162">
<p>This is a look at other data sets.</p>
</div>
<div class="outline-4" id="outline-container-orge51ec69">
<h4 id="orge51ec69">MNIST</h4>
<div class="outline-text-4" id="text-orge51ec69">
<p>This is a set of handwritten digits. The originals are hosted on <a href="http://yann.lecun.com/exdb/mnist/">yann.lecun.com</a> but the <a href="https://course.fast.ai/datasets#image-classification">fast.ai datasets page</a> has the images converted from the original IDX format to the PNG format.</p>
<div class="highlight">
<pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">IPyExperimentsPytorch</span><span class="p">()</span>
</pre></div>
<pre class="example">

*** Experiment started with the Pytorch backend
Device: ID 0, GeForce GTX 1060 6GB (6069 RAM)


*** Current state:
RAM:    Used    Free   Total       Util
CPU:   3,070  57,254  64,336 MB   4.77% 
GPU:   1,706   4,363   6,069 MB  28.11% 


･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.097
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.043
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
</pre>
<div class="highlight">
<pre><span></span><span class="n">mnist_path_original</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MNIST"</span><span class="p">))</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">mnist_path_original</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">mnist_path_original</span><span class="p">)</span>
</pre></div>
<pre class="example">
/home/athena/data/datasets/images/mnist_png
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.046
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |

</pre>
<p>Now that we know it's there we can create a data bunch for it… Actually I tried it and found out that this is the wrong set (it throws an error for some reason), let's try it their way.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
<span class="n">mnist_path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">)</span>
</pre></div>
<pre class="example">
http://files.fast.ai/data/examples/mnist_sample
/home/athena/.fastai/data/mnist_sample
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.309
･ CPU:          0          1      3,070 MB |
･ GPU:          0          0      1,706 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.379
･ CPU:          0          0      3,070 MB |
･ GPU:          0          0      1,706 MB |

</pre>
<p>Let's look at the difference. Here's what I downloaded.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">mnist_path_original</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {path}"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li>/home/athena/data/datasets/images/mnist_png/testing</li>
<li>/home/athena/data/datasets/images/mnist_png/README.org</li>
<li>/home/athena/data/datasets/images/mnist_png/training</li>
</ul>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.026 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB | ･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.071 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB |</p>
<p>And here's what they downloaded.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">mnist_path</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {path}"</span><span class="p">)</span>
</pre></div>
<ul class="org-ul">
<li><i>home/athena</i>.fastai/data/mnist_sample/labels.csv</li>
<li><i>home/athena</i>.fastai/data/mnist_sample/train</li>
<li><i>home/athena</i>.fastai/data/mnist_sample/valid</li>
<li><i>home/athena</i>.fastai/data/mnist_sample/models</li>
</ul>
<p>･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.043 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB | ･ RAM: △Consumed △Peaked Used Total | Exec time 0:00:00.090 ･ CPU: 0 0 3,070 MB | ･ GPU: 0 0 1,706 MB |</p>
<p>Maybe you need a <code>labels.csv</code> file… I guess that's the point of this being in the "other formats" section.</p>
<div class="highlight">
<pre><span></span><span class="n">transforms</span> <span class="o">=</span> <span class="n">get_transforms</span><span class="p">(</span><span class="n">do_flip</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
</pre></div>
<p>I don't know why the size is 26 in this case.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
<div class="figure">
<p><img alt="mnist_batch.png" src="/posts/fastai/dog-and-cat-breed-classification/mnist_batch.png"></p>
</div>
<p>Now to fit the model. This uses a smaller version of the resnet (18 layers) and the <code>accuracy</code> metric.</p>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 19:15:13.568995
Ended: 2019-04-21 19:15:44.806330
Elapsed: 0:00:31.237335
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:31.239
･ CPU:          0          0      3,075 MB |
･ GPU:         46      1,379      1,733 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:31.297
･ CPU:          0          0      3,075 MB |
･ GPU:         46      1,379      1,733 MB |

</pre>
<p>So, since the labels are so important, maybe we should look at them.</p>
<div class="highlight">
<pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">mnist_path</span><span class="o">/</span><span class="s1">'labels.csv'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">ORG_TABLE</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">name</th>
<th class="org-right" scope="col">label</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">train/3/7463.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/21102.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/31559.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/46882.png</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">train/3/26209.png</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>
<p>Well, that's not realy revelatory.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">ImageDataBunch</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="n">mnist_path</span><span class="p">,</span> <span class="n">ds_tfms</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">28</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">classes</span><span class="p">)</span>
</pre></div>
<pre class="example">
[0, 1]
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.001
･ CPU:          0          0      3,080 MB |
･ GPU:          0          0      1,733 MB |
･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.047
･ CPU:          0          0      3,080 MB |
･ GPU:          0          0      1,733 MB |

</pre>
<p>So there are only two classes, presumably meaning that they are <code>3</code> and <code>7</code>.</p>
<p>There's more examples of… something in the notebook, but they don't explain it so I'm just going to skip over the rest of it.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org74d91ee">
<h2 id="org74d91ee">Return</h2>
<div class="outline-text-2" id="text-org74d91ee">
<p>This last bit just let's me run the whole notebook and get a message when it's over.</p>
<div class="highlight">
<pre><span></span><span class="n">TIMER</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s2">"The Dog and cat breed classification buffer is done. Come check it out."</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
<pre class="example">
Started: 2019-04-21 10:43:46.858157
Ended: 2019-04-21 10:43:46.858197
Elapsed: 0:00:00.000040

</pre></div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/pytorch/pytorch-60-minute-blitz/">Pytorch 60 Minute Blitz</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/pytorch/pytorch-60-minute-blitz/" rel="bookmark"><time class="published dt-published" datetime="2019-04-03T12:36:06-07:00" itemprop="datePublished" title="2019-04-03 12:36">2019-04-03 12:36</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org37aab3a">The Departure</a>
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org309c4ea">Imports</a>
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#orgb278128">PyPi</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org313c9a9">The Initiation</a>
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org18a996d">What is PyTorch?</a>
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#orgea0f1ff">Tensors</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#orgab3333a">Operations</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#orgc2159ad">Torch to Numpy</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org1c96447">Numpy to Torch</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org1f4fd44">Cuda</a></li>
</ul>
</li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org9743118">Autograd: Automatic Differentiation</a>
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org0aea9c7">Backpropagation</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org6fce262">Context Manager</a></li>
</ul>
</li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org9037538">Neural Networks</a>
<ul>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#orga0a4462">A Typical Model Training Procedure</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org1e08dca">Defining the Network</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org58daa76">The Loss Function</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org79444ee">Backpropagation</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org7357c7d">Update the Weights</a></li>
</ul>
</li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org59aeac0">Training a Classifier</a></li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#orga51b848">Data Parallelism</a></li>
</ul>
</li>
<li><a href="/posts/pytorch/pytorch-60-minute-blitz/#org765611b">The Return</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org37aab3a">
<h2 id="org37aab3a">The Departure</h2>
<div class="outline-text-2" id="text-org37aab3a">
<p>This is a replication of <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">Deep Learning With Pytorch: A 60 Minute Blitz</a> to get me back into using <a href="https://pytorch.org">PyTorch</a>.</p>
</div>
<div class="outline-3" id="outline-container-org309c4ea">
<h3 id="org309c4ea">Imports</h3>
<div class="outline-text-3" id="text-org309c4ea"></div>
<div class="outline-4" id="outline-container-orgb278128">
<h4 id="orgb278128">PyPi</h4>
<div class="outline-text-4" id="text-orgb278128">
<p>Although the project is called PyTorch, the package is named <code>torch</code>.</p>
<div class="highlight">
<pre><span></span>import torch
import torch.nn as neural_network
import torch.nn.functional as functional
</pre></div>
<p>And we're going to use numpy a little.</p>
<div class="highlight">
<pre><span></span>import numpy
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org313c9a9">
<h2 id="org313c9a9">The Initiation</h2>
<div class="outline-text-2" id="text-org313c9a9"></div>
<div class="outline-3" id="outline-container-org18a996d">
<h3 id="org18a996d">What is PyTorch?</h3>
<div class="outline-text-3" id="text-org18a996d"></div>
<div class="outline-4" id="outline-container-orgea0f1ff">
<h4 id="orgea0f1ff">Tensors</h4>
<div class="outline-text-4" id="text-orgea0f1ff">
<p>In PyTorch, <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">tensors</a> are similar to numpy's <a href="https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html">ndarrays</a> (n-dimensional arrays). You can create an unitialized one using the <code>empty</code> function.</p>
</div>
<ul class="org-ul">
<li><a id="orgebf2a87"></a>Empty<br>
<div class="outline-text-5" id="text-orgebf2a87">
<div class="highlight">
<pre><span></span>empty_tensor = torch.empty(5, 3)
print(empty_tensor)
</pre></div>
<pre class="example">
tensor([[-2.3492e+02,  4.5902e-41, -2.3492e+02],
        [ 4.5902e-41,  3.1766e+30,  1.7035e+25],
        [ 4.0498e-43,  0.0000e+00, -2.3492e+02],
        [ 4.5902e-41,  2.6417e-37,  0.0000e+00],
        [ 1.4607e-19,  1.8469e+25,  1.0901e+27]])

</pre>
<p>Here's the docstring for <code>empty</code>:</p>
<div class="highlight">
<pre><span></span>print(torch.empty.__doc__)
</pre></div>
<pre class="example">

empty(*sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -&gt; Tensor

Returns a tensor filled with uninitialized data. The shape of the tensor is
defined by the variable argument :attr:`sizes`.

Args:
    sizes (int...): a sequence of integers defining the shape of the output tensor.
        Can be a variable number of arguments or a collection like a list or tuple.
    out (Tensor, optional): the output tensor
    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.
        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).
    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.
        Default: ``torch.strided``.
    device (:class:`torch.device`, optional): the desired device of returned tensor.
        Default: if ``None``, uses the current device for the default tensor type
        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU
        for CPU tensor types and the current CUDA device for CUDA tensor types.
    requires_grad (bool, optional): If autograd should record operations on the
        returned tensor. Default: ``False``.

Example::

    &gt;&gt;&gt; torch.empty(2, 3)
    tensor(1.00000e-08 *
           [[ 6.3984,  0.0000,  0.0000],
            [ 0.0000,  0.0000,  0.0000]])


</pre></div>
</li>
<li><a id="org247fd6f"></a>Random<br>
<div class="outline-text-5" id="text-org247fd6f">
<div class="highlight">
<pre><span></span>print(torch.rand(5, 3))
</pre></div>
<pre class="example">
tensor([[0.1767, 0.9520, 0.1488],
        [0.5592, 0.4836, 0.2645],
        [0.8066, 0.8864, 0.1083],
        [0.9206, 0.7311, 0.1278],
        [0.0140, 0.5370, 0.3123]])

</pre>
<p>The arguments are the same as for empty.</p>
</div>
</li>
<li><a id="org45917cd"></a>Zeros<br>
<div class="outline-text-5" id="text-org45917cd">
<p>Here we'll create a tensor of zeros as long integers.</p>
<div class="highlight">
<pre><span></span>print(torch.zeros(5, 3, dtype=torch.long))
</pre></div>
<pre class="example">
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])

</pre>
<p>Once again the argument for <code>zeros</code> is the same as those for <code>empty</code>.</p>
</div>
</li>
<li><a id="org9969449"></a>From Data<br>
<div class="outline-text-5" id="text-org9969449">
<div class="highlight">
<pre><span></span>print(torch.tensor([5.5, 3]))
</pre></div>
<pre class="example">
tensor([5.5000, 3.0000])

</pre></div>
</li>
<li><a id="org1292744"></a>From A Tensor<br>
<div class="outline-text-5" id="text-org1292744">
<p>You can create a new tensor from a previously constructed one. This preserves any parameters you passed in that you don't subsequently override.</p>
<div class="highlight">
<pre><span></span>x = torch.tensor([5, 3], dtype=torch.int)
print(x)
y = x.new_ones(5, 3)
print(y)
</pre></div>
<pre class="example">
tensor([5, 3], dtype=torch.int32)
tensor([[1, 1, 1],
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1],
        [1, 1, 1]], dtype=torch.int32)

</pre>
<p>PyTorch also has another syntax for creating a random tensor from another tensor.</p>
<div class="highlight">
<pre><span></span>print(torch.randn_like(x, dtype=torch.float))
</pre></div>
<pre class="example">
tensor([ 0.6447, -0.9750])

</pre>
<p>So in this case it kept the shape but used our dtype. The values seemed odd at first, but that's because the <code>randn</code> indicates it comes from a standard-normal distribution centered at 0, not some value in the range from zero to one (non-inclusive) like a regular random function would.</p>
</div>
</li>
<li><a id="orgb2cdd5c"></a>Tensor Size<br>
<div class="outline-text-5" id="text-orgb2cdd5c">
<p>Like pandas, the tensor has a shape, but confusingly it's called <code>Size</code> and can be accessed either from the <code>size</code> method of the <code>shape</code> attribute.</p>
<div class="highlight">
<pre><span></span>print(y.size())
</pre></div>
<pre class="example">
torch.Size([5, 3])

</pre>
<div class="highlight">
<pre><span></span>print(y.shape)
</pre></div>
<pre class="example">
torch.Size([5, 3])

</pre>
<div class="highlight">
<pre><span></span>print(torch.Size.__base__)
</pre></div>
<pre class="example">
&lt;class 'tuple'&gt;

</pre>
<p>The <code>Size</code> object inherits from tuples and supports all the tuple operations.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgab3333a">
<h4 id="orgab3333a">Operations</h4>
<div class="outline-text-4" id="text-orgab3333a"></div>
<ul class="org-ul">
<li><a id="org3b2ef1a"></a>Addition<br>
<div class="outline-text-5" id="text-org3b2ef1a">
<p>For some operations you can use either the operators (like <code>+</code>) or method calls. Here's two ways to do addition.</p>
<div class="highlight">
<pre><span></span>SIZE = (5, 3)
x = torch.rand(*SIZE)
y = torch.rand(*SIZE)
output = x + y
print(output)
print()
print(torch.add(x, y))
</pre></div>
<pre class="example">
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])

tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])
</pre></div>
</li>
<li><a id="orgce1356a"></a>Pre-Made Tensors<br>
<div class="outline-text-5" id="text-orgce1356a">
<p>One advantage to using the function is that you can pass in a tensor, rather than having pytorch create the output-tensor for you.</p>
<div class="highlight">
<pre><span></span>summation = torch.empty(SIZE)
torch.add(x, y, out=summation)
print(summation)
</pre></div>
<pre class="example">
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])

</pre></div>
</li>
<li><a id="org8aec580"></a>In-Place Operations<br>
<div class="outline-text-5" id="text-org8aec580">
<p>Tensors also have methods that let you update them instead of creating a new tensor.</p>
<div class="highlight">
<pre><span></span>x.add_(y)
print(x)
</pre></div>
<pre class="example">
tensor([[0.4370, 1.4905, 0.8806],
        [1.7555, 0.9883, 0.8121],
        [1.1988, 0.6291, 1.2755],
        [1.2424, 1.1548, 1.1025],
        [0.8627, 0.9954, 1.1028]])

</pre></div>
</li>
<li><a id="orgd9fd4f1"></a>Slicing<br>
<div class="outline-text-5" id="text-orgd9fd4f1">
<p>The slicing follows what numpy's arrays do. Here's how to get all the rows of the second column.</p>
<div class="highlight">
<pre><span></span>print(x[:, 1])
</pre></div>
<pre class="example">
tensor([1.4905, 0.9883, 0.6291, 1.1548, 0.9954])

</pre></div>
</li>
<li><a id="orgd69be8c"></a>Reshaping<br>
<div class="outline-text-5" id="text-orgd69be8c">
<p>You can create a new tensor with the same data but a different shape using the <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view">view</a> method.</p>
<div class="highlight">
<pre><span></span>y = x.view(15)
z = x.view(-1, 5)
print(x.shape)
print(y.shape)
print(z.shape)
</pre></div>
<pre class="example">
torch.Size([5, 3])
torch.Size([15])
torch.Size([3, 5])

</pre>
<p>Using <code>-1</code> tells pytorch to infer the dimension based on the original and the dimension that you did pass in.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgc2159ad">
<h4 id="orgc2159ad">Torch to Numpy</h4>
<div class="outline-text-4" id="text-orgc2159ad">
<p>While there are advantages to using torch for operations (it can use the GPU, for instance), there might be times when you want to convert the tensor to a numpy array.</p>
<div class="highlight">
<pre><span></span>x = torch.zeros(5)
print(x)
y = x.numpy()
print(y)
x.add_(1)
print(x)
print(y)
print(type(y))
</pre></div>
<pre class="example">
tensor([0., 0., 0., 0., 0.])
[0. 0. 0. 0. 0.]
tensor([1., 1., 1., 1., 1.])
[1. 1. 1. 1. 1.]
&lt;class 'numpy.ndarray'&gt;

</pre>
<p>Somehow updating the tensor in place updates the numpy array as well, even though it's an ndarray.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org1c96447">
<h4 id="org1c96447">Numpy to Torch</h4>
<div class="outline-text-4" id="text-org1c96447">
<p>You can go the other way as well.</p>
<div class="highlight">
<pre><span></span>x = numpy.zeros(5)
print(x)
y = torch.from_numpy(x)
print(y)
x += 5
print(y)
</pre></div>
<pre class="example">
[0. 0. 0. 0. 0.]
tensor([0., 0., 0., 0., 0.], dtype=torch.float64)
tensor([5., 5., 5., 5., 5.], dtype=torch.float64)

</pre>
<p>So updating the array (in place) updates the tensor.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org1f4fd44">
<h4 id="org1f4fd44">Cuda</h4>
<div class="outline-text-4" id="text-org1f4fd44">
<p>As I mentioned before, an advantage of pytorch tensors is that they can be run on the GPU - unfortunately the computer I'm on is old and CUDA doesn't run on it, but we can make a check to see if it will first using =torch.cuda.is_available()</p>
<div class="highlight">
<pre><span></span>device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(device)

x = torch.ones(5)

# pass in the device
y = torch.ones_like(x, device=device)

# or move the tensor to the device (not an inplace operation)
x = x.to(device)

z = x + y
print(z)
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9743118">
<h3 id="org9743118">Autograd: Automatic Differentiation</h3>
<div class="outline-text-3" id="text-org9743118">
<p>The <a href="https://pytorch.org/docs/stable/autograd.html">autograd</a> module in pytorch performs automatic differentiation for you. It works using <i>define-by-run</i>, meaning that as you run you forward-pass through the network, it tracks your calls so you don't have to explicitly define anything for backpropagation to work. To enable or disable it you set the <code>requires_grad</code> attribute of the tensor you want to train.</p>
<div class="highlight">
<pre><span></span>tense = torch.ones(2, 2, requires_grad=True)
print(tense)
</pre></div>
<pre class="example">
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)

</pre>
<p>Now if you do a tensor operation:</p>
<div class="highlight">
<pre><span></span>tensed = tense + 1
print(tensed)
</pre></div>
<pre class="example">
tensor([[2., 2.],
        [2., 2.]], grad_fn=&lt;AddBackward0&gt;)

</pre>
<p>Our new tensor has a gradient function set for it. If you do more operations on <code>tensed</code>:</p>
<div class="highlight">
<pre><span></span>tenser = tensed * 5
print(tenser)
</pre></div>
<pre class="example">
tensor([[10., 10.],
        [10., 10.]], grad_fn=&lt;MulBackward0&gt;)

</pre>
<div class="highlight">
<pre><span></span>a = torch.ones(5, requires_grad=False)
b = a * 5
a.requires_grad_(True)
c = a * 6
print(b)
print(c)
</pre></div>
<pre class="example">
tensor([5., 5., 5., 5., 5.])
tensor([6., 6., 6., 6., 6.], grad_fn=&lt;MulBackward0&gt;)

</pre>
<p>Two things to note, one is that the gradient function is only set while the <code>requires_grad</code> attribute is true, the other is that this only works on the leafs in the graph - you can set it on <code>a</code> and <code>b</code> but not <code>c</code> - because since I set <code>requires_grad</code> to True on <code>a</code>, when I created <code>c</code> by multiplying <code>a</code> by 6, <code>c</code> became part of <code>a</code>'s graph… I think. Anyway, you can't set it on tensors that are part of the backpropagation path.</p>
</div>
<div class="outline-4" id="outline-container-org0aea9c7">
<h4 id="org0aea9c7">Backpropagation</h4>
<div class="outline-text-4" id="text-org0aea9c7">
<p>You run back-propagation by calling the <a href="https://pytorch.org/docs/stable/autograd.html#torch.Tensor.backward"><code>backward</code></a> method on the last tensor in the graph. In our case the last tensor we have (<code>tenser</code>) doesn't output numbers so we need to create a final tensor that does for back-propagation to work.</p>
<div class="highlight">
<pre><span></span>output = tenser.mean()
output.backward()
print(tense.grad)
</pre></div>
<pre class="example">
tensor([[1.2500, 1.2500],
        [1.2500, 1.2500]])

</pre>
<p>After one pass through the network (and back) our root-node tensor has some gradients.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org6fce262">
<h4 id="org6fce262">Context Manager</h4>
<div class="outline-text-4" id="text-org6fce262">
<p>If you need to temporarily turn the gradient tracking on or off you can use a context manager.</p>
<div class="highlight">
<pre><span></span>print((tense*2).requires_grad)
with torch.no_grad():
    print((tense* 2).requires_grad)
print((tense * 2).requires_grad)
</pre></div>
<pre class="example">
True
False
True

</pre>
<p>Note that the root-will still have <code>require_grad</code> as true, it's the output of operations working with it that don't get the gradient set.</p>
<div class="highlight">
<pre><span></span>print(tense.requires_grad)
with torch.no_grad():
    print(tense.requires_grad)
print(tense.requires_grad)
</pre></div>
<pre class="example">
True
True
True

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9037538">
<h3 id="org9037538">Neural Networks</h3>
<div class="outline-text-3" id="text-org9037538"></div>
<div class="outline-4" id="outline-container-orga0a4462">
<h4 id="orga0a4462">A Typical Model Training Procedure</h4>
<div class="outline-text-4" id="text-orga0a4462">
<ol class="org-ol">
<li>Define the neural network</li>
<li>Iterate over a dataset of inputs</li>
<li>Process each input through the network</li>
<li>Compute the loss (how much error there is)</li>
<li>Update the weights of the network</li>
</ol>
<p>The most common way to update the weights is to use a simple formula. \[ weight = weight - textit{learning rate} \times gradient \]</p>
</div>
</div>
<div class="outline-4" id="outline-container-org1e08dca">
<h4 id="org1e08dca">Defining the Network</h4>
<div class="outline-text-4" id="text-org1e08dca">
<p>This will be a network with five layers - two <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer">convolutional layers</a> followed by three <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Fully_connected_layer">fully-connected layers</a>. For the convolutional layers we're going to use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer">Max-Pooling</a> and for the fully-connected layers we'll use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#ReLU_layer">ReLU</a> activation.</p>
</div>
<ul class="org-ul">
<li><a id="orga483846"></a>The Layers<br>
<div class="outline-text-5" id="text-orga483846">
<p>You can just create the layers in the constructor, but since I'm trying to re-learn what's going on I'm going to peel it apart a little more.</p>
<p>The first layer is the input layer, so the <code>inputs</code> have to match whatever data you are going to get. In our case we are going to look at a black and white image so it has one input-channel. The three required arguments to the <a href="https://pytorch.org/docs/stable/nn.html#convolution-layers">Conv2d</a> constructor are:</p>
<ul class="org-ul">
<li><code>in_channels</code></li>
<li><code>out_channels</code></li>
<li><code>kernel_size</code></li>
</ul>
<div class="highlight">
<pre><span></span>class LayerOne:
    inputs = 1
    outputs = 6
    convolution_size = 5
    layer = neural_network.Conv2d(inputs, outputs, convolution_size)
</pre></div>
<div class="highlight">
<pre><span></span>class LayerTwo:
    inputs = LayerOne.outputs
    outputs = 16
    convolution_size = 5
    layer = neural_network.Conv2d(inputs, outputs, convolution_size)
</pre></div>
<p>Layer Three is the first <a href="https://pytorch.org/docs/stable/nn.html#linear">Linear</a> layer. Linear layers do a linear transformation on the inputs.</p>
<p>\[ y = x W^T + b \]</p>
<p>Where <i>x</i> is the input, <i>W</i> is the weight matrix and <i>b</i> is a bias constant.</p>
<div class="highlight">
<pre><span></span>class LayerThree:
    inputs = (LayerTwo.outputs * LayerOne.convolution_size 
              * LayerTwo.convolution_size)
    outputs = 120
    layer = neural_network.Linear(inputs, outputs)
</pre></div>
<div class="highlight">
<pre><span></span>class LayerFour:
    inputs = LayerThree.outputs
    outputs = 84
    layer = neural_network.Linear(inputs, outputs)
</pre></div>
<p>This is the last layer so the outputs are the outputs for the model as a whole.</p>
<div class="highlight">
<pre><span></span>class LayerFive:
    inputs = LayerFour.outputs
    outputs = 10
    layer = neural_network.Linear(inputs, outputs)
</pre></div>
<p>For the forward-pass our convolutional layers will have their output pooled using <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.max_pool2d">max_pool2d</a> and all the layers (except for the output layers) will use <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.functional.relu">relu</a> as the activation function to keep the model from being linear.</p>
<div class="highlight">
<pre><span></span>class NeuralNetwork(neural_network.Module):
    """A five-layer Convolutional Neural Network"""
    def __init__(self):
        super().__init__()
        self.layer_one = LayerOne.layer
        self.layer_two = LayerTwo.layer
        self.layer_three = LayerThree.layer
        self.layer_four = LayerFour.layer
        self.layer_five = LayerFive.layer
        return

    def flattened_features_counts(self, x):
        sizes = x.size()[1:]
        features = 1
        for size in sizes:
            features *= size
        return features

    def forward(self, x):
        """One forward pass through the network

        Args:
         x: a one-channel image

        Returns:
         a ten-output linear layer
        """
        x = functional.max_pool2d(functional.relu(self.layer_one(x)), (2, 2))
        x = functional.max_pool2d(functional.relu(self.layer_two(x)), 2)
        x = x.view(-1, self.flattened_features_counts(x))
        x = functional.relu(self.layer_three(x))
        x = functional.relu(self.layer_four(x))
        return self.layer_five(x)
</pre></div>
<div class="highlight">
<pre><span></span>model = NeuralNetwork()
print(model)
</pre></div>
<pre class="example">
NeuralNetwork(
  (layer_one): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (layer_two): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (layer_three): Linear(in_features=400, out_features=120, bias=True)
  (layer_four): Linear(in_features=120, out_features=84, bias=True)
  (layer_five): Linear(in_features=84, out_features=10, bias=True)
)

</pre>
<p>The output shows the parameters for each layer in our model.</p>
<p>A sample output.</p>
<div class="highlight">
<pre><span></span>INPUT_SIZE = 32
mock_image = torch.randn(1, 1, INPUT_SIZE, INPUT_SIZE)
output = model(mock_image)
print(output)
</pre></div>
<pre class="example">
tensor([[ 0.1163,  0.0882,  0.0529,  0.0546, -0.0196, -0.1215, -0.1736,  0.0659,
          0.0762, -0.0093]], grad_fn=&lt;AddmmBackward&gt;)

</pre>
<p>This is the output after one forward pass. Unfortunately we didn't want to train it on fake data so we should reset it.</p>
<div class="highlight">
<pre><span></span>model.zero_grad()
output.backward(torch.randn(1, 10))
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org58daa76">
<h4 id="org58daa76">The Loss Function</h4>
</div>
<div class="outline-4" id="outline-container-org79444ee">
<h4 id="org79444ee">Backpropagation</h4>
</div>
<div class="outline-4" id="outline-container-org7357c7d">
<h4 id="org7357c7d">Update the Weights</h4>
</div>
</div>
<div class="outline-3" id="outline-container-org59aeac0">
<h3 id="org59aeac0">Training a Classifier</h3>
</div>
<div class="outline-3" id="outline-container-orga51b848">
<h3 id="orga51b848">Data Parallelism</h3>
</div>
</div>
<div class="outline-2" id="outline-container-org765611b">
<h2 id="org765611b">The Return</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/pytorch/text/chatbot-tutorial/">Chatbot Tutorial</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/pytorch/text/chatbot-tutorial/" rel="bookmark"><time class="published dt-published" datetime="2019-02-10T15:02:29-08:00" itemprop="datePublished" title="2019-02-10 15:02">2019-02-10 15:02</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org297c911">Introduction</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org58354ee">Set Up</a>
<ul>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org27b1c27">Imports</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org2a9f6de">Setup the Timer</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org76e9bdb">Load Dotenv</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#orgddb80f8">Check CUDA</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org0cc0df6">Some Type Hints</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#orga62820b">Some Constants</a></li>
</ul>
</li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org5b4097d">The Data</a>
<ul>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org8e9c0e7">Download</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#orgeaf32ee">Movie Lines</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org39ecf8e">Conversations</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org59e1b90">Store the Processed Lines</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org3e6b0f9">Check Our Stored File</a></li>
</ul>
</li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#orgdc266ed">A Vocabulary</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#org44ddea5">Preparing the Data For Model-Training</a></li>
<li><a href="/posts/pytorch/text/chatbot-tutorial/#orgb02c501">Related Repositories To Check Out</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org297c911">
<h2 id="org297c911">Introduction</h2>
<div class="outline-text-2" id="text-org297c911">
<p>This is a walk-through the <a href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html">pytorch Chatbot Tutorial</a> which builds a chatbot using a recurrent Sequence-to-Sequence model trained on the <a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie-Dialogs Corpus</a>.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org58354ee">
<h2 id="org58354ee">Set Up</h2>
<div class="outline-text-2" id="text-org58354ee"></div>
<div class="outline-3" id="outline-container-org27b1c27">
<h3 id="org27b1c27">Imports</h3>
<div class="outline-text-3" id="text-org27b1c27"></div>
<div class="outline-4" id="outline-container-org1b72d47">
<h4 id="org1b72d47">Python</h4>
<div class="outline-text-4" id="text-org1b72d47">
<div class="highlight">
<pre><span></span>from collections import defaultdict, namedtuple
import codecs
from pathlib import Path
from typing import Dict, List, Union
from zipfile import ZipFile
import csv
import os
import subprocess
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org08e6367">
<h4 id="org08e6367">PyPi</h4>
<div class="outline-text-4" id="text-org08e6367">
<div class="highlight">
<pre><span></span>from dotenv import load_dotenv
import requests
import torch
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org503a3b8">
<h4 id="org503a3b8">This Project</h4>
<div class="outline-text-4" id="text-org503a3b8">
<div class="highlight">
<pre><span></span>from neurotic.tangles.timer import Timer
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2a9f6de">
<h3 id="org2a9f6de">Setup the Timer</h3>
<div class="outline-text-3" id="text-org2a9f6de">
<div class="highlight">
<pre><span></span>TIMER = Timer()
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org76e9bdb">
<h3 id="org76e9bdb">Load Dotenv</h3>
<div class="outline-text-3" id="text-org76e9bdb">
<div class="highlight">
<pre><span></span>load_dotenv("../../.env")
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgddb80f8">
<h3 id="orgddb80f8">Check CUDA</h3>
<div class="outline-text-3" id="text-orgddb80f8">
<div class="highlight">
<pre><span></span>device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using {}".format(device))
</pre></div>
<pre class="example">
Using cuda

</pre></div>
</div>
<div class="outline-3" id="outline-container-org0cc0df6">
<h3 id="org0cc0df6">Some Type Hints</h3>
<div class="outline-text-3" id="text-org0cc0df6">
<div class="highlight">
<pre><span></span>OptionalList = Union[list, None]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orga62820b">
<h3 id="orga62820b">Some Constants</h3>
<div class="outline-text-3" id="text-orga62820b">
<div class="highlight">
<pre><span></span>ENCODING = "iso-8859-1"
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org5b4097d">
<h2 id="org5b4097d">The Data</h2>
<div class="outline-text-2" id="text-org5b4097d"></div>
<div class="outline-3" id="outline-container-org8e9c0e7">
<h3 id="org8e9c0e7">Download</h3>
<div class="outline-text-3" id="text-org8e9c0e7">
<div class="highlight">
<pre><span></span>class MovieData:
    """Dowload and ready the movie data
    Args:
     download_path: Path to the folder to store the data
     url: download url for the zip file
     chunk_size: bytes to read from stream during download
     clean_up: remove the extra downloaded files
    """
    def __init__(self,
                 download_path: Path,
                 url: str=("http://www.cs.cornell.edu/~cristian/data/"
                           "cornell_movie_dialogs_corpus.zip"),
                 chunk_size=1024,
                 clean_up: bool=True) -&gt; None:
        self.download_path = download_path
        self.url = url
        self.chunk_size = chunk_size
        self.clean_up = clean_up
        self._zip_path = None
        self._data_path = None
        self._zip_file = None
        return

    @property
    def zip_path(self) -&gt; Path:
        """Path to the downloaded zip file"""
        if self._zip_path is None:
            self._zip_path = self.download_path.joinpath(Path(self.url).name)
        return self._zip_path

    @property
    def data_path(self) -&gt; Path:
        """Path to the unzipped file"""
        if self._data_path is None:
            self._data_path = self.download_path.joinpath(
                Path(self.zip_path).stem)
        return self._data_path

    @property
    def zip_file(self) -&gt; ZipFile:
        """the Zip file for the zipped data"""
        if self._zip_file is None:
            self._zip_file = ZipFile(self.zip_path)
        return self._zip_file

    def clean(self) -&gt; None:
        """remove the extra downloaded files"""
        os.remove(self.zip_path)
        return

    def __call__(self) -&gt; None:
        """downloads and prepares the file if needed"""
        if not self.data_path.is_dir():
            if not self.zip_path.is_file():
                response = requests.get(self.url, stream=True)
                with self.zip_path.open("wb") as writer:
                    for chunk in response.iter_content(chunk_size=self.chunk_size):
                        if chunk:
                            writer.write(chunk)
            unpacked = []
            for name in self.zip_file.namelist():
                name = Path(name)
                # there's extra folders and hidden files in there that I'll avoid
                if name.suffix in (".pdf", ".txt") and not name.name.startswith("."):
                    self.zip_file.extract(str(name), path=self.data_path)
                    unpacked.append(name)
            assert self.data_path.is_dir()
            if self.clean_up:
                # there is a sub-folder in the unzipped folder so move the
                # the files up one
                for to_move in unpacked:
                    self.data_path.joinpath(to_move).rename(
                        self.data_path.joinpath(to_move.name))

                # now delete the temporary file
                os.remove(self.zip_path)
                if unpacked:
                    # now remove the sub-folder
                    self.data_path.joinpath(unpacked[0].parent).rmdir()
        return
</pre></div>
<p>Now let's download and unpack the data.</p>
<div class="highlight">
<pre><span></span>datasets = Path(os.environ.get("DATASETS")).expanduser()
assert datasets.is_dir()
movie_data = MovieData(datasets, clean_up=True)
movie_data()
for name in movie_data.data_path.iterdir():
    print(" - {}".format(name.name))
</pre></div>
<ul class="org-ul">
<li>chameleons.pdf</li>
<li>conversation_line_pairs.tsv</li>
<li>movie_conversations.txt</li>
<li>movie_characters_metadata.txt</li>
<li>movie_lines.txt</li>
<li>movie_titles_metadata.txt</li>
<li>raw_script_urls.txt</li>
<li>README.txt</li>
</ul>
<div class="highlight">
<pre><span></span>class MovieFile:
    urls = "raw_script_urls.txt"
    readme = "README.txt"
    lines = "movie_lines.txt"
    characters = "movie_characters_metadata.txt"
    conversations = "movie_conversations.txt"
    titles = "movie_titles_metadata.txt"
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgeaf32ee">
<h3 id="orgeaf32ee">Movie Lines</h3>
<div class="outline-text-3" id="text-orgeaf32ee">
<p>Here's an excerpt from the <code>README.txt</code> file:</p>
<blockquote>
<p>In all files the field separator is " <del><del><del>$</del></del></del> "</p>
<ul class="org-ul">
<li>movie_lines.txt
<ul class="org-ul">
<li>contains the actual text of each utterance</li>
<li>fields:
<ul class="org-ul">
<li>lineID</li>
<li>characterID (who uttered this phrase)</li>
<li>movieID</li>
<li>character name</li>
<li>text of the utterance</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
</div>
<div class="outline-4" id="outline-container-orga4cdf3a">
<h4 id="orga4cdf3a">Movie Line Data</h4>
<div class="outline-text-4" id="text-orga4cdf3a">
<p>To load the lines I'm going to make a <a href="https://docs.python.org/3.6/library/collections.html#collections.namedtuple">namedtuple</a>.</p>
<div class="highlight">
<pre><span></span>MovieLine = namedtuple("MovieLine", ["line_id",
                                     "character_id",
                                     "movie_id",
                                     "character_name",
                                     "text"])

LineData = Dict[str, MovieLine]
LineFields = MovieLine(**{field: index
                          for index, field in enumerate(MovieLine._fields)})
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org448139f">
<h4 id="org448139f">A Line Loader</h4>
<div class="outline-text-4" id="text-org448139f">
<div class="highlight">
<pre><span></span>class MovieLines:
    """loads the movie dialog lines

    Args:
     path: path to the source file
     separator: column-separator
     encoding: the file encoding type (e.g. UTF-8)
    """
    def __init__(self, path: Path, separator: str=" +++$+++ ",
                 encoding="UTF-8") -&gt; None:
        self.path = path
        self.separator = separator
        self.encoding = encoding
        self._lines = None
        return

    @property
    def lines(self) -&gt; LineData:
        """Dictionary Of Lines in the Data"""
        if self._lines is None:
            self._lines = {}
            with self.path.open(encoding=self.encoding) as reader:
                for line in reader:
                    tokens = line.strip().split(self.separator)

                    text = tokens[LineFields.text] if len(tokens) == len(LineFields) else ""
                    movie_line = MovieLine(line_id=tokens[LineFields.line_id],
                                           character_id=tokens[LineFields.character_id],
                                           movie_id=tokens[LineFields.movie_id],
                                           character_name=tokens[LineFields.character_name],
                                           text=text,
                    )
                    self._lines[movie_line.line_id] = movie_line
        return self._lines

    def head(self, lines: int=5, get: bool=False) -&gt; OptionalList:
        """show the first lines

        Args:
         lines: number of lines to read
         get: if true, return the lines
        """
        output = [] if get else None
        with self.path.open() as reader:
            for index, line in enumerate(reader):
                line = line.rstrip()
                print(line)
                if get:
                    output.append(line)
                if index + 1 &gt;= lines:
                    break
        return output
</pre></div>
<div class="highlight">
<pre><span></span>movie_lines = MovieLines(movie_data.data_path.joinpath(MovieFile.lines), encoding=ENCODING)
output_lines = movie_lines.head(10)
</pre></div>
<pre class="example">
L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!
L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!
L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.
L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?
L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.
L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow
L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.
L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No
L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this "persona"?  And you don't know how to quit?
L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?
</pre>
<p>As note in the <code>README.txt</code> those strange characters are how the columns are separated (I guess so that the commas could be kept in the text). The Line IDs seem to be in reverse oredr, and don't seem to have all the lines - unless they're out of order and just looking at the head is misleading. For reference the movie for the lines I showed (the dialog between Bianca and Cameron) is from <a href="https://www.imdb.com/title/tt0147800/">12 Things I Hate About You</a>. For some reason they both encode the chraracters and give their names - <code>u0</code> is <code>BIANCA</code>.</p>
<p>If you poke around in the file you'll find that there's something peculiar about the characters in it.</p>
<div class="highlight">
<pre><span></span>output = subprocess.run(["file", "-i", str(movie_lines.path)], stdout=subprocess.PIPE)
print(output.stdout)
</pre></div>
<pre class="example">
b'/home/athena/data/datasets/cornell_movie_dialogs_corpus/movie_lines.txt: text/plain; charset=unknown-8bit\n'

</pre>
<p>It doesn't look like standard ASCII, but I wonder if it matters. In the pytorch tutorial they give the encoding as <code>iso-8859-1</code>, although I can't find any documentation for this, but since they gave it, I guess we can use it.</p>
<div class="highlight">
<pre><span></span><span class="n">ENCODING</span> <span class="o">=</span> <span class="s2">"iso-8859-1"</span>
</pre></div>
<p>I'm using it in MovieLines too so I defined ENCODING at the top of the notebook, this is just to show where it came from.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org39ecf8e">
<h3 id="org39ecf8e">Conversations</h3>
<div class="outline-text-3" id="text-org39ecf8e">
<p>The movie-lines file has all the movie-conversations together, but we want conversations between characters. For that you need to group the lines using the <code>movie_conversations.txt</code> file.</p>
<blockquote>
<ul class="org-ul">
<li>movie_conversations.txt
<ul class="org-ul">
<li>the structure of the conversations</li>
<li>fields
<ul class="org-ul">
<li>characterID of the first character involved in the conversation</li>
<li>characterID of the second character involved in the conversation</li>
<li>movieID of the movie in which the conversation occurred</li>
<li>list of the utterances that make the conversation, in chronological order: ['lineID1','lineID2',É,'lineIDN'] has to be matched with movie_lines.txt to reconstruct the actual content</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<p>You can see that the README has some kind of funky character in it (the third item in the <code>order</code> list). Weird.</p>
</div>
<div class="outline-4" id="outline-container-orgf13f9cc">
<h4 id="orgf13f9cc">A Conversation Holder</h4>
<div class="outline-text-4" id="text-orgf13f9cc">
<p>A <i>conversation</i> is a list of lines said by characters to each other. Although the dialog file is presumably in order, we want to be able to partition lines that are part of a single conversation - a verbal interaction between two characters.</p>
<div class="highlight">
<pre><span></span>ConversationIDs = namedtuple("ConversationIDs", ["character_id_1",
                                                 "character_id_2",
                                                 "movie_id",
                                                 "lines"])
ConversationFields = ConversationIDs(
    **{field: index
       for index, field in enumerate(ConversationIDs._fields)})
ConversationData = List[ConversationIDs]
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb4d6818">
<h4 id="orgb4d6818">A Conversations Builder</h4>
<div class="outline-text-4" id="text-orgb4d6818">
<p>This is code to pull the lines out and group them by conversation.</p>
<div class="highlight">
<pre><span></span>class Conversations:
    """Holds the conversations

    Args:
     path: path to the conversations file
     moviez: object with the movie lines
     encoding: the encoding for the file
     separator: the column separator
    """
    def __init__(self,
                 path: Path,
                 movies: MovieLines,
                 separator: str=" +++$+++ ",
                 encoding:str="UTF-8") -&gt; None:
        self.path = path
        self.movies = movies
        self.separator = separator
        self.encoding = encoding
        self._conversations = None
        self._sentence_pairs = None
        return

    @property
    def conversations(self) -&gt; ConversationData:
        """The list of conversation line data
        """
        if self._conversations is None:
            self._conversations = []
            with self.path.open(encoding=self.encoding) as reader:
                for line in reader:
                    tokens = line.strip().split(self.separator)
                    line_ids = eval(tokens[ConversationFields.lines])
                    lines = [self.movies.lines[line_id] for line_id in line_ids]
                    self._conversations.append(
                        ConversationIDs(
                            character_id_1=tokens[ConversationFields.character_id_1],
                            character_id_2=tokens[ConversationFields.character_id_2],
                            movie_id=tokens[ConversationFields.movie_id],
                            lines = lines,
                        ))
        return self._conversations

    @property
    def sentence_pairs(self) -&gt; list:
        """paired-sentences from the conversations"""
        if self._sentence_pairs is None:
            self._sentence_pairs = []
            for conversation in self.conversations:
                for index in range(len(conversation.lines) - 1):
                    utterance = conversation.lines[index].text
                    response = conversation.lines[index + 1].text
                    # you might not always have pairs
                    if utterance and response:
                        self._sentence_pairs.append([utterance, response])
        return self._sentence_pairs

    def head(self, count: int=5) -&gt; None:
        """Print the first lines

        Args:
         count: how many lines to print
        """
        with self.path.open(encoding=self.encoding) as reader:
            so_far = 0
            for line in reader:
                print(line.rstrip())
                so_far += 1
                if so_far &gt;= count:
                    break
        return
</pre></div>
<p>Now I'll build the conversations from the file.</p>
<div class="highlight">
<pre><span></span>conversations_path = movie_data.data_path.joinpath(MovieFile.conversations)
conversations = Conversations(conversations_path, movie_lines, encoding=ENCODING)
conversations.head()
</pre></div>
<pre class="example">
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']
u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']

</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org59e1b90">
<h3 id="org59e1b90">Store the Processed Lines</h3>
<div class="outline-text-3" id="text-org59e1b90">
<p>Since we've transformed the data we should store it to avoid needing to transform it again later.</p>
<div class="highlight">
<pre><span></span>with TIMER:
    processed_path = movie_data.data_path.joinpath("conversation_line_pairs.tsv")
    delimiter = str(codecs.decode("\t", "unicode_escape"))
    NEWLINE = "\n"
    with processed_path.open("w", encoding="utf-8") as outputfile:
        writer = csv.writer(outputfile, delimiter=delimiter)
        for pair in conversations.sentence_pairs:
            writer.writerow(pair)
</pre></div>
<pre class="example">
Started: 2019-02-18 18:44:01.624014
Ended: 2019-02-18 18:44:04.127445
Elapsed: 0:00:02.503431

</pre></div>
</div>
<div class="outline-3" id="outline-container-org3e6b0f9">
<h3 id="org3e6b0f9">Check Our Stored File</h3>
<div class="outline-text-3" id="text-org3e6b0f9">
<div class="highlight">
<pre><span></span>with processed_path.open() as reader:
    count = 0
    for line in reader:
        print(repr(line))
        count += 1
        if count == 5:
            break
</pre></div>
<pre class="example">
"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n"
"Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\n"
"Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n"
"You're asking me out.  That's so cute. What's your name again?\tForget it.\n"
"No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\n"

</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgdc266ed">
<h2 id="orgdc266ed">A Vocabulary</h2>
<div class="outline-text-2" id="text-orgdc266ed">
<div class="highlight">
<pre><span></span>PADDING, START_OF_SENTENCE, END_OF_SENTENCE = 0, 1, 2

class Vocabulary:
    """A class to hold words and sentences

    Args:
     name: name of the vocabulary
     token_delimiter: what to split sentences on
    """
    def __init__(self, name: str, token_delimiter: str=" ") -&gt; None:
        self.name = name
        self.trimmed = False
        self.token_delimiter = token_delimiter
        self.word_to_index = {}
        self._word_to_count = None
        self._index_to_word = None
        return

    @property
    def word_to_count(self) -&gt; defaultdict:
        """map of word to word count"""
        if self._word_to_count is None:
            self._word_to_count = defaultdict(lambda: 1)
        return self._word_to_count

    @property
    def index_to_word(self) -&gt; dict:
        """map of word-index back to the word"""
        if self._index_to_word is None:
            self._index_to_word = dict(
                PADDING="PAD",
                START_OF_SENTENCE="SOS",
                END_OF_SENTENCE="EOS",
            )
        return self._index_to_word

    @property
    def word_count(self) -&gt; int:
        """the number of words in our vocabulary"""
        return len(self.index_to_word)

    def add_sentence(self, sentence: str) -&gt; None:
        """Adds the words in the sentence to our dictionary

        Args:
         sentence: string of words
        """
        for word in sentence.split(self.token_delimiter):
            self.add_word(word)
        return

    def add_word(self, word: str) -&gt; None:
        """add the word to our vocabulary

        Args:
         word: word to add
        """
        if word not in self.word_to_index:
            self.word_to_index[word] = self.word_count
            self.index_to_word[self.word_count] = word
        else:
            self.word_to_count[word] += 1
        return

    def trim(self, minimum: int) -&gt; None:
        """Trim words below the minimum

        .. warning:: This will only work once, even if you change the
          minimum. set self.trimmed to False if you want to do it again

        Args:
         minimum: lowest acceptible count for a word
        """
        if self.trimmed:
            return
        self.trimmed = True
        keepers = []
        for word, count in self.word_to_count.items():
            if count &gt;= minimum:
                keepers.append(word)
        print("Keep: {}/{} = {:.2f}".format(len(keepers),
                                            len(self.word_count),
                                            len(keepers)/len(self.word_count)))
        self.reset()
        for word in keepers:
            self.add_word(word)
        return

    def reset(self) -&gt; None:
        """Resets the dictionaries"""
        self.word_to_index = {}
        self._word_to_count = None
        self._index_to_word = None
        return
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org44ddea5">
<h2 id="org44ddea5">Preparing the Data For Model-Training</h2>
</div>
<div class="outline-2" id="outline-container-orgb02c501">
<h2 id="orgb02c501">Related Repositories To Check Out</h2>
<div class="outline-text-2" id="text-orgb02c501">
<ul class="org-ul">
<li><a href="https://github.com/ywk991112/pytorch-chatbot">Formosa Speech Grand Challenge Chatbot</a></li>
<li><a href="https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation">Practical Pytorch seq2seq translation</a></li>
<li><a href="https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus">Cornell Movie Corpus Pre-processor</a></li>
</ul>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/nano/tv-script-generation/tv-script-generation/">TV Script Generation</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/nano/tv-script-generation/tv-script-generation/" rel="bookmark"><time class="published dt-published" datetime="2019-02-05T15:29:20-08:00" itemprop="datePublished" title="2019-02-05 15:29">2019-02-05 15:29</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org72e2240">Act I - The Call To Adventure</a>
<ul>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#orgc122e63">What is this about, then?</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org94d1bfb">Set Up</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#orgf766a42">Get the Data</a></li>
</ul>
</li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#orgf38980a">Act II - The Departure</a>
<ul>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org0d0a4d9">Build the Neural Network</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org7865caa">Input</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#orgace293c">Batching</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#orged62fb3">Test your dataloader</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org28fb5b5">Sizes</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org71c131d">Values</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org3e75ea0">Build the Neural Network</a></li>
</ul>
</li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org9477792">Act III - The Final Battle</a>
<ul>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org050c946">Generate TV Script</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org473d2c4">Generate Text</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#orgda90654">Generate a New Script</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org5585b5c">Save your favorite scripts</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org334015c">The TV Script is Not Perfect</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org9c7596e">Example generated script</a></li>
<li><a href="/posts/nano/tv-script-generation/tv-script-generation/#org59f319b">Submitting This Project</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org72e2240">
<h2 id="org72e2240">Act I - The Call To Adventure</h2>
<div class="outline-text-2" id="text-org72e2240"></div>
<div class="outline-3" id="outline-container-orgc122e63">
<h3 id="orgc122e63">What is this about, then?</h3>
<div class="outline-text-3" id="text-orgc122e63">
<p>We want to create a model that can generate scripts for you. To do I'll use part of the <a href="https://en.wikipedia.org/wiki/Seinfeld">Seinfeld</a> <a href="https://www.kaggle.com/thec03u5/seinfeld-chronicles#scripts.csv">dataset of scripts hosted on kaggle</a> to create an RNN to create "fake" TV scripts that emulate the Seinfeld ones.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org94d1bfb">
<h3 id="org94d1bfb">Set Up</h3>
<div class="outline-text-3" id="text-org94d1bfb"></div>
<div class="outline-4" id="outline-container-orgfe55dd3">
<h4 id="orgfe55dd3">Imports</h4>
<div class="outline-text-4" id="text-orgfe55dd3"></div>
<ul class="org-ul">
<li><a id="org76adc6a"></a>Python<br>
<div class="outline-text-5" id="text-org76adc6a">
<div class="highlight">
<pre><span></span>from collections import Counter
from functools import partial
from pathlib import Path
from typing import Collection
import os
import pickle
</pre></div>
</div>
</li>
<li><a id="org1ac9669"></a>PyPi<br>
<div class="outline-text-5" id="text-org1ac9669">
<div class="highlight">
<pre><span></span>from dotenv import load_dotenv
from tabulate import tabulate
from torch import nn
from torch.utils.data import TensorDataset, DataLoader
import hvplot.pandas
import numpy
import pandas
import torch
</pre></div>
</div>
</li>
<li><a id="org166d712"></a>This Project<br>
<div class="outline-text-5" id="text-org166d712">
<div class="highlight">
<pre><span></span>from bartleby_the_penguin.tangles.embed_bokeh import EmbedBokeh
</pre></div>
</div>
</li>
<li><a id="org81f1519"></a>Support Code<br>
<div class="outline-text-5" id="text-org81f1519">
<div class="highlight">
<pre><span></span>from udacity.project_tv_script_generation import helper
import udacity.project_tv_script_generation.problem_unittests as unittests
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org6746876">
<h4 id="org6746876">Load Dotenv</h4>
<div class="outline-text-4" id="text-org6746876">
<div class="highlight">
<pre><span></span>load_dotenv()
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc152580">
<h4 id="orgc152580">The Folder Path</h4>
<div class="outline-text-4" id="text-orgc152580">
<p>This is the path for saving files for this post.</p>
<div class="highlight">
<pre><span></span>FOLDER_PATH = Path("../../../files/posts/nano/tv-script-generation/"
                   "tv-script-generation/")
if not FOLDER_PATH.is_dir():
    FOLDER_PATH.mkdir(parents=True)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1b5f948">
<h4 id="org1b5f948">The Bokeh Embedder</h4>
<div class="outline-text-4" id="text-org1b5f948">
<p>This sets up the bokeh files and HTML.</p>
<div class="highlight">
<pre><span></span>Embed = partial(EmbedBokeh, folder_path=FOLDER_PATH)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6e65f6e">
<h4 id="org6e65f6e">Check CUDA</h4>
<div class="outline-text-4" id="text-org6e65f6e">
<p>Make sure that we can use CUDA.</p>
<div class="highlight">
<pre><span></span>device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
assert device.type == "cuda", 'No GPU found. Please use a GPU to train your neural network.'
print("Using {}".format(device))
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org89a60a2">
<h4 id="org89a60a2">Some Types</h4>
<div class="outline-text-4" id="text-org89a60a2">
<div class="highlight">
<pre><span></span>WordIndices = Collection[int]
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf766a42">
<h3 id="orgf766a42">Get the Data</h3>
<div class="outline-text-3" id="text-orgf766a42"></div>
<div class="outline-4" id="outline-container-orgbd3acbe">
<h4 id="orgbd3acbe">Scripts</h4>
<div class="outline-text-4" id="text-orgbd3acbe">
<div class="highlight">
<pre><span></span>class Scripts:
    """Seinfeld Scripts

    Args:
     environment_key: environment variable with the source location
     dialog_only: remove descriptive columns
    """
    def __init__(self, environment_key: str="SCRIPTS", dialog_only: bool=True) -&gt; None:
        self.environment_key = environment_key
        self.dialog_only = dialog_only
        self._script_blob = None
        self._path = None
        self._lines = None
        self._tokens = None
        self._line_tokens = None
        return

    @property
    def path(self) -&gt; Path:
        """The path to the file"""
        if self._path is None:
            load_dotenv(".env")
            self._path = Path(os.environ.get("SCRIPTS")).expanduser()
            assert self._path.is_file()
        return self._path

    @property
    def script_blob(self) -&gt; str:
        """The input file as a string"""
        if self._script_blob is None:
            with open(self.path) as reader:
                self._script_blob = reader.read()
        return self._script_blob

    @property
    def line_tokens(self) -&gt; list:
        """list of tokens for each line"""
        if self._line_tokens is None:
            self._line_tokens = [line.split(" ") for line in self.lines]
        return self._line_tokens

    @property
    def lines(self) -&gt; list:
        """The lines of the script"""
        if self._lines is None:
            lines = self.script_blob.split("\n")
            if self.dialog_only:
                lines = lines[1:]
                lines = [(",").join(line.split(",")[2:-3]) for line in lines]
            self._lines = lines
        return self._lines

    @property
    def tokens(self) -&gt; Counter:
        """The tokens and their counts"""
        if self._tokens is None:
            self._tokens = Counter()
            for token in self.script_blob.split():
                self._tokens[token] += 1
        return self._tokens
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd290aa1">
<h4 id="orgd290aa1">Script Inspector</h4>
<div class="outline-text-4" id="text-orgd290aa1">
<p>This is just to help with some preliminary exploratory data analysis.</p>
<div class="highlight">
<pre><span></span>class ScriptInspector:
    """gets some basic counts

    Args:
     scripts: object with the scripts
    """
    def __init__(self, scripts: Scripts=None) -&gt; None:
        self._scripts = scripts
        self._line_count = None
        self._count_per_line = None
        self._mean_words_per_line = None
        self._median_words_per_line = None
        self._max_words_per_line = None
        self._min_words_per_line = None
        self._token_count = None
        return

    @property
    def scripts(self) -&gt; Scripts:
        """The scripts object"""
        if self._scripts is None:
            self._scripts = Scripts()
        return self._scripts

    @property
    def line_count(self) -&gt; int:
        """Number of lines in the source"""
        if self._line_count is None:
            self._line_count = len(self.scripts.lines)
        return self._line_count

    @property
    def count_per_line(self) -&gt; list:
        """tokens per line"""
        if self._count_per_line is None:
            self._count_per_line = [len(tokens)
                                    for tokens in self.scripts.line_tokens]
        return self._count_per_line

    @property
    def mean_words_per_line(self) -&gt; float:
        """Average number of words per line"""
        if self._mean_words_per_line is None:
            self._mean_words_per_line = (sum(self.count_per_line)
                                         /self.line_count)
        return self._mean_words_per_line

    @property
    def median_words_per_line(self) -&gt; float:
        """Median words per line in the scripts"""
        if self._median_words_per_line is None:
            self._median_words_per_line = numpy.median(self.count_per_line)
        return self._median_words_per_line

    @property
    def max_words_per_line(self) -&gt; int:
        """Count of words in longest line"""
        if self._max_words_per_line is None:
            self._max_words_per_line = max(self.count_per_line)
        return self._max_words_per_line

    @property
    def min_words_per_line(self) -&gt; int:
        """Count of words in shortest line"""
        if self._min_words_per_line is None:
            self._min_words_per_line = min(self.count_per_line)
        return self._min_words_per_line

    @property
    def token_count(self) -&gt; int:
        """Number of tokens in the text"""
        if self._token_count is None:
            self._token_count = sum(self.scripts.tokens.values())
        return self._token_count

    def most_common_tokens(self, count: int=10) -&gt; list:
        """token, count tuples in descending rank

        Args:
         count: number of tuples to return in the list
        """
        if count &gt; 0:
            return self.scripts.tokens.most_common(count)
        return self.scripts.tokens.most_common()[count:]

    def line_range(self, start: int=0, stop: int=10) -&gt; list:
        """lines within range

        Args:
         start: index of first line
         stop: upper bound for last line
        """
        return self.scripts.lines[start:stop]
</pre></div>
<p>The scripts aren't really in a format that is optimized for pandas, at least not for this initial look, so we'll just load it as text.</p>
<div class="highlight">
<pre><span></span>inspector = ScriptInspector()
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf9e9bea">
<h4 id="orgf9e9bea">Explore the Data</h4>
<div class="outline-text-4" id="text-orgf9e9bea">
<div class="highlight">
<pre><span></span>view_line_range = (0, 10)
</pre></div>
<div class="highlight">
<pre><span></span>words_per_line = pandas.DataFrame(inspector.count_per_line,
                                  columns=["line_counts"])
print(words_per_line.shape)
</pre></div>
<pre class="example">
(54617, 1)

</pre></div>
</div>
<div class="outline-4" id="outline-container-org99c35ff">
<h4 id="org99c35ff">Dataset Statistics</h4>
<div class="outline-text-4" id="text-org99c35ff">
<div class="highlight">
<pre><span></span>lines = (("Number of unique tokens", "{:,}".format(inspector.token_count)),
         ("Number of lines", "{:,}".format(inspector.line_count)),
         ("Words in longest line", "{:,}".format(inspector.max_words_per_line)),
         ("Average number of words in each line", "{:.2f}".format(
             inspector.mean_words_per_line)),
         ("Median Words Per Line", "{:.2f}".format(
             inspector.median_words_per_line)),
         ("Words in shortest line", "{}".format(inspector.min_words_per_line))
)
print(tabulate(lines, headers="Statistic Value".split(), tablefmt="orgtbl"))
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Statistic</th>
<th class="org-right" scope="col">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Number of unique tokens</td>
<td class="org-right">550,996</td>
</tr>
<tr>
<td class="org-left">Number of lines</td>
<td class="org-right">54,617</td>
</tr>
<tr>
<td class="org-left">Words in longest line</td>
<td class="org-right">363</td>
</tr>
<tr>
<td class="org-left">Average number of words in each line</td>
<td class="org-right">10.01</td>
</tr>
<tr>
<td class="org-left">Median Words Per Line</td>
<td class="org-right">7.00</td>
</tr>
<tr>
<td class="org-left">Words in shortest line</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>
<p>Why would a line have 363 words?</p>
<div class="highlight">
<pre><span></span>index = words_per_line.line_counts.idxmax()
print(inspector.count_per_line[index])
print(inspector.scripts.lines[index])
</pre></div>
<pre class="example">
363
"The dating world is not a fun world...its a pressure world, its a world of tension, its a world of pain...and you know, if a woman comes over to my house, I gotta get that bathroom ready, cause she needs things. Women need equipment. I dont know what they need. I know I dont have it, I know that- You know what they need, women seem to need a lot of cotton-balls. This is the one Im- always has been one of the amazing things to me...I have no cotton-balls, were all human beings, what is the story? Ive never had one...I never bought one, I never needed one, Ive never been in a situation, when I thought to myself I could use a cotton-ball right now. I can certainly get out of this mess. Women need them and they dont need one or two, they need thousands of them, they need bags, theyre like peat moss bags, have you ever seen these giant bags? Theyre huge and two days later, theyre out, theyre gone, the, the bag is empty, where are the cotton-balls, ladies? What are you doin with them? The only time I ever see em is in the bottom of your little waste basket, theres two or three, that look like theyve been through some horrible experience... tortured, interrogated, I dont know what happened to them. I once went out with a girl whos left a little zip-lock-baggy of cotton-balls over at my house. I dont know what to do with them, I took them out, I put them on my kitchen floor like little tumbleweeds. I thought maybe the cockroaches would see it, figure this is a dead town. Lets move on. The dating world is a world of pressure. Lets face it a date is a job interview that lasts all night. The only difference between a date and a job interview is not many job interviews is there a chance youll end up naked at the end of it. You know? Well, Bill, the boss thinks youre the man for the position, why dont you strip down and meet some of the people youll be workin with?"

</pre>
<p>This is one of Seinfeld's stand up routines, so I don't think it's, strictly speaking, a line, or at least not a line of dialog.</p>
<p>What about one word?</p>
<div class="highlight">
<pre><span></span>print(inspector.scripts.lines[words_per_line.line_counts.idxmin()])
</pre></div>
<pre class="example">
Ha.

</pre>
<p>There's probably a lot of one word lines ("Yes", "No", etc.).</p>
</div>
</div>
<div class="outline-4" id="outline-container-org1dd6d0a">
<h4 id="org1dd6d0a">Plot the Words Per Line</h4>
<div class="outline-text-4" id="text-org1dd6d0a">
<div class="highlight">
<pre><span></span>plot = words_per_line.line_counts.hvplot.kde(title="Word Counts Per Line Distribution")
plotter = plot.opts(width=600, height=600, tools=["hover"])
Embed(plotter, "line_counts.js")()
</pre></div>
<script id="250c8a54-0b89-45b6-8d90-75202b719f48" src="/posts/nano/tv-script-generation/tv-script-generation/line_counts.js"></script>
<div class="highlight">
<pre><span></span>plot = words_per_line.line_counts.hvplot.box(title="Words Per Line")
plot = plot.opts(tools=["hover"])
Embed(plot, "line_counts_boxplot.js")()
</pre></div>
<script id="f60e5282-ccfb-4fe1-bd48-8578c8761f21" src="posts/nano/tv-script-generation/tv-script-generation/line_counts_boxplot.js"></script>
<div class="outline-4" id="outline-container-org8cee6fb">
<h4 id="org8cee6fb">Most Used Words</h4>
<div class="outline-text-4" id="text-org8cee6fb">
<p>&gt;&gt;&gt;&gt;&gt;&gt;&gt; d51aea0b1ff0725156523a28363e1f7bc18d91e0</p>
<div class="highlight">
<pre><span></span>lines = ((token, "{:,}".format(count))
         for token, count in inspector.most_common_tokens())
print(tabulate(lines,
               tablefmt="orgtbl", headers=["Token", "Count"]))
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-left" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">the</td>
<td class="org-left">16,373</td>
</tr>
<tr>
<td class="org-left">I</td>
<td class="org-left">13,911</td>
</tr>
<tr>
<td class="org-left">you</td>
<td class="org-left">12,831</td>
</tr>
<tr>
<td class="org-left">a</td>
<td class="org-left">12,096</td>
</tr>
<tr>
<td class="org-left">to</td>
<td class="org-left">11,594</td>
</tr>
<tr>
<td class="org-left">of</td>
<td class="org-left">5,490</td>
</tr>
<tr>
<td class="org-left">and</td>
<td class="org-left">5,210</td>
</tr>
<tr>
<td class="org-left">in</td>
<td class="org-left">4,741</td>
</tr>
<tr>
<td class="org-left">is</td>
<td class="org-left">4,283</td>
</tr>
<tr>
<td class="org-left">that</td>
<td class="org-left">4,047</td>
</tr>
</tbody>
</table>
<p>So it looks like the stop words are the most common, as you might expect.</p>
<div class="highlight">
<pre><span></span>words, counts = zip(*inspector.most_common_tokens(20))
top_twenty = pandas.DataFrame([counts], columns=words).T.reset_index()
top_twenty.columns = ["Word", "Count"]
layout = top_twenty.hvplot.bar(x="Word", y="Count",
                               title="Twenty Most Used Words",
                               colormap="Category20")
layout.opts(height=500, width=600)
Embed(layout, "top_twenty.js")()
</pre></div>
<script id="4ad3d0ad-3f73-4d1d-9707-73e2f3a80ee7" src="posts/nano/tv-script-generation/tv-script-generation/top_twenty.js"></script></div>
</div>
<div class="outline-4" id="outline-container-org0c2e913">
<h4 id="org0c2e913">The First five Lines</h4>
<div class="outline-text-4" id="text-org0c2e913">
<div class="highlight">
<pre><span></span>for line in inspector.line_range(stop=5):
    print(line)
</pre></div>
<pre class="example">
"Do you know what this is all about? Do you know, why were here? To be out, this is out...and out is one of the single most enjoyable experiences of life. People...did you ever hear people talking about We should go out? This is what theyre talking about...this whole thing, were all out now, no one is home. Not one person here is home, were all out! There are people tryin to find us, they dont know where we are. (on an imaginary phone) Did you ring?, I cant find him. Where did he go? He didnt tell me where he was going. He must have gone out. You wanna go out you get ready, you pick out the clothes, right? You take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...Then youre standing around, whatta you do? You go We gotta be getting back. Once youre out, you wanna get back! You wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? Where ever you are in life, its my feeling, youve gotta go."
"(pointing at Georges shirt) See, to me, that button is in the worst possible spot. The second button literally makes or breaks the shirt, look at it. Its too high! Its in no-mans-land. You look like you live with your mother."
Are you through?
"You do of course try on, when you buy?"
"Yes, it was purple, I liked it, I dont actually recall considering the buttons."

</pre>
<p>I took out the header and the identifying columns so this is just the dialog part of the data. It looks like they left in all the punctuation except for apostrophes for some reason.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org89529dd">
<h4 id="org89529dd">Pre-Processing the Text</h4>
<div class="outline-text-4" id="text-org89529dd">
<p>The first thing to do to any dataset is pre-processing. Implement the following pre-processing functions below:</p>
<ul class="org-ul">
<li>Lookup Table</li>
<li>Tokenize Punctuation</li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-orgd5fa990">
<h4 id="orgd5fa990">Lookup Table</h4>
<div class="outline-text-4" id="text-orgd5fa990">
<p>To create a word embedding, you first need to transform the words to ids. In this function, create two dictionaries:</p>
<ul class="org-ul">
<li>Dictionary to go from the <i>words</i> to an <i>ID</i>, we'll call it <code>vocab_to_int</code></li>
<li>Dictionary to go from the <i>ID</i> to <i>word</i>, we'll call it <code>int_to_vocab</code></li>
</ul>
<p>Return these dictionaries in the following <b>tuple</b> <code>(vocab_to_int, int_to_vocab)</code></p>
<div class="highlight">
<pre><span></span>def create_lookup_tables(text: list) -&gt; tuple:
    """
    Create lookup tables for vocabulary

    Args:
     text The text of tv scripts split into words

    Returns: 
     A tuple of dicts (vocab_to_int, int_to_vocab)
    """
    text = set(text)
    vocabulary_to_index = {token: index for index, token in enumerate(text)}
    index_to_vocabulary = {index: token for index, token in enumerate(text)}
    return vocabulary_to_index, index_to_vocabulary
</pre></div>
<div class="highlight">
<pre><span></span>test_text = '''
Moe_Szyslak Moe's Tavern Where the elite meet to drink
Bart_Simpson Eh yeah hello is Mike there Last name Rotch
Moe_Szyslak Hold on I'll check Mike Rotch Mike Rotch Hey has anybody seen Mike Rotch lately
Moe_Szyslak Listen you little puke One of these days I'm gonna catch you and I'm gonna carve my name on your back with an ice pick
Moe_Szyslak Whats the matter Homer You're not your normal effervescent self
Homer_Simpson I got my problems Moe Give me another one
Moe_Szyslak Homer hey you should not drink to forget your problems
Barney_Gumble Yeah you should only drink to enhance your social skills'''
</pre></div>
<div class="highlight">
<pre><span></span>unittests.test_create_lookup_tables(create_lookup_tables)
</pre></div>
<pre class="example">
Tests Passed

</pre></div>
</div>
<div class="outline-4" id="outline-container-org26c6ffd">
<h4 id="org26c6ffd">Tokenize Punctuation</h4>
<div class="outline-text-4" id="text-org26c6ffd">
<p>We'll be splitting the script into a word array using spaces as delimiters. However, punctuations like periods and exclamation marks can create multiple ids for the same word. For example, "bye" and "bye!" would generate two different word ids.</p>
<p>Implement the function <code>token_lookup</code> to return a dict that will be used to tokenize symbols like "!" into "||Exclamation_Mark||". Create a dictionary for the following symbols where the symbol is the key and value is the token:</p>
<ul class="org-ul">
<li>Period ( <b>.</b> )</li>
<li>Comma ( <b>,</b> )</li>
<li>Quotation Mark ( <b>"</b> )</li>
<li>Semicolon ( <b>;</b> )</li>
<li>Exclamation mark ( <b>!</b> )</li>
<li>Question mark ( <b>?</b> )</li>
<li>Left Parentheses ( <b>(</b> )</li>
<li>Right Parentheses ( <b>)</b> )</li>
<li>Dash ( <b>-</b> )</li>
<li>Return ( <b>\n</b> )</li>
</ul>
<p>This dictionary will be used to tokenize the symbols and add the delimiter (space) around it. This separates each symbols as its own word, making it easier for the neural network to predict the next word. Make sure you don't use a value that could be confused as a word; for example, instead of using the value "dash", try using something like "||dash||".</p>
<div class="highlight">
<pre><span></span>def token_lookup():
    """
    Generate a dict to turn punctuation into a token.

    Returns:
     Tokenized dictionary where the key is the punctuation and the value is the token
    """
    tokens = {'.': "period",
              ',': 'comma',
              '"': 'quotation',
              ';': 'semicolon',
              '!': 'exclamation',
              '?': 'question',
              '(': 'leftparenthesis',
              ')': 'rightparenthesis',
              '-': 'dash',
              '\n': 'newline'}
    return {token: '**{}**'.format(coded) for token,coded in tokens.items()}
</pre></div>
<div class="highlight">
<pre><span></span>unittests.test_tokenize(token_lookup)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga37f0ab">
<h4 id="orga37f0ab">Pre-process all the data and save it</h4>
<div class="outline-text-4" id="text-orga37f0ab">
<p>Running the code cell below will pre-process all the data and save it to file. You're encouraged to look at the code for <code>preprocess_and_save_data</code> in the <code>helpers.py</code> file to see what it's doing in detail, but you do not need to change this code.</p>
<div class="highlight">
<pre><span></span>text = helper.load_data(inspector.scripts.path)
text = text[81:]
token_dict = token_lookup()
for key, token in token_dict.items():
    text = text.replace(key, ' {} '.format(token))
text = text.lower()
text = text.split()
vocab_to_int, int_to_vocab = create_lookup_tables(text + list(helper.SPECIAL_WORDS.values()))
int_text = [vocab_to_int[word] for word in text]
pre_processed = inspector.scripts.path.parent.joinpath('preprocess.pkl')
with pre_processed.open("wb") as writer:
    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), writer)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4637e3a">
<h4 id="org4637e3a">Check Point</h4>
<div class="outline-text-4" id="text-org4637e3a">
<p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>
<div class="highlight">
<pre><span></span>pre_processed = inspector.scripts.path.parent.joinpath('preprocess.pkl')
with pre_processed.open("rb") as reader:
    int_text, vocab_to_int, int_to_vocab, token_dict = pickle.load(reader)
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf38980a">
<h2 id="orgf38980a">Act II - The Departure</h2>
<div class="outline-text-2" id="text-orgf38980a"></div>
<div class="outline-3" id="outline-container-org0d0a4d9">
<h3 id="org0d0a4d9">Build the Neural Network</h3>
<div class="outline-text-3" id="text-org0d0a4d9">
<p>In this section, you'll build the components necessary to build an RNN by implementing the RNN Module and forward and backpropagation functions.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org7865caa">
<h3 id="org7865caa">Input</h3>
<div class="outline-text-3" id="text-org7865caa">
<p>Let's start with the preprocessed input data. We'll use <a href="http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset">TensorDataset</a> to provide a known format to our dataset; in combination with <a href="http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader">DataLoader</a>, it will handle batching, shuffling, and other dataset iteration functions.</p>
<p>You can create data with TensorDataset by passing in feature and target tensors. Then create a DataLoader as usual.</p>
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">feature_tensors</span><span class="p">,</span> <span class="n">target_tensors</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> 
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgace293c">
<h3 id="orgace293c">Batching</h3>
<div class="outline-text-3" id="text-orgace293c">
<p>Implement the <code>batch_data</code> function to batch <code>words</code> data into chunks of size <code>batch_size</code> using the <code>TensorDataset</code> and <code>DataLoader</code> classes.</p>
<p>You can batch words using the DataLoader, but it will be up to you to create <code>feature_tensors</code> and <code>target_tensors</code> of the correct size and content for a given <code>sequence_length</code>.</p>
<p>For example, say we have these as input:</p>
<div class="highlight">
<pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
<p>Your first <code>feature_tensor</code> should contain the values:</p>
<div class="highlight">
<pre><span></span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
</pre></div>
<p>And the corresponding <code>target_tensor</code> should just be the next "word"/tokenized word value:</p>
<div class="highlight">
<pre><span></span><span class="mi">5</span>
</pre></div>
<p>This should continue with the second <code>feature_tensor</code>, <code>target_tensor</code> being:</p>
<div class="highlight">
<pre><span></span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>  <span class="c1"># features</span>
<span class="mi">6</span>             <span class="c1"># target</span>
</pre></div>
<div class="highlight">
<pre><span></span>def train_test_split(words: WordIndices, sequence_length: int) -&gt; tuple:
    """Breaks the words into a training and a test set

    Args:
     words: the IDs of the TV scripts
     sequence_length: the sequence length of each training instance

    Returns:
     tuple of training tensors, target tensors
    """
    training, testing = [], []
    for start in range(len(words) - sequence_length):
        training.append(words[start:start+sequence_length])
        testing.append(words[start + sequence_length])
    return torch.Tensor(training), torch.Tensor(testing)
</pre></div>
<div class="highlight">
<pre><span></span>words = list(range(1, 8))
sequence_length = 4
training, testing = train_test_split(words, sequence_length)
assert training[0] == torch.Tensor([1, 2, 3, 4])
assert testing[0] == torch.Tensor(5)
assert training[1] == torch.Tensor([2, 3, 4, 5])
assert testing[1] == torch.Tensor(6)
assert training[2] == torch.Tensor([3, 4, 5, 6])
assert testing[2] == torch.Tensor(7)
assert len(training) == torch.Tensor(3)
assert len(testing) == torch.Tensor(3)
</pre></div>
<div class="highlight">
<pre><span></span>def batch_data(words: WordIndices, sequence_length: int, batch_size: int) -&gt; DataLoader:
    """
    Batch the neural network data using DataLoader

    Args:
     - words: The word ids of the TV scripts
     - sequence_length: The sequence length of each batch
     - batch_size: The size of each batch; the number of sequences in a batch
    Returns: 
     DataLoader with batched data
    """
    training, target = train_test_split(words, sequence_length)
    data = TensorDataset(training, target)
    return DataLoader(data)
</pre></div>
<p>There is no test for this function, but you are encouraged to create tests of your own.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orged62fb3">
<h3 id="orged62fb3">Test your dataloader</h3>
<div class="outline-text-3" id="text-orged62fb3">
<p>You'll have to modify this code to test a batching function, but it should look fairly similar.</p>
<p>Below, we're generating some test text data and defining a dataloader using the function you defined, above. Then, we are getting some sample batch of inputs `sample_x` and targets `sample_y` from our dataloader.</p>
<p>Your code should return something like the following (likely in a different order, if you shuffled your data):</p>
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">28</span><span class="p">,</span>  <span class="mi">29</span><span class="p">,</span>  <span class="mi">30</span><span class="p">,</span>  <span class="mi">31</span><span class="p">,</span>  <span class="mi">32</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">21</span><span class="p">,</span>  <span class="mi">22</span><span class="p">,</span>  <span class="mi">23</span><span class="p">,</span>  <span class="mi">24</span><span class="p">,</span>  <span class="mi">25</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">17</span><span class="p">,</span>  <span class="mi">18</span><span class="p">,</span>  <span class="mi">19</span><span class="p">,</span>  <span class="mi">20</span><span class="p">,</span>  <span class="mi">21</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">34</span><span class="p">,</span>  <span class="mi">35</span><span class="p">,</span>  <span class="mi">36</span><span class="p">,</span>  <span class="mi">37</span><span class="p">,</span>  <span class="mi">38</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">11</span><span class="p">,</span>  <span class="mi">12</span><span class="p">,</span>  <span class="mi">13</span><span class="p">,</span>  <span class="mi">14</span><span class="p">,</span>  <span class="mi">15</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">23</span><span class="p">,</span>  <span class="mi">24</span><span class="p">,</span>  <span class="mi">25</span><span class="p">,</span>  <span class="mi">26</span><span class="p">,</span>  <span class="mi">27</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mi">6</span><span class="p">,</span>   <span class="mi">7</span><span class="p">,</span>   <span class="mi">8</span><span class="p">,</span>   <span class="mi">9</span><span class="p">,</span>  <span class="mi">10</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">38</span><span class="p">,</span>  <span class="mi">39</span><span class="p">,</span>  <span class="mi">40</span><span class="p">,</span>  <span class="mi">41</span><span class="p">,</span>  <span class="mi">42</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">25</span><span class="p">,</span>  <span class="mi">26</span><span class="p">,</span>  <span class="mi">27</span><span class="p">,</span>  <span class="mi">28</span><span class="p">,</span>  <span class="mi">29</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mi">7</span><span class="p">,</span>   <span class="mi">8</span><span class="p">,</span>   <span class="mi">9</span><span class="p">,</span>  <span class="mi">10</span><span class="p">,</span>  <span class="mi">11</span><span class="p">]])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">33</span><span class="p">,</span>  <span class="mi">26</span><span class="p">,</span>  <span class="mi">22</span><span class="p">,</span>  <span class="mi">39</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span>  <span class="mi">28</span><span class="p">,</span>  <span class="mi">11</span><span class="p">,</span>  <span class="mi">43</span><span class="p">,</span>  <span class="mi">30</span><span class="p">,</span>  <span class="mi">12</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org28fb5b5">
<h3 id="org28fb5b5">Sizes</h3>
<div class="outline-text-3" id="text-org28fb5b5">
<p>Your sample_x should be of size `(batch_size, sequence_length)` or (10, 5) in this case and sample_y should just have one dimension: batch_size (10).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org71c131d">
<h3 id="org71c131d">Values</h3>
<div class="outline-text-3" id="text-org71c131d">
<p>You should also notice that the targets, sample_y, are the <b>next</b> value in the ordered test_text data. So, for an input sequence `[ 28, 29, 30, 31, 32]` that ends with the value `32`, the corresponding output should be `33`.</p>
<div class="highlight">
<pre><span></span>test_text = range(50)
t_loader = batch_data(test_text, sequence_length=5, batch_size=10)

data_iter = iter(t_loader)
sample_x, sample_y = data_iter.next()

print(sample_x.shape)
print(sample_x)
print()
print(sample_y.shape)
print(sample_y)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org3e75ea0">
<h3 id="org3e75ea0">Build the Neural Network</h3>
<div class="outline-text-3" id="text-org3e75ea0">
<p>Implement an RNN using PyTorch's [Module class](<a href="http://pytorch.org/docs/master/nn.html#torch.nn.Module">http://pytorch.org/docs/master/nn.html#torch.nn.Module</a>). You may choose to use a GRU or an LSTM. To complete the RNN, you'll have to implement the following functions for the class:</p>
<ul class="org-ul">
<li>`__init__` - The initialize function.</li>
<li>`init_hidden` - The initialization function for an LSTM/GRU hidden state</li>
<li>`forward` - Forward propagation function.</li>
</ul>
<p>The initialize function should create the layers of the neural network and save them to the class. The forward propagation function will use these layers to run forward propagation and generate an output and a hidden state.</p>
<p><b>*The output of this model should be the *last</b> batch of word scores** after a complete sequence has been processed. That is, for each input sequence of words, we only want to output the word scores for a single, most likely, next word.</p>
</div>
<div class="outline-4" id="outline-container-orgd6f3faf">
<h4 id="orgd6f3faf">Hints</h4>
<div class="outline-text-4" id="text-orgd6f3faf">
<ol class="org-ol">
<li>Make sure to stack the outputs of the lstm to pass to your fully-connected layer, you can do this with `lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)`</li>
<li>You can get the last batch of word scores by shaping the output of the final, fully-connected layer like so:</li>
</ol>
<div class="highlight">
<pre><span></span><span class="c1"># reshape into (batch_size, seq_length, output_size)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">)</span>
<span class="c1"># get last batch</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<div class="highlight">
<pre><span></span>import torch.nn as nn

class RNN(nn.Module):

    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):
        """
        Initialize the PyTorch RNN Module
        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)
        :param output_size: The number of output dimensions of the neural network
        :param embedding_dim: The size of embeddings, should you choose to use them        
        :param hidden_dim: The size of the hidden layer outputs
        :param dropout: dropout to add in between LSTM/GRU layers
        """
        super(RNN, self).__init__()
        # TODO: Implement function

        # set class variables

        # define model layers


    def forward(self, nn_input, hidden):
        """
        Forward propagation of the neural network
        :param nn_input: The input to the neural network
        :param hidden: The hidden state        
        :return: Two Tensors, the output of the neural network and the latest hidden state
        """
        # TODO: Implement function   

        # return one batch of output word scores and the hidden state
        return None, None


    def init_hidden(self, batch_size):
        '''
        Initialize the hidden state of an LSTM/GRU
        :param batch_size: The batch_size of the hidden state
        :return: hidden state of dims (n_layers, batch_size, hidden_dim)
        '''
        # Implement function

        # initialize hidden state with zero weights, and move to GPU if available

        return None

tests.test_rnn(RNN, train_on_gpu)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgac51a09">
<h4 id="orgac51a09">Define forward and backpropagation</h4>
<div class="outline-text-4" id="text-orgac51a09">
<p>Use the RNN class you implemented to apply forward and back propagation. This function will be called, iteratively, in the training loop as follows:</p>
<div class="highlight">
<pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">forward_back_prop</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</pre></div>
<p>And it should return the average loss over a batch and the hidden state returned by a call to `RNN(inp, hidden)`. Recall that you can get this loss by computing it, as usual, and calling `loss.item()`.</p>
<p><b>If a GPU is available, you should move your data to that GPU device, here.</b></p>
<div class="highlight">
<pre><span></span>def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):
    """
    Forward and backward propagation on the neural network
    :param decoder: The PyTorch Module that holds the neural network
    :param decoder_optimizer: The PyTorch optimizer for the neural network
    :param criterion: The PyTorch loss function
    :param inp: A batch of input to the neural network
    :param target: The target output for the batch of input
    :return: The loss and the latest hidden state Tensor
    """

    # TODO: Implement Function

    # move data to GPU, if available

    # perform backpropagation and optimization

    # return the loss over a batch and the hidden state produced by our model
    return None, None

# Note that these tests aren't completely extensive.
# they are here to act as general checks on the expected outputs of your functions
"""
DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE
"""
tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3ba95ec">
<h4 id="org3ba95ec">Neural Network Training</h4>
<div class="outline-text-4" id="text-org3ba95ec">
<p>With the structure of the network complete and data ready to be fed in the neural network, it's time to train it.</p>
</div>
<ul class="org-ul">
<li><a id="org5f01b89"></a>Train Loop<br>
<div class="outline-text-5" id="text-org5f01b89">
<p>The training loop is implemented for you in the `train_decoder` function. This function will train the network over all the batches for the number of epochs given. The model progress will be shown every number of batches. This number is set with the `show_every_n_batches` parameter. You'll set this parameter along with other parameters in the next section.</p>
<div class="highlight">
<pre><span></span>def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):
    batch_losses = []

    rnn.train()

    print("Training for %d epoch(s)..." % n_epochs)
    for epoch_i in range(1, n_epochs + 1):

        # initialize hidden state
        hidden = rnn.init_hidden(batch_size)

        for batch_i, (inputs, labels) in enumerate(train_loader, 1):

            # make sure you iterate over completely full batches, only
            n_batches = len(train_loader.dataset)//batch_size
            if(batch_i &gt; n_batches):
                break

            # forward, back prop
            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          
            # record loss
            batch_losses.append(loss)

            # printing loss stats
            if batch_i % show_every_n_batches == 0:
                print('Epoch: {:&gt;4}/{:&lt;4}  Loss: {}\n'.format(
                    epoch_i, n_epochs, np.average(batch_losses)))
                batch_losses = []

    # returns a trained rnn
    return rnn
</pre></div>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org54b6d10">
<h4 id="org54b6d10">Hyperparameters</h4>
<div class="outline-text-4" id="text-org54b6d10">
<p>Set and train the neural network with the following parameters:</p>
<ul class="org-ul">
<li>Set `sequence_length` to the length of a sequence.</li>
<li>Set `batch_size` to the batch size.</li>
<li>Set `num_epochs` to the number of epochs to train for.</li>
<li>Set `learning_rate` to the learning rate for an Adam optimizer.</li>
<li>Set `vocab_size` to the number of unique tokens in our vocabulary.</li>
<li>Set `output_size` to the desired size of the output.</li>
<li>Set `embedding_dim` to the embedding dimension; smaller than the vocab_size.</li>
<li>Set `hidden_dim` to the hidden dimension of your RNN.</li>
<li>Set `n_layers` to the number of layers/cells in your RNN.</li>
<li>Set `show_every_n_batches` to the number of batches at which the neural network should print progress.</li>
</ul>
<p>If the network isn't getting the desired results, tweak these parameters and/or the layers in the `RNN` class.</p>
<div class="highlight">
<pre><span></span># Data params
# Sequence Length
sequence_length =   # of words in a sequence
# Batch Size
batch_size = 

# data loader - do not change
train_loader = batch_data(int_text, sequence_length, batch_size)
</pre></div>
<p>Training parameters</p>
<div class="highlight">
<pre><span></span># Number of Epochs
num_epochs = 
# Learning Rate
learning_rate = 

# Model parameters
# Vocab size
vocab_size = 
# Output size
output_size = 
# Embedding Dimension
embedding_dim = 
# Hidden Dimension
hidden_dim = 
# Number of RNN Layers
n_layers = 

# Show stats for every n number of batches
show_every_n_batches = 500
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6750fd5">
<h4 id="org6750fd5">Train</h4>
<div class="outline-text-4" id="text-org6750fd5">
<p>In the next cell, you'll train the neural network on the pre-processed data. If you have a hard time getting a good loss, you may consider changing your hyperparameters. In general, you may get better results with larger hidden and n_layer dimensions, but larger models take a longer time to train. &gt; <b>You should aim for a loss less than 3.5.</b></p>
<p>You should also experiment with different sequence lengths, which determine the size of the long range dependencies that a model can learn.</p>
<div class="highlight">
<pre><span></span># create model and move to gpu if available
rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)
if train_on_gpu:
    rnn.cuda()

# defining loss and optimization functions for training
optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

# training the model
trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)

# saving the trained model
helper.save_model('./save/trained_rnn', trained_rnn)
print('Model Trained and Saved')
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org55e27aa">
<h4 id="org55e27aa">Question: How did you decide on your model hyperparameters?</h4>
<div class="outline-text-4" id="text-org55e27aa">
<p>For example, did you try different sequence_lengths and find that one size made the model converge faster? What about your hidden_dim and n_layers; how did you decide on those?</p>
<p><b>Answer:</b> (Write answer, here)</p>
</div>
</div>
<div class="outline-4" id="outline-container-org15f6bb7">
<h4 id="org15f6bb7">Checkpoint</h4>
<div class="outline-text-4" id="text-org15f6bb7">
<p>After running the above training cell, your model will be saved by name, `trained_rnn`, and if you save your notebook progress, <b>you can pause here and come back to this code at another time</b>. You can resume your progress by running the next cell, which will load in our word:id dictionaries <span class="underline">and</span> load in your saved model by name!</p>
<div class="highlight">
<pre><span></span>import torch
import helper
import problem_unittests as tests

_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()
trained_rnn = helper.load_model('./save/trained_rnn')
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org9477792">
<h2 id="org9477792">Act III - The Final Battle</h2>
<div class="outline-text-2" id="text-org9477792"></div>
<div class="outline-3" id="outline-container-org050c946">
<h3 id="org050c946">Generate TV Script</h3>
<div class="outline-text-3" id="text-org050c946">
<p>With the network trained and saved, you'll use it to generate a new, "fake" Seinfeld TV script in this section.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org473d2c4">
<h3 id="org473d2c4">Generate Text</h3>
<div class="outline-text-3" id="text-org473d2c4">
<p>To generate the text, the network needs to start with a single word and repeat its predictions until it reaches a set length. You'll be using the `generate` function to do this. It takes a word id to start with, `prime_id`, and generates a set length of text, `predict_len`. Also note that it uses topk sampling to introduce some randomness in choosing the most likely next word, given an output set of word scores!</p>
<div class="highlight">
<pre><span></span>import torch.nn.functional as F

def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):
    """
    Generate text using the neural network
    :param decoder: The PyTorch Module that holds the trained neural network
    :param prime_id: The word id to start the first prediction
    :param int_to_vocab: Dict of word id keys to word values
    :param token_dict: Dict of puncuation tokens keys to puncuation values
    :param pad_value: The value used to pad a sequence
    :param predict_len: The length of text to generate
    :return: The generated text
    """
    rnn.eval()

    # create a sequence (batch_size=1) with the prime_id
    current_seq = np.full((1, sequence_length), pad_value)
    current_seq[-1][-1] = prime_id
    predicted = [int_to_vocab[prime_id]]

    for _ in range(predict_len):
        if train_on_gpu:
            current_seq = torch.LongTensor(current_seq).cuda()
        else:
            current_seq = torch.LongTensor(current_seq)

        # initialize the hidden state
        hidden = rnn.init_hidden(current_seq.size(0))

        # get the output of the rnn
        output, _ = rnn(current_seq, hidden)

        # get the next word probabilities
        p = F.softmax(output, dim=1).data
        if(train_on_gpu):
            p = p.cpu() # move to cpu

        # use top_k sampling to get the index of the next word
        top_k = 5
        p, top_i = p.topk(top_k)
        top_i = top_i.numpy().squeeze()

        # select the likely next word index with some element of randomness
        p = p.numpy().squeeze()
        word_i = np.random.choice(top_i, p=p/p.sum())

        # retrieve that word from the dictionary
        word = int_to_vocab[word_i]
        predicted.append(word)     

        # the generated word becomes the next "current sequence" and the cycle can continue
        current_seq = np.roll(current_seq, -1, 1)
        current_seq[-1][-1] = word_i

    gen_sentences = ' '.join(predicted)

    # Replace punctuation tokens
    for key, token in token_dict.items():
        ending = ' ' if key in ['\n', '(', '"'] else ''
        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)
    gen_sentences = gen_sentences.replace('\n ', '\n')
    gen_sentences = gen_sentences.replace('( ', '(')

    # return all the sentences
    return gen_sentences
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgda90654">
<h3 id="orgda90654">Generate a New Script</h3>
<div class="outline-text-3" id="text-orgda90654">
<p>It's time to generate the text. Set `gen_length` to the length of TV script you want to generate and set `prime_word` to one of the following to start the prediction:</p>
<ul class="org-ul">
<li>"jerry"</li>
<li>"elaine"</li>
<li>"george"</li>
<li>"kramer"</li>
</ul>
<p>You can set the prime word to <span class="underline">any word</span> in our dictionary, but it's best to start with a name for generating a TV script. (You can also start with any other names you find in the original text file!)</p>
<div class="highlight">
<pre><span></span># run the cell multiple times to get different results!
gen_length = 400 # modify the length to your preference
prime_word = 'jerry' # name for starting the script

"""
DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE
"""
pad_word = helper.SPECIAL_WORDS['PADDING']
generated_script = generate(trained_rnn, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)
print(generated_script)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5585b5c">
<h3 id="org5585b5c">Save your favorite scripts</h3>
<div class="outline-text-3" id="text-org5585b5c">
<p>Once you have a script that you like (or find interesting), save it to a text file!</p>
<div class="highlight">
<pre><span></span># save script to a text file
f =  open("generated_script_1.txt","w")
f.write(generated_script)
f.close()
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org334015c">
<h3 id="org334015c">The TV Script is Not Perfect</h3>
<div class="outline-text-3" id="text-org334015c">
<p>It's ok if the TV script doesn't make perfect sense. It should look like alternating lines of dialogue, here is one such example of a few generated lines.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org9c7596e">
<h3 id="org9c7596e">Example generated script</h3>
<div class="outline-text-3" id="text-org9c7596e">
<p>&gt;jerry: what about me? &gt; &gt;jerry: i don't have to wait. &gt; &gt;kramer:(to the sales table) &gt; &gt;elaine:(to jerry) hey, look at this, i'm a good doctor. &gt; &gt;newman:(to elaine) you think i have no idea of this… &gt; &gt;elaine: oh, you better take the phone, and he was a little nervous. &gt; &gt;kramer:(to the phone) hey, hey, jerry, i don't want to be a little bit.(to kramer and jerry) you can't. &gt; &gt;jerry: oh, yeah. i don't even know, i know. &gt; &gt;jerry:(to the phone) oh, i know. &gt; &gt;kramer:(laughing) you know…(to jerry) you don't know.</p>
<p>You can see that there are multiple characters that say (somewhat) complete sentences, but it doesn't have to be perfect! It takes quite a while to get good results, and often, you'll have to use a smaller vocabulary (and discard uncommon words), or get more data. The Seinfeld dataset is about 3.4 MB, which is big enough for our purposes; for script generation you'll want more than 1 MB of text, generally.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org59f319b">
<h3 id="org59f319b">Submitting This Project</h3>
<div class="outline-text-3" id="text-org59f319b">
<p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_tv_script_generation.ipynb" and save another copy as an HTML file by clicking "File" -&gt; "Download as.."-&gt;"html". Include the "helper.py" and "problem_unittests.py" files in your submission. Once you download these files, compress them into one zip file for submission.</p>
</div>
</div>
</div>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/more-links/">More Links</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/more-links/" rel="bookmark"><time class="published dt-published" datetime="2019-01-30T21:47:39-08:00" itemprop="datePublished" title="2019-01-30 21:47">2019-01-30 21:47</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/more-links/#org45515a2">Finding Projects</a></li>
<li><a href="posts/more-links/#orgb7f0ae8">Style</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org45515a2">
<h2 id="org45515a2">Finding Projects</h2>
<div class="outline-text-2" id="text-org45515a2">
<ul class="org-ul">
<li><a href="https://openhatch.org/">open hatch</a></li>
<li><a href="https://www.freecodecamp.org/">free code camp</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgb7f0ae8">
<h2 id="orgb7f0ae8">Style</h2>
<div class="outline-text-2" id="text-orgb7f0ae8">
<ul class="org-ul">
<li><a href="https://udacity.github.io/git-styleguide/">Udacity Commit Style Guide</a></li>
</ul>
</div>
</div>
</div>
</article>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-9.html" rel="prev">Newer posts</a></li>
<li class="next"><a href="index-7.html" rel="next">Older posts</a></li>
</ul>
<!--End of body content-->
<footer id="footer">Contents © 2019 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> </div>
</div>
</div>
</div>
</div>
</article>
</div>
</div>
</div>
</body>
</html>
