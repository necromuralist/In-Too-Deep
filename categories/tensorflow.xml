<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>In Too Deep (Posts about tensorflow)</title><link>https://necromuralist.github.io/In-Too-Deep/</link><description></description><atom:link href="https://necromuralist.github.io/In-Too-Deep/categories/tensorflow.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2020 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sun, 02 Feb 2020 02:26:32 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>IMDB Reviews Tensorflow Dataset</title><link>https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org858cad4"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org37964d8"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org14d7452"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orge7f4b53"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orgc8669c8"&gt;Graeae&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orge4e6fa6"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org7d26401"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org973ffb3"&gt;Timer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org0967f83"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org5e22d38"&gt;Get the Dataset&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org0ebb0c7"&gt;Load It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orgaca3d2c"&gt;Split It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orgfd0a13e"&gt;The Tokenizer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org2df599a"&gt;Set Up Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orgddcd230"&gt;The Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org32384d7"&gt;Compile It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orgfc3e3a0"&gt;Train It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#orgf1f4cb8"&gt;Plot the Performance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org024af60"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/#org81e5eab"&gt;Citation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org858cad4" class="outline-2"&gt;
&lt;h2 id="org858cad4"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org858cad4"&gt;
&lt;p&gt;
We're going to use the &lt;a href="https://www.tensorflow.org/datasets/catalog/imdb_reviews"&gt;IMDB Reviews Dataset&lt;/a&gt; (used in &lt;a href="https://www.tensorflow.org/tutorials/keras/basic_text_classification"&gt;this tutorial&lt;/a&gt;) - a set of 50,000 movie reviews taken from the &lt;a href="https://www.imdb.com/"&gt;Internet Movie Database&lt;/a&gt; that have been classified as either positive or negative. It looks like the original source is from a page on Stanford University's web sight title &lt;a href="http://ai.stanford.edu/~amaas/data/sentiment/"&gt;Large Movie Review Dataset&lt;/a&gt;. The dataset seems to be widely available (the Stanford page and &lt;a href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"&gt;Kaggle&lt;/a&gt; for instance) but this will serve as practice for using tensorflow datasets as well.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org37964d8" class="outline-3"&gt;
&lt;h3 id="org37964d8"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org37964d8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org14d7452" class="outline-4"&gt;
&lt;h4 id="org14d7452"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org14d7452"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge7f4b53" class="outline-4"&gt;
&lt;h4 id="orge7f4b53"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge7f4b53"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hvplot.pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow_datasets&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc8669c8" class="outline-4"&gt;
&lt;h4 id="orgc8669c8"&gt;Graeae&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc8669c8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graeae&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge4e6fa6" class="outline-3"&gt;
&lt;h3 id="orge4e6fa6"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge4e6fa6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7d26401" class="outline-4"&gt;
&lt;h4 id="org7d26401"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7d26401"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"imdb-reviews-tensorflow-dataset"&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;folder_path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/keras/&lt;/span&gt;&lt;span class="si"&gt;{SLUG}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org973ffb3" class="outline-4"&gt;
&lt;h4 id="org973ffb3"&gt;Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org973ffb3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TIMER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0967f83" class="outline-2"&gt;
&lt;h2 id="org0967f83"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0967f83"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5e22d38" class="outline-3"&gt;
&lt;h3 id="org5e22d38"&gt;Get the Dataset&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5e22d38"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ebb0c7" class="outline-4"&gt;
&lt;h4 id="org0ebb0c7"&gt;Load It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0ebb0c7"&gt;
&lt;p&gt;
The &lt;a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/load"&gt;load&lt;/a&gt; function takes quite a few parameters, in this case we're just passing in three - the name of the dataset, &lt;code&gt;with_info&lt;/code&gt; which tells it to return both a &lt;a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset"&gt;Dataset&lt;/a&gt; and a &lt;a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetInfo"&gt;DatasetInfo&lt;/a&gt; object, and &lt;code&gt;as_supervised&lt;/code&gt;, which tells the builder to return the &lt;code&gt;Dataset&lt;/code&gt; as a series of &lt;code&gt;(input, label)&lt;/code&gt; tuples.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow_datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'imdb_reviews/subwords8k'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
					 &lt;span class="n"&gt;with_info&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
					 &lt;span class="n"&gt;as_supervised&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaca3d2c" class="outline-4"&gt;
&lt;h4 id="orgaca3d2c"&gt;Split It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgaca3d2c"&gt;
&lt;p&gt;
The &lt;code&gt;dataset&lt;/code&gt; is a dict with three keys:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
dict_keys(['test', 'train', 'unsupervised'])
&lt;/pre&gt;


&lt;p&gt;
As you might guess, we don't use the &lt;code&gt;unsupervised&lt;/code&gt; key.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfd0a13e" class="outline-4"&gt;
&lt;h4 id="orgfd0a13e"&gt;The Tokenizer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfd0a13e"&gt;
&lt;p&gt;
One of the advantages of using the tensorflow dataset version of this is that it comes with a pre-built tokenizer inside the DatasetInfo object.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=&amp;lt;SubwordTextEncoder vocab_size=8185&amp;gt;),
})
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'text'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoder&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;lt;SubwordTextEncoder vocab_size=8185&amp;gt;
&lt;/pre&gt;


&lt;p&gt;
The &lt;code&gt;tokenizer&lt;/code&gt; is a &lt;a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/SubwordTextEncoder"&gt;SubwordTextEncoder&lt;/a&gt; with a vocabulary size of 8,185.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2df599a" class="outline-4"&gt;
&lt;h4 id="org2df599a"&gt;Set Up Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2df599a"&gt;
&lt;p&gt;
We're going to shuffle the training data and then add padding to both sets so theyre all the same size.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BUFFER_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20000&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BUFFER_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_shapes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_shapes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgddcd230" class="outline-3"&gt;
&lt;h3 id="orgddcd230"&gt;The Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgddcd230"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Bidirectional&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
    &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;tensorflow&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'sigmoid'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 64)          523840    
_________________________________________________________________
bidirectional (Bidirectional (None, 128)               66048     
_________________________________________________________________
dense (Dense)                (None, 64)                8256      
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 65        
=================================================================
Total params: 598,209
Trainable params: 598,209
Non-trainable params: 0
_________________________________________________________________
&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org32384d7" class="outline-4"&gt;
&lt;h4 id="org32384d7"&gt;Compile It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org32384d7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'binary_crossentropy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	      &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'adam'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	      &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'accuracy'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgfc3e3a0" class="outline-4"&gt;
&lt;h4 id="orgfc3e3a0"&gt;Train It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfc3e3a0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;SILENT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;ONCE_PER_EPOCH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			&lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			&lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ONCE_PER_EPOCH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2019-09-21 15:52:50,469 graeae.timers.timer start: Started: 2019-09-21 15:52:50.469787
I0921 15:52:50.469841 140086305412928 timer.py:70] Started: 2019-09-21 15:52:50.469787
Epoch 1/10
391/391 - 80s - loss: 0.3991 - accuracy: 0.8377 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00
Epoch 2/10
391/391 - 80s - loss: 0.3689 - accuracy: 0.8571 - val_loss: 0.4595 - val_accuracy: 0.8021
Epoch 3/10
391/391 - 80s - loss: 0.3664 - accuracy: 0.8444 - val_loss: 0.5262 - val_accuracy: 0.7228
Epoch 4/10
391/391 - 80s - loss: 0.5611 - accuracy: 0.7133 - val_loss: 0.6832 - val_accuracy: 0.6762
Epoch 5/10
391/391 - 80s - loss: 0.6151 - accuracy: 0.6597 - val_loss: 0.5164 - val_accuracy: 0.7844
Epoch 6/10
391/391 - 80s - loss: 0.3842 - accuracy: 0.8340 - val_loss: 0.4970 - val_accuracy: 0.7996
Epoch 7/10
391/391 - 80s - loss: 0.2449 - accuracy: 0.9058 - val_loss: 0.3639 - val_accuracy: 0.8463
Epoch 8/10
391/391 - 80s - loss: 0.1896 - accuracy: 0.9306 - val_loss: 0.3698 - val_accuracy: 0.8614
Epoch 9/10
391/391 - 80s - loss: 0.1555 - accuracy: 0.9456 - val_loss: 0.3896 - val_accuracy: 0.8535
Epoch 10/10
391/391 - 80s - loss: 0.1195 - accuracy: 0.9606 - val_loss: 0.4878 - val_accuracy: 0.8428
2019-09-21 16:06:09,935 graeae.timers.timer end: Ended: 2019-09-21 16:06:09.935707
I0921 16:06:09.935745 140086305412928 timer.py:77] Ended: 2019-09-21 16:06:09.935707
2019-09-21 16:06:09,938 graeae.timers.timer end: Elapsed: 0:13:19.465920
I0921 16:06:09.938812 140086305412928 timer.py:78] Elapsed: 0:13:19.465920
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf1f4cb8" class="outline-4"&gt;
&lt;h4 id="orgf1f4cb8"&gt;Plot the Performance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf1f4cb8"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;b&gt;&lt;b&gt;Note&lt;/b&gt;&lt;/b&gt;: This only works if your kernel is on the local machine, running it remotely gives an error, as it tries to save it on the remote machine.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;history&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"loss"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Training Loss"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="s2"&gt;"accuracy"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Training Accuracy"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="s2"&gt;"val_loss"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Validation Loss"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="s2"&gt;"val_accuracy"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Validation Accuracy"&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hvplot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"LSTM IMDB Performance"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;800&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"model_performance"&lt;/span&gt;&lt;span class="p"&gt;)()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/model_performance.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
It looks like I over-trained it, as the loss is getting high. (Also note that I used this notebook to troubleshoot so there was actually one extra epoch that isn't shown).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org024af60" class="outline-2"&gt;
&lt;h2 id="org024af60"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org024af60"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org81e5eab" class="outline-3"&gt;
&lt;h3 id="org81e5eab"&gt;Citation&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org81e5eab"&gt;
&lt;p&gt;
This is the paper where the dataset was originally used.
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>nlp</category><category>sentiment</category><category>tensorflow</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/keras/imdb-reviews-tensorflow-dataset/</guid><pubDate>Mon, 09 Sep 2019 23:24:46 GMT</pubDate></item><item><title>Horse Or Human Using TensorFlow 2.0</title><link>https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orgd1888ae"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org4c99c41"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org4a22255"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org81ce7c2"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orgb4063be"&gt;Graeae&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org3f10b71"&gt;Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org842ab27"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org6436490"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org3a3143a"&gt;Storage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org99b6c91"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orge08cf23"&gt;The Data Set&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org68924fb"&gt;The Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org6201b7d"&gt;Create the Output Layers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org9273b01"&gt;Compile the Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org4246026"&gt;Train the Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org346c4e4"&gt;A Model Saver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orgbb3baba"&gt;A good Enough Callback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org777904a"&gt;A Data Generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org2c4874c"&gt;A Model Builder&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orgf842d3e"&gt;Train It&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org96b2ce9"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org68bfcd1"&gt;Sources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org6c738b1"&gt;Raw&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#org1275424"&gt;Testing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orgc90f241"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/#orgec40c44"&gt;Sources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd1888ae" class="outline-2"&gt;
&lt;h2 id="orgd1888ae"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd1888ae"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4c99c41" class="outline-3"&gt;
&lt;h3 id="org4c99c41"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4c99c41"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4a22255" class="outline-4"&gt;
&lt;h4 id="org4a22255"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4a22255"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from functools import partial
from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org81ce7c2" class="outline-4"&gt;
&lt;h4 id="org81ce7c2"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org81ce7c2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from holoviews.operation.datashader import datashade
from tensorflow.keras.models import load_model
from tensorflow.keras import layers
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import cv2
import holoviews
import hvplot.pandas
import matplotlib.pyplot as pyplot
import numpy
import pandas
import tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb4063be" class="outline-4"&gt;
&lt;h4 id="orgb4063be"&gt;Graeae&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb4063be"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import EmbedHoloviews, Timer, ZipDownloader
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3f10b71" class="outline-3"&gt;
&lt;h3 id="org3f10b71"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3f10b71"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org842ab27" class="outline-4"&gt;
&lt;h4 id="org842ab27"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org842ab27"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6436490" class="outline-4"&gt;
&lt;h4 id="org6436490"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6436490"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Embed = partial(
    EmbedHoloviews,
    folder_path="../../files/posts/keras/horse-or-human-using-tensorflow-20")
holoviews.extension("bokeh")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3a3143a" class="outline-4"&gt;
&lt;h4 id="org3a3143a"&gt;Storage&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3a3143a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;MODELS = Path("~/models/horses-vs-humans/").expanduser()
if not MODELS.is_dir():
    MODELS.mkdir()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org99b6c91" class="outline-2"&gt;
&lt;h2 id="org99b6c91"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org99b6c91"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge08cf23" class="outline-3"&gt;
&lt;h3 id="orge08cf23"&gt;The Data Set&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge08cf23"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;OUTPUT = "~/data/datasets/images/horse-or-human/training/"
URL = ("https://storage.googleapis.com/"
       "laurencemoroney-blog.appspot.com/"
       "horse-or-human.zip")

download = ZipDownloader(url=URL, target=OUTPUT)
download()
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Files exist, not downloading
&lt;/pre&gt;

&lt;p&gt;
:RESULTS:
&lt;/p&gt;
&lt;pre class="example"&gt;
2019-08-13 13:51:57,970 [1mZipDownloader[0m start: ([1mZipDownloader[0m) Started: 2019-08-13 13:51:57.970533
2019-08-13 13:51:57,972 [1mZipDownloader[0m download: Downloading the zip file
2019-08-13 13:52:08,157 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Ended: 2019-08-13 13:52:08.157484
2019-08-13 13:52:08,159 [1mZipDownloader[0m end: ([1mZipDownloader[0m) Elapsed: 0:00:10.186951
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output_path = download.target
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The convention for training models for computer vision appears to be that you use the folder names to label the contents of the images within them. In this case we have &lt;code&gt;horses&lt;/code&gt; and &lt;code&gt;humans&lt;/code&gt;.
&lt;/p&gt;

&lt;p&gt;
Here's what some of the files themselves are named.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;horses_path = output_path/"horses"
humans_path = output_path/"humans"

for path in (horses_path, humans_path):
    print(path.name)
    for index, image in enumerate(path.iterdir()):
	print(f"File: {image.name}")
	if index == 9:
	    break
    print()
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
horses
File: horse48-5.png
File: horse45-8.png
File: horse13-5.png
File: horse34-4.png
File: horse46-5.png
File: horse02-3.png
File: horse06-3.png
File: horse32-1.png
File: horse25-3.png
File: horse04-3.png

humans
File: human01-07.png
File: human02-11.png
File: human13-07.png
File: human10-10.png
File: human15-06.png
File: human05-15.png
File: human06-18.png
File: human16-28.png
File: human02-24.png
File: human10-05.png
&lt;/pre&gt;

&lt;p&gt;
So, in this case you can tell what they are from the file-names as well. How many images are there?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;horse_files = list(horses_path.iterdir())
human_files = list(humans_path.iterdir())
print(f"Horse Images: {len(horse_files)}")
print(f"Human Images: {len(human_files)}")
print(f"Image Shape: {pyplot.imread(str(horse_files[0])).shape}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Horse Images: 500
Human Images: 527
Image Shape: (300, 300, 4)
&lt;/pre&gt;


&lt;p&gt;
This is sort of a small data-set, and it's odd that there are more humans than horses. Let's see what some of them look like. I'm assuming all the files have the same shape. In this case it looks like they are 300 x 300 with four channels (RGB and alpha?).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;height = width = 300
count = 4
columns = 2
horse_plots = [datashade(holoviews.RGB.load_image(str(horse)).opts(
    height=height,
    width=width,
))
	       for horse in horse_files[:count]]
human_plots = [datashade(holoviews.RGB.load_image(str(human))).opts(
    height=height,
    width=width,
)
	       for human in human_files[:count]]

plot = holoviews.Layout(horse_plots + human_plots).cols(2).opts(
    title="Horses and Humans")
Embed(plot=plot, file_name="horses_and_humans", 
      height_in_pixels=900)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/horses_and_humans.html" style="width:100%" height="900"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
As you can see, the people in the images aren't really humans (and it may not be so obvious, but they aren't horses either), these are computer-generated images.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org68924fb" class="outline-3"&gt;
&lt;h3 id="org68924fb"&gt;The Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org68924fb"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;input_shape = (300, 300, 3)
base_model = InceptionV3(input_shape=input_shape, include_top=False)
base_model.trainable = False
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(base_model.summary())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Model: "inception_v3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               
                                                                 activation_7[0][0]               
                                                                 activation_10[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              
                                                                 activation_14[0][0]              
                                                                 activation_17[0][0]              
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              
                                                                 activation_21[0][0]              
                                                                 activation_24[0][0]              
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              
                                                                 activation_29[0][0]              
                                                                 max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              
                                                                 activation_33[0][0]              
                                                                 activation_38[0][0]              
                                                                 activation_39[0][0]              
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              
                                                                 activation_43[0][0]              
                                                                 activation_48[0][0]              
                                                                 activation_49[0][0]              
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              
                                                                 activation_53[0][0]              
                                                                 activation_58[0][0]              
                                                                 activation_59[0][0]              
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              
                                                                 activation_63[0][0]              
                                                                 activation_68[0][0]              
                                                                 activation_69[0][0]              
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              
                                                                 activation_75[0][0]              
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              
                                                                 activation_79[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              
                                                                 activation_83[0][0]              
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              
                                                                 mixed9_0[0][0]                   
                                                                 concatenate[0][0]                
                                                                 activation_84[0][0]              
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              
                                                                 activation_88[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              
                                                                 activation_92[0][0]              
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_1[0][0]              
                                                                 activation_93[0][0]              
==================================================================================================
Total params: 21,802,784
Trainable params: 0
Non-trainable params: 21,802,784
__________________________________________________________________________________________________
None
&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6201b7d" class="outline-4"&gt;
&lt;h4 id="org6201b7d"&gt;Create the Output Layers&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6201b7d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x = layers.GlobalAveragePooling2D()(base_model.output)
x = layers.Dense(1024, activation="relu")(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(1, activation="sigmoid")(x)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now build the model combining the pre-built layer with a Dense layer (that we're going to train). Since we only have two classes the activation function is the &lt;i&gt;sigmoid&lt;/i&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = tensorflow.keras.Model(
    base_model.input,
    x,
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9273b01" class="outline-3"&gt;
&lt;h3 id="org9273b01"&gt;Compile the Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9273b01"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model.compile(optimizer = RMSprop(lr=0.0001), 
	      loss = 'binary_crossentropy', 
	      metrics = ['acc'])
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4246026" class="outline-3"&gt;
&lt;h3 id="org4246026"&gt;Train the Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4246026"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org346c4e4" class="outline-4"&gt;
&lt;h4 id="org346c4e4"&gt;A Model Saver&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org346c4e4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;best_model = MODELS/"inception_transfer.hdf5"
checkpoint = tensorflow.keras.callbacks.ModelCheckpoint(
    str(best_model), monitor="val_acc", verbose=1, 
    save_best_only=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbb3baba" class="outline-4"&gt;
&lt;h4 id="orgbb3baba"&gt;A good Enough Callback&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgbb3baba"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class GoodEnough(tensorflow.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if logs.get('acc') &amp;gt; 0.999:
      print("\nReached 99.9% accuracy so cancelling training!")
      self.model.stop_training = True
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org777904a" class="outline-4"&gt;
&lt;h4 id="org777904a"&gt;A Data Generator&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org777904a"&gt;
&lt;p&gt;
This bundles up the steps to build the data generator.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Data:
    """creates the data generators

    Args:
     path: path to the images
     validation_split: fraction that goes to the validation set
     batch_size: size for the batches in the epochs
    """
    def __init__(self, path: str, validation_split: float=0.2,
		 batch_size: int=20) -&amp;gt; None:
	self.path = path
	self.validation_split = validation_split
	self.batch_size = batch_size
	self._data_generator = None
	self._testing_data_generator = None
	self._training_generator = None
	self._validation_generator = None
	return

    @property
    def data_generator(self) -&amp;gt; ImageDataGenerator:
	"""The data generator for training and validation"""
	if self._data_generator is None:
	    self._data_generator = ImageDataGenerator(
		rescale=1/255,
		rotation_range=40,
		width_shift_range=0.2,
		height_shift_range=0.2,
		horizontal_flip=True,
		shear_range=0.2,
		zoom_range=0.2,
		fill_mode="nearest",
		validation_split=self.validation_split)
	return self._data_generator

    @property
    def training_generator(self):
	"""The training data generator"""
	if self._training_generator is None:
	    self._training_generator = (self.data_generator
					.flow_from_directory)(
					    self.path,
					    batch_size=self.batch_size,
					    class_mode="binary",
					    target_size=(300, 300),
					    subset="training",
	    )
	return self._training_generator

    @property
    def validation_generator(self):
	"""the validation data generator"""
	if self._validation_generator is None:
	    self._validation_generator = (self.data_generator
					  .flow_from_directory)(
					      self.path,
					      batch_size=self.batch_size,
					      class_mode="binary",
					      target_size = (300, 300),
					      subset="validation",
	    )
	return self._validation_generator

    def __str__(self) -&amp;gt; str:
	return (f"(Data) - Path: {self.path}, "
		f"Validation Split: {self.validation_split},"
		f"Batch Size: {self.batch_size}")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2c4874c" class="outline-4"&gt;
&lt;h4 id="org2c4874c"&gt;A Model Builder&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2c4874c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Network:
    """The model to categorize the images

    Args:
     model: model to train
     path: path to the training data
     epochs: number of epochs to train
     batch_size: size of the batches for each epoch
     convolution_layers: layers of cnn/max-pooling
     callbacks: things to stop the training
     set_steps: whether to set the training steps-per-epoch
    """
    def __init__(self, model, path: str, epochs: int=15,
		 batch_size: int=128, convolution_layers: int=3,
		 set_steps: bool=True,
		 callbacks: list=None) -&amp;gt; None:
	self.model = model
	self.path = path
	self.epochs = epochs
	self.batch_size = batch_size
	self.convolution_layers = convolution_layers
	self.set_steps = set_steps
	self.callbacks = callbacks
	self._data = None
	self._model = None
	self.history = None
	return

    @property
    def data(self) -&amp;gt; Data:
	"""The data generator builder"""
	if self._data is None:
	    self._data = Data(self.path, batch_size=self.batch_size)
	return self._data

    def summary(self) -&amp;gt; None:
	"""Prints the model summary"""
	print(self.model.summary())
	return

    def train(self) -&amp;gt; None:
	"""Trains the model"""
	callbacks = self.callbacks if self.callbacks else []
	arguments = dict(
	    generator=self.data.training_generator,
	    validation_data=self.data.validation_generator,
	    epochs = self.epochs,
	    callbacks = callbacks,
	    verbose=2,
	)
	if self.set_steps:
	    arguments["steps_per_epoch"] = int(
		self.data.training_generator.samples/self.batch_size)
	    arguments["validation_steps"] = int(
		self.data.validation_generator.samples/self.batch_size)

	self.history = self.model.fit_generator(**arguments)
	return

    def __str__(self) -&amp;gt; str:
	return (f"(Network) - \nPath: {self.path}\n Epochs: {self.epochs}\n "
		f"Batch Size: {self.batch_size}\n Callbacks: {self.callbacks}\n"
		f"Data: {self.data}\n"
		f"Callbacks: {self.callbacks}")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf842d3e" class="outline-3"&gt;
&lt;h3 id="orgf842d3e"&gt;Train It&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf842d3e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;good_enough = GoodEnough()
network = Network(model, Path(OUTPUT).expanduser(), 
		  set_steps = True,
		  epochs = 40,
		  callbacks=[checkpoint, good_enough],
		  batch_size=1)
with TIMER:
    network.train()
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2019-08-03 19:28:04,102 graeae.timers.timer start: Started: 2019-08-03 19:28:04.102954
I0803 19:28:04.102986 139918777980736 timer.py:70] Started: 2019-08-03 19:28:04.102954
Found 20000 images belonging to 2 classes.
Found 5000 images belonging to 2 classes.
Epoch 1/10

Epoch 00001: val_acc improved from -inf to 0.43660, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 615s - loss: 0.7032 - acc: 0.4977 - val_loss: 0.8069 - val_acc: 0.4366
Epoch 2/10

Epoch 00002: val_acc improved from 0.43660 to 0.43780, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 631s - loss: 0.6933 - acc: 0.5049 - val_loss: 0.7958 - val_acc: 0.4378
Epoch 3/10

Epoch 00003: val_acc did not improve from 0.43780
20000/20000 - 670s - loss: 0.6932 - acc: 0.4990 - val_loss: 0.8142 - val_acc: 0.4230
Epoch 4/10

Epoch 00004: val_acc improved from 0.43780 to 0.45020, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 666s - loss: 0.6932 - acc: 0.4990 - val_loss: 0.7856 - val_acc: 0.4502
Epoch 5/10

Epoch 00005: val_acc did not improve from 0.45020
20000/20000 - 636s - loss: 0.6932 - acc: 0.4983 - val_loss: 0.7982 - val_acc: 0.4312
Epoch 6/10

Epoch 00006: val_acc did not improve from 0.45020
20000/20000 - 618s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.8018 - val_acc: 0.4326
Epoch 7/10

Epoch 00007: val_acc did not improve from 0.45020
20000/20000 - 614s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.7870 - val_acc: 0.4484
Epoch 8/10

Epoch 00008: val_acc improved from 0.45020 to 0.45660, saving model to /home/athena/models/dogs-vs-cats/inception_transfer.hdf5
20000/20000 - 607s - loss: 0.6932 - acc: 0.4981 - val_loss: 0.7773 - val_acc: 0.4566
Epoch 9/10

Epoch 00009: val_acc did not improve from 0.45660
20000/20000 - 608s - loss: 0.6932 - acc: 0.4891 - val_loss: 0.7811 - val_acc: 0.4414
Epoch 10/10

Epoch 00010: val_acc did not improve from 0.45660
20000/20000 - 619s - loss: 0.6932 - acc: 0.5010 - val_loss: 0.7878 - val_acc: 0.4474
2019-08-03 21:12:49,142 graeae.timers.timer end: Ended: 2019-08-03 21:12:49.142478
I0803 21:12:49.142507 139918777980736 timer.py:77] Ended: 2019-08-03 21:12:49.142478
2019-08-03 21:12:49,143 graeae.timers.timer end: Elapsed: 1:44:45.039524
I0803 21:12:49.143225 139918777980736 timer.py:78] Elapsed: 1:44:45.039524
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org96b2ce9" class="outline-2"&gt;
&lt;h2 id="org96b2ce9"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org96b2ce9"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org68bfcd1" class="outline-3"&gt;
&lt;h3 id="org68bfcd1"&gt;Sources&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org68bfcd1"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#horses_or_humans"&gt;Horses Or Humans Dataset&lt;/a&gt;. Moroney Laurence. Feb 2019. url: &lt;a href="http://laurencemoroney.com/horses-or-humans-dataset"&gt;http://laurencemoroney.com/horses-or-humans-dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6c738b1" class="outline-2"&gt;
&lt;h2 id="org6c738b1"&gt;Raw&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6c738b1"&gt;
&lt;p&gt;
#+begin_comment
import os
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import Model
&amp;gt;
&lt;/p&gt;

&lt;p&gt;
Epoch 00002: val_acc improved from 0.88780 to 0.89268, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 61s - loss: 0.7190 - acc: 0.5255 - val_loss: 0.5419 - val_acc: 0.8927
Epoch 3/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00003: val_acc improved from 0.89268 to 0.92195, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 61s - loss: 0.7102 - acc: 0.5170 - val_loss: 0.5290 - val_acc: 0.9220
Epoch 4/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00004: val_acc did not improve from 0.92195
822/822 - 60s - loss: 0.7103 - acc: 0.5097 - val_loss: 0.5357 - val_acc: 0.8146
Epoch 5/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00005: val_acc did not improve from 0.92195
822/822 - 60s - loss: 0.7051 - acc: 0.5012 - val_loss: 0.5330 - val_acc: 0.6780
Epoch 6/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00006: val_acc did not improve from 0.92195
822/822 - 64s - loss: 0.7006 - acc: 0.5012 - val_loss: 0.5969 - val_acc: 0.5317
Epoch 7/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00007: val_acc did not improve from 0.92195
822/822 - 63s - loss: 0.7009 - acc: 0.5109 - val_loss: 0.5356 - val_acc: 0.9122
Epoch 8/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00008: val_acc did not improve from 0.92195
822/822 - 62s - loss: 0.7025 - acc: 0.4878 - val_loss: 0.5103 - val_acc: 0.9073
Epoch 9/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00009: val_acc did not improve from 0.92195
822/822 - 60s - loss: 0.6972 - acc: 0.5207 - val_loss: 0.5321 - val_acc: 0.7561
Epoch 10/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00010: val_acc did not improve from 0.92195
822/822 - 61s - loss: 0.6946 - acc: 0.5316 - val_loss: 0.5102 - val_acc: 0.9220
Epoch 11/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00011: val_acc did not improve from 0.92195
822/822 - 62s - loss: 0.6966 - acc: 0.5365 - val_loss: 0.5149 - val_acc: 0.8488
Epoch 12/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00012: val_acc did not improve from 0.92195
822/822 - 62s - loss: 0.6981 - acc: 0.5073 - val_loss: 0.5266 - val_acc: 0.8293
Epoch 13/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00013: val_acc did not improve from 0.92195
822/822 - 62s - loss: 0.6949 - acc: 0.5182 - val_loss: 0.5046 - val_acc: 0.8780
Epoch 14/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00014: val_acc improved from 0.92195 to 0.95122, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 62s - loss: 0.6957 - acc: 0.5170 - val_loss: 0.4872 - val_acc: 0.9512
Epoch 15/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00015: val_acc did not improve from 0.95122
822/822 - 61s - loss: 0.6944 - acc: 0.5049 - val_loss: 0.4904 - val_acc: 0.9366
Epoch 16/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00016: val_acc did not improve from 0.95122
822/822 - 60s - loss: 0.6920 - acc: 0.5158 - val_loss: 0.5201 - val_acc: 0.7463
Epoch 17/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00017: val_acc did not improve from 0.95122
822/822 - 60s - loss: 0.6951 - acc: 0.4988 - val_loss: 0.4872 - val_acc: 0.8488
Epoch 18/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00018: val_acc improved from 0.95122 to 0.97073, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 61s - loss: 0.6927 - acc: 0.5377 - val_loss: 0.4889 - val_acc: 0.9707
Epoch 19/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00019: val_acc did not improve from 0.97073
822/822 - 63s - loss: 0.6900 - acc: 0.5255 - val_loss: 0.4912 - val_acc: 0.7854
Epoch 20/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00020: val_acc did not improve from 0.97073
822/822 - 64s - loss: 0.6927 - acc: 0.5243 - val_loss: 0.4651 - val_acc: 0.8878
Epoch 21/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00021: val_acc did not improve from 0.97073
822/822 - 64s - loss: 0.6914 - acc: 0.5304 - val_loss: 0.4368 - val_acc: 0.9659
Epoch 22/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00022: val_acc improved from 0.97073 to 0.97561, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 65s - loss: 0.6881 - acc: 0.5341 - val_loss: 0.4350 - val_acc: 0.9756
Epoch 23/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00023: val_acc did not improve from 0.97561
822/822 - 62s - loss: 0.6914 - acc: 0.5401 - val_loss: 0.4421 - val_acc: 0.8439
Epoch 24/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00024: val_acc improved from 0.97561 to 0.99024, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 61s - loss: 0.6887 - acc: 0.5511 - val_loss: 0.3974 - val_acc: 0.9902
Epoch 25/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00025: val_acc did not improve from 0.99024
822/822 - 62s - loss: 0.6855 - acc: 0.5535 - val_loss: 0.3716 - val_acc: 0.9902
Epoch 26/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00026: val_acc did not improve from 0.99024
822/822 - 63s - loss: 0.6865 - acc: 0.5389 - val_loss: 0.3736 - val_acc: 0.9610
Epoch 27/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00027: val_acc did not improve from 0.99024
822/822 - 60s - loss: 0.6823 - acc: 0.5718 - val_loss: 0.3799 - val_acc: 0.9220
Epoch 28/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00028: val_acc did not improve from 0.99024
822/822 - 61s - loss: 0.6875 - acc: 0.5474 - val_loss: 0.3530 - val_acc: 0.9902
Epoch 29/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00029: val_acc did not improve from 0.99024
822/822 - 60s - loss: 0.6881 - acc: 0.5487 - val_loss: 0.3376 - val_acc: 0.9902
Epoch 30/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00030: val_acc did not improve from 0.99024
822/822 - 62s - loss: 0.6857 - acc: 0.5462 - val_loss: 0.3216 - val_acc: 0.9707
Epoch 31/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00031: val_acc did not improve from 0.99024
822/822 - 62s - loss: 0.6847 - acc: 0.5450 - val_loss: 0.3025 - val_acc: 0.9902
Epoch 32/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00032: val_acc improved from 0.99024 to 0.99512, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 64s - loss: 0.6821 - acc: 0.5535 - val_loss: 0.2852 - val_acc: 0.9951
Epoch 33/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00033: val_acc did not improve from 0.99512
822/822 - 62s - loss: 0.6793 - acc: 0.5669 - val_loss: 0.2617 - val_acc: 0.9854
Epoch 34/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00034: val_acc did not improve from 0.99512
822/822 - 60s - loss: 0.6772 - acc: 0.5937 - val_loss: 0.2565 - val_acc: 0.9707
Epoch 35/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00035: val_acc did not improve from 0.99512
822/822 - 61s - loss: 0.6766 - acc: 0.5803 - val_loss: 0.2190 - val_acc: 0.9951
Epoch 36/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00036: val_acc did not improve from 0.99512
822/822 - 63s - loss: 0.6726 - acc: 0.5937 - val_loss: 0.2423 - val_acc: 0.9463
Epoch 37/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00037: val_acc did not improve from 0.99512
822/822 - 61s - loss: 0.6735 - acc: 0.5669 - val_loss: 0.2106 - val_acc: 0.9902
Epoch 38/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00038: val_acc improved from 0.99512 to 1.00000, saving model to /home/athena/models/horses-vs-humans/inception_transfer.hdf5
822/822 - 61s - loss: 0.6718 - acc: 0.5949 - val_loss: 0.1868 - val_acc: 1.0000
Epoch 39/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00039: val_acc did not improve from 1.00000
822/822 - 60s - loss: 0.6647 - acc: 0.6119 - val_loss: 0.2140 - val_acc: 0.9610
Epoch 40/40
&lt;/p&gt;

&lt;p&gt;
Epoch 00040: val_acc did not improve from 1.00000
822/822 - 60s - loss: 0.6671 - acc: 0.5815 - val_loss: 0.1823 - val_acc: 0.9707
2019-08-18 14:37:14,814 graeae.timers.timer end: Ended: 2019-08-18 14:37:14.814322
I0818 14:37:14.814355 139914340390720 timer.py:77] Ended: 2019-08-18 14:37:14.814322
2019-08-18 14:37:14,815 graeae.timers.timer end: Elapsed: 0:41:03.671258
I0818 14:37:14.815070 139914340390720 timer.py:78] Elapsed: 0:41:03.671258
#+end_example
&lt;/p&gt;

&lt;p&gt;
So, we got 100% accuracyâ¦ that seems to be an overfitting. Also, why didn't the callback stop it? On further inspection I noticed that the training accuracy never gets to 100%, while the validation accuracy doesâ¦ that seems odd.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;history_ = pandas.DataFrame.from_dict(model.history.history)
history = history_.rename(columns={"loss": "Training Loss",
				   "acc": "Training Accuracy",
				   "val_loss": "Validation Loss",
				   "val_acc": "Validation Accuracy"})
plot = history.hvplot().opts(
    title="Loss and Accuracy of the Horses Vs Humans Model",
    height=800,
    width=1000,
)
Embed(plot=plot, file_name="model_history")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/model_history.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
So this is a little weird - should Validation Accuracy start out that high? Maybe, since the original network is pre-trainedâ¦ And why does the Validation Loss improve faster than the Training Loss?
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1275424" class="outline-3"&gt;
&lt;h3 id="org1275424"&gt;Testing&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1275424"&gt;
&lt;p&gt;
I don't remember downloading this, but there's a separate folder called "validation" which I'm assuming has a different set of image files.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = load_model(best_model)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;target_size = (300, 300)
def predict(model, filename):
    loaded = cv2.imread(str(filename))
    x = cv2.resize(loaded, target_size)/255
    x = numpy.reshape(x, (1, 300, 300, 3))
    return model.predict(x)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/images/horse-or-human/validation/").expanduser()
target_size = (300, 300)
correct = 0
for index, filename in enumerate((path/"horses").iterdir()):
    prediction = predict(model, filename)
    correct += 0 if prediction[0] &amp;gt; 0.5 else 1
print(f"Fraction of horses correctly classified: {correct/(index + 1):.2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Fraction of horses correctly classified: 0.99
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;correct = 0
for index, filename in enumerate((path/"humans").iterdir()):
    prediction = predict(model, filename)
    correct += 1 if prediction[0] &amp;gt; 0.5 else 0
print(f"Fraction of humans correctly classified: {correct/(index + 1):.2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Fraction of humans correctly classified: 1.00
&lt;/pre&gt;


&lt;p&gt;
The testing images are slightly different in that they are on a white background, rather than a simulated background.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc90f241" class="outline-2"&gt;
&lt;h2 id="orgc90f241"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc90f241"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgec40c44" class="outline-3"&gt;
&lt;h3 id="orgec40c44"&gt;Sources&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgec40c44"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#horses_or_humans"&gt;Horses Or Humans Dataset&lt;/a&gt;. Moroney Laurence. Feb 2019. url: &lt;a href="http://laurencemoroney.com/horses-or-humans-dataset"&gt;http://laurencemoroney.com/horses-or-humans-dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>cnn</category><category>tensorflow</category><category>transfer learning</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/keras/horse-or-human-using-tensorflow-20/</guid><pubDate>Mon, 05 Aug 2019 19:37:31 GMT</pubDate></item></channel></rss>