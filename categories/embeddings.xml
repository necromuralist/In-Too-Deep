<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>In Too Deep (Posts about embeddings)</title><link>https://necromuralist.github.io/In-Too-Deep/</link><description></description><atom:link href="https://necromuralist.github.io/In-Too-Deep/categories/embeddings.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2019 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sun, 29 Sep 2019 02:45:56 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Embeddings from Scratch</title><link>https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org4a41309"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org3ff541b"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org093f061"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#orgaf6f43a"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org36b47f9"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#orgce4084e"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org5b4728e"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org7b49415"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org4e302e0"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#orgd45e3e4"&gt;Some Constants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org1614462"&gt;The Embeddings Layer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org74c2e38"&gt;The Dataset&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org5010690"&gt;Add Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#orgc7b8673"&gt;Checkout a Sample&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org954b9de"&gt;Build a Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#org04d5dbc"&gt;Compile and Train&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/#orgda18e8a"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4a41309" class="outline-2"&gt;
&lt;h2 id="org4a41309"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4a41309"&gt;
&lt;p&gt;
This is a walk-through of the tensorflow &lt;a href="https://www.tensorflow.org/beta/tutorials/text/word_embeddings"&gt;Word Embeddings&lt;/a&gt; tutorial, just to make sure I can do it.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3ff541b" class="outline-3"&gt;
&lt;h3 id="org3ff541b"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3ff541b"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org093f061" class="outline-4"&gt;
&lt;h4 id="org093f061"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org093f061"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from functools import partial
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaf6f43a" class="outline-4"&gt;
&lt;h4 id="orgaf6f43a"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgaf6f43a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from tensorflow import keras
from tensorflow.keras import layers
import hvplot.pandas
import pandas
import tensorflow
import tensorflow_datasets
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org36b47f9" class="outline-4"&gt;
&lt;h4 id="org36b47f9"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org36b47f9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import EmbedHoloviews, Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgce4084e" class="outline-3"&gt;
&lt;h3 id="orgce4084e"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgce4084e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5b4728e" class="outline-4"&gt;
&lt;h4 id="org5b4728e"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5b4728e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;prefix = "../../files/posts/keras/"
slug = "embeddings-from-scratch"

Embed = partial(EmbedHoloviews, folder_path=f"{prefix}{slug}")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7b49415" class="outline-4"&gt;
&lt;h4 id="org7b49415"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7b49415"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4e302e0" class="outline-2"&gt;
&lt;h2 id="org4e302e0"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4e302e0"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd45e3e4" class="outline-3"&gt;
&lt;h3 id="orgd45e3e4"&gt;Some Constants&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd45e3e4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Text = Namespace(
    vocabulary_size=1000,
    embeddings_size=16,
    max_length=500,
    padding="post",
)

Tokens = Namespace(
    padding = "&amp;lt;PAD&amp;gt;",
    start = "&amp;lt;START&amp;gt;",
    unknown = "&amp;lt;UNKNOWN&amp;gt;",
    unused = "&amp;lt;UNUSED&amp;gt;",
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1614462" class="outline-3"&gt;
&lt;h3 id="org1614462"&gt;The Embeddings Layer&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1614462"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(layers.Embedding.__doc__)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Turns positive integers (indexes) into dense vectors of fixed size.

  e.g. `[[4], [20]] -&amp;gt; [[0.25, 0.1], [0.6, -0.2]]`

  This layer can only be used as the first layer in a model.

  Example:

  ```python
  model = Sequential()
  model.add(Embedding(1000, 64, input_length=10))
  # the model will take as input an integer matrix of size (batch,
  # input_length).
  # the largest integer (i.e. word index) in the input should be no larger
  # than 999 (vocabulary size).
  # now model.output_shape == (None, 10, 64), where None is the batch
  # dimension.

  input_array = np.random.randint(1000, size=(32, 10))

  model.compile('rmsprop', 'mse')
  output_array = model.predict(input_array)
  assert output_array.shape == (32, 10, 64)
  ```

  Arguments:
    input_dim: int &amp;gt; 0. Size of the vocabulary,
      i.e. maximum integer index + 1.
    output_dim: int &amp;gt;= 0. Dimension of the dense embedding.
    embeddings_initializer: Initializer for the `embeddings` matrix.
    embeddings_regularizer: Regularizer function applied to
      the `embeddings` matrix.
    embeddings_constraint: Constraint function applied to
      the `embeddings` matrix.
    mask_zero: Whether or not the input value 0 is a special "padding"
      value that should be masked out.
      This is useful when using recurrent layers
      which may take variable length input.
      If this is `True` then all subsequent layers
      in the model need to support masking or an exception will be raised.
      If mask_zero is set to True, as a consequence, index 0 cannot be
      used in the vocabulary (input_dim should equal size of
      vocabulary + 1).
    input_length: Length of input sequences, when it is constant.
      This argument is required if you are going to connect
      `Flatten` then `Dense` layers upstream
      (without it, the shape of the dense outputs cannot be computed).

  Input shape:
    2D tensor with shape: `(batch_size, input_length)`.

  Output shape:
    3D tensor with shape: `(batch_size, input_length, output_dim)`.
  
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;embedding_layer = layers.Embedding(Text.vocabulary_size, Text.embeddings_size)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The first argument is the number of possible words in the vocabulary and the second is the number of dimensions. The Emebdding is a sort of lookup table that maps an integer that represents a word to a vector. In this case we're going to build a vocabulary of 1,000 words represented by vectors with a length of 32. The weights in the vectors are learned when we train the model and will encode the distance between words.
&lt;/p&gt;

&lt;p&gt;
The input to the embeddings layer is a 2D tensor of integers with the shape (&lt;code&gt;number of samples&lt;/code&gt;, &lt;code&gt;sequence_length&lt;/code&gt;). The sequences are integer-encoded sentences of the same length - so you have to pad the shorter sentences to match the longest one (the &lt;code&gt;sequence_length&lt;/code&gt;).
&lt;/p&gt;

&lt;p&gt;
The ouput of the embeddings layer is a 3D tensor with the shape (&lt;code&gt;number of samples&lt;/code&gt;, &lt;code&gt;sequence_length&lt;/code&gt;, &lt;code&gt;embedding_dimensionality&lt;/code&gt;).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org74c2e38" class="outline-3"&gt;
&lt;h3 id="org74c2e38"&gt;The Dataset&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org74c2e38"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(train_data, test_data), info = tensorflow_datasets.load(
    "imdb_reviews/subwords8k",
    split=(tensorflow_datasets.Split.TRAIN,
	   tensorflow_datasets.Split.TEST),
    with_info=True, as_supervised=True)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;encoder = info.features["text"].encoder
print(encoder.subwords[:10])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br']

&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5010690" class="outline-4"&gt;
&lt;h4 id="org5010690"&gt;Add Padding&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5010690"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;padded_shapes = ([None], ())
train_batches = train_data.shuffle(Text.vocabulary_size).padded_batch(
    10, padded_shapes=padded_shapes)
test_batches = test_data.shuffle(Text.vocabulary_size).padded_batch(
    10, padded_shapes=padded_shapes
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc7b8673" class="outline-4"&gt;
&lt;h4 id="orgc7b8673"&gt;Checkout a Sample&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc7b8673"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;batch, labels = next(iter(train_batches))
print(batch.numpy())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[  62    9    4 ...    0    0    0]
 [  19 2428    6 ...    0    0    0]
 [ 691    2  594 ... 7961 1457 7975]
 ...
 [6072 5644 8043 ...    0    0    0]
 [ 977   15   57 ...    0    0    0]
 [5646    2    1 ...    0    0    0]]

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org954b9de" class="outline-3"&gt;
&lt;h3 id="org954b9de"&gt;Build a Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org954b9de"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = keras.Sequential([
    layers.Embedding(encoder.vocab_size, Text.embeddings_size),
    layers.GlobalAveragePooling1D(),
    layers.Dense(1, activation="sigmoid")
])
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(model.summary())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, None, 16)          130960    
_________________________________________________________________
global_average_pooling1d (Gl (None, 16)                0         
_________________________________________________________________
dense (Dense)                (None, 1)                 17        
=================================================================
Total params: 130,977
Trainable params: 130,977
Non-trainable params: 0
_________________________________________________________________
None
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org04d5dbc" class="outline-3"&gt;
&lt;h3 id="org04d5dbc"&gt;Compile and Train&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org04d5dbc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
ONCE_PER_EPOCH = 2
with TIMER:
    history = model.fit(train_batches, epochs=10,
			validation_data=test_batches,
			verbose=ONCE_PER_EPOCH,
			validation_steps=20)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2019-09-28 17:14:52,764 graeae.timers.timer start: Started: 2019-09-28 17:14:52.764725
I0928 17:14:52.764965 140515023214400 timer.py:70] Started: 2019-09-28 17:14:52.764725
W0928 17:14:52.806057 140515023214400 deprecation.py:323] From /home/hades/.virtualenvs/In-Too-Deep/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Epoch 1/10
 val_loss: 0.3015 - val_accuracy: 0.8900
2019-09-28 17:17:36,036 graeae.timers.timer end: Ended: 2019-09-28 17:17:36.036090
I0928 17:17:36.036139 140515023214400 timer.py:77] Ended: 2019-09-28 17:17:36.036090
2019-09-28 17:17:36,037 graeae.timers.timer end: Elapsed: 0:02:43.271365
I0928 17:17:36.037808 140515023214400 timer.py:78] Elapsed: 0:02:43.271365
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgda18e8a" class="outline-2"&gt;
&lt;h2 id="orgda18e8a"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgda18e8a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.DataFrame(history.history)
plot = data.hvplot().opts(title="Training/Validation Performance",
			  width=1000,
			  height=800)
Embed(plot=plot, file_name="training")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/training.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
Amazingly, even with such a simple model, it managed a 92 % validation accuracy.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>embeddings</category><category>keras</category><category>nlp</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/keras/embeddings-from-scratch/</guid><pubDate>Wed, 25 Sep 2019 20:30:12 GMT</pubDate></item></channel></rss>