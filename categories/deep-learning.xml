<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>In Too Deep (Posts about deep learning)</title><link>https://necromuralist.github.io/In-Too-Deep/</link><description></description><atom:link href="https://necromuralist.github.io/In-Too-Deep/categories/deep-learning.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2019 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Tue, 16 Apr 2019 14:23:24 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Dog and Cat Breed Classification (What's Your Pet?)</title><link>https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#org9c25070"&gt;Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#org2bac08e"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#org15a2f55"&gt;Some Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#org633abff"&gt;Initiation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#org19c779c"&gt;Downloading the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#orgc2880a7"&gt;Looking At the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#orgd0adadf"&gt;Training: resnet34&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#org1d271fa"&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#orga8c5058"&gt;Unfreezing, fine-tuning, and learning rates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/#orgc38987b"&gt;Training: resnet50&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9c25070" class="outline-2"&gt;
&lt;h2 id="org9c25070"&gt;Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9c25070"&gt;
&lt;p&gt;
This is lesson one from the &lt;a href="https://www.fast.ai"&gt;fastai&lt;/a&gt; course &lt;a href="https://course.fast.ai/index.html"&gt;Practical Deep Learning for Coders, v3&lt;/a&gt;, which I assume is the third version of the course, and not a reference to a &lt;a href="https://www.wikiwand.com/en/Kamen_Rider_V3"&gt;Japanese television show&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2bac08e" class="outline-3"&gt;
&lt;h3 id="org2bac08e"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2bac08e"&gt;
&lt;p&gt;
We are going to work with the &lt;a href="http://www.fast.ai/2018/10/02/fastai-ai/"&gt;fastai V1 library&lt;/a&gt; which sits on top of &lt;a href="https://hackernoon.com/pytorch-1-0-468332ba5163"&gt;Pytorch 1.0&lt;/a&gt;. The &lt;i&gt;fastai&lt;/i&gt; library provides many useful functions that enable us to quickly and easily build neural networks and train our models.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge3cf65e" class="outline-4"&gt;
&lt;h4 id="orge3cf65e"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge3cf65e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from functools import partial
from pathlib import Path
import os
import re
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org587bf39" class="outline-4"&gt;
&lt;h4 id="org587bf39"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org587bf39"&gt;
&lt;p&gt;
&lt;code&gt;fastai&lt;/code&gt; recommends using &lt;code&gt;*&lt;/code&gt; to import everything, but I'd like to know where everything comes from and not import something that might conflict with my naming conventions so I'm going to (at least try to) import things individually.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from dotenv import load_dotenv
from fastai.datasets import untar_data
from fastai.train import ClassificationInterpretation
from fastai.vision.data import get_image_files, imagenet_stats, ImageDataBunch
from fastai.vision.learner import cnn_learner
from fastai.vision.models import resnet34
from fastai.vision.transform import get_transforms
from fastai.metrics import error_rate
from tabulate import tabulate
import holoviews
import matplotlib.pyplot as pyplot
import numpy
import pandas
import seaborn
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0896b3a" class="outline-4"&gt;
&lt;h4 id="org0896b3a"&gt;My Stuff&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0896b3a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae.tables import CountPercentage
from graeae.timers import Timer
from graeae.visualization import EmbedHoloview
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org15a2f55" class="outline-3"&gt;
&lt;h3 id="org15a2f55"&gt;Some Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org15a2f55"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcf02c32" class="outline-4"&gt;
&lt;h4 id="orgcf02c32"&gt;The Random Seed&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcf02c32"&gt;
&lt;p&gt;
To make this reproducible we'll set the random seed in numpy.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;numpy.random.seed(2)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd26fcfc" class="outline-4"&gt;
&lt;h4 id="orgd26fcfc"&gt;Batch Size&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd26fcfc"&gt;
&lt;p&gt;
If you're using a computer with an unusually small GPU, you may get an out of memory error when running this notebook. If this happens, reduce the batch size.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;batch_size = 64 # = 16  change this if you run out of memory.
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcc6714c" class="outline-4"&gt;
&lt;h4 id="orgcc6714c"&gt;The Path&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcc6714c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv(".env", override=True)
DATA_PATH = Path(os.environ.get("OXFORD_PET_DATASET")).expanduser()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org41d296f" class="outline-4"&gt;
&lt;h4 id="org41d296f"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org41d296f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org458986a" class="outline-5"&gt;
&lt;h5 id="org458986a"&gt;Matplotlib&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org458986a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
seaborn.set(style="whitegrid",
	    rc={"axes.grid": False,
		"font.family": ["sans-serif"],
		"font.sans-serif": ["Open Sans", "Latin Modern Sans", "Lato"],
		"figure.figsize": (8, 6)},
	    font_scale=1)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf7d2811" class="outline-5"&gt;
&lt;h5 id="orgf7d2811"&gt;The Bokeh&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgf7d2811"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;holoviews.extension("bokeh")
SLUG = "dog-and-cat-breed-classification"
OUTPUT_FOLDER = Path("../../files/posts/fastai/" + SLUG)
Embed = partial(EmbedHoloview, folder_path=OUTPUT_FOLDER)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Plot = Namespace(
    width = 1000,
    height = 800,
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org358c5bc" class="outline-4"&gt;
&lt;h4 id="org358c5bc"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org358c5bc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9e7ab29" class="outline-4"&gt;
&lt;h4 id="org9e7ab29"&gt;Tabulate&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9e7ab29"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ORG_TABLE = partial(tabulate, headers="keys", 
		    showindex=False, 
		    tablefmt="orgtbl")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org633abff" class="outline-2"&gt;
&lt;h2 id="org633abff"&gt;Initiation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org633abff"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org19c779c" class="outline-3"&gt;
&lt;h3 id="org19c779c"&gt;Downloading the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org19c779c"&gt;
&lt;p&gt;
We are going to use the &lt;a href="http://www.robots.ox.ac.uk/~vgg/data/pets/"&gt;Oxford-IIIT Pet Dataset&lt;/a&gt; by &lt;a href="http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf"&gt;O. M. Parkhi et al., 2012&lt;/a&gt; which features 12 cat breeds and 25 dogs breeds. Our model will need to learn to differentiate between these 37 distinct categories. According to their paper, the best accuracy they could get in 2012 was 59.21%, using a complex model that was specific to pet detection, with separate "Image", "Head", and "Body" models for the pet photos. Let's see how accurate we can be using deep learning.
&lt;/p&gt;

&lt;p&gt;
We are going to use the &lt;a href="https://docs.fast.ai/datasets.html#untar_data"&gt;untar_data&lt;/a&gt; function to which we must pass a URL as an argument and which will download and extract the data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;help(untar_data)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Help on function untar_data in module fastai.datasets:

untar_data(url:str, fname:Union[pathlib.Path, str]=None, dest:Union[pathlib.Path, str]=None, data=True, force_download=False) -&amp;gt; pathlib.Path
    Download `url` to `fname` if it doesn't exist, and un-tgz to folder `dest`.


&lt;/pre&gt;

&lt;p&gt;
This data set is 774 Megabytes and given my over-priced yet still incredibly slow CenturyLink speeds I found downloading it from the &lt;a href="https://course.fast.ai/datasets#image-classification"&gt;fastai datasets page&lt;/a&gt; a little more satisfactory, since the progress widget that runs during the download  when &lt;code&gt;untar_data&lt;/code&gt; downloads the dataset doesn't show up in emacs.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert DATA_PATH.is_dir()
print(DATA_PATH)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
/home/athena/data/datasets/images/oxford-iiit-pet

&lt;/pre&gt;

&lt;p&gt;
I didn't know it, but &lt;code&gt;Paths&lt;/code&gt; have an &lt;code&gt;ls&lt;/code&gt; method (so far as I could see this isn't in &lt;a href="https://docs.python.org/3/library/pathlib.html"&gt;python's documentation&lt;/a&gt;).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(DATA_PATH.ls())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[PosixPath('/home/athena/data/datasets/images/oxford-iiit-pet/images_backup'), PosixPath('/home/athena/data/datasets/images/oxford-iiit-pet/README.org'), PosixPath('/home/athena/data/datasets/images/oxford-iiit-pet/images'), PosixPath('/home/athena/data/datasets/images/oxford-iiit-pet/annotations')]

&lt;/pre&gt;

&lt;p&gt;
Here's another trick I didn't know about, instead of using the &lt;code&gt;joinpath&lt;/code&gt; method you can just use a forward-slash.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path_to_annotations = DATA_PATH/'annotations'
path_to_images = DATA_PATH/'images'
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc2880a7" class="outline-3"&gt;
&lt;h3 id="orgc2880a7"&gt;Looking At the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc2880a7"&gt;
&lt;p&gt;
The first thing we do when we approach a problem is to take a look at the data. We &lt;i&gt;always&lt;/i&gt; need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Taking a look at the data means understanding how the data directories are structured, what the labels are and what some sample images look like.
&lt;/p&gt;

&lt;p&gt;
The main difference between the handling of image classification datasets is the way labels are stored. In this particular dataset, labels are stored in the filenames themselves. We will need to extract them to be able to classify the images into the correct categories. Fortunately, the fastai library has a handy function made exactly for this, &lt;a href="https://docs.fast.ai/vision.data.html#ImageDataBunch.from_name_re"&gt;ImageDataBunch.from_name_re&lt;/a&gt; gets the labels from the filenames using a &lt;a href="https://docs.python.org/3.6/library/re.html"&gt;regular expression&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
First we'll get a list of the files in the images folder using &lt;a href="https://docs.fast.ai/vision.data.html#get_image_files"&gt;get_image_files&lt;/a&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;file_names = get_image_files(path_to_images)
for path in file_names[:5]:
    print(path.name)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Boxer_20.jpg
Saint_Bernard_195.jpg
Saint_Bernard_133.jpg
English_Cocker_Spaniel_43.jpg
Pug_51.jpg

&lt;/pre&gt;

&lt;p&gt;
Later on we're going to use the labels when we inspect the model so I'm going to make the case standardized.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;UNDERSCORE, SPACE = "_", " "
for path in file_names:
    name, extension = os.path.splitext(path.name)
    name = name.replace(UNDERSCORE, SPACE).title()
    file_name = (name + extension).replace(SPACE, UNDERSCORE)
    target = path.parent.joinpath(file_name)
    path.rename(target)

file_names = get_image_files(path_to_images)
for path in file_names[:2]:
    print(path.name)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Boxer_20.jpg
Saint_Bernard_195.jpg

&lt;/pre&gt;

&lt;p&gt;
This is the pattern to match the file-name.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;end_of_line = "$"
one_or_more = "+"
digit = r"\d"
index = rf"{digit}{one_or_more}"
forward_slash = "/"

anything_but_a_slash = f"[^{forward_slash}]"
label = f'({anything_but_a_slash}{one_or_more})'
file_extension = ".jpg"
expression = rf'{forward_slash}{label}{UNDERSCORE}{index}{file_extension}{end_of_line}'

test = "/home/athena/data/datasets/images/oxford-iiit-pet/images/Havanese_128.jpg"

assert re.search(expression, test).groups()[0] == "Havanese"
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The reason for the forward slash at the beginning of the expression is that we're passing in the entire path to each image, not just the name of the image.
&lt;/p&gt;

&lt;p&gt;
Here's the arguments we need to pass in
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(help(ImageDataBunch.from_name_re))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Help on method from_name_re in module fastai.vision.data:

from_name_re(path:Union[pathlib.Path, str], fnames:Collection[pathlib.Path], pat:str, valid_pct:float=0.2, **kwargs) method of builtins.type instance
    Create from list of `fnames` in `path` with re expression `pat`.

None

&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = ImageDataBunch.from_name_re(path_to_images, 
				   file_names, 
				   expression, 
				   ds_tfms=get_transforms(), 
				   size=224, 
				   bs=batch_size
				  ).normalize(imagenet_stats)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
One of the arguments we passed in isn't particularly obviously named, unless you already know about applying transforms to images, but here's what we passed to it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(help(get_transforms))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Help on function get_transforms in module fastai.vision.transform:

get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10.0, max_zoom:float=1.1, max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75, p_lighting:float=0.75, xtra_tfms:Union[Collection[fastai.vision.image.Transform], NoneType]=None) -&amp;gt; Collection[fastai.vision.image.Transform]
    Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.

None

&lt;/pre&gt;

&lt;p&gt;
&lt;a href="https://docs.fast.ai/vision.transform.html#get_transforms"&gt;get_transforms&lt;/a&gt; adds random changes to the images to help with our training.
&lt;/p&gt;

&lt;p&gt;
We also added a call to &lt;a href="https://docs.fast.ai/vision.data.html#normalize"&gt;normalize&lt;/a&gt; which sets the mean and standard deviation of the images to match those of the images used to train the model that we're going to use (&lt;a href="https://arxiv.org/abs/1512.03385"&gt;ResNet&lt;/a&gt;).
&lt;/p&gt;

&lt;p&gt;
The &lt;a href="https://docs.fast.ai/basic_data.html#DataBunch.show_batch"&gt;show_batch&lt;/a&gt; function is a simple way to show some of the images. It retrieves them randomly so calling the method repeatedly will pull up different images. Unfortunately you can't pass in a figure or axes so it isn't easily configurable.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data.show_batch(rows=3, figsize=(7,6))
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/show_batch.png" alt="show_batch.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(data)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
ImageDataBunch;

Train: LabelList (5912 items)
x: ImageList
Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
y: CategoryList
Boxer,Saint_Bernard,Saint_Bernard,Ragdoll,Birman
Path: /home/athena/data/datasets/images/oxford-iiit-pet/images;

Valid: LabelList (1478 items)
x: ImageList
Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)
y: CategoryList
Siamese,British_Shorthair,English_Cocker_Spaniel,Newfoundland,Russian_Blue
Path: /home/athena/data/datasets/images/oxford-iiit-pet/images;

Test: None
&lt;/pre&gt;

&lt;p&gt;
So it looks like the &lt;code&gt;ImageDataBunch&lt;/code&gt; created a training and a validation set and each of the images has three channels and is 224 x 224 pixels.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd0adadf" class="outline-3"&gt;
&lt;h3 id="orgd0adadf"&gt;Training: resnet34&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd0adadf"&gt;
&lt;p&gt;
Now we will start training our model. We will use a &lt;a href="http://cs231n.github.io/convolutional-networks/"&gt;convolutional neural network&lt;/a&gt; backbone and a fully connected head with a single hidden layer as a classifier. Don't know what these things mean? Not to worry, we will dive deeper in the coming lessons. For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories (in this case, it will have 37 outputs).
&lt;/p&gt;

&lt;p&gt;
We will train for 4 epochs (4 cycles through all our data).
&lt;/p&gt;

&lt;p&gt;
First we'll load the model to train into the &lt;a href="https://docs.fast.ai/vision.learner.html#cnn_learner"&gt;cnn_learner&lt;/a&gt;. If you look at the &lt;a href="https://github.com/fastai/fastai/blob/master/fastai/vision/models/__init__.py"&gt;fast ai code&lt;/a&gt; they are importing the &lt;code&gt;resnet34&lt;/code&gt; model from &lt;a href="https://pytorch.org/docs/stable/torchvision/models.html#id3"&gt;pytorch's torchvision&lt;/a&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learn = cnn_learner(data, resnet34, metrics=error_rate)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
#+RESULTS
&lt;/p&gt;
&lt;pre class="example"&gt;
Downloading: "https://download.pytorch.org/models/resnet34-333f7ec4.pth" to /home/athena/.torch/models/resnet34-333f7ec4.pth
87306240it [00:26, 3321153.99it/s]
&lt;/pre&gt;

&lt;p&gt;
As you can see, it downloaded the stored model parameters from pytorch. This is because I've never downloaded this particular model before if you run it again it shouldn't need to re-download it. Since this is a &lt;a href="https://pytorch.org"&gt;pytorch&lt;/a&gt; model we can look at it's represetantion to see the architecture of the network.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(learn.model)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Sequential(
  (0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (1): Sequential(
    (0): AdaptiveConcatPool2d(
      (ap): AdaptiveAvgPool2d(output_size=1)
      (mp): AdaptiveMaxPool2d(output_size=1)
    )
    (1): Flatten()
    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.25)
    (4): Linear(in_features=1024, out_features=512, bias=True)
    (5): ReLU(inplace)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): Dropout(p=0.5)
    (8): Linear(in_features=512, out_features=37, bias=True)
  )
)
&lt;/pre&gt;

&lt;p&gt;
That's a pretty big network, but the main thing to notice is the last layer, which has 37 &lt;code&gt;out_features&lt;/code&gt; which corresponds to the number of breeds we have in our data-set.
&lt;/p&gt;

&lt;p&gt;
Now we need to train it using the &lt;a href="https://docs.fast.ai/train.html#fit_one_cycle"&gt;fit_one_cycle&lt;/a&gt; method. At first I thought 'one cycle' meant just one pass through the batches but according to the &lt;a href="https://docs.fast.ai/callbacks.one_cycle.html"&gt;documentation&lt;/a&gt;, this is a reference to a training method called the &lt;a href="https://sgugger.github.io/the-1cycle-policy.html"&gt;1Cycle Policy&lt;/a&gt; proposed by &lt;a href="https://arxiv.org/abs/1803.09820"&gt;Leslie N. Smith&lt;/a&gt; that changes the hyperparameters to make the model train faster.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    learn.fit_one_cycle(4)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-04-15 21:58:04.280169
Ended: 2019-04-15 22:01:05.727543
Elapsed: 0:03:01.447374

&lt;/pre&gt;

&lt;p&gt;
Now we can store the parameters for the trained model.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learn.save('stage-1')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-org1d271fa" class="outline-3"&gt;
&lt;h3 id="org1d271fa"&gt;Results&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1d271fa"&gt;
&lt;p&gt;
Let's see what results we have got. 
&lt;/p&gt;

&lt;p&gt;
We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. 
&lt;/p&gt;

&lt;p&gt;
Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour.
&lt;/p&gt;

&lt;p&gt;
The &lt;a href="https://docs.fast.ai/train.html#ClassificationInterpretation"&gt;ClassificationInterpretation&lt;/a&gt; class contains methods to help look at how the model did.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;interpreter = ClassificationInterpretation.from_learner(learn)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The &lt;a href="https://docs.fast.ai/vision.learner.html#ClassificationInterpretation.top_losses"&gt;top_losses&lt;/a&gt; method returns a tuple of the highest losses along with the indices of the data that gave those losses. By default it actually gives all the losses sorted from largest to smallest, but you could pass in an integer to limit how much it returns.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;losses, indexes = interpreter.top_losses()
print(losses)
print(indexes)
assert len(data.valid_ds)==len(losses)==len(indexes)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor([7.3065e+00, 6.9973e+00, 5.7732e+00,  ..., 7.6294e-06, 5.7220e-06,
        3.8147e-06])
tensor([1298, 1418, 1443,  ...,  735,   96,  404])

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = holoviews.Distribution(losses).opts(title="Loss Distribution", 
					   xlabel="Loss", 
					   width=Plot.width, 
					   height=Plot.height)
Embed(plot=plot, file_name="loss_distribution")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/loss_distribution.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
Although it looks like there are negative losses, that's just the way the distribution works out.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(losses.max())
print(losses.min())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
tensor(7.3065)
tensor(3.8147e-06)

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bins = pandas.cut(losses.tolist(), bins=10).value_counts().reset_index()
print(ORG_TABLE(bins, headers="Range Count".split()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Range&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;(-0.0073, 0.731]&lt;/td&gt;
&lt;td class="org-right"&gt;1366&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(0.731, 1.461]&lt;/td&gt;
&lt;td class="org-right"&gt;43&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(1.461, 2.192]&lt;/td&gt;
&lt;td class="org-right"&gt;35&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(2.192, 2.923]&lt;/td&gt;
&lt;td class="org-right"&gt;17&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(2.923, 3.653]&lt;/td&gt;
&lt;td class="org-right"&gt;7&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(3.653, 4.384]&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(4.384, 5.115]&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(5.115, 5.845]&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(5.845, 6.576]&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;(6.576, 7.307]&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;
Alternatively we can plot the images that had the highest losses.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;interpreter.plot_top_losses(9, figsize=(15,11))
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/top_losses.png" alt="top_losses.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
It looks like the ones that had the most loss had some kind of weird flare effect applied to the image. Now that we've used it, maybe we can see how we're supposed to call &lt;code&gt;plot_top_losses&lt;/code&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(help(interpreter.plot_top_losses))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Help on method _cl_int_plot_top_losses in module fastai.vision.learner:

_cl_int_plot_top_losses(k, largest=True, figsize=(12, 12), heatmap:bool=True, heatmap_thresh:int=16, return_fig:bool=None) -&amp;gt; Union[matplotlib.figure.Figure, NoneType] method of fastai.train.ClassificationInterpretation instance
    Show images in `top_losses` along with their prediction, actual, loss, and probability of actual class.

None

&lt;/pre&gt;

&lt;p&gt;
&lt;b&gt;Note:&lt;/b&gt; in the original notebook they were using a function called &lt;a href="https://github.com/fastai/fastai/blob/master/fastai/gen_doc/nbdoc.py#L126"&gt;doc&lt;/a&gt;, which tries to open another window and will thus hang when run in emacs. They &lt;i&gt;really&lt;/i&gt; want you to use jupyter.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;interpreter.plot_confusion_matrix(figsize=(12,12), dpi=60)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/confusion_matrix.png" alt="confusion_matrix.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;
If you compare the images with the worst losses to the confusion matrix you'll notice that they don't seem to correlate - the worst losses were one-offs, probably due to the flare effect. The most confused was the &lt;i&gt;Ragdoll&lt;/i&gt; being confused for a &lt;i&gt;Birman&lt;/i&gt;, but, as noted in the lecture, &lt;a href="https://pets.thenest.com/birman-vs-ragdoll-cat-11758.html"&gt;distinguishing them is hard for people too&lt;/a&gt;. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(ORG_TABLE(interpreter.most_confused(min_val=2), 
		headers="Actual Predicted Count".split()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Actual&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Predicted&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;American_Pit_Bull_Terrier&lt;/td&gt;
&lt;td class="org-left"&gt;Staffordshire_Bull_Terrier&lt;/td&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Staffordshire_Bull_Terrier&lt;/td&gt;
&lt;td class="org-left"&gt;American_Pit_Bull_Terrier&lt;/td&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;American_Bulldog&lt;/td&gt;
&lt;td class="org-left"&gt;Staffordshire_Bull_Terrier&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Egyptian_Mau&lt;/td&gt;
&lt;td class="org-left"&gt;Bengal&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Miniature_Pinscher&lt;/td&gt;
&lt;td class="org-left"&gt;Chihuahua&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;American_Pit_Bull_Terrier&lt;/td&gt;
&lt;td class="org-left"&gt;American_Bulldog&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Bengal&lt;/td&gt;
&lt;td class="org-left"&gt;Abyssinian&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Birman&lt;/td&gt;
&lt;td class="org-left"&gt;Ragdoll&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Maine_Coon&lt;/td&gt;
&lt;td class="org-left"&gt;Persian&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Samoyed&lt;/td&gt;
&lt;td class="org-left"&gt;Great_Pyrenees&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Abyssinian&lt;/td&gt;
&lt;td class="org-left"&gt;Egyptian_Mau&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;American_Bulldog&lt;/td&gt;
&lt;td class="org-left"&gt;American_Pit_Bull_Terrier&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Basset_Hound&lt;/td&gt;
&lt;td class="org-left"&gt;Beagle&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Bengal&lt;/td&gt;
&lt;td class="org-left"&gt;Egyptian_Mau&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Boxer&lt;/td&gt;
&lt;td class="org-left"&gt;American_Bulldog&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;English_Cocker_Spaniel&lt;/td&gt;
&lt;td class="org-left"&gt;English_Setter&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Maine_Coon&lt;/td&gt;
&lt;td class="org-left"&gt;Bengal&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Ragdoll&lt;/td&gt;
&lt;td class="org-left"&gt;Birman&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yorkshire_Terrier&lt;/td&gt;
&lt;td class="org-left"&gt;Havanese&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
It doesn't look too bad, actually, other that the first 5 entries, maybe.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga8c5058" class="outline-3"&gt;
&lt;h3 id="orga8c5058"&gt;Unfreezing, fine-tuning, and learning rates&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga8c5058"&gt;
&lt;p&gt;
Since our model is working as we expect it to, we will &lt;a href="https://docs.fast.ai/basic_train.html#Learner.unfreeze"&gt;&lt;b&gt;unfreeze&lt;/b&gt;&lt;/a&gt; our model and train some more.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learn.unfreeze()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Since we are using a pre-trained model we normally freeze all but the last layer to do transfer learning, by unfreezing the mode we'll train all the layers to our dataset.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    learn.fit_one_cycle(1)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-04-15 22:05:19.209649
Ended: 2019-04-15 22:06:00.831873
Elapsed: 0:00:41.622224

&lt;/pre&gt;

&lt;p&gt;
Now we save it again.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learn.save('stage-1');
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we're going to use the &lt;a href="https://docs.fast.ai/callbacks.lr_finder.html"&gt;lr_find&lt;/a&gt; method to find the best learning rate.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    learn.lr_find()
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-04-15 22:06:16.068039
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Ended: 2019-04-15 22:06:43.852905
Elapsed: 0:00:27.784866

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learn.recorder.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/learning.png" alt="learning.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;
So, it's kind of hard to see the exact number, but you can see that somewhere around a learning rate of 0.0001 we get a good loss and then after that the loss starts to go way up.
&lt;/p&gt;

&lt;p&gt;
So next we're going to re-train it using an interval that hopefully gives us the best loss.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learn.unfreeze()
with TIMER:
    print(learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4)))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-04-15 22:45:51.354368
None
Ended: 2019-04-15 22:47:15.945090
Elapsed: 0:01:24.590722

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-orgc38987b" class="outline-3"&gt;
&lt;h3 id="orgc38987b"&gt;Training: resnet50&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc38987b"&gt;
&lt;p&gt;
Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. It will be explained later in the course and you can learn the details in the &lt;a href="https://arxiv.org/pdf/1512.03385.pdf"&gt;resnet paper&lt;/a&gt;).
&lt;/p&gt;

&lt;p&gt;
Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let's see if we can achieve a higher performance here. To help it along, let's us use larger images too, since that way the network can see more detail. We reduce the batch size a bit since otherwise this larger network will require more GPU memory.
&lt;/p&gt;


&lt;p&gt;
data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(),
                                   size=299, bs=bs//2).normalize(imagenet_stats)
&lt;/p&gt;


&lt;p&gt;
learn = cnn_learner(data, models.resnet50, metrics=error_rate)
&lt;/p&gt;


&lt;p&gt;
learn.lr_find()
learn.recorder.plot()
&lt;/p&gt;


&lt;p&gt;
learn.fit_one_cycle(8)
&lt;/p&gt;


&lt;p&gt;
learn.save('stage-1-50')
&lt;/p&gt;


&lt;p&gt;
learn.unfreeze()
learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))
&lt;/p&gt;


&lt;p&gt;
learn.load('stage-1-50');
&lt;/p&gt;


&lt;p&gt;
interp = ClassificationInterpretation.from_learner(learn)
&lt;/p&gt;


&lt;p&gt;
interp.most_confused(min_val=2)
&lt;/p&gt;


&lt;p&gt;
path = untar_data(URLs.MNIST_SAMPLE); path
&lt;/p&gt;


&lt;p&gt;
tfms = get_transforms(do_flip=False)
data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=26)
&lt;/p&gt;


&lt;p&gt;
data.show_batch(rows=3, figsize=(5,5))
&lt;/p&gt;


&lt;p&gt;
learn = cnn_learner(data, models.resnet18, metrics=accuracy)
learn.fit(2)
&lt;/p&gt;


&lt;p&gt;
df = pd.read_csv(path/'labels.csv')
df.head()
&lt;/p&gt;


&lt;p&gt;
data = ImageDataBunch.from_csv(path, ds_tfms=tfms, size=28)
&lt;/p&gt;


&lt;p&gt;
data.show_batch(rows=3, figsize=(5,5))
data.classes
&lt;/p&gt;


&lt;p&gt;
data = ImageDataBunch.from_df(path, df, ds_tfms=tfms, size=24)
data.classes
&lt;/p&gt;


&lt;p&gt;
fn_paths = [path/name for name in df['name']]; fn_paths[:2]
&lt;/p&gt;


&lt;p&gt;
pat = r"&lt;i&gt;(\d)&lt;/i&gt;\d+\.png$"
data = ImageDataBunch.from_name_re(path, fn_paths, pat=pat, ds_tfms=tfms, size=24)
data.classes
&lt;/p&gt;


&lt;p&gt;
data = ImageDataBunch.from_name_func(path, fn_paths, ds_tfms=tfms, size=24,
        label_func = lambda x: '3' if '&lt;i&gt;3&lt;/i&gt;' in str(x) else '7')
data.classes
&lt;/p&gt;


&lt;p&gt;
labels = [('3' if '&lt;i&gt;3&lt;/i&gt;' in str(x) else '7') for x in fn_paths]
labels[:5]
&lt;/p&gt;


&lt;p&gt;
data = ImageDataBunch.from_lists(path, fn_paths, labels=labels, ds_tfms=tfms, size=24)
data.classes
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>cnn</category><category>deep learning</category><category>fastai</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/fastai/dog-and-cat-breed-classification/</guid><pubDate>Sat, 13 Apr 2019 23:14:46 GMT</pubDate></item><item><title>Bibliography: Deep Learning With PyTorch</title><link>https://necromuralist.github.io/In-Too-Deep/posts/bibliographies/bibliography-deep-learning-with-pytorch/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-orgce5635a" class="outline-2"&gt;
&lt;h2 id="orgce5635a"&gt;Reference&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgce5635a"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;[DLWP] 1. Subramanian V. Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham: Packt Publishing; 2018.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography</category><category>deep learning</category><category>pytorch</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/bibliographies/bibliography-deep-learning-with-pytorch/</guid><pubDate>Sun, 23 Dec 2018 21:44:21 GMT</pubDate></item><item><title>Notes on The Deep Learning Revolution</title><link>https://necromuralist.github.io/In-Too-Deep/posts/notes/notes-on-the-deep-learning-revolution/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/notes/notes-on-the-deep-learning-revolution/#org1d25b7d"&gt;Intelligence Reimagined (Where did this come from?)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/notes/notes-on-the-deep-learning-revolution/#org0ff85be"&gt;Many Ways To Learn (How does it work?)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/notes/notes-on-the-deep-learning-revolution/#org35fe2fa"&gt;Technological and Scientific Impact (What has it done and what might it do?)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/notes/notes-on-the-deep-learning-revolution/#org1b7ed82"&gt;Citation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1d25b7d" class="outline-2"&gt;
&lt;h2 id="org1d25b7d"&gt;Intelligence Reimagined (Where did this come from?)&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1d25b7d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0675ca1" class="outline-3"&gt;
&lt;h3 id="org0675ca1"&gt;Timeline&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0675ca1"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;1956: Dartmouth Artificial Intelligence Summer Research Project - start of the field of Artificial Intelligence.&lt;/li&gt;
&lt;li&gt;1962: Frank Rosenblatt publishes description of the Perceptron&lt;/li&gt;
&lt;li&gt;1962: David Huble and Torsten Wiesel report first recordings of responses from neurons&lt;/li&gt;
&lt;li&gt;1969: Marvin Minsky and Seymour Papert point out limits of perceptron, triggering the &lt;i&gt;AI Winter&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;1979: Geoffrey Hinton and James Anderson organize Parallel Models of Associative Memory workshop to gather researchers working on neural networks&lt;/li&gt;
&lt;li&gt;1987: First Neural Information Processing Systems (NIPS) conference held, bringing machine learning reasearchers together&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4903ee8" class="outline-3"&gt;
&lt;h3 id="org4903ee8"&gt;The Rise of Machine Learning&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4903ee8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdfe2fe0" class="outline-4"&gt;
&lt;h4 id="orgdfe2fe0"&gt;What is deep learning?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgdfe2fe0"&gt;
&lt;p&gt;
&lt;i&gt;Deep Learning&lt;/i&gt; is a form of machine learning that uses data to train artificial neural networks to do things. When the field of artificial intelligence began in the 1950s there were two camps - one that believed the path to intelligenc lay in using formal logic and writing computer programs, and one that believe intelligence would come by learning directly from data. Deep Learning belongs to the second camp, and although it has been around for a long time, only once we had enough computational power and data was it able to compete. 
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org89072c9" class="outline-4"&gt;
&lt;h4 id="org89072c9"&gt;How did self-driving cars come about?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org89072c9"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;In 2005 a group from Stanford lead by Sebastian Thrun won the &lt;a href="https://en.wikipedia.org/wiki/DARPA_Grand_Challenge_(2005)"&gt;DARPA Grand Challenge&lt;/a&gt;. This was the second Darpa challenge and the first where (five) vehicles were able to finish.&lt;/li&gt;
&lt;li&gt;Some see self-driving cars as a way to remake society:
&lt;ul class="org-ul"&gt;
&lt;li&gt;no need to own a car, use a just-in-time service&lt;/li&gt;
&lt;li&gt;No need for parking lots and so many lanes on the road&lt;/li&gt;
&lt;li&gt;Travel time can be productive&lt;/li&gt;
&lt;li&gt;Once one car learns something it can be taught to all the other cars so 'rare' events will be handled even if it is the first time a car sees the event.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcd059eb" class="outline-4"&gt;
&lt;h4 id="orgcd059eb"&gt;How do machines translate languages?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcd059eb"&gt;
&lt;p&gt;
Originally they worked using a statistical approach, looking for familiar word combinations and counts. Now they are able to keep longer sections of text which improves the translation because there is more seen in contetxt. The hope is that when they can be expanded to learn paragraphs or an author's entire body of work, then they can learn more subtleties and the poetry of the text.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga9f88b8" class="outline-4"&gt;
&lt;h4 id="orga9f88b8"&gt;What's the big deal about speech recognition?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga9f88b8"&gt;
&lt;p&gt;
Some people think that the next interface to our machines will be the human voice. There have already been demonstrations of live translations made using computer speech recognition and translation.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge8a5070" class="outline-4"&gt;
&lt;h4 id="orge8a5070"&gt;How good is machine learning at playing poker?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge8a5070"&gt;
&lt;p&gt;
DeepStack played poker against professional poker players and beat all of them. This is important because the nature of the game means that every player is working with imperfect information (the unseen cards and the other players' cards). This could imply that machine learning could be used in other places where you don't have all the information, like politics and negotiations.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org10e66aa" class="outline-4"&gt;
&lt;h4 id="org10e66aa"&gt;Does artificial intelligence pose a threat to humanity?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org10e66aa"&gt;
&lt;p&gt;
If you look an the areas where deep learning managed to outdo human competitors (e.g. Alpha Go), what eventually happened was that the human players were able to learn moves from the Artificial Intelligence that they would likely not have come up with themselves. This points the way to the immediate future of Artificial Intelligence. Although AI can sometimes outperform humans, the more open-ended the problem, the more it is likely that humans and machines can complement each other, with the machine creating outcomes we could never think of and the humans contributing the expertise needed as a human to solve human problems. AI is, so far, more of a complement to human intelligence, not a replacement for it.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7125435" class="outline-3"&gt;
&lt;h3 id="org7125435"&gt;The Rebirth of Artificial Intelligence&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7730158" class="outline-3"&gt;
&lt;h3 id="org7730158"&gt;The Dawn of Neural Networks&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org29259d0" class="outline-3"&gt;
&lt;h3 id="org29259d0"&gt;Brain-style Computing&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org432c76d" class="outline-3"&gt;
&lt;h3 id="org432c76d"&gt;Insights from the Visual System&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ff85be" class="outline-2"&gt;
&lt;h2 id="org0ff85be"&gt;Many Ways To Learn (How does it work?)&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0ff85be"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org28af883" class="outline-3"&gt;
&lt;h3 id="org28af883"&gt;The Cocktail Party Problem&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcd7d0c2" class="outline-3"&gt;
&lt;h3 id="orgcd7d0c2"&gt;The Hopfield Net and Boltzmann Machine&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org14f4f78" class="outline-3"&gt;
&lt;h3 id="org14f4f78"&gt;Backpropagating Errors&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org645ea29" class="outline-3"&gt;
&lt;h3 id="org645ea29"&gt;Convolutional Learning&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc0312cc" class="outline-3"&gt;
&lt;h3 id="orgc0312cc"&gt;Reward Learning&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2c4bb5c" class="outline-3"&gt;
&lt;h3 id="org2c4bb5c"&gt;Neural Information Processing Systems&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org35fe2fa" class="outline-2"&gt;
&lt;h2 id="org35fe2fa"&gt;Technological and Scientific Impact (What has it done and what might it do?)&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org35fe2fa"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org278f58e" class="outline-3"&gt;
&lt;h3 id="org278f58e"&gt;The Future of Machine Learning&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd80e955" class="outline-3"&gt;
&lt;h3 id="orgd80e955"&gt;The Age of Algorithms&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5bb6afb" class="outline-3"&gt;
&lt;h3 id="org5bb6afb"&gt;Hello, Mr. Chips&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgafebf71" class="outline-3"&gt;
&lt;h3 id="orgafebf71"&gt;Inside Information&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-org102a99b" class="outline-3"&gt;
&lt;h3 id="org102a99b"&gt;Conscousness&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc2f3308" class="outline-3"&gt;
&lt;h3 id="orgc2f3308"&gt;Nature Is Cleverer Than We Are&lt;/h3&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdef7de9" class="outline-3"&gt;
&lt;h3 id="orgdef7de9"&gt;Deep Intelligence&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1b7ed82" class="outline-2"&gt;
&lt;h2 id="org1b7ed82"&gt;Citation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1b7ed82"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org76789b6" class="outline-3"&gt;
&lt;h3 id="org76789b6"&gt;[TDLR] Sejnowski TJ. The deep learning revolution. MIT Press; 2018 Oct 23.&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>book</category><category>deep learning</category><category>notes</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/notes/notes-on-the-deep-learning-revolution/</guid><pubDate>Thu, 01 Nov 2018 21:18:50 GMT</pubDate></item><item><title>Okay, but what about this deep-learning stuff?</title><link>https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#orgf70a8ca"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#org7a5df9a"&gt;Typing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#org6e5561f"&gt;What is this about?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#orgcf55ff0"&gt;Okay, so how do you implement that?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#orgad432ce"&gt;Let's try it out&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#org91af9f2"&gt;Okay, but can we do that with numpy?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/#org64969d7"&gt;Okay, so what was this about again?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf70a8ca" class="outline-2"&gt;
&lt;h2 id="orgf70a8ca"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf70a8ca"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org72b6a95" class="outline-3"&gt;
&lt;h3 id="org72b6a95"&gt;From Python&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org72b6a95"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;typing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org26e0730" class="outline-3"&gt;
&lt;h3 id="org26e0730"&gt;From Pypi&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org26e0730"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graphviz&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Digraph&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7a5df9a" class="outline-2"&gt;
&lt;h2 id="org7a5df9a"&gt;Typing&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7a5df9a"&gt;
&lt;p&gt;
This is to develop some type hinting.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Vector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6e5561f" class="outline-2"&gt;
&lt;h2 id="org6e5561f"&gt;What is this about?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6e5561f"&gt;
&lt;p&gt;
I previously looked at a model with multiple inputs and outputs to predict whether a team would win or lose and how the fans would feel in response to the outcome. Now I'm going to stack the network on top of another one to 'deepen' the network.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Digraph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;comment&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Hidden Layers"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"png"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# input layer&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"A"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Toes"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"B"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Wins"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"C"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Fans"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Hidden Layer&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"D"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"H1"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"E"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"H2"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"F"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"H3"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Output Layer&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"G"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Hurt"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"H"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Win"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"I"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Sad"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Input to hidden edges&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;"AD"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"AE"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"AF"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	     &lt;span class="s2"&gt;"BD"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"BE"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"BF"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	     &lt;span class="s2"&gt;"CD"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"CE"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"CF"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# Hidden to output egdes&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edges&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;"DG"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"DH"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"DI"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	     &lt;span class="s2"&gt;"EG"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"EH"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"EI"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	     &lt;span class="s2"&gt;"FG"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"FH"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"FI"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"graphs/hidden_layer.dot"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/hidden_layer.dot.png" alt="hidden_layer.dot.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
These networks between the input and output layers are called &lt;i&gt;hidden layers&lt;/i&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgcf55ff0" class="outline-2"&gt;
&lt;h2 id="orgcf55ff0"&gt;Okay, so how do you implement that?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgcf55ff0"&gt;
&lt;p&gt;
It works like our previous model except that you insert an extra vector-matrix-multiplication call between the inputs and outputs. For this example I'm going to do it as a class so that I can check the hidden layer's values more easily, but otherwise you would do it using matrices and vectors.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;HiddenLayer&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""Implements a neural network with one hidden layer&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;     inputs: vector of input values&lt;/span&gt;
&lt;span class="sd"&gt;     input_to_hidden_weights: vector of weights for the first layer&lt;/span&gt;
&lt;span class="sd"&gt;     hidden_to_output_weights: vector of weights of the second layer&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		 &lt;span class="n"&gt;hidden_to_output_weights&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;
	&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt;
	&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_to_output_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hidden_to_output_weights&lt;/span&gt;
	&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_hidden_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
	&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
	&lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hidden_output&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	&lt;span class="sd"&gt;"""the output of the hidden layer"""&lt;/span&gt;
	&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_hidden_output&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_hidden_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vector_matrix_multiplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
		&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_hidden_output&lt;/span&gt;

    &lt;span class="nd"&gt;@property&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	&lt;span class="sd"&gt;"""Predictions for the inputs"""&lt;/span&gt;
	&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vector_matrix_multiplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
		&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_to_output_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_predictions&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;vector_matrix_multiplication&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				     &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	&lt;span class="sd"&gt;"""calculates the dot-product for each row of the matrix&lt;/span&gt;

&lt;span class="sd"&gt;	Args:&lt;/span&gt;
&lt;span class="sd"&gt;	 vector: input with one cell for each row in the matrix&lt;/span&gt;
&lt;span class="sd"&gt;	 matrix: input with rows of the same length as the vector&lt;/span&gt;

&lt;span class="sd"&gt;	Returns:&lt;/span&gt;
&lt;span class="sd"&gt;	 vector: dot-products for the vector and matrix rows&lt;/span&gt;
&lt;span class="sd"&gt;	"""&lt;/span&gt;
	&lt;span class="n"&gt;vector_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;vector_length&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
	&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot_product&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;dot_product&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vector_1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vector_2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
	&lt;span class="sd"&gt;"""Calculate the dot-product of the two vectors&lt;/span&gt;

&lt;span class="sd"&gt;	Returns:&lt;/span&gt;
&lt;span class="sd"&gt;	 dot-product: the dot product of the two vectors&lt;/span&gt;
&lt;span class="sd"&gt;	"""&lt;/span&gt;
	&lt;span class="n"&gt;vector_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vector_1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;vector_length&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vector_2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;entries&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vector_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;vector_1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;vector_2&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;entries&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgad432ce" class="outline-2"&gt;
&lt;h2 id="orgad432ce"&gt;Let's try it out&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgad432ce"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf2568ce" class="outline-3"&gt;
&lt;h3 id="orgf2568ce"&gt;The Input Layer To Hidden Layer Weights&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf2568ce"&gt;
&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Toes&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Wins&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Fans&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;0.1&lt;/td&gt;
&lt;td class="org-right"&gt;0.2&lt;/td&gt;
&lt;td class="org-right"&gt;-0.1&lt;/td&gt;
&lt;td class="org-left"&gt;h&lt;sub&gt;0&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;-0.1&lt;/td&gt;
&lt;td class="org-right"&gt;0.1&lt;/td&gt;
&lt;td class="org-right"&gt;0.9&lt;/td&gt;
&lt;td class="org-left"&gt;h&lt;sub&gt;1&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;0.1&lt;/td&gt;
&lt;td class="org-right"&gt;0.4&lt;/td&gt;
&lt;td class="org-right"&gt;0.1&lt;/td&gt;
&lt;td class="org-left"&gt;h&lt;sub&gt;2&lt;/sub&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			   &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			   &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbf2dc78" class="outline-3"&gt;
&lt;h3 id="orgbf2dc78"&gt;The Weights From the Hidden Layer to the Outputs&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbf2dc78"&gt;
&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;h0&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;h1&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;h2&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;0.3&lt;/td&gt;
&lt;td class="org-right"&gt;1.1&lt;/td&gt;
&lt;td class="org-right"&gt;-0.3&lt;/td&gt;
&lt;td class="org-left"&gt;hurt&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;0.1&lt;/td&gt;
&lt;td class="org-right"&gt;0.2&lt;/td&gt;
&lt;td class="org-right"&gt;0.0&lt;/td&gt;
&lt;td class="org-left"&gt;won&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;0.0&lt;/td&gt;
&lt;td class="org-right"&gt;1.3&lt;/td&gt;
&lt;td class="org-right"&gt;0.1&lt;/td&gt;
&lt;td class="org-left"&gt;sad&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;hidden_layer_to_output_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
				  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
				  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb37abdb" class="outline-3"&gt;
&lt;h3 id="orgb37abdb"&gt;Testing it Out&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb37abdb"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;toes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;8.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;9.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;9.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;9.0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;wins&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.65&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;fans&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;expected_hiddens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.86&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.295&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.23&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;expected_outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.214&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.145&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.507&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;first_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;toes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;wins&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;fans&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;network&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HiddenLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		       &lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		       &lt;span class="n"&gt;hidden_layer_to_output_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hidden_outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_output&lt;/span&gt;
&lt;span class="n"&gt;expected_actual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_hiddens&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_outputs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tolerance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"h0 h1 h2"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|Node | Expected | Actual"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|-+-+-|"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_actual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|{} | {}| {:.2f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;tolerance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Node&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Expected&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Actual&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;h0&lt;/td&gt;
&lt;td class="org-right"&gt;0.86&lt;/td&gt;
&lt;td class="org-right"&gt;0.86&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;h1&lt;/td&gt;
&lt;td class="org-right"&gt;0.295&lt;/td&gt;
&lt;td class="org-right"&gt;0.29&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;h2&lt;/td&gt;
&lt;td class="org-right"&gt;1.23&lt;/td&gt;
&lt;td class="org-right"&gt;1.23&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;
&lt;span class="n"&gt;expected_actual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_outputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tolerance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Hurt Won Sad"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|Node | Expected | Actual"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|-+-+-|"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_actual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|{} | {}| {:.3f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;tolerance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Node&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Expected&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Actual&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;Hurt&lt;/td&gt;
&lt;td class="org-right"&gt;0.214&lt;/td&gt;
&lt;td class="org-right"&gt;0.214&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Won&lt;/td&gt;
&lt;td class="org-right"&gt;0.145&lt;/td&gt;
&lt;td class="org-right"&gt;0.145&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Sad&lt;/td&gt;
&lt;td class="org-right"&gt;0.507&lt;/td&gt;
&lt;td class="org-right"&gt;0.506&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org91af9f2" class="outline-2"&gt;
&lt;h2 id="org91af9f2"&gt;Okay, but can we do that with numpy?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org91af9f2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;one_hidden_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""Converts arguments to numpy and calculates predictions&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;     inputs: array of inputs&lt;/span&gt;
&lt;span class="sd"&gt;     weights: matrix with two rows of weights&lt;/span&gt;

&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;     predictions: predicted values for each output node&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
One thing to watch out for here is that the dot product won't raise an error if you don't transpose the weights, but you will get the wrong values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;input_to_hidden_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	   &lt;span class="n"&gt;hidden_layer_to_output_weights&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;one_hidden_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;expected_actual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_outputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tolerance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Hurt Won Sad"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|Node | Expected | Actual"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|-+-+-|"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected_actual&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"|{} | {}| {:.3f}"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;tolerance&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Node&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Expected&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Actual&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;Hurt&lt;/td&gt;
&lt;td class="org-right"&gt;0.214&lt;/td&gt;
&lt;td class="org-right"&gt;0.214&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Won&lt;/td&gt;
&lt;td class="org-right"&gt;0.145&lt;/td&gt;
&lt;td class="org-right"&gt;0.145&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Sad&lt;/td&gt;
&lt;td class="org-right"&gt;0.507&lt;/td&gt;
&lt;td class="org-right"&gt;0.506&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org64969d7" class="outline-2"&gt;
&lt;h2 id="org64969d7"&gt;Okay, so what was this about again?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org64969d7"&gt;
&lt;p&gt;
This showed that you can stack networks up and have the outputs of one layer feed into the next until you reach the output layer. This is called &lt;i&gt;Forward Propagation&lt;/i&gt;. Although I mentioned deep-learning in the title this really isn't an example yet, it's more like a multilayer perceptron, but it's deeper than two-layers, anyway.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>deep learning</category><category>grokking</category><category>hidden layers</category><category>neural networks</category><guid>https://necromuralist.github.io/In-Too-Deep/posts/grokking/03_forward_propagation/okay-but-what-about-this-deep-learning-stuff/</guid><pubDate>Wed, 24 Oct 2018 20:26:12 GMT</pubDate></item></channel></rss>