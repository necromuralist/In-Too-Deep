<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Neurotic Networking (Posts about book notes)</title><link>https://necromuralist.github.io/Neurotic-Networking/</link><description></description><atom:link href="https://necromuralist.github.io/Neurotic-Networking/categories/book-notes.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2020 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sun, 21 Jun 2020 23:45:48 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>How Do Machines Learn?</title><link>https://necromuralist.github.io/Neurotic-Networking/posts/grokking/how-do-machines-learn/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-org6a2b729" class="outline-2"&gt;
&lt;h2 id="org6a2b729"&gt;What is this?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6a2b729"&gt;
&lt;p&gt;
I'm reading &lt;a href="https://www.manning.com/books/grokking-deep-learning"&gt;Grokking Deep Learning&lt;/a&gt; and am going to put my notes here. This is from Chapter 2 - &lt;i&gt;How Do Machines Learn&lt;/i&gt;?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7ab9d7f" class="outline-2"&gt;
&lt;h2 id="org7ab9d7f"&gt;What is Deep Learning?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7ab9d7f"&gt;
&lt;p&gt;
Deep learning is a sub-field of &lt;i&gt;Machine Learning&lt;/i&gt; that primarily use &lt;i&gt;Artificial Neural Networks&lt;/i&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5271d87" class="outline-2"&gt;
&lt;h2 id="org5271d87"&gt;What is Machine Learning?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5271d87"&gt;
&lt;p&gt;
Machine Learning is a sub-field of computer science where computers learn to do things that they weren't explicitly programmed to do. Their main goal is to map a data set to some other useful data set.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org203ee47" class="outline-2"&gt;
&lt;h2 id="org203ee47"&gt;What is Supervised Learning?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org203ee47"&gt;
&lt;p&gt;
Supervised Learning methods transforms one dataset into another. They take what we already know and try to come up with what we want to know.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb76c4ca" class="outline-2"&gt;
&lt;h2 id="orgb76c4ca"&gt;What is Unsupervised Learning?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgb76c4ca"&gt;
&lt;p&gt;
Unsupervised Learring methods group your data. They take your data and try to come up with labels for clusters within the data.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgde93e74" class="outline-2"&gt;
&lt;h2 id="orgde93e74"&gt;What are Parametric and Non-Parametric Learning?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgde93e74"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9f6980e" class="outline-3"&gt;
&lt;h3 id="org9f6980e"&gt;What is Parametric Learning?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9f6980e"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Parametric: trial-and-error (has a fixed number of parameters)&lt;/li&gt;
&lt;li&gt;Non-Parametric: counting and probability (has an infinite number of parameters)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
The classifications &lt;i&gt;Supervised&lt;/i&gt; and &lt;i&gt;Unsupervised&lt;/i&gt; refers to the pattern that is being learned, while &lt;i&gt;Parametric&lt;/i&gt; vs &lt;i&gt;Non-Parametric&lt;/i&gt; is about the way what's learned is stored.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdc66eb2" class="outline-4"&gt;
&lt;h4 id="orgdc66eb2"&gt;What is Supervised Parametric Learning?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgdc66eb2"&gt;
&lt;p&gt;
Trial and error learning that tunes your model's knobs.
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Step One: Make a prediction using your data&lt;/li&gt;
&lt;li&gt;Step Two: Compare your predictions to the real answer&lt;/li&gt;
&lt;li&gt;Step Three: Change your model based on how you did - make it more or less sensitive to each of the parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbb34481" class="outline-4"&gt;
&lt;h4 id="orgbb34481"&gt;What is Unsupervised Parametric Learning?&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgbb34481"&gt;
&lt;p&gt;
It's parametric, so it has knobs to twiddle when finding groups, but the knobs are used to tune the input data's likelihood of being in a group.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5df824b" class="outline-3"&gt;
&lt;h3 id="org5df824b"&gt;What is Non-Parametric Learnining?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5df824b"&gt;
&lt;p&gt;
These are counting-based methods - the number of parameters depends on the data. If you have a set of labels relating to an outcome, each label might be a parameter and your model would count how many times each label lead to the outcome you're watching.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>book notes</category><category>grokking</category><category>machine learning</category><guid>https://necromuralist.github.io/Neurotic-Networking/posts/grokking/how-do-machines-learn/</guid><pubDate>Wed, 17 Oct 2018 19:13:54 GMT</pubDate></item></channel></rss>