<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Studies in Deep Learning." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Neurotic Networking (old posts, page 3) | Neurotic Networking</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Neurotic-Networking/index-3.html" rel="canonical">
<link href="index-4.html" rel="prev" type="text/html">
<link href="index-2.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180">
<link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="site.webmanifest" rel="manifest">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Neurotic-Networking/"><span id="blog-title">Neurotic Networking</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="rss.xml">RSS feed</a></li>
<li class="nav-item"><a class="nav-link" href="https://necromuralist.github.io/">Cloistered Monkey</a></li>
</ul>
<!-- Google custom search -->
<form action="https://www.google.com/search" class="navbar-form navbar-right" method="get" role="search">
<div class="form-group"><input class="form-control" name="q" placeholder="Search" type="text"></div>
<!-- 
<button type="submit" class="btn btn-primary">
        <span class="glyphicon glyphicon-search"></span>
</button>
-->
<input name="sitesearch" type="hidden" value="https://necromuralist.github.io/Neurotic-Networking/"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/sentiment_analysis/removing-noise/">Removing Noise</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/sentiment_analysis/removing-noise/" rel="bookmark"><time class="published dt-published" datetime="2018-11-11T16:30:38-08:00" itemprop="datePublished" title="2018-11-11 16:30">2018-11-11 16:30</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/sentiment_analysis/removing-noise/#orga15c972">Set Up</a></li>
<li><a href="posts/nano/sentiment_analysis/removing-noise/#org292e015">Understanding Neural Noise</a></li>
<li><a href="posts/nano/sentiment_analysis/removing-noise/#org238525c">Reducing Noise in Our Input Data</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orga15c972">
<h2 id="orga15c972">Set Up</h2>
<div class="outline-text-2" id="text-orga15c972"></div>
<div class="outline-3" id="outline-container-org001b49d">
<h3 id="org001b49d">Imports</h3>
<div class="outline-text-3" id="text-org001b49d"></div>
<div class="outline-4" id="outline-container-org2e09486">
<h4 id="org2e09486">Python</h4>
<div class="outline-text-4" id="text-org2e09486">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">pickle</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org591c4ea">
<h4 id="org591c4ea">PyPy</h4>
<div class="outline-text-4" id="text-org591c4ea">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcfdebf0">
<h4 id="orgcfdebf0">This Project</h4>
<div class="outline-text-4" id="text-orgcfdebf0">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">network_helpers</span> <span class="kn">import</span> <span class="n">update_input_layer</span>
<span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPath</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org998be4b">
<h3 id="org998be4b">Constants</h3>
<div class="outline-text-3" id="text-org998be4b">
<div class="highlight">
<pre><span></span><span class="n">SPLIT_ON_THIS</span> <span class="o">=</span> <span class="s2">" "</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org292e015">
<h2 id="org292e015">Understanding Neural Noise</h2>
<div class="outline-text-2" id="text-org292e015">
<p>We're going to try and figure out why the Neural Network isn't improving as much as we want it to. First, let's checkout the first review.</p>
</div>
<div class="outline-3" id="outline-container-org1b7410f">
<h3 id="org1b7410f">The Pickles</h3>
<div class="outline-text-3" id="text-org1b7410f">
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"total_counts.pkl"</span><span class="p">)</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">total_counts</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_counts</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"reviews.pkl"</span><span class="p">)</span>
<span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">reviews</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">total_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="n">word2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">counter</span> <span class="o">=</span> <span class="n">update_input_layer</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">layer_0</span><span class="p">,</span> <span class="n">word2index</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">layer_0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
<pre class="example">
[27.0, 15.0, 9.0, 6.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0]

</pre>
<p>So it looks like two of the words in the first review have a disproportionate representation. Lets see what they are.</p>
<div class="highlight">
<pre><span></span><span class="n">table</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">print_most_common</span><span class="p">(</span><span class="n">counter</span><span class="p">:</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""Prints most common tokens as an org-tabel"""</span>
    <span class="n">tokens</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="n">bottom</span><span class="p">)[:</span><span class="n">count</span><span class="p">]:</span>
        <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="n">counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Token</span><span class="o">=</span><span class="n">tokens</span><span class="p">,</span> <span class="n">Count</span><span class="o">=</span><span class="n">counts</span><span class="p">)))</span>
    <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">print_most_common</span><span class="p">(</span><span class="n">counter</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-right" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&nbsp;</td>
<td class="org-right">15</td>
</tr>
<tr>
<td class="org-left">.</td>
<td class="org-right">27</td>
</tr>
<tr>
<td class="org-left">a</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">about</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">adults</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">age</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">all</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">and</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">as</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">at</td>
<td class="org-right">2</td>
</tr>
</tbody>
</table>
<p>So, as I noted before, the dominant tokens aren't revealing as far as sentiment goes. A smarter tokenizer would probably have helped.</p>
<div class="highlight">
<pre><span></span><span class="n">print_most_common</span><span class="p">(</span><span class="n">total_counts</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-right" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&nbsp;</td>
<td class="org-right">1049343</td>
</tr>
<tr>
<td class="org-left">.</td>
<td class="org-right">327192</td>
</tr>
<tr>
<td class="org-left">a</td>
<td class="org-right">163009</td>
</tr>
<tr>
<td class="org-left">aa</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">aaa</td>
<td class="org-right">9</td>
</tr>
<tr>
<td class="org-left">aaaaaaah</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">aaaaah</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">aaaaatch</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">aaaahhhhhhh</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">aaaand</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>
<p>You can see that it gets even worse when you look at the overall corpus. All these unuseful tokens are adding too much noise to the dataset.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org238525c">
<h2 id="org238525c">Reducing Noise in Our Input Data</h2>
<div class="outline-text-2" id="text-org238525c">
<p>Rather than using a tokenizer that knows stop-words, punctuation, etc. we're going to just stop using counts and rely on the neural network to figure out which weights between the input layer and the hidden layer to zero-out. To do this we just have to convert the inputs from word counts to just binary inputs (is the token in the review or not)?</p>
<p>I'm going to keep extending this class so I'll tangle it out so I can import it elsewhere so the next two blocks are actually in a module named <code>sentiment_renetwork</code>.</p>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sentiment_network</span> <span class="kn">import</span> <span class="n">SentimentNetwork</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">SentimentRenetwork</span><span class="p">(</span><span class="n">SentimentNetwork</span><span class="p">):</span>
    <span class="sd">"""Re-do of the Sentiment Network</span>

<span class="sd">    .. uml::</span>

<span class="sd">       SentimentRenetwork --|&gt; SentimentNetwork</span>

<span class="sd">    This is a re-implementation that doesn't use counts as inputs</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="nf">update_input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="sd">"""Update the counts in the input layer</span>

<span class="sd">       Args:</span>
<span class="sd">        review: A movie review</span>
<span class="sd">       """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">*=</span> <span class="mi">0</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_to_index</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_to_index</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sentiment_renetwork</span> <span class="kn">import</span> <span class="n">SentimentRenetwork</span>
<span class="n">sentimental</span> <span class="o">=</span> <span class="n">SentimentRenetwork</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"x_train.pkl"</span><span class="p">)</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>

<span class="k">with</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"y_train.pkl"</span><span class="p">)</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">sentimental</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<pre class="example">
Progress: 0.00 % Speed(reviews/sec): 0.00 Error: [-0.5] #Correct: 1 #Trained: 1 Training Accuracy: 100.00 %
Progress: 4.17 % Speed(reviews/sec): 250.00 Error: [-0.12803969] #Correct: 745 #Trained: 1001 Training Accuracy: 74.43 %
Progress: 8.33 % Speed(reviews/sec): 285.71 Error: [-0.05466563] #Correct: 1542 #Trained: 2001 Training Accuracy: 77.06 %
Progress: 12.50 % Speed(reviews/sec): 300.00 Error: [-0.76659525] #Correct: 2378 #Trained: 3001 Training Accuracy: 79.24 %
Progress: 16.67 % Speed(reviews/sec): 285.71 Error: [-0.13244093] #Correct: 3185 #Trained: 4001 Training Accuracy: 79.61 %
Progress: 20.83 % Speed(reviews/sec): 294.12 Error: [-0.03716464] #Correct: 3997 #Trained: 5001 Training Accuracy: 79.92 %
Progress: 25.00 % Speed(reviews/sec): 300.00 Error: [-0.00921009] #Correct: 4835 #Trained: 6001 Training Accuracy: 80.57 %
Progress: 29.17 % Speed(reviews/sec): 304.35 Error: [-0.00274399] #Correct: 5703 #Trained: 7001 Training Accuracy: 81.46 %
Progress: 33.33 % Speed(reviews/sec): 307.69 Error: [-0.0040905] #Correct: 6555 #Trained: 8001 Training Accuracy: 81.93 %
Progress: 37.50 % Speed(reviews/sec): 300.00 Error: [-0.02414385] #Correct: 7412 #Trained: 9001 Training Accuracy: 82.35 %
Progress: 41.67 % Speed(reviews/sec): 303.03 Error: [-0.11133286] #Correct: 8282 #Trained: 10001 Training Accuracy: 82.81 %
Progress: 45.83 % Speed(reviews/sec): 305.56 Error: [-0.05147756] #Correct: 9143 #Trained: 11001 Training Accuracy: 83.11 %
Progress: 50.00 % Speed(reviews/sec): 300.00 Error: [-0.00178148] #Correct: 10006 #Trained: 12001 Training Accuracy: 83.38 %
Progress: 54.17 % Speed(reviews/sec): 302.33 Error: [-0.3016099] #Correct: 10874 #Trained: 13001 Training Accuracy: 83.64 %
Progress: 58.33 % Speed(reviews/sec): 304.35 Error: [-0.00105685] #Correct: 11741 #Trained: 14001 Training Accuracy: 83.86 %
Progress: 62.50 % Speed(reviews/sec): 306.12 Error: [-0.49072786] #Correct: 12584 #Trained: 15001 Training Accuracy: 83.89 %
Progress: 66.67 % Speed(reviews/sec): 307.69 Error: [-0.18036635] #Correct: 13414 #Trained: 16001 Training Accuracy: 83.83 %
Progress: 70.83 % Speed(reviews/sec): 309.09 Error: [-0.17892538] #Correct: 14265 #Trained: 17001 Training Accuracy: 83.91 %
Progress: 75.00 % Speed(reviews/sec): 305.08 Error: [-0.00702446] #Correct: 15127 #Trained: 18001 Training Accuracy: 84.03 %
Progress: 79.17 % Speed(reviews/sec): 306.45 Error: [-0.99885025] #Correct: 16000 #Trained: 19001 Training Accuracy: 84.21 %
Progress: 83.33 % Speed(reviews/sec): 307.69 Error: [-0.02833534] #Correct: 16873 #Trained: 20001 Training Accuracy: 84.36 %
Progress: 87.50 % Speed(reviews/sec): 308.82 Error: [-0.22776195] #Correct: 17746 #Trained: 21001 Training Accuracy: 84.50 %
Progress: 91.67 % Speed(reviews/sec): 305.56 Error: [-0.22165232] #Correct: 18630 #Trained: 22001 Training Accuracy: 84.68 %
Progress: 95.83 % Speed(reviews/sec): 306.67 Error: [-0.13901935] #Correct: 19489 #Trained: 23001 Training Accuracy: 84.73 %
Training Time: 0:01:18.649050
</pre>
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"sentimental_renetwork.pkl"</span><span class="p">,</span> <span class="n">check_exists</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">sentimental</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
<p>Here's how well it does on the test-set.</p>
<div class="highlight">
<pre><span></span><span class="n">sentimental</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
<pre class="example">
Progress: 0.00% Speed(reviews/sec): 0.00 #Correct: 1 #Tested: 1 Testing Accuracy: 100.00 %
Progress: 10.00% Speed(reviews/sec): 0.00 #Correct: 92 #Tested: 101 Testing Accuracy: 91.09 %
Progress: 20.00% Speed(reviews/sec): 0.00 #Correct: 178 #Tested: 201 Testing Accuracy: 88.56 %
Progress: 30.00% Speed(reviews/sec): 0.00 #Correct: 268 #Tested: 301 Testing Accuracy: 89.04 %
Progress: 40.00% Speed(reviews/sec): 0.00 #Correct: 351 #Tested: 401 Testing Accuracy: 87.53 %
Progress: 50.00% Speed(reviews/sec): 0.00 #Correct: 442 #Tested: 501 Testing Accuracy: 88.22 %
Progress: 60.00% Speed(reviews/sec): 0.00 #Correct: 533 #Tested: 601 Testing Accuracy: 88.69 %
Progress: 70.00% Speed(reviews/sec): 0.00 #Correct: 610 #Tested: 701 Testing Accuracy: 87.02 %
Progress: 80.00% Speed(reviews/sec): 0.00 #Correct: 689 #Tested: 801 Testing Accuracy: 86.02 %
Progress: 90.00% Speed(reviews/sec): 0.00 #Correct: 777 #Tested: 901 Testing Accuracy: 86.24 %
</pre>
<p>Oddly, it does better on the test set than the training set?</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/pytorch/tensors-in-pytorch/">Tensors In PyTorch</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/pytorch/tensors-in-pytorch/" rel="bookmark"><time class="published dt-published" datetime="2018-11-11T16:02:32-08:00" itemprop="datePublished" title="2018-11-11 16:02">2018-11-11 16:02</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org7ed9e11">Introduction to Deep Learning with PyTorch</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org0d61fe1">Neural Networks</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org2063463">Tensors</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#orga51e9e4">Imports</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org971ccf2">The Activation Function</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#orgdd92c84">Generate some data</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org045e98f">Stack them up!</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org8cc4730">Generate some data</a></li>
<li><a href="posts/nano/pytorch/tensors-in-pytorch/#org42ca59d">Numpy to Torch and back</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org7ed9e11">
<h2 id="org7ed9e11">Introduction to Deep Learning with PyTorch</h2>
<div class="outline-text-2" id="text-org7ed9e11">
<p>In this notebook, you'll get introduced to <a href="http://pytorch.org/">PyTorch</a>, a framework for building and training neural networks. PyTorch, in a lot of ways, behaves like the arrays you love from Numpy. These Numpy arrays, after all, are just tensors. PyTorch takes these tensors and makes it simple to move them to GPUs for the faster processing needed when training neural networks. It also provides a module that automatically calculates gradients (for backpropagation!) and another module specifically for building neural networks. All together, PyTorch ends up being more coherent with Python and the Numpy/Scipy stack compared to TensorFlow and other frameworks.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org0d61fe1">
<h2 id="org0d61fe1">Neural Networks</h2>
<div class="outline-text-2" id="text-org0d61fe1">
<p>Deep Learning is based on artificial neural networks which have been around in some form since the late 1950s. The networks are built from individual parts approximating neurons, typically called units or simply "neurons." Each unit has some number of weighted inputs. These weighted inputs are summed together (a linear combination) then passed through an activation function to get the unit's output.</p>
<p>Mathematically this looks like:</p>
<p>\[ y = f(w_1 x_1 + w_2 x_2 + b) \\ y = f\left(\sum_i w_i x_i +b \right) \]</p>
<p>With vectors this is the dot/inner product of two vectors:</p>
<p>$$ h = x_1 , x_2 ⋅ x_n<br>
⋅</p>
\begin{bmatrix} w_1 \\ w_2 \\ \vdots \\ w_n \end{bmatrix}
<p>$$</p>
</div>
</div>
<div class="outline-2" id="outline-container-org2063463">
<h2 id="org2063463">Tensors</h2>
<div class="outline-text-2" id="text-org2063463">
<p>It turns out neural network computations are just a bunch of linear algebra operations on <b>tensors</b>, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.</p>
<p>Now that we have the basics covered, it's time to explore how we can use PyTorch to build a simple neural network.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orga51e9e4">
<h2 id="orga51e9e4">Imports</h2>
<div class="outline-text-2" id="text-orga51e9e4"></div>
<div class="outline-3" id="outline-container-org01c7638">
<h3 id="org01c7638">From PyPi</h3>
<div class="outline-text-3" id="text-org01c7638">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org971ccf2">
<h2 id="org971ccf2">The Activation Function</h2>
<div class="outline-text-2" id="text-org971ccf2">
<p>Using <a href="https://pytorch.org/docs/stable/torch.html?highlight=exp#torch.exp">pytorch's exp</a> function looks a lot like it did with numpy.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">activation</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">""" Sigmoid activation function </span>

<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>
<span class="sd">       x: torch.Tensor</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-orgdd92c84">
<h2 id="orgdd92c84">Generate some data</h2>
<div class="outline-text-2" id="text-orgdd92c84">
<p><a href="https://pytorch.org/docs/stable/torch.html?highlight=exp#torch.exp">Set the random seed</a> so things are predictable.</p>
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-orga9d21d1">
<h3 id="orga9d21d1">Features</h3>
<div class="outline-text-3" id="text-orga9d21d1">
<p>Our features will be a tensor of 3 random normal variables created with <a href="https://pytorch.org/docs/stable/torch.html?highlight=randn#torch.randn">torch.randn</a>.</p>
<div class="highlight">
<pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org689639f">
<h3 id="org689639f">True weights for our data, random normal variables again</h3>
<div class="outline-text-3" id="text-org689639f">
<p><a href="https://pytorch.org/docs/stable/torch.html?highlight=randn_like#torch.randn_like">randn_like</a> creates a tensor of random numbers that is the same size as the tensor it is given.</p>
<div class="highlight">
<pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcfd3f19">
<h3 id="orgcfd3f19">And a true bias term.</h3>
<div class="outline-text-3" id="text-orgcfd3f19">
<div class="highlight">
<pre><span></span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
<p>Above I generated data we can use to get the output of our simple network. This is all just random for now, going forward we'll start using normal data. Going through each relevant line:</p>
<p>`features = torch.randn((1, 5))` creates a tensor with shape `(1, 5)`, one row and five columns, that contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one.</p>
<p>`weights = torch.randn_like(features)` creates another tensor with the same shape as `features`, again containing values from a normal distribution.</p>
<p>Finally, `bias = torch.randn((1, 1))` creates a single value from a normal distribution.</p>
<p>PyTorch tensors can be added, multiplied, subtracted, etc, just like Numpy arrays. In general, you'll use PyTorch tensors pretty much the same way you'd use Numpy arrays. They come with some nice benefits though such as GPU acceleration which we'll get to later. For now, use the generated data to calculate the output of this simple single layer network.</p>
<p><b>Exercise</b>: Calculate the output of the network with input features `features`, weights `weights`, and bias `bias`. Similar to Numpy, PyTorch has a <a href="https://pytorch.org/docs/stable/torch.html#torch.sum"><code>torch.sum()</code></a> function, as well as a `.sum()` method on tensors, for taking sums. Use the function `activation` defined above as the activation function.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org25ce0ef">
<h3 id="org25ce0ef">Calculate the output of this network using the weights and bias tensors</h3>
<div class="outline-text-3" id="text-org25ce0ef">
<p>You can do the multiplication and sum in the same operation using a matrix multiplication. In general, you'll want to use matrix multiplications since they are more efficient and accelerated using modern libraries and high-performance computing on GPUs.</p>
<p>Here, we want to do a matrix multiplication of the features and the weights. For this we can use [`torch.mm()`] or <a href="https://pytorch.org/docs/stable/torch.html#torch.mm"><code>torch.matmul()</code></a> which is somewhat more complicated and supports broadcasting. If we try to do it with `features` and `weights` as they are, we'll get an error:</p>
<pre class="example">
torch.mm(features, weights);
 
 ---------------------------------------------------------------------------
 RuntimeError                              Traceback (most recent call last)
 &lt;python-input-13-15d592eb5279&gt; in &lt;module&gt;()
 ----&gt; 1 torch.mm(features, weights)
 
 RuntimeError: size mismatch, m1: [1 x 5], m2: [1 x 5] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:2033
</pre>
<p>As you're building neural networks in any framework, you'll see this often. Really often. What's happening here is our tensors aren't the correct shapes to perform a matrix multiplication. Remember that for matrix multiplications, the number of columns in the first tensor must equal to the number of rows in the second column. Both `features` and `weights` have the same shape, `(1, 5)`. This means we need to change the shape of `weights` to get the matrix multiplication to work.</p>
<p><b>Note:</b> To see the shape of a tensor called `tensor`, use `tensor.shape`. If you're building neural networks, you'll be using this method often.</p>
<p>There are a few options here: <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape"><code>weights.reshape()</code></a>, <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_"><code>weights.resize_()</code></a>, and <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view"><code>weights.view()</code></a>.</p>
<p>-`weights.reshape(a, b)` will return a new tensor with the same data as `weights` with size `(a, b)` sometimes, and sometimes a clone, as in it copies the data to another part of memory.</p>
<ul class="org-ul">
<li>`weights.resize_(a, b)` returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed <b>in-place</b>. Here is a great forum thread to <a href="https://discuss.pytorch.org/t/what-is-in-place-operation/16244">read more about in-place operations</a> in PyTorch.</li>
<li>`weights.view(a, b)` will return a new tensor with the same data as `weights` with size `(a, b)`.</li>
</ul>
<p>I usually use `.view()`, but any of the three methods will work for this. So, now we can reshape `weights` to have five rows and one column with something like `weights.view(5, 1)`.</p>
<p><b>Exercise</b>: Calculate the output of our little network using matrix multiplication.</p>
<div class="highlight">
<pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">product</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">product</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">activation</span><span class="p">(</span><span class="n">total</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>
<pre class="example">
tensor(0.1595)

</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org045e98f">
<h2 id="org045e98f">Stack them up!</h2>
<div class="outline-text-2" id="text-org045e98f">
<p>That's how you can calculate the output for a single neuron. The real power of this algorithm happens when you start stacking these individual units into layers and stacks of layers, into a network of neurons. The output of one layer of neurons becomes the input for the next layer. With multiple input units and output units, we now need to express the weights as a matrix.</p>
<p>The first layer shown on the bottom here are the inputs, understandably called the <b>input layer</b>. The middle layer is called the <b>hidden layer</b>, and the final layer (on the right) is the <b>output layer</b>. We can express this network mathematically with matrices again and use matrix multiplication to get linear combinations for each unit in one operation. For example, the hidden layer (\(h_1\) and \(h_2\) here) can be calculated</p>
<p>\[ \vec{h} = [h_1 \, h_2] =</p>
\begin{bmatrix} x_1 \, x_2 \cdots \, x_n \end{bmatrix}
<p>⋅</p>
\begin{bmatrix} w_{11} & w_{12} \\ w_{21} &amp;w_{22} \\ \vdots &amp;\vdots \\ w_{n1} &amp;w_{n2} \end{bmatrix}
<p>\]</p>
<p>The output for this small network is found by treating the hidden layer as inputs for the output unit. The network output is expressed simply</p>
<p>\[ y = f_2 \! \left(\, f_1 \! \left(\vec{x} \, \mathbf{W_1}\right) \mathbf{W_2} \right) \]</p>
</div>
</div>
<div class="outline-2" id="outline-container-org8cc4730">
<h2 id="org8cc4730">Generate some data</h2>
<div class="outline-text-2" id="text-org8cc4730">
<p>Set the random seed so things are predictable</p>
<div class="highlight">
<pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
<p>The features are 3 random normal variables that will be your input.</p>
<div class="highlight">
<pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
<p>Define the size of each layer in our network</p>
<div class="highlight">
<pre><span></span><span class="n">n_input</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>     <span class="c1"># Number of input units, must match number of input features</span>
<span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">2</span>                    <span class="c1"># Number of hidden units </span>
<span class="n">n_output</span> <span class="o">=</span> <span class="mi">1</span>                    <span class="c1"># Number of output units</span>
</pre></div>
<p>Weights for inputs to hidden layer</p>
<div class="highlight">
<pre><span></span><span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
</pre></div>
<p>Weights for hidden layer to output layer</p>
<div class="highlight">
<pre><span></span><span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">)</span>
</pre></div>
<p>and bias terms for hidden and output layers</p>
<div class="highlight">
<pre><span></span><span class="n">B1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">))</span>
<span class="n">B2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_output</span><span class="p">))</span>
</pre></div>
<p><b>Exercise:</b> Calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`.</p>
<div class="highlight">
<pre><span></span><span class="n">input_layer_out</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">W1</span><span class="p">))</span> <span class="o">+</span> <span class="n">B1</span>
<span class="n">hidden_layer_out</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer_out</span><span class="p">,</span> <span class="n">W2</span><span class="p">))</span> <span class="o">+</span> <span class="n">B2</span>
<span class="k">print</span><span class="p">(</span><span class="n">hidden_layer_out</span><span class="p">)</span>
</pre></div>
<pre class="example">
tensor([[0.4813]])

</pre>
<div class="highlight">
<pre><span></span><span class="n">expected</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.4813</span><span class="p">]])</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">hidden_layer_out</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">expected</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.000305</span><span class="p">)</span>
</pre></div>
<p>If you did this correctly, you should see the output <code>tensor([[ 0.4813]])</code>.</p>
<p>The number of hidden units a parameter of the network, often called a <b>hyperparameter</b> to differentiate it from the weights and biases parameters. As you'll see later when we discuss training a neural network, the more hidden units a network has, and the more layers, the better able it is to learn from data and make accurate predictions.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org42ca59d">
<h2 id="org42ca59d">Numpy to Torch and back</h2>
<div class="outline-text-2" id="text-org42ca59d">
<p>Special bonus section! PyTorch has a great feature for converting between Numpy arrays and Torch tensors. To create a tensor from a Numpy array, use <a href="https://pytorch.org/docs/stable/torch.html?highlight=from_numpy#torch.from_numpy">torch.from_numpy()</a>. To convert a tensor to a Numpy array, use the <a href="https://pytorch.org/docs/stable/tensors.html?highlight=numpy#torch.Tensor.numpy">.numpy()</a> method.</p>
<div class="highlight">
<pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
<pre class="example">
[[0.07665652 0.06831265 0.7607324 ]
 [0.71495335 0.34479699 0.67489027]
 [0.45834284 0.78789824 0.40383355]
 [0.28864364 0.21713754 0.62036028]]

</pre>
<div class="highlight">
<pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
<pre class="example">
tensor([[0.0767, 0.0683, 0.7607],
        [0.7150, 0.3448, 0.6749],
        [0.4583, 0.7879, 0.4038],
        [0.2886, 0.2171, 0.6204]], dtype=torch.float64)

</pre>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
<pre class="example">
[[0.07665652 0.06831265 0.7607324 ]
 [0.71495335 0.34479699 0.67489027]
 [0.45834284 0.78789824 0.40383355]
 [0.28864364 0.21713754 0.62036028]]

</pre>
<p>The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well.</p>
<p><i>Multiply PyTorch Tensor by 2, in place</i></p>
<div class="highlight">
<pre><span></span><span class="n">b</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
<p>Numpy array matches new values from Tensor</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
<pre class="example">
[[0.15331305 0.1366253  1.52146479]
 [1.4299067  0.68959399 1.34978053]
 [0.91668568 1.57579648 0.80766711]
 [0.57728729 0.43427509 1.24072056]]

</pre></div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/sentiment_analysis/the-sentiment-analyzer/">The Sentiment Analyzer</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/sentiment_analysis/the-sentiment-analyzer/" rel="bookmark"><time class="published dt-published" datetime="2018-11-11T15:10:27-08:00" itemprop="datePublished" title="2018-11-11 15:10">2018-11-11 15:10</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/sentiment_analysis/the-sentiment-analyzer/#org4ee66ed">Set Up</a></li>
<li><a href="posts/nano/sentiment_analysis/the-sentiment-analyzer/#orgad97aea">Encapsulate our neural network in a class</a></li>
<li><a href="posts/nano/sentiment_analysis/the-sentiment-analyzer/#org28ea96f">Test The Network</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4ee66ed">
<h2 id="org4ee66ed">Set Up</h2>
<div class="outline-text-2" id="text-org4ee66ed"></div>
<div class="outline-3" id="outline-container-org6b53b9f">
<h3 id="org6b53b9f">Imports</h3>
<div class="outline-text-3" id="text-org6b53b9f"></div>
<div class="outline-4" id="outline-container-org9da84d4">
<h4 id="org9da84d4">Python</h4>
<div class="outline-text-4" id="text-org9da84d4">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2dd89a6">
<h4 id="org2dd89a6">This Project</h4>
<div class="outline-text-4" id="text-org2dd89a6">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPath</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org35bfb25">
<h3 id="org35bfb25">The Data</h3>
<div class="outline-text-3" id="text-org35bfb25">
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"reviews.pkl"</span><span class="p">)</span>
<span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">reviews</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org234520a">
<h3 id="org234520a">The Labels</h3>
<div class="outline-text-3" id="text-org234520a">
<p>A similar deal except casting the labels to upper case.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"labels.pkl"</span><span class="p">)</span>
<span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
<p><b>Note:</b> The data in <code>reviews.txt</code> we're using has already been preprocessed a bit and contains only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgad97aea">
<h2 id="orgad97aea">Encapsulate our neural network in a class</h2>
<div class="outline-text-2" id="text-orgad97aea">
<p>I'm going to try and break up the class so that I can make notes. You can't really do that in a notebook, though, so I'm going to tangle it out. The following Class is going to end up in a module named <code>sentiment_network</code>.</p>
<div class="highlight">
<pre><span></span><span class="o">&lt;&lt;</span><span class="n">imports</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">constants</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">review</span><span class="o">-</span><span class="n">vocabulary</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">review</span><span class="o">-</span><span class="n">vocabulary</span><span class="o">-</span><span class="n">size</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">label</span><span class="o">-</span><span class="n">vocabulary</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">label</span><span class="o">-</span><span class="n">vocabulary</span><span class="o">-</span><span class="n">size</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">word</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">index</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">label</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">index</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="n">nodes</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">weights</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">hidden</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">weights</span><span class="o">-</span><span class="n">hidden</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">output</span><span class="o">&gt;&gt;</span>

    <span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="n">layer</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">update</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="n">layer</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">get</span><span class="o">-</span><span class="n">target</span><span class="o">-</span><span class="k">for</span><span class="o">-</span><span class="n">label</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">sigmoid</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">sigmoid</span><span class="o">-</span><span class="n">output</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="n">derivative</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">train</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">test</span><span class="o">&gt;&gt;</span>

<span class="o">&lt;&lt;</span><span class="n">sentiment</span><span class="o">-</span><span class="n">network</span><span class="o">-</span><span class="n">run</span><span class="o">&gt;&gt;</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org7fda599">
<h3 id="org7fda599">Imports</h3>
<div class="outline-text-3" id="text-org7fda599">
<div class="highlight">
<pre><span></span><span class="c1"># From python</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="p">)</span>
<span class="c1"># from pypi</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org89c85c4">
<h3 id="org89c85c4">Constants</h3>
<div class="outline-text-3" id="text-org89c85c4">
<div class="highlight">
<pre><span></span><span class="n">SPLIT_ON_THIS</span> <span class="o">=</span> <span class="s2">" "</span>
<span class="n">Review</span> <span class="o">=</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
<span class="n">Label</span> <span class="o">=</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
<span class="n">Classification</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0d3588d">
<h3 id="org0d3588d">Sentiment Network Constructor</h3>
<div class="outline-text-3" id="text-org0d3588d">
<p>To make this more like a SKlearn implementation I'm not going to add the training and testing data at this point. This will break one of the examples given. Oh well.</p>
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">SentimentNetwork</span><span class="p">:</span>
    <span class="sd">"""A network to predict if a review is positive or negative</span>

<span class="sd">    Args:</span>
<span class="sd">     hidden_nodes: Number of nodes to create in the hidden layer</span>
<span class="sd">     learning_rate: Learning rate to use while training        </span>
<span class="sd">     output_nodes: Number of output nodes (should always be 1)</span>
<span class="sd">     tokenizer: what to split on</span>
<span class="sd">     verbose: whether to output update information</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">hidden_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                 <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">output_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">tokenizer</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s2">" "</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Assign a seed to our random number generator to ensure we get</span>
        <span class="c1"># reproducable results during development </span>
        <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary_size</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary_size</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_word_to_index</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_to_index</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_nodes</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_layer</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0bb574b">
<h3 id="org0bb574b">The Review Vocabulary</h3>
<div class="outline-text-3" id="text-org0bb574b">
<p>This takes the training reviews and tokenizes them so we have a set of unique tokens to work with. This requires that <code>self.reviews</code> and <code>self.tokenizer</code> are set.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">review_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="sd">"""list of tokens in the reviews"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">vocabulary</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reviews</span><span class="p">:</span>
            <span class="n">vocabulary</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5e1e32c">
<h3 id="org5e1e32c">The Review Vocabulary Size</h3>
<div class="outline-text-3" id="text-org5e1e32c">
<p>This is the number of tokens we ended up with after tokenizing the training reviews.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">review_vocabulary_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""The amount of tokens in our reviews"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_review_vocabulary_size</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb6ed7a1">
<h3 id="orgb6ed7a1">The Label Vocabulary</h3>
<div class="outline-text-3" id="text-orgb6ed7a1">
<p>These are the labels - there should only be two in this case. This requires that <code>self.labels</code> has been set.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">label_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="sd">"""List of sentiment labels"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd0429f1">
<h3 id="orgd0429f1">The Label Vocabulary Size</h3>
<div class="outline-text-3" id="text-orgd0429f1">
<p>The number of labels we ended up with.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">label_vocabulary_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""The amount of tokens in our labels"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_vocabulary_size</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6baef37">
<h3 id="org6baef37">The Word To Index Map</h3>
<div class="outline-text-3" id="text-org6baef37">
<p>This is a map to find the index in our review vocabulary where a word is. This requires that <code>self.review_vocabulary</code> has been set.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">word_to_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""maps a word to the index in our review vocabulary"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_word_to_index</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_word_to_index</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">word</span><span class="p">:</span> <span class="n">index</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocabulary</span><span class="p">)}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_word_to_index</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc5fa029">
<h3 id="orgc5fa029">The Label To Index Map</h3>
<div class="outline-text-3" id="text-orgc5fa029">
<p>This finds the index where a label is in our vocabulary of labels. This requires that <code>self.label_vocabulary</code> has been set.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">label_to_index</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">"""maps a label to the index in our label vocabulary"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_to_index</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_label_to_index</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">label</span><span class="p">:</span> <span class="n">index</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vocabulary</span><span class="p">)}</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_label_to_index</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd3e20b4">
<h3 id="orgd3e20b4">Input Nodes</h3>
<div class="outline-text-3" id="text-orgd3e20b4">
<p>The number of input nodes is the size of our vocabulary built from the reviews. This requires <code>self.review_vocabulary</code> to have been set.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">input_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Number of input nodes"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_nodes</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">review_vocabulary</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_nodes</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4b9a2c4">
<h3 id="org4b9a2c4">Weight From the Input Layer To the Hidden Layer</h3>
<div class="outline-text-3" id="text-org4b9a2c4">
<p>This is a matrix with as many rows as the number of input nodes and as many columns as the number of hidden nodes. This relies on <code>self.input_nodes</code> and <code>self.hidden_nodes</code>.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">weights_input_to_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Weights for edges from input to hidden layer"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span>

<span class="nd">@weights_input_to_hidden.setter</span>
<span class="k">def</span> <span class="nf">weights_input_to_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""Set the weights"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org24615a2">
<h3 id="org24615a2">Weight From the Hidden Layer To the Output Layer</h3>
<div class="outline-text-3" id="text-org24615a2">
<p>This is a matrix with as many rows as the number of hidden nodes and as many columns as the number of output nodes (which should be 1). This depends of <code>self.hidden_nodes</code> and <code>self.output_nodes</code>.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">weights_hidden_to_output</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Weights for edges from hidden to output layer"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span>

<span class="nd">@weights_hidden_to_output.setter</span>
<span class="k">def</span> <span class="nf">weights_hidden_to_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""updates the weights"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgfb3df3e">
<h3 id="orgfb3df3e">The Input Layer</h3>
<div class="outline-text-3" id="text-orgfb3df3e">
<p>This is the layer where we will set the tokens for a particular review that we are going to categorize. This depends on <code>self.input_nodes</code>.</p>
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""The Input Layer for the review tokens"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_layer</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_layer</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_layer</span>

<span class="nd">@input_layer.setter</span>
<span class="k">def</span> <span class="nf">input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""Set the input layer"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_layer</span> <span class="o">=</span> <span class="n">layer</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org56bd189">
<h3 id="org56bd189">Update the Input Layer</h3>
<div class="outline-text-3" id="text-org56bd189">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">update_input_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""Update the counts in the input layer</span>

<span class="sd">    Args:</span>
<span class="sd">     review: A movie review</span>
<span class="sd">    """</span>
    <span class="c1"># reset any previous inputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">*=</span> <span class="mi">0</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="n">counter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_to_index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_to_index</span><span class="p">[</span><span class="n">key</span><span class="p">]]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9db21dd">
<h3 id="org9db21dd">Get the Target for the Label</h3>
<div class="outline-text-3" id="text-org9db21dd">
<p>This converts a string label to an integer.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Convert a label to `0` or `1`.</span>
<span class="sd">    Args:</span>
<span class="sd">     label(string) - Either "POSITIVE" or "NEGATIVE".</span>
<span class="sd">    Returns:</span>
<span class="sd">     `0` or `1`.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s2">"POSITIVE"</span> <span class="k">else</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc5c1cbd">
<h3 id="orgc5c1cbd">The Sigmoid</h3>
<div class="outline-text-3" id="text-orgc5c1cbd">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""calculates the sigmoid for the input</span>

<span class="sd">    Args:</span>
<span class="sd">     x: vector to calculate the sigmoid</span>

<span class="sd">    Returns:</span>
<span class="sd">     sigmoid of x</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org53d1d7e">
<h3 id="org53d1d7e">Sigmoid Derivative</h3>
<div class="outline-text-3" id="text-org53d1d7e">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid_output_to_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Calculates the derivative if the sigmoid</span>

<span class="sd">    Args:</span>
<span class="sd">     output: the sigmoid output</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org2c01a60">
<h3 id="org2c01a60">Train the Network</h3>
<div class="outline-text-3" id="text-org2c01a60">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_reviews</span><span class="p">:</span> <span class="n">Review</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">:</span> <span class="n">Label</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Trains the model</span>

<span class="sd">    Args:</span>
<span class="sd">     training_reviews: list of reviews</span>
<span class="sd">     training_labels: listo of labels for the reviews</span>

<span class="sd">    Returns:</span>
<span class="sd">     count of correct</span>
<span class="sd">    """</span>
    <span class="c1"># there are side-effects that require self.reviews and self.labels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reviews</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">training_reviews</span><span class="p">,</span> <span class="n">training_labels</span>

    <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_labels</span><span class="p">))</span>
    <span class="n">correct_so_far</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>        
        <span class="c1"># Remember when we started for printing time statistics</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

    <span class="c1"># loop through all the given reviews and run a forward and backward pass,</span>
    <span class="c1"># updating weights for every item</span>
    <span class="n">reviews_labels</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">)</span>
    <span class="n">n_records</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">review</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reviews_labels</span><span class="p">):</span>
        <span class="c1"># feed-forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
        <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span><span class="p">)</span>
        <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="n">hidden_inputs</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">hidden_outputs</span><span class="p">)</span>

        <span class="c1"># Backpropagation</span>
        <span class="c1"># we need to calculate the output_error separately</span>
        <span class="c1"># to update our correct count</span>
        <span class="n">output_error</span> <span class="o">=</span> <span class="n">output</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="c1"># we applied a sigmoid to the output</span>
        <span class="c1"># so we need to apply the derivative</span>
        <span class="n">hidden_to_output_delta</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_error</span>
            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid_output_to_derivative</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>

        <span class="n">input_to_hidden_error</span> <span class="o">=</span> <span class="n">hidden_to_output_delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="c1"># we didn't apply a function to the inputs to the hidden layer</span>
        <span class="c1"># so we don't need a derivative</span>
        <span class="n">input_to_hidden_delta</span> <span class="o">=</span> <span class="n">input_to_hidden_error</span>

        <span class="c1"># our delta is based on the derivative which is heading</span>
        <span class="c1"># in the opposite direction of what we want so we need to negate it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span> <span class="o">-=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
            <span class="o">*</span> <span class="n">hidden_inputs</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hidden_to_output_delta</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span> <span class="o">-=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">input_to_hidden_delta</span><span class="p">))</span>

        <span class="k">if</span> <span class="p">((</span><span class="n">output</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span><span class="o">==</span><span class="s2">"NEGATIVE"</span><span class="p">)</span>
            <span class="ow">or</span> <span class="p">(</span><span class="n">output</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">label</span><span class="o">==</span><span class="s2">"POSITIVE"</span><span class="p">)):</span>
            <span class="n">correct_so_far</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">index</span> <span class="o">%</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="p">(</span><span class="n">index</span><span class="o">/</span><span class="n">elapsed_time</span><span class="o">.</span><span class="n">seconds</span>
                                  <span class="k">if</span> <span class="n">elapsed_time</span><span class="o">.</span><span class="n">seconds</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span>
                <span class="s2">"Progress: {:.2f} %"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">index</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">training_reviews</span><span class="p">))</span>
                <span class="o">+</span> <span class="s2">" Speed(reviews/sec): {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">" Error: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_error</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="o">+</span> <span class="s2">" #Correct: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">correct_so_far</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">" #Trained: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">" Training Accuracy: {:.2f} %"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">correct_so_far</span> <span class="o">*</span> <span class="mi">100</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"Training Time: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">correct_so_far</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8bc864f">
<h3 id="org8bc864f">Test The Model</h3>
<div class="outline-text-3" id="text-org8bc864f">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">testing_reviews</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">:</span><span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Attempts to predict the labels for the given testing_reviews,</span>
<span class="sd">    and uses the test_labels to calculate the accuracy of those predictions.</span>

<span class="sd">    Returns:</span>
<span class="sd">     correct: number of correct predictions</span>
<span class="sd">    """</span>

    <span class="c1"># keep track of how many correct predictions we make</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># we'll time how many predictions per second we make</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

    <span class="c1"># Loop through each of the given reviews and call run to predict</span>
    <span class="c1"># its label.</span>
    <span class="n">reviews_and_labels</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">review</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reviews_and_labels</span><span class="p">):</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prediction</span> <span class="o">==</span> <span class="n">label</span><span class="p">:</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">index</span> <span class="o">%</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
            <span class="n">reviews_per_second</span> <span class="o">=</span> <span class="p">(</span><span class="n">index</span><span class="o">/</span><span class="n">elapsed_time</span><span class="o">.</span><span class="n">seconds</span>
                                  <span class="k">if</span> <span class="n">elapsed_time</span><span class="o">.</span><span class="n">seconds</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>

            <span class="k">print</span><span class="p">(</span>
                <span class="s2">"Progress: {:.2f}%"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="mi">100</span> <span class="o">*</span> <span class="n">index</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testing_reviews</span><span class="p">))</span>
                <span class="o">+</span> <span class="s2">" Speed(reviews/sec): {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reviews_per_second</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">" #Correct: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">correct</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">" #Tested: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">" Testing Accuracy: {:.2f} %"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">correct</span> <span class="o">*</span> <span class="mi">100</span><span class="o">/</span><span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">correct</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0047ab6">
<h3 id="org0047ab6">Run a Prediction</h3>
<div class="outline-text-3" id="text-org0047ab6">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">review</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Returns a POSITIVE or NEGATIVE prediction for the given review.</span>
<span class="sd">    """</span>
    <span class="n">review</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="p">)</span>
    <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span><span class="p">)</span>
    <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="n">hidden_inputs</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">hidden_outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">"POSITIVE"</span> <span class="k">if</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">"NEGATIVE"</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org28ea96f">
<h2 id="org28ea96f">Test The Network</h2>
<div class="outline-text-2" id="text-org28ea96f">
<p>So now we'll actually try and run the network to see how it does.</p>
<div class="highlight">
<pre><span></span><span class="o">%</span><span class="n">reload_ext</span> <span class="n">autoreload</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sentiment_network</span> <span class="kn">import</span> <span class="n">SentimentNetwork</span>
</pre></div>
<p>We'll be using the last 1,000 labels to test the network and all but the last to train it.</p>
<div class="highlight">
<pre><span></span><span class="n">BOUNDARY</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1000</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">reviews</span><span class="p">[</span><span class="n">BOUNDARY</span><span class="p">:],</span><span class="n">labels</span><span class="p">[</span><span class="n">BOUNDARY</span><span class="p">:]</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
<pre class="example">
1000

</pre>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">reviews</span><span class="p">[:</span><span class="n">BOUNDARY</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="n">BOUNDARY</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span>
</pre></div>
<pre class="example">
24000

</pre>
<p>Since I split this up into multiple posts I'm going to pickle up the data-sets to make sure that they're only being created once.</p>
<div class="highlight">
<pre><span></span><span class="n">pickles</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">x_test</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
               <span class="n">x_train</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">for</span> <span class="n">potential_pickle</span><span class="p">,</span> <span class="n">collection</span> <span class="ow">in</span> <span class="n">pickles</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">potential_path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"{}.pkl"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">potential_pickle</span><span class="p">),</span> <span class="n">check_exists</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">potential_path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">potential_path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">collection</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">untrained</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<p>Run the following cell to actually train the network. During training, it will display the model's accuracy repeatedly as it trains so you can see how well it's doing.</p>
<div class="highlight">
<pre><span></span><span class="n">untrained</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<pre class="example">
Progress: 0.00 % Speed(reviews/sec): 0.00 Error: [-0.5] #Correct: 1 #Trained: 1 Training Accuracy: 100.00 %
Progress: 4.17 % Speed(reviews/sec): 125.00 Error: [-0.50133709] #Correct: 492 #Trained: 1001 Training Accuracy: 49.15 %
Progress: 8.33 % Speed(reviews/sec): 153.85 Error: [-0.46896641] #Correct: 940 #Trained: 2001 Training Accuracy: 46.98 %
Progress: 12.50 % Speed(reviews/sec): 150.00 Error: [-0.76053545] #Correct: 1401 #Trained: 3001 Training Accuracy: 46.68 %
Progress: 16.67 % Speed(reviews/sec): 142.86 Error: [-0.5175674] #Correct: 1860 #Trained: 4001 Training Accuracy: 46.49 %
Progress: 20.83 % Speed(reviews/sec): 142.86 Error: [-0.7057053] #Correct: 2329 #Trained: 5001 Training Accuracy: 46.57 %
Progress: 25.00 % Speed(reviews/sec): 146.34 Error: [-0.87768714] #Correct: 2859 #Trained: 6001 Training Accuracy: 47.64 %
Progress: 29.17 % Speed(reviews/sec): 142.86 Error: [-0.42471556] #Correct: 3376 #Trained: 7001 Training Accuracy: 48.22 %
Progress: 33.33 % Speed(reviews/sec): 140.35 Error: [-0.25287871] #Correct: 3931 #Trained: 8001 Training Accuracy: 49.13 %
Progress: 37.50 % Speed(reviews/sec): 138.46 Error: [-0.13143902] #Correct: 4508 #Trained: 9001 Training Accuracy: 50.08 %
Progress: 41.67 % Speed(reviews/sec): 136.99 Error: [-0.30215181] #Correct: 5141 #Trained: 10001 Training Accuracy: 51.40 %
Progress: 45.83 % Speed(reviews/sec): 137.50 Error: [-0.83628373] #Correct: 5690 #Trained: 11001 Training Accuracy: 51.72 %
Progress: 50.00 % Speed(reviews/sec): 136.36 Error: [-0.2236724] #Correct: 6318 #Trained: 12001 Training Accuracy: 52.65 %
Progress: 54.17 % Speed(reviews/sec): 136.84 Error: [-0.00040756] #Correct: 6873 #Trained: 13001 Training Accuracy: 52.87 %
Progress: 58.33 % Speed(reviews/sec): 137.25 Error: [-0.24857157] #Correct: 7463 #Trained: 14001 Training Accuracy: 53.30 %
Progress: 62.50 % Speed(reviews/sec): 136.36 Error: [-0.56169307] #Correct: 8091 #Trained: 15001 Training Accuracy: 53.94 %
Progress: 66.67 % Speed(reviews/sec): 136.75 Error: [-0.30580514] #Correct: 8710 #Trained: 16001 Training Accuracy: 54.43 %
Progress: 70.83 % Speed(reviews/sec): 136.00 Error: [-0.85096669] #Correct: 9343 #Trained: 17001 Training Accuracy: 54.96 %
Progress: 75.00 % Speed(reviews/sec): 136.36 Error: [-0.0031485] #Correct: 9973 #Trained: 18001 Training Accuracy: 55.40 %
Progress: 79.17 % Speed(reviews/sec): 135.71 Error: [-0.73531052] #Correct: 10671 #Trained: 19001 Training Accuracy: 56.16 %
Progress: 83.33 % Speed(reviews/sec): 136.05 Error: [-0.14522187] #Correct: 11341 #Trained: 20001 Training Accuracy: 56.70 %
Progress: 87.50 % Speed(reviews/sec): 135.48 Error: [-0.38478658] #Correct: 11973 #Trained: 21001 Training Accuracy: 57.01 %
Progress: 91.67 % Speed(reviews/sec): 134.97 Error: [-0.39655627] #Correct: 12678 #Trained: 22001 Training Accuracy: 57.62 %
Progress: 95.83 % Speed(reviews/sec): 134.50 Error: [-0.55767025] #Correct: 13345 #Trained: 23001 Training Accuracy: 58.02 %
</pre>
<p>That most likely didn't train very well. Part of the reason may be because the learning rate is too high. Run the following cell to recreate the network with a smaller learning rate, `0.01`, and then train the new network.</p>
<div class="highlight">
<pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<pre class="example">
Progress: 0.00 % Speed(reviews/sec): 0.00 Error: [-0.5] #Correct: 1 #Trained: 1 Training Accuracy: 100.00 %
Progress: 4.17 % Speed(reviews/sec): 250.00 Error: [-0.73627527] #Correct: 482 #Trained: 1001 Training Accuracy: 48.15 %
Progress: 8.33 % Speed(reviews/sec): 333.33 Error: [-0.27663369] #Correct: 1065 #Trained: 2001 Training Accuracy: 53.22 %
Progress: 12.50 % Speed(reviews/sec): 333.33 Error: [-0.41620613] #Correct: 1743 #Trained: 3001 Training Accuracy: 58.08 %
Progress: 16.67 % Speed(reviews/sec): 333.33 Error: [-0.41925862] #Correct: 2378 #Trained: 4001 Training Accuracy: 59.44 %
Progress: 20.83 % Speed(reviews/sec): 333.33 Error: [-0.3792133] #Correct: 3022 #Trained: 5001 Training Accuracy: 60.43 %
Progress: 25.00 % Speed(reviews/sec): 333.33 Error: [-0.31493906] #Correct: 3670 #Trained: 6001 Training Accuracy: 61.16 %
Progress: 29.17 % Speed(reviews/sec): 333.33 Error: [-0.19472257] #Correct: 4380 #Trained: 7001 Training Accuracy: 62.56 %
Progress: 33.33 % Speed(reviews/sec): 333.33 Error: [-0.20326775] #Correct: 5068 #Trained: 8001 Training Accuracy: 63.34 %
Progress: 37.50 % Speed(reviews/sec): 333.33 Error: [-0.17244992] #Correct: 5751 #Trained: 9001 Training Accuracy: 63.89 %
Progress: 41.67 % Speed(reviews/sec): 333.33 Error: [-0.74943668] #Correct: 6475 #Trained: 10001 Training Accuracy: 64.74 %
Progress: 45.83 % Speed(reviews/sec): 333.33 Error: [-0.34768212] #Correct: 7171 #Trained: 11001 Training Accuracy: 65.18 %
Progress: 50.00 % Speed(reviews/sec): 333.33 Error: [-0.23588717] #Correct: 7895 #Trained: 12001 Training Accuracy: 65.79 %
Progress: 54.17 % Speed(reviews/sec): 325.00 Error: [-0.67639111] #Correct: 8634 #Trained: 13001 Training Accuracy: 66.41 %
Progress: 58.33 % Speed(reviews/sec): 325.58 Error: [-0.18425262] #Correct: 9360 #Trained: 14001 Training Accuracy: 66.85 %
Progress: 62.50 % Speed(reviews/sec): 326.09 Error: [-0.31647149] #Correct: 10083 #Trained: 15001 Training Accuracy: 67.22 %
Progress: 66.67 % Speed(reviews/sec): 326.53 Error: [-0.31838031] #Correct: 10791 #Trained: 16001 Training Accuracy: 67.44 %
Progress: 70.83 % Speed(reviews/sec): 326.92 Error: [-0.71363956] #Correct: 11494 #Trained: 17001 Training Accuracy: 67.61 %
Progress: 75.00 % Speed(reviews/sec): 327.27 Error: [-0.03786987] #Correct: 12237 #Trained: 18001 Training Accuracy: 67.98 %
Progress: 79.17 % Speed(reviews/sec): 327.59 Error: [-0.89039967] #Correct: 12995 #Trained: 19001 Training Accuracy: 68.39 %
Progress: 83.33 % Speed(reviews/sec): 327.87 Error: [-0.19787345] #Correct: 13741 #Trained: 20001 Training Accuracy: 68.70 %
Progress: 87.50 % Speed(reviews/sec): 328.12 Error: [-0.60033441] #Correct: 14484 #Trained: 21001 Training Accuracy: 68.97 %
Progress: 91.67 % Speed(reviews/sec): 323.53 Error: [-0.47631941] #Correct: 15242 #Trained: 22001 Training Accuracy: 69.28 %
Progress: 95.83 % Speed(reviews/sec): 323.94 Error: [-0.47388592] #Correct: 15995 #Trained: 23001 Training Accuracy: 69.54 %
Training Time: 0:01:15.489437
</pre>
<p>This actually did better, but let's see what a smaller learning rate will do.</p>
<div class="highlight">
<pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">SentimentNetwork</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<pre class="example">
Progress: 0.00 % Speed(reviews/sec): 0.00 Error: [-0.5] #Correct: 1 #Trained: 1 Training Accuracy: 100.00 %
Progress: 4.17 % Speed(reviews/sec): 250.00 Error: [-0.42248049] #Correct: 472 #Trained: 1001 Training Accuracy: 47.15 %
Progress: 8.33 % Speed(reviews/sec): 333.33 Error: [-0.27087125] #Correct: 1046 #Trained: 2001 Training Accuracy: 52.27 %
Progress: 12.50 % Speed(reviews/sec): 333.33 Error: [-0.45852835] #Correct: 1708 #Trained: 3001 Training Accuracy: 56.91 %
Progress: 16.67 % Speed(reviews/sec): 333.33 Error: [-0.41728936] #Correct: 2334 #Trained: 4001 Training Accuracy: 58.34 %
Progress: 20.83 % Speed(reviews/sec): 333.33 Error: [-0.37365937] #Correct: 2959 #Trained: 5001 Training Accuracy: 59.17 %
Progress: 25.00 % Speed(reviews/sec): 315.79 Error: [-0.25350906] #Correct: 3595 #Trained: 6001 Training Accuracy: 59.91 %
Progress: 29.17 % Speed(reviews/sec): 318.18 Error: [-0.22273178] #Correct: 4292 #Trained: 7001 Training Accuracy: 61.31 %
Progress: 33.33 % Speed(reviews/sec): 320.00 Error: [-0.22148954] #Correct: 4985 #Trained: 8001 Training Accuracy: 62.30 %
Progress: 37.50 % Speed(reviews/sec): 321.43 Error: [-0.164888] #Correct: 5670 #Trained: 9001 Training Accuracy: 62.99 %
Progress: 41.67 % Speed(reviews/sec): 322.58 Error: [-0.70030978] #Correct: 6381 #Trained: 10001 Training Accuracy: 63.80 %
Progress: 45.83 % Speed(reviews/sec): 305.56 Error: [-0.37677934] #Correct: 7082 #Trained: 11001 Training Accuracy: 64.38 %
Progress: 50.00 % Speed(reviews/sec): 307.69 Error: [-0.25747753] #Correct: 7812 #Trained: 12001 Training Accuracy: 65.09 %
Progress: 54.17 % Speed(reviews/sec): 302.33 Error: [-0.66038851] #Correct: 8550 #Trained: 13001 Training Accuracy: 65.76 %
Progress: 58.33 % Speed(reviews/sec): 304.35 Error: [-0.21017589] #Correct: 9271 #Trained: 14001 Training Accuracy: 66.22 %
Progress: 62.50 % Speed(reviews/sec): 306.12 Error: [-0.32861519] #Correct: 9993 #Trained: 15001 Training Accuracy: 66.62 %
Progress: 66.67 % Speed(reviews/sec): 307.69 Error: [-0.31545046] #Correct: 10705 #Trained: 16001 Training Accuracy: 66.90 %
Progress: 70.83 % Speed(reviews/sec): 309.09 Error: [-0.70497608] #Correct: 11411 #Trained: 17001 Training Accuracy: 67.12 %
Progress: 75.00 % Speed(reviews/sec): 310.34 Error: [-0.04885612] #Correct: 12162 #Trained: 18001 Training Accuracy: 67.56 %
Progress: 79.17 % Speed(reviews/sec): 316.67 Error: [-0.79732231] #Correct: 12916 #Trained: 19001 Training Accuracy: 67.98 %
Progress: 83.33 % Speed(reviews/sec): 312.50 Error: [-0.2568252] #Correct: 13678 #Trained: 20001 Training Accuracy: 68.39 %
Progress: 87.50 % Speed(reviews/sec): 313.43 Error: [-0.59070143] #Correct: 14418 #Trained: 21001 Training Accuracy: 68.65 %
Progress: 91.67 % Speed(reviews/sec): 305.56 Error: [-0.42520887] #Correct: 15181 #Trained: 22001 Training Accuracy: 69.00 %
Progress: 95.83 % Speed(reviews/sec): 302.63 Error: [-0.50276096] #Correct: 15931 #Trained: 23001 Training Accuracy: 69.26 %
Training Time: 0:01:19.701444
</pre>
<p>Surprisingly it did around the same (maybe a little worse). It looks like tuning the learning rate isn't enough.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/sentiment_analysis/the-network-parts/">The Network Parts</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/sentiment_analysis/the-network-parts/" rel="bookmark"><time class="published dt-published" datetime="2018-11-11T14:44:07-08:00" itemprop="datePublished" title="2018-11-11 14:44">2018-11-11 14:44</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/sentiment_analysis/the-network-parts/#orgb02acc9">Set Up</a></li>
<li><a href="posts/nano/sentiment_analysis/the-network-parts/#org290afd4">The Data</a></li>
<li><a href="posts/nano/sentiment_analysis/the-network-parts/#org8efa3b0">Transforming Text into Numbers</a></li>
<li><a href="posts/nano/sentiment_analysis/the-network-parts/#org7e970ac">Creating the Input/Output Data</a></li>
</ul>
</div>
</div>
<p>This is an initial exploration of some of the parts that are going to make up the Neural Network as well as a little inspection of the data and how we're going to use it.</p>
<div class="outline-2" id="outline-container-orgb02acc9">
<h2 id="orgb02acc9">Set Up</h2>
<div class="outline-text-2" id="text-orgb02acc9"></div>
<div class="outline-3" id="outline-container-org2ce881a">
<h3 id="org2ce881a">Imports</h3>
<div class="outline-text-3" id="text-org2ce881a"></div>
<div class="outline-4" id="outline-container-org963cb7c">
<h4 id="org963cb7c">The Tangle</h4>
<div class="outline-text-4" id="text-org963cb7c">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPath</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0042b4d">
<h4 id="org0042b4d">Python</h4>
<div class="outline-text-4" id="text-org0042b4d">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org659fcf6">
<h4 id="org659fcf6">PyPi</h4>
<div class="outline-text-4" id="text-org659fcf6">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graphviz</span> <span class="kn">import</span> <span class="n">Graph</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org54ff3f4">
<h4 id="org54ff3f4">This Project</h4>
<div class="outline-text-4" id="text-org54ff3f4">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">neurotic.tangles.data_paths</span> <span class="kn">import</span> <span class="n">DataPath</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orged9f288">
<h3 id="orged9f288">Loading The Pickles</h3>
<div class="outline-text-3" id="text-orged9f288">
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"total_count.pkl"</span><span class="p">)</span>
<span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">total_counts</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org14d717b">
<h3 id="org14d717b">Some Constants</h3>
<div class="outline-text-3" id="text-org14d717b">
<div class="highlight">
<pre><span></span><span class="n">SPLIT_ON_THIS</span> <span class="o">=</span> <span class="s2">" "</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org290afd4">
<h2 id="org290afd4">The Data</h2>
<div class="outline-text-2" id="text-org290afd4">
<p>The Reviews.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"reviews.txt"</span><span class="p">)</span>
<span class="n">output_path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"reviews.pkl"</span><span class="p">,</span> <span class="n">check_exists</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">output_path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="p">,</span><span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">reviews</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">output_path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">reviews</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
<p>The labels.</p>
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"labels.txt"</span><span class="p">)</span>
<span class="n">output_path</span> <span class="o">=</span> <span class="n">DataPath</span><span class="p">(</span><span class="s2">"labels.pkl"</span><span class="p">,</span> <span class="n">check_exists</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">output_path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">()</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">output_path</span><span class="o">.</span><span class="n">from_folder</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">writer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org8efa3b0">
<h2 id="org8efa3b0">Transforming Text into Numbers</h2>
<div class="outline-text-2" id="text-org8efa3b0">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">plot_network</span><span class="p">():</span>
    <span class="sd">"""</span>
<span class="sd">    Creates a simplified plot of our network (simple_network.dot.png)</span>
<span class="sd">    """</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">Graph</span><span class="p">(</span><span class="n">format</span><span class="o">=</span><span class="s2">"png"</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">attr</span><span class="p">(</span><span class="n">rankdir</span><span class="o">=</span><span class="s2">"LR"</span><span class="p">)</span>

    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"horrible"</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"b"</span><span class="p">,</span> <span class="s2">"excellent"</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"c"</span><span class="p">,</span> <span class="s2">"terrible"</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"d"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"e"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"f"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"g"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s2">"h"</span><span class="p">,</span> <span class="s2">"positive"</span><span class="p">)</span>

    <span class="n">graph</span><span class="o">.</span><span class="n">edges</span><span class="p">([</span><span class="s2">"ad"</span><span class="p">,</span> <span class="s2">"ae"</span><span class="p">,</span> <span class="s2">"af"</span><span class="p">,</span> <span class="s2">"ag"</span><span class="p">,</span>
                 <span class="s2">"bd"</span><span class="p">,</span> <span class="s2">"be"</span><span class="p">,</span> <span class="s2">"bf"</span><span class="p">,</span> <span class="s2">"bg"</span><span class="p">,</span>
                 <span class="s2">"cd"</span><span class="p">,</span> <span class="s2">"ce"</span> <span class="p">,</span> <span class="s2">"cf"</span><span class="p">,</span> <span class="s2">"cg"</span><span class="p">])</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">edges</span><span class="p">([</span><span class="s2">"dh"</span><span class="p">,</span> <span class="s1">'eh'</span><span class="p">,</span> <span class="s1">'fh'</span><span class="p">,</span> <span class="s1">'gh'</span><span class="p">])</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">"graphs/simple_network.dot"</span><span class="p">)</span>
    <span class="n">graph</span>
    <span class="k">return</span>
</pre></div>
<p>This is one potential way to classify the sentiment of a review using a neural network. In this case if any of the terms (<i>horrible, excellent,</i> or <i>terrible</i>) exists the input is a one for that term and the output is the sum of the multiplication of the weights times the inputs.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org7e970ac">
<h2 id="org7e970ac">Creating the Input/Output Data</h2>
<div class="outline-text-2" id="text-org7e970ac"></div>
<div class="outline-3" id="outline-container-orgd1a20ac">
<h3 id="orgd1a20ac">The Vocabulary</h3>
<div class="outline-text-3" id="text-orgd1a20ac">
<p>We're going to create a "vocabulary" which is just a list of all the words in our reviews.</p>
<div class="highlight">
<pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">total_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
<p>Here's our vocabulary size.</p>
<div class="highlight">
<pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"{:,}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">vocab_size</span><span class="o">==</span><span class="mi">74074</span>
</pre></div>
<pre class="example">
74,074

</pre></div>
</div>
<div class="outline-3" id="outline-container-org6d64fa8">
<h3 id="org6d64fa8">Layer 0</h3>
<div class="outline-text-3" id="text-org6d64fa8">
<p>Now we're going to create a numpy array called <i>layer_0</i> and initialize it to all <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html">zeros</a>. This will represent our input layer, so it will be a 2-dimensional matrix with 1 row and <i>vocab_size</i> columns.</p>
<div class="highlight">
<pre><span></span><span class="n">layer_0</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
</pre></div>
<p>Now we can double-check the shape to make sure it matches what we're expecting.</p>
<div class="highlight">
<pre><span></span><span class="n">shape</span> <span class="o">=</span> <span class="n">layer_0</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"{}, {:,}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">74074</span><span class="p">)</span>
</pre></div>
<pre class="example">
1, 74,074

</pre></div>
</div>
<div class="outline-3" id="outline-container-org22ed6d6">
<h3 id="org22ed6d6">Word 2 Index</h3>
<div class="outline-text-3" id="text-org22ed6d6">
<p><code>layer_0</code> contains one entry for every word in the vocabulary. We need to make sure we know the index of each word, so we'rec going to create a lookup table that stores the index of every word.</p>
<div class="highlight">
<pre><span></span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
</pre></div>
<p>Here's the first ten entries in the lookup table.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"|Term| Index|"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"|-+-|"</span><span class="p">)</span>
<span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word2index</span><span class="o">.</span><span class="n">keys</span><span class="p">())[:</span><span class="mi">10</span><span class="p">]</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"|{}|{}|"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">word2index</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Term</th>
<th class="org-right" scope="col">Index</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">bromwell</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-left">high</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-left">is</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">a</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">cartoon</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">comedy</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">.</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">it</td>
<td class="org-right">7</td>
</tr>
<tr>
<td class="org-left">ran</td>
<td class="org-right">8</td>
</tr>
<tr>
<td class="org-left">at</td>
<td class="org-right">9</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="outline-3" id="outline-container-org7e62bdb">
<h3 id="org7e62bdb">Update Input Layer</h3>
<div class="outline-text-3" id="text-org7e62bdb">
<p>The <code>update_input_layer</code> will count how many times each word is used in the review and then store those counts at the appropriate indices inside <code>layer_0</code>. To make this useable in other posts you have to pass in the <code>word2index</code> table, but in the actual Neural Network we're going to use a class so it will look a little different.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">update_input_layer</span><span class="p">(</span><span class="n">review</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">layer_0</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">word2index</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Counter</span><span class="p">:</span>
    <span class="sd">""" Modify the global layer_0 to represent the vector form of review.</span>
<span class="sd">    The element at a given index of layer_0 should represent</span>
<span class="sd">    how many times the given word occurs in the review.</span>

<span class="sd">    Args:</span>
<span class="sd">       review: the string of the review</span>
<span class="sd">       layer_0: array representing layer 0</span>
<span class="sd">       word2index: dict mapping word to index in layer_0</span>
<span class="sd">    Returns:</span>
<span class="sd">        counter for the tokens (used for troubleshooting)</span>
<span class="sd">    """</span>
    <span class="c1"># clear out previous state by resetting the layer to be all 0s</span>
    <span class="n">layer_0</span> <span class="o">*=</span> <span class="mi">0</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">review</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">SPLIT_ON_THIS</span><span class="p">)</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="n">counter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">layer_0</span><span class="p">[:,</span> <span class="n">word2index</span><span class="p">[</span><span class="n">key</span><span class="p">]]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">counter</span>
</pre></div>
<p>Here's what happens when you update <code>layer_0</code> with the first review.</p>
<div class="highlight">
<pre><span></span><span class="n">update_input_layer</span><span class="p">(</span><span class="n">reviews</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">layer_0</span><span class="p">)</span>
</pre></div>
<pre class="example">
[[4. 5. 4. ... 0. 0. 0.]]

</pre>
<p>It doesn't look exciting, but if we remember that we initialized the values as all zeros, then we can see that something is changing.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org7ddea88">
<h3 id="org7ddea88">Get Target For Labels</h3>
<div class="outline-text-3" id="text-org7ddea88">
<p><code>get_target_for_labels</code> returns <code>0</code> or <code>1</code>, depending on whether the given label is <code>NEGATIVE</code> or <code>POSITIVE</code>, respectively. This will allow us to use the labels as we were given them and map them to numbers inside the neural net. An alternative might be to pre-process the labels or make this a dictionary.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_target_for_label</span><span class="p">(</span><span class="n">label</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">"""Convert a label to `0` or `1`.</span>
<span class="sd">    Args:</span>
<span class="sd">       label(string) - Either "POSITIVE" or "NEGATIVE".</span>
<span class="sd">    Returns:</span>
<span class="sd">       `0` or `1`.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s2">"POSITIVE"</span> <span class="k">else</span> <span class="mi">0</span>
</pre></div>
<p>So, here's the first label.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
POSITIVE

</pre>
<p>And here's what we mapped it to.</p>
<div class="highlight">
<pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">get_target_for_label</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">output</span> <span class="o">==</span> <span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<pre class="example">
1

</pre>
<p>And here we go with the second label.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
<pre class="example">
NEGATIVE

</pre>
<div class="highlight">
<pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">get_target_for_label</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">output</span> <span class="o">==</span> <span class="mi">0</span>
<span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
<pre class="example">
0

</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/">Exploring the Reviews Dataset</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/" rel="bookmark"><time class="published dt-published" datetime="2018-11-11T14:25:48-08:00" itemprop="datePublished" title="2018-11-11 14:25">2018-11-11 14:25</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/#org590ac2a">Set Up</a></li>
<li><a href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/#org70340ad">Lesson 1: Curate a Dataset</a></li>
<li><a href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/#org00beecd">Develop a Predictive Theory</a></li>
<li><a href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/#orga16330e">Quick Theory Validation</a></li>
<li><a href="posts/nano/sentiment_analysis/exploring-the-reviews-dataset/#org6b31d3d">Pickling</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org590ac2a">
<h2 id="org590ac2a">Set Up</h2>
<div class="outline-text-2" id="text-org590ac2a"></div>
<div class="outline-3" id="outline-container-org24b03cb">
<h3 id="org24b03cb">Imports</h3>
<div class="outline-text-3" id="text-org24b03cb"></div>
<div class="outline-4" id="outline-container-org11542ad">
<h4 id="org11542ad">Python</h4>
<div class="outline-text-4" id="text-org11542ad">
<div class="highlight">
<pre><span></span>from collections import Counter
import pickle
import textwrap
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3f293a9">
<h4 id="org3f293a9">PyPi</h4>
<div class="outline-text-4" id="text-org3f293a9">
<div class="highlight">
<pre><span></span>import numpy
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org201faa7">
<h4 id="org201faa7">This Project</h4>
<div class="outline-text-4" id="text-org201faa7">
<div class="highlight">
<pre><span></span>from neurotic.tangles.data_paths import DataPath
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org70340ad">
<h2 id="org70340ad">Lesson 1: Curate a Dataset</h2>
<div class="outline-text-2" id="text-org70340ad">
<p>The goal of this section is to become familiar with the data and perform any preprocessing that might be needed.</p>
</div>
<div class="outline-3" id="outline-container-org3e89856">
<h3 id="org3e89856">A Helper To Print</h3>
<div class="outline-text-3" id="text-org3e89856">
<div class="highlight">
<pre><span></span>def pretty_print_review_and_label(index: int, up_to: int=80) -&gt; None:
    """Prints the label and review

    Args:
     index: the index of the review in the data set
     up_to: number of characters in the review to show
    """
    print("|{}|{}|".format(labels[index], reviews[index][:up_to] + "..."))
    return
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgff8d1d2">
<h3 id="orgff8d1d2">The Reviews</h3>
<div class="outline-text-3" id="text-orgff8d1d2">
<p>It's not really clear what he's doing here. I think he's stripping the newlines off of the reviews, so each review must be one line.</p>
<div class="highlight">
<pre><span></span>path = DataPath("reviews.txt")
with open(path.from_folder,'r') as reader:
    reviews = [line.rstrip() for line in reader]
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7bb6eb6">
<h3 id="org7bb6eb6">The Labels</h3>
<div class="outline-text-3" id="text-org7bb6eb6">
<p>A similar deal except casting the labels to upper case.</p>
<div class="highlight">
<pre><span></span>path = DataPath("labels.txt")
with open(path.from_folder,'r') as reader:
    labels = (line.rstrip() for line in reader)
    labels = [line.upper() for line in labels]
</pre></div>
<p><b>Note:</b> The data in <code>reviews.txt</code> we're using has already been preprocessed a bit and contains only lower case characters. If we were working from raw data, where we didn't know it was all lower case, we would want to add a step here to convert it. That's so we treat different variations of the same word, like `The`, `the`, and `THE`, all the same way.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org78c8490">
<h3 id="org78c8490">How many reviews do we have?</h3>
<div class="outline-text-3" id="text-org78c8490">
<div class="highlight">
<pre><span></span>print("{:,}".format(len(reviews)))
</pre></div>
<pre class="example">
25,000

</pre></div>
</div>
<div class="outline-3" id="outline-container-orgc499752">
<h3 id="orgc499752">What does a review look like?</h3>
<div class="outline-text-3" id="text-orgc499752">
<div class="highlight">
<pre><span></span>print("\n".join(textwrap.wrap(reviews[0], width=80)))
</pre></div>
<pre class="example">
bromwell high is a cartoon comedy . it ran at the same time as some other
programs about school life  such as  teachers  . my   years in the teaching
profession lead me to believe that bromwell high  s satire is much closer to
reality than is  teachers  . the scramble to survive financially  the insightful
students who can see right through their pathetic teachers  pomp  the pettiness
of the whole situation  all remind me of the schools i knew and their students .
when i saw the episode in which a student repeatedly tried to burn down the
school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a
classic line inspector i  m here to sack one of your teachers . student welcome
to bromwell high . i expect that many adults of my age think that bromwell high
is far fetched . what a pity that it isn  t
</pre>
<p>Kind of odd looking. It looks like the pre-processor did some bad things.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgca93d6a">
<h3 id="orgca93d6a">What does the label for that review look like?</h3>
<div class="outline-text-3" id="text-orgca93d6a">
<div class="highlight">
<pre><span></span>print(labels[0])
</pre></div>
<pre class="example">
POSITIVE

</pre></div>
</div>
<div class="outline-3" id="outline-container-org96f1764">
<h3 id="org96f1764">What are the labels available?</h3>
<div class="outline-text-3" id="text-org96f1764">
<p>At this point we don't have pandas loaded, so I'll just use a set to look at the labels.</p>
<div class="highlight">
<pre><span></span>print(set(labels))
</pre></div>
<pre class="example">
{'NEGATIVE', 'POSITIVE'}

</pre>
<p>So there are two labels - "NEGATIVE" and "POSITIVE".</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org00beecd">
<h2 id="org00beecd">Develop a Predictive Theory</h2>
<div class="outline-text-2" id="text-org00beecd">
<p>The previous section gave us a rough idea of what's in the data set. Now we want to make a guess as to what the labels mean - why is a review labled POSITIVE or NEGATIVE?</p>
<div class="highlight">
<pre><span></span>print("|labels.txt| reviews.txt|")
print("|-+-|")
indices = (2137, 12816, 6267, 21934, 5297, 4998)
for index in indices:
    pretty_print_review_and_label(index)
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">labels.txt</th>
<th class="org-left" scope="col">reviews.txt</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">NEGATIVE</td>
<td class="org-left">this movie is terrible but it has some good effects ….</td>
</tr>
<tr>
<td class="org-left">POSITIVE</td>
<td class="org-left">adrian pasdar is excellent is this film . he makes a fascinating woman ….</td>
</tr>
<tr>
<td class="org-left">NEGATIVE</td>
<td class="org-left">comment this movie is impossible . is terrible very improbable bad interpretat…</td>
</tr>
<tr>
<td class="org-left">POSITIVE</td>
<td class="org-left">excellent episode movie ala pulp fiction . days suicides . it doesnt get more…</td>
</tr>
<tr>
<td class="org-left">NEGATIVE</td>
<td class="org-left">if you haven t seen this it s terrible . it is pure trash . i saw this about …</td>
</tr>
<tr>
<td class="org-left">POSITIVE</td>
<td class="org-left">this schiffer guy is a real genius the movie is of excellent quality and both e…</td>
</tr>
</tbody>
</table>
<p>If you look at the negative reviews, they all have the work 'terrible' in them, and the positives all have the workd 'excellent' in them. The theory then, is that the labels are based on whether a review has a key-word in it that makes it either positive or negative.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orga16330e">
<h2 id="orga16330e">Quick Theory Validation</h2>
<div class="outline-text-2" id="text-orga16330e">
<p>In this section we're going to test our theory that key-words identify whether a review is positive or negative using the <a href="https://docs.python.org/2/library/collections.html#collections.Counter">Counter</a> class and the <a href="https://docs.scipy.org/doc/numpy/reference/">numpy</a> library.</p>
</div>
<div class="outline-3" id="outline-container-orgcdc1f99">
<h3 id="orgcdc1f99">Word Counter</h3>
<div class="outline-text-3" id="text-orgcdc1f99">
<p>We'll create three <code>Counter</code> objects, one for words from postive reviews, one for words from negative reviews, and one for all the words.</p>
<div class="highlight">
<pre><span></span>positive_counts = Counter()
negative_counts = Counter()
total_counts = Counter()
</pre></div>
<p>Examine all the reviews. For each word in a positive review, increase the count for that word in both your positive counter and the total words counter; likewise, for each word in a negative review, increase the count for that word in both your negative counter and the total words counter.</p>
<p><b>Note:</b> Throughout these projects, you should use `split(' ')` to divide a piece of text (such as a review) into individual words. If you use `split()` instead, you'll get slightly different results than what the videos and solutions show.</p>
<p>The classifications in the <code>labels</code> list.</p>
<div class="highlight">
<pre><span></span>class Classification:
    positive = "POSITIVE"
    negative = "NEGATIVE"
</pre></div>
<p>What we are splitting on.</p>
<div class="highlight">
<pre><span></span>class Tokens:
    splitter = " "
</pre></div>
<div class="highlight">
<pre><span></span>with DataPath("labels.pkl").from_folder.open("rb") as reader:
    labels = pickle.load(reader)
</pre></div>
<div class="highlight">
<pre><span></span>for label, review in zip(labels, reviews):
    tokens = review.split(Tokens.splitter)
    total_counts.update(tokens)

    if label == Classification.positive:
        positive_counts.update(tokens)        
    else:
        negative_counts.update(tokens)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9aa1dc8">
<h3 id="org9aa1dc8">Most Common Words</h3>
<div class="outline-text-3" id="text-org9aa1dc8">
<p>Run the following two cells to list the words used in positive reviews and negative reviews, respectively, ordered from most to least commonly used.</p>
<p>Examine the counts of the most common words in positive reviews</p>
<div class="highlight">
<pre><span></span>print("|Token| Count|")
print("|-+-|")
for token, count in positive_counts.most_common(10):
    print("|{}|{:,}|".format(token, count))
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-left" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&nbsp;</td>
<td class="org-left">518,327</td>
</tr>
<tr>
<td class="org-left">the</td>
<td class="org-left">173,324</td>
</tr>
<tr>
<td class="org-left">.</td>
<td class="org-left">159,654</td>
</tr>
<tr>
<td class="org-left">and</td>
<td class="org-left">89,722</td>
</tr>
<tr>
<td class="org-left">a</td>
<td class="org-left">83,688</td>
</tr>
<tr>
<td class="org-left">of</td>
<td class="org-left">76,855</td>
</tr>
<tr>
<td class="org-left">to</td>
<td class="org-left">66,746</td>
</tr>
<tr>
<td class="org-left">is</td>
<td class="org-left">57,245</td>
</tr>
<tr>
<td class="org-left">in</td>
<td class="org-left">50,215</td>
</tr>
<tr>
<td class="org-left">br</td>
<td class="org-left">49,235</td>
</tr>
</tbody>
</table>
<p>So, we probably don't want most of the most common tokens.</p>
<p>Examine the counts of the most common words in negative reviews</p>
<div class="highlight">
<pre><span></span>print("|Token| Count|")
print("|-+-|")
for token, count in negative_counts.most_common(10):
    print("|{}|{:,}|".format(token, count))
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-left" scope="col">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&nbsp;</td>
<td class="org-left">531,016</td>
</tr>
<tr>
<td class="org-left">.</td>
<td class="org-left">167,538</td>
</tr>
<tr>
<td class="org-left">the</td>
<td class="org-left">163,389</td>
</tr>
<tr>
<td class="org-left">a</td>
<td class="org-left">79,321</td>
</tr>
<tr>
<td class="org-left">and</td>
<td class="org-left">74,385</td>
</tr>
<tr>
<td class="org-left">of</td>
<td class="org-left">69,009</td>
</tr>
<tr>
<td class="org-left">to</td>
<td class="org-left">68,974</td>
</tr>
<tr>
<td class="org-left">br</td>
<td class="org-left">52,637</td>
</tr>
<tr>
<td class="org-left">is</td>
<td class="org-left">50,083</td>
</tr>
<tr>
<td class="org-left">it</td>
<td class="org-left">48,327</td>
</tr>
</tbody>
</table>
<p>As you can see, common words like "the" appear very often in both positive and negative reviews. Instead of finding the most common words in positive or negative reviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you'll need to calculate the <b>ratios</b> of word usage between positive and negative reviews.</p>
<p>Check all the words you've seen and calculate the ratio of postive to negative uses and store that ratio in <code>pos_neg_ratios</code>.</p>
<p>Hint: the positive-to-negative ratio for a given word can be calculated with `positive_counts[word] / float(negative_counts[word]+1)`. Notice the `+1` in the denominator –&nbsp;that ensures we don't divide by zero for words that are only seen in positive reviews.</p>
<p>Create a Counter object to store positive/negative ratios</p>
<div class="highlight">
<pre><span></span>pos_neg_ratios = Counter()
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0d9a828">
<h3 id="org0d9a828">Positive to negative ratios</h3>
<div class="outline-text-3" id="text-org0d9a828">
<p>Calculate the ratios of positive and negative uses of the most common words</p>
<div class="highlight">
<pre><span></span>ratios = {element: positive_counts[element]/(negative_counts[element] + 1)
          for element in total_counts}
pos_neg_ratios.update(ratios)
</pre></div>
<div class="highlight">
<pre><span></span>with DataPath("pos_neg_ratios.pkl",
              check_exists=False).from_folder.open("wb") as writer:
    pickle.dump(pos_neg_ratios, writer)
</pre></div>
<p>Examine the ratios you've calculated for a few words:</p>
<div class="highlight">
<pre><span></span>print("Pos-to-neg ratio for 'the' = {:.2f}".format(pos_neg_ratios["the"]))
print("Pos-to-neg ratio for 'amazing' = {:.2f}".format(pos_neg_ratios["amazing"]))
print("Pos-to-neg ratio for 'terrible' = {:.2f}".format(pos_neg_ratios["terrible"]))
</pre></div>
<pre class="example">
Pos-to-neg ratio for 'the' = 1.06
Pos-to-neg ratio for 'amazing' = 4.02
Pos-to-neg ratio for 'terrible' = 0.18

</pre>
<p>Looking closely at the values you just calculated, we see the following:</p>
<ul class="org-ul">
<li>Words that you would expect to see more often in positive reviews - like "amazing" - have a ratio greater than 1. The more skewed a word is toward postive, the farther from 1 its positive-to-negative ratio will be.</li>
<li>Words that you would expect to see more often in negative reviews - like "terrible" - have positive values that are less than 1. The more skewed a word is toward negative, the closer to zero its positive-to-negative ratio will be.</li>
<li>Neutral words, which don't really convey any sentiment because you would expect to see them in all sorts of reviews – like "the" – have values very close to 1. A perfectly neutral word –&nbsp;one that was used in exactly the same number of positive reviews as negative reviews – would be almost exactly 1. The `+1` we suggested you add to the denominator slightly biases words toward negative, but it won't matter because it will be a tiny bias and later we'll be ignoring words that are too close to neutral anyway.</li>
</ul>
<p>Ok, the ratios tell us which words are used more often in postive or negative reviews, but the specific values we've calculated are a bit difficult to work with. A very positive word like "amazing" has a value above 4, whereas a very negative word like "terrible" has a value around 0.18. Those values aren't easy to compare for a couple of reasons:</p>
<ul class="org-ul">
<li>Right now, 1 is considered neutral, but the absolute value of the postive-to-negative ratios of very postive words is larger than the absolute value of the ratios for the very negative words. So there is no way to directly compare two numbers and see if one word conveys the same magnitude of positive sentiment as another word conveys negative sentiment. So we should center all the values around netural so the absolute value from neutral of the postive-to-negative ratio for a word would indicate how much sentiment (positive or negative) that word conveys.</li>
</ul>
<p><i>When comparing absolute values it's easier to do that around zero than one.</i></p>
<p>To fix these issues, we'll convert all of our ratios to new values using logarithms.</p>
<p>Go through all the ratios you calculated and convert them to logarithms. (i.e. use `np.log(ratio)`)</p>
<p>In the end, extremely positive and extremely negative words will have positive-to-negative ratios with similar magnitudes but opposite signs. Note that you have to create a new counter - the <code>update</code> method adds the new value to the previous values.</p>
<div class="highlight">
<pre><span></span>log_ratios = {}
for token, ratio in pos_neg_ratios.items():
    if ratio &gt; 1:
        log_ratios[token] = numpy.log(ratio)
    else:
        log_ratios[token] = -numpy.log(1/(ratio + 0.01))
positive_negative_log_ratios = Counter()
positive_negative_log_ratios.update(log_ratios)
</pre></div>
<p>Examine the new ratios you've calculated for the same words from before:</p>
<div class="highlight">
<pre><span></span>print("Pos-to-neg ratio for 'the' = {:.2f}".format(positive_negative_log_ratios["the"]))
print("Pos-to-neg ratio for 'amazing' = {:.2f}".format(positive_negative_log_ratios["amazing"]))
print("Pos-to-neg ratio for 'terrible' = {:.2f}".format(positive_negative_log_ratios["terrible"]))
</pre></div>
<pre class="example">
Pos-to-neg ratio for 'the' = 0.06
Pos-to-neg ratio for 'amazing' = 1.39
Pos-to-neg ratio for 'terrible' = -1.67

</pre>
<div class="highlight">
<pre><span></span>with DataPath("pos_neg_log_ratios.pkl",
              check_exists=False).from_folder.open("wb") as writer:
    pickle.dump(positive_negative_log_ratios, writer)
</pre></div>
<p>If everything worked, now you should see neutral words with values close to zero. In this case, "the" is near zero but slightly positive, so it was probably used in more positive reviews than negative reviews. But look at "amazing"'s ratio - it's above <code>1</code>, showing it is clearly a word with positive sentiment. And "terrible" has a similar score, but in the opposite direction, so it's below <code>-1</code>. It's now clear that both of these words are associated with specific, opposing sentiments.</p>
<p>Now run the following cells to see more ratios.</p>
<p>The first cell displays all the words, ordered by how associated they are with postive reviews. (Your notebook will most likely truncate the output so you won't actually see <b>all</b> the words in the list.)</p>
<p>The second cell displays the 30 words most associated with negative reviews by reversing the order of the first list and then looking at the first 30 words. (If you want the second cell to display all the words, ordered by how associated they are with negative reviews, you could just write `reversed(pos_neg_ratios.most_common())`.)</p>
<p>You should continue to see values similar to the earlier ones we checked –&nbsp;neutral words will be close to `0`, words will get more positive as their ratios approach and go above `1`, and words will get more negative as their ratios approach and go below `-1`. That's why we decided to use the logs instead of the raw ratios.</p>
<p>Here are the words most frequently seen in a review with a "POSITIVE" label.</p>
<div class="highlight">
<pre><span></span>print("|Token|Log Ratio|")
print("|-+-|")
for token, ratio in positive_negative_log_ratios.most_common(10):
    print("|{}|{:.2f}|".format(token, ratio))
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-right" scope="col">Log Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">edie</td>
<td class="org-right">4.69</td>
</tr>
<tr>
<td class="org-left">antwone</td>
<td class="org-right">4.48</td>
</tr>
<tr>
<td class="org-left">din</td>
<td class="org-right">4.41</td>
</tr>
<tr>
<td class="org-left">gunga</td>
<td class="org-right">4.19</td>
</tr>
<tr>
<td class="org-left">goldsworthy</td>
<td class="org-right">4.17</td>
</tr>
<tr>
<td class="org-left">gypo</td>
<td class="org-right">4.09</td>
</tr>
<tr>
<td class="org-left">yokai</td>
<td class="org-right">4.09</td>
</tr>
<tr>
<td class="org-left">paulie</td>
<td class="org-right">4.08</td>
</tr>
<tr>
<td class="org-left">visconti</td>
<td class="org-right">3.93</td>
</tr>
<tr>
<td class="org-left">flavia</td>
<td class="org-right">3.93</td>
</tr>
</tbody>
</table>
<p>Ummm… okay.</p>
<div class="highlight">
<pre><span></span>print(positive_counts["edie"])
print(negative_counts["edie"])
</pre></div>
<pre class="example">
109
0

</pre>
<p>So the ones that are most positive appeared in the positive but not in the negative.</p>
<p>Here are the words most frequently seen in a review with a "NEGATIVE" label. The python slice notation is <code>list-name[first to include: first to exclude: step ]</code>.</p>
<div class="highlight">
<pre><span></span>print("|Token|Log Ratio|")
print("|-+-|")
for token, ratio in positive_negative_log_ratios.most_common()[:-11:-1]:
    print("|{}|{:.2f}|".format(token, ratio))
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Token</th>
<th class="org-right" scope="col">Log Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">whelk</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">pressurized</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">bellwood</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">mwuhahahaa</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">insulation</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">hoodies</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">yaks</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">raksha</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">deamon</td>
<td class="org-right">-4.61</td>
</tr>
<tr>
<td class="org-left">ziller</td>
<td class="org-right">-4.61</td>
</tr>
</tbody>
</table>
<div class="highlight">
<pre><span></span>print(positive_counts["whelk"])
print(negative_counts["whelk"])
</pre></div>
<pre class="example">
0
1

</pre>
<p>And the most negative counts just didn't appear in the positive counts, even if they only appeared once in the negative counts.</p>
<p>As with the positive reviews, it's actually hard to figure out exactly what the most common tokens for negative reviews are.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgf106d2d">
<h3 id="orgf106d2d">Did our theory work?</h3>
<div class="outline-text-3" id="text-orgf106d2d">
<p>Our theory was that key-words identify whether a review is positive or negative. There is some evidence for this, but really, it's not obvious that this is the case in general.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org6b31d3d">
<h2 id="org6b31d3d">Pickling</h2>
<div class="outline-text-2" id="text-org6b31d3d">
<p>Since the other posts in this section re-use some of this stuff it might make sense to pickle them.</p>
<div class="highlight">
<pre><span></span>with DataPath("total_counts.pkl", check_exists=False).from_folder.open("wb") as writer:
    pickle.dump(total_counts, writer)
</pre></div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/bike-sharing/bike-sharing-project-feedback/">Bike Sharing Project Feedback</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/bike-sharing/bike-sharing-project-feedback/" rel="bookmark"><time class="published dt-published" datetime="2018-11-05T12:55:10-08:00" itemprop="datePublished" title="2018-11-05 12:55">2018-11-05 12:55</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/bike-sharing/bike-sharing-project-feedback/#orgea43722">On the Number of Hidden Units</a></li>
<li><a href="posts/nano/bike-sharing/bike-sharing-project-feedback/#orge962861">On the Learning Rate</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgea43722">
<h2 id="orgea43722">On the Number of Hidden Units</h2>
<div class="outline-text-2" id="text-orgea43722">
<ul class="org-ul">
<li>Rule of thumb: halfway between number of inputs and outputs</li>
<li><a href="https://www.quora.com/How-do-I-decide-the-number-of-nodes-in-a-hidden-layer-of-a-neural-network-I-will-be-using-a-three-layer-model">Quora link</a></li>
</ul>
<p>\[8 \leq \text{number of hidden units} \leq \text{twice the number of inputs} \]</p>
</div>
</div>
<div class="outline-2" id="outline-container-orge962861">
<h2 id="orge962861">On the Learning Rate</h2>
<div class="outline-text-2" id="text-orge962861">
<p>\[ 0.001 \leq \alpha \leq 0.1 \]</p>
<p>When considering the learning rate calculate \[\frac{\alpha}{\text{number of records}}\] and see if it's too small or too larg.e</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/sentiment_analysis/sentiment-classification-lectures/">Sentiment Classification Lectures</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/sentiment_analysis/sentiment-classification-lectures/" rel="bookmark"><time class="published dt-published" datetime="2018-11-04T14:17:10-08:00" itemprop="datePublished" title="2018-11-04 14:17">2018-11-04 14:17</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/sentiment_analysis/sentiment-classification-lectures/#org1e9f375">Sentiment Classification & How To "Frame Problems" for a Neural Network</a></li>
<li><a href="posts/nano/sentiment_analysis/sentiment-classification-lectures/#org349327e">Set Up</a></li>
<li><a href="posts/nano/sentiment_analysis/sentiment-classification-lectures/#orgd138c2b">Analysis: What's Going on in the Weights?</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org1e9f375">
<h2 id="org1e9f375">Sentiment Classification & How To "Frame Problems" for a Neural Network</h2>
<div class="outline-text-2" id="text-org1e9f375">
<p>by Andrew Trask</p>
<ul class="org-ul">
<li><b>Twitter</b>: @iamtrask</li>
<li><b>Blog</b>: <a href="http://iamtrask.github.io">http://iamtrask.github.io</a></li>
</ul>
</div>
<div class="outline-3" id="outline-container-orgf4ead2e">
<h3 id="orgf4ead2e">What You Should Already Know</h3>
<div class="outline-text-3" id="text-orgf4ead2e">
<ul class="org-ul">
<li>neural networks, forward and back-propagation</li>
<li>stochastic gradient descent</li>
<li>mean squared error</li>
<li>and train/test splits</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orgfa65358">
<h3 id="orgfa65358">Where to Get Help if You Need it</h3>
<div class="outline-text-3" id="text-orgfa65358">
<ul class="org-ul">
<li>Re-watch previous Udacity Lectures</li>
<li>Leverage the recommended Course Reading Material - <a href="https://www.manning.com/books/grokking-deep-learning">Grokking Deep Learning</a></li>
<li>Shoot me Andrew a tweet @iamtrask</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org349327e">
<h2 id="org349327e">Set Up</h2>
<div class="outline-text-2" id="text-org349327e"></div>
<div class="outline-3" id="outline-container-org40a691a">
<h3 id="org40a691a">Debug</h3>
<div class="outline-text-3" id="text-org40a691a">
<div class="highlight">
<pre><span></span>%load_ext autoreload
%autoreload 2
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org3efbf7e">
<h3 id="org3efbf7e">Imports</h3>
<div class="outline-text-3" id="text-org3efbf7e"></div>
<div class="outline-4" id="outline-container-orgf9c8688">
<h4 id="orgf9c8688">Python Standard Library</h4>
<div class="outline-text-4" id="text-orgf9c8688">
<div class="highlight">
<pre><span></span>from datetime import datetime
from functools import partial
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1118cef">
<h4 id="org1118cef">From Pypi</h4>
<div class="outline-text-4" id="text-org1118cef">
<div class="highlight">
<pre><span></span>from graphviz import Graph
from tabulate import tabulate
import matplotlib.pyplot as pyplot
import numpy
import seaborn
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org40f3b2f">
<h4 id="org40f3b2f">This Project</h4>
<div class="outline-text-4" id="text-org40f3b2f">
<div class="highlight">
<pre><span></span>from neurotic.tangles.data_paths import DataPath
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgea05b3d">
<h3 id="orgea05b3d">Tables</h3>
<div class="outline-text-3" id="text-orgea05b3d">
<div class="highlight">
<pre><span></span>table = partial(tabulate, tablefmt="orgtbl", headers="keys")
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8ae9801">
<h3 id="org8ae9801">Printing</h3>
<div class="outline-text-3" id="text-org8ae9801">
<div class="highlight">
<pre><span></span>%matplotlib inline
seaborn.set_style("whitegrid")
FIGURE_SIZE = (12, 10)
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd138c2b">
<h2 id="orgd138c2b">Analysis: What's Going on in the Weights?</h2>
<div class="outline-text-2" id="text-orgd138c2b">
<p>Let's start with a model that doesn't have any noise cancellation.</p>
<div class="highlight">
<pre><span></span>mlp_full = SentimentNoiseReduction(reviews=x_train, labels=y_train,
                                   lower_bound=0,
                                   polarity_cutoff=0,
                                   learning_rate=0.01)
</pre></div>
<div class="highlight">
<pre><span></span>mlp_full.train()
</pre></div>
<pre class="example">
Progress: 0.00 % Speed(reviews/sec): 0.00 Error: [-0.5] #Correct: 1 #Trained: 1 Training Accuracy: 100.00 %
Progress: 4.17 % Speed(reviews/sec): 100.00 Error: [-0.38320156] #Correct: 740 #Trained: 1001 Training Accuracy: 73.93 %
Progress: 8.33 % Speed(reviews/sec): 181.82 Error: [-0.26004622] #Correct: 1529 #Trained: 2001 Training Accuracy: 76.41 %
Progress: 12.50 % Speed(reviews/sec): 250.00 Error: [-0.40350302] #Correct: 2376 #Trained: 3001 Training Accuracy: 79.17 %
Progress: 16.67 % Speed(reviews/sec): 285.71 Error: [-0.23990249] #Correct: 3187 #Trained: 4001 Training Accuracy: 79.66 %
Progress: 20.83 % Speed(reviews/sec): 333.33 Error: [-0.14119144] #Correct: 4002 #Trained: 5001 Training Accuracy: 80.02 %
Progress: 25.00 % Speed(reviews/sec): 375.00 Error: [-0.06442389] #Correct: 4829 #Trained: 6001 Training Accuracy: 80.47 %
Progress: 29.17 % Speed(reviews/sec): 411.76 Error: [-0.03508728] #Correct: 5690 #Trained: 7001 Training Accuracy: 81.27 %
Progress: 33.33 % Speed(reviews/sec): 444.44 Error: [-0.05110633] #Correct: 6548 #Trained: 8001 Training Accuracy: 81.84 %
Progress: 37.50 % Speed(reviews/sec): 450.00 Error: [-0.07432703] #Correct: 7404 #Trained: 9001 Training Accuracy: 82.26 %
Progress: 41.67 % Speed(reviews/sec): 476.19 Error: [-0.26512013] #Correct: 8272 #Trained: 10001 Training Accuracy: 82.71 %
Progress: 45.83 % Speed(reviews/sec): 500.00 Error: [-0.14067275] #Correct: 9129 #Trained: 11001 Training Accuracy: 82.98 %
Progress: 50.00 % Speed(reviews/sec): 521.74 Error: [-0.01215903] #Correct: 9994 #Trained: 12001 Training Accuracy: 83.28 %
Progress: 54.17 % Speed(reviews/sec): 541.67 Error: [-0.33825111] #Correct: 10864 #Trained: 13001 Training Accuracy: 83.56 %
Progress: 58.33 % Speed(reviews/sec): 560.00 Error: [-0.00522004] #Correct: 11721 #Trained: 14001 Training Accuracy: 83.72 %
Progress: 62.50 % Speed(reviews/sec): 555.56 Error: [-0.49523538] #Correct: 12553 #Trained: 15001 Training Accuracy: 83.68 %
Progress: 66.67 % Speed(reviews/sec): 571.43 Error: [-0.20026672] #Correct: 13390 #Trained: 16001 Training Accuracy: 83.68 %
Progress: 70.83 % Speed(reviews/sec): 586.21 Error: [-0.20786817] #Correct: 14243 #Trained: 17001 Training Accuracy: 83.78 %
Progress: 75.00 % Speed(reviews/sec): 580.65 Error: [-0.03469862] #Correct: 15108 #Trained: 18001 Training Accuracy: 83.93 %
Progress: 79.17 % Speed(reviews/sec): 593.75 Error: [-0.99460657] #Correct: 15982 #Trained: 19001 Training Accuracy: 84.11 %
Progress: 83.33 % Speed(reviews/sec): 606.06 Error: [-0.0523489] #Correct: 16867 #Trained: 20001 Training Accuracy: 84.33 %
Progress: 87.50 % Speed(reviews/sec): 617.65 Error: [-0.28370015] #Correct: 17734 #Trained: 21001 Training Accuracy: 84.44 %
Progress: 91.67 % Speed(reviews/sec): 611.11 Error: [-0.33222958] #Correct: 18616 #Trained: 22001 Training Accuracy: 84.61 %
Progress: 95.83 % Speed(reviews/sec): 621.62 Error: [-0.17177784] #Correct: 19475 #Trained: 23001 Training Accuracy: 84.67 %
Training Time: 0:00:38.794351
</pre>
<p>Now here's a function to find the similarity of words in the vocabulary to a word, based on the dot product of the weights from the input layer to the hidden layer.</p>
<div class="highlight">
<pre><span></span>def get_most_similar_words(focus: str="horrible", count:int=10) -&gt; list:
    """Returns a list of similar words based on weights"""
    most_similar = Counter()
    for word in mlp_full.word_to_index:
        most_similar[word] = numpy.dot(
            mlp_full.weights_input_to_hidden[mlp_full.word_to_index[word]],
            mlp_full.weights_input_to_hidden[mlp_full.word_to_index[focus]])    
    return most_similar.most_common(count)
</pre></div>
<div class="highlight">
<pre><span></span>print(get_most_similar_words("excellent"))
</pre></div>
<pre class="example">
[('excellent', 0.14672474869646132), ('perfect', 0.12529721850063252), ('great', 0.1072983586254582), ('amazing', 0.10168346112776101), ('wonderful', 0.0971402564667566), ('best', 0.09640599864254018), ('today', 0.09064606014006837), ('fun', 0.08859560811231239), ('loved', 0.07914150763452406), ('definitely', 0.07693307843353574)]

</pre>
<p><i>excellent</i> was, ouf course, most similar to itself, but we can see that the network's weights are most similar to each other when the words are most similar to each other - the network has 'learned' what words are similar to <i>excellent</i> using the training set.</p>
<p>Now a negative example.</p>
<div class="highlight">
<pre><span></span>print(get_most_similar_words("terrible"))
</pre></div>
<pre class="example">
[('worst', 0.1761389721390966), ('awful', 0.12576492326546337), ('waste', 0.11989143949659276), ('poor', 0.10186721140388931), ('boring', 0.09740050873489904), ('terrible', 0.09719144477251088), ('bad', 0.08198016341605044), ('dull', 0.0812576973066953), ('worse', 0.07504920898991188), ('poorly', 0.07494303321254764)]

</pre>
<p>Once again, the more similar words were in sentiment, the closer the weights leading from their inputs became.</p>
<div class="highlight">
<pre><span></span>import matplotlib.colors as colors

words_to_visualize = list()
for word, ratio in pos_neg_ratios.most_common(500):
    if(word in mlp_full.word_to_index):
        words_to_visualize.append(word)

for word, ratio in list(reversed(pos_neg_ratios.most_common()))[0:500]:
    if(word in mlp_full.word_to_index):
        words_to_visualize.append(word)
</pre></div>
<div class="highlight">
<pre><span></span>pos = 0
neg = 0

colors_list = list()
vectors_list = list()
for word in words_to_visualize:
    if word in pos_neg_ratios.keys():
        vectors_list.append(mlp_full.weights_input_to_hidden[mlp_full.word_to_index[word]])
        if(pos_neg_ratios[word] &gt; 0):
            pos+=1
            colors_list.append("#00ff00")
        else:
            neg+=1
            colors_list.append("#000000")
</pre></div>
<div class="highlight">
<pre><span></span>from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)
words_top_ted_tsne = tsne.fit_transform(vectors_list)
</pre></div>
<p>p = figure(tools="pan,wheel_zoom,reset,save", toolbar_location="above", title="vector T-SNE for most polarized words")</p>
<p>source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0], x2=words_top_ted_tsne[:,1], names=words_to_visualize, color=colors_list))</p>
<p>p.scatter(x="x1", y="x2", size=8, source=source, fill_color="color")</p>
<p>word_labels = LabelSet(x="x1", y="x2", text="names", y_offset=6, text_font_size="8pt", text_color="#555555", source=source, text_align='center') p.add_layout(word_labels)</p>
<p>show(p)</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/notes/notes-on-the-deep-learning-revolution/">Notes on The Deep Learning Revolution</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/notes/notes-on-the-deep-learning-revolution/" rel="bookmark"><time class="published dt-published" datetime="2018-11-01T14:18:50-07:00" itemprop="datePublished" title="2018-11-01 14:18">2018-11-01 14:18</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/notes/notes-on-the-deep-learning-revolution/#orgadb1abc">Intelligence Reimagined (Where did this come from?)</a></li>
<li><a href="posts/notes/notes-on-the-deep-learning-revolution/#orgebe76e5">Many Ways To Learn (How does it work?)</a></li>
<li><a href="posts/notes/notes-on-the-deep-learning-revolution/#orgb4c9208">Technological and Scientific Impact (What has it done and what might it do?)</a></li>
<li><a href="posts/notes/notes-on-the-deep-learning-revolution/#org8d70f46">Citation</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgadb1abc">
<h2 id="orgadb1abc">Intelligence Reimagined (Where did this come from?)</h2>
<div class="outline-text-2" id="text-orgadb1abc"></div>
<div class="outline-3" id="outline-container-orgc18e1b3">
<h3 id="orgc18e1b3">Timeline</h3>
<div class="outline-text-3" id="text-orgc18e1b3">
<ul class="org-ul">
<li>1956: Dartmouth Artificial Intelligence Summer Research Project - start of the field of Artificial Intelligence.</li>
<li>1962: Frank Rosenblatt publishes description of the Perceptron</li>
<li>1962: David Huble and Torsten Wiesel report first recordings of responses from neurons</li>
<li>1969: Marvin Minsky and Seymour Papert point out limits of perceptron, triggering the <i>AI Winter</i></li>
<li>1979: Geoffrey Hinton and James Anderson organize Parallel Models of Associative Memory workshop to gather researchers working on neural networks</li>
<li>1987: First Neural Information Processing Systems (NIPS) conference held, bringing machine learning reasearchers together</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-orga6646cc">
<h3 id="orga6646cc">The Rise of Machine Learning</h3>
<div class="outline-text-3" id="text-orga6646cc"></div>
<div class="outline-4" id="outline-container-org1e489a9">
<h4 id="org1e489a9">What is deep learning?</h4>
<div class="outline-text-4" id="text-org1e489a9">
<p><i>Deep Learning</i> is a form of machine learning that uses data to train artificial neural networks to do things. When the field of artificial intelligence began in the 1950s there were two camps - one that believed the path to intelligenc lay in using formal logic and writing computer programs, and one that believe intelligence would come by learning directly from data. Deep Learning belongs to the second camp, and although it has been around for a long time, only once we had enough computational power and data was it able to compete.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org2ecca78">
<h4 id="org2ecca78">How did self-driving cars come about?</h4>
<div class="outline-text-4" id="text-org2ecca78">
<ul class="org-ul">
<li>In 2005 a group from Stanford lead by Sebastian Thrun won the <a href="https://en.wikipedia.org/wiki/DARPA_Grand_Challenge_(2005)">DARPA Grand Challenge</a>. This was the second Darpa challenge and the first where (five) vehicles were able to finish.</li>
<li>Some see self-driving cars as a way to remake society:
<ul class="org-ul">
<li>no need to own a car, use a just-in-time service</li>
<li>No need for parking lots and so many lanes on the road</li>
<li>Travel time can be productive</li>
<li>Once one car learns something it can be taught to all the other cars so 'rare' events will be handled even if it is the first time a car sees the event.</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-org9e910c0">
<h4 id="org9e910c0">How do machines translate languages?</h4>
<div class="outline-text-4" id="text-org9e910c0">
<p>Originally they worked using a statistical approach, looking for familiar word combinations and counts. Now they are able to keep longer sections of text which improves the translation because there is more seen in contetxt. The hope is that when they can be expanded to learn paragraphs or an author's entire body of work, then they can learn more subtleties and the poetry of the text.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org72e2cb7">
<h4 id="org72e2cb7">What's the big deal about speech recognition?</h4>
<div class="outline-text-4" id="text-org72e2cb7">
<p>Some people think that the next interface to our machines will be the human voice. There have already been demonstrations of live translations made using computer speech recognition and translation.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgc35c406">
<h4 id="orgc35c406">How good is machine learning at playing poker?</h4>
<div class="outline-text-4" id="text-orgc35c406">
<p>DeepStack played poker against professional poker players and beat all of them. This is important because the nature of the game means that every player is working with imperfect information (the unseen cards and the other players' cards). This could imply that machine learning could be used in other places where you don't have all the information, like politics and negotiations.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org39da653">
<h4 id="org39da653">Does artificial intelligence pose a threat to humanity?</h4>
<div class="outline-text-4" id="text-org39da653">
<p>If you look an the areas where deep learning managed to outdo human competitors (e.g. Alpha Go), what eventually happened was that the human players were able to learn moves from the Artificial Intelligence that they would likely not have come up with themselves. This points the way to the immediate future of Artificial Intelligence. Although AI can sometimes outperform humans, the more open-ended the problem, the more it is likely that humans and machines can complement each other, with the machine creating outcomes we could never think of and the humans contributing the expertise needed as a human to solve human problems. AI is, so far, more of a complement to human intelligence, not a replacement for it.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org873bdea">
<h3 id="org873bdea">The Rebirth of Artificial Intelligence</h3>
</div>
<div class="outline-3" id="outline-container-orgf0dba7a">
<h3 id="orgf0dba7a">The Dawn of Neural Networks</h3>
</div>
<div class="outline-3" id="outline-container-org1854abf">
<h3 id="org1854abf">Brain-style Computing</h3>
</div>
<div class="outline-3" id="outline-container-org5dc49a9">
<h3 id="org5dc49a9">Insights from the Visual System</h3>
</div>
</div>
<div class="outline-2" id="outline-container-orgebe76e5">
<h2 id="orgebe76e5">Many Ways To Learn (How does it work?)</h2>
<div class="outline-text-2" id="text-orgebe76e5"></div>
<div class="outline-3" id="outline-container-orgc47bb25">
<h3 id="orgc47bb25">The Cocktail Party Problem</h3>
</div>
<div class="outline-3" id="outline-container-org9cee6ef">
<h3 id="org9cee6ef">The Hopfield Net and Boltzmann Machine</h3>
</div>
<div class="outline-3" id="outline-container-org3f616ad">
<h3 id="org3f616ad">Backpropagating Errors</h3>
</div>
<div class="outline-3" id="outline-container-orgb096225">
<h3 id="orgb096225">Convolutional Learning</h3>
</div>
<div class="outline-3" id="outline-container-orga4ef3b2">
<h3 id="orga4ef3b2">Reward Learning</h3>
</div>
<div class="outline-3" id="outline-container-org7dd4f0b">
<h3 id="org7dd4f0b">Neural Information Processing Systems</h3>
</div>
</div>
<div class="outline-2" id="outline-container-orgb4c9208">
<h2 id="orgb4c9208">Technological and Scientific Impact (What has it done and what might it do?)</h2>
<div class="outline-text-2" id="text-orgb4c9208"></div>
<div class="outline-3" id="outline-container-org2963a7f">
<h3 id="org2963a7f">The Future of Machine Learning</h3>
</div>
<div class="outline-3" id="outline-container-orgd4247a0">
<h3 id="orgd4247a0">The Age of Algorithms</h3>
</div>
<div class="outline-3" id="outline-container-org533aea2">
<h3 id="org533aea2">Hello, Mr. Chips</h3>
</div>
<div class="outline-3" id="outline-container-org4e3cb91">
<h3 id="org4e3cb91">Inside Information</h3>
</div>
<div class="outline-3" id="outline-container-org5b4d2f2">
<h3 id="org5b4d2f2">Conscousness</h3>
</div>
<div class="outline-3" id="outline-container-orgae7ee07">
<h3 id="orgae7ee07">Nature Is Cleverer Than We Are</h3>
</div>
<div class="outline-3" id="outline-container-org77f3eec">
<h3 id="org77f3eec">Deep Intelligence</h3>
</div>
</div>
<div class="outline-2" id="outline-container-org8d70f46">
<h2 id="org8d70f46">Citation</h2>
<div class="outline-text-2" id="text-org8d70f46"></div>
<div class="outline-3" id="outline-container-org6003d55">
<h3 id="org6003d55">[TDLR] Sejnowski TJ. The deep learning revolution. MIT Press; 2018 Oct 23.</h3>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/notes/reading-list/">Reading List</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/notes/reading-list/" rel="bookmark"><time class="published dt-published" datetime="2018-11-01T13:34:48-07:00" itemprop="datePublished" title="2018-11-01 13:34">2018-11-01 13:34</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/notes/reading-list/#org2232796">Books</a></li>
<li><a href="posts/notes/reading-list/#orgd06cc7a">Links</a></li>
<li><a href="posts/notes/reading-list/#orgbcf6fc9">Papers</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org2232796">
<h2 id="org2232796">Books</h2>
<div class="outline-text-2" id="text-org2232796"></div>
<div class="outline-3" id="outline-container-orgab07604">
<h3 id="orgab07604">Deep Learning</h3>
<div class="outline-text-3" id="text-orgab07604"></div>
<div class="outline-4" id="outline-container-org720f5f4">
<h4 id="org720f5f4">[DLI] Krohn J. Deep Learning Illustrated: a visual, interactive guide to artificial intelligence. Boston, MA: Addison-Wesley; 2019.</h4>
</div>
<div class="outline-4" id="outline-container-orgfed28c7">
<h4 id="orgfed28c7">[GDL] Trask AW. Grokking Deep Learning. Shelter Island: Manning; 2019. 309 p.</h4>
</div>
<div class="outline-4" id="outline-container-orgd76332c">
<h4 id="orgd76332c">[TDLR] Sejnowski TJ. The Deep Learning Revolution. MIT Press; 2018 Oct 23.</h4>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd06cc7a">
<h2 id="orgd06cc7a">Links</h2>
<div class="outline-text-2" id="text-orgd06cc7a">
<ul class="org-ul">
<li><a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> - halfway between <i>Grokking Deep Learning</i> and the <a href="http://www.deeplearningbook.org/">Deep Learning Textbook</a></li>
<li><a href="http://www.deeplearningbook.org/">Deep Learning</a> - textbook written by the guys who came up with it</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgbcf6fc9">
<h2 id="orgbcf6fc9">Papers</h2>
<div class="outline-text-2" id="text-orgbcf6fc9">
<ul class="org-ul">
<li><a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a></li>
<li><a href="https://arxiv.org/pdf/1502.01852v1.pdf">Delving Deep Into Rectifiers</a></li>
<li><a href="https://arxiv.org/pdf/1502.03167v2.pdf">Batch Normalization</a></li>
</ul>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="posts/nano/bike-sharing/bike-sharing-project-answers/">Bike Sharing Project Answers</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="posts/nano/bike-sharing/bike-sharing-project-answers/" rel="bookmark"><time class="published dt-published" datetime="2018-10-30T15:31:25-07:00" itemprop="datePublished" title="2018-10-30 15:31">2018-10-30 15:31</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/nano/bike-sharing/bike-sharing-project-answers/#org6affa50">Introduction</a></li>
<li><a href="posts/nano/bike-sharing/bike-sharing-project-answers/#orgc8706e7">Imports</a></li>
<li><a href="posts/nano/bike-sharing/bike-sharing-project-answers/#org4eb1508">The Neural Network</a></li>
<li><a href="posts/nano/bike-sharing/bike-sharing-project-answers/#org7d6a19e">The Hyper Parameters</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org6affa50">
<h2 id="org6affa50">Introduction</h2>
<div class="outline-text-2" id="text-org6affa50">
<p>The Bike Sharing Project uses a neural network to predict daily ridership for a bike sharing service. The code is split into two parts - a jupyter notebook that you work with and a python file (<code>my_answers.py</code>) where you put the parts of the code that isn't provided. This creates the <code>my_answer.py</code> file.</p>
</div>
</div>
<div class="outline-2" id="outline-container-orgc8706e7">
<h2 id="orgc8706e7">Imports</h2>
<div class="outline-text-2" id="text-orgc8706e7">
<div class="highlight">
<pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org4eb1508">
<h2 id="org4eb1508">The Neural Network</h2>
<div class="outline-text-2" id="text-org4eb1508">
<div class="highlight">
<pre><span></span><span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">"""Implementation of a neural network with one hidden layer</span>

<span class="sd">    Args:</span>
<span class="sd">     input_nodes: number of input nodes</span>
<span class="sd">     hidden_nodes: number of hidden nodes</span>
<span class="sd">     output_nodes: number of output_nodes</span>
<span class="sd">     learning_rate: rate at which to update the weights</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
                 <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Set number of nodes in input, hidden and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1"># Initialize weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">return</span>
</pre></div>
</div>
<div class="outline-3" id="outline-container-org87b0558">
<h3 id="org87b0558">Input To Hidden Weights</h3>
<div class="outline-text-3" id="text-org87b0558">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">weights_input_to_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">"""Array of weights from input layer to the hidden layer"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
            <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span>
</pre></div>
<p>The unit-test tries to set the weights so we need a setter.</p>
<div class="highlight">
<pre><span></span><span class="nd">@weights_input_to_hidden.setter</span>
<span class="k">def</span> <span class="nf">weights_input_to_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""Sets the weights"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_weights_input_to_hidden</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0577ef3">
<h3 id="org0577ef3">Hidden To Output Weights</h3>
<div class="outline-text-3" id="text-org0577ef3">
<div class="highlight">
<pre><span></span><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">weights_hidden_to_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">"""Array of weights for edges from hidden layer to output"""</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
            <span class="mf">0.0</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_nodes</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span>
</pre></div>
<p>Once again, this is for the unit-testing.</p>
<div class="highlight">
<pre><span></span><span class="nd">@weights_hidden_to_output.setter</span>
<span class="k">def</span> <span class="nf">weights_hidden_to_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
    <span class="sd">"""sets the weights for edges from hidden layer to output"""</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_weights_hidden_to_output</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5991c3c">
<h3 id="org5991c3c">Activation Function</h3>
<div class="outline-text-3" id="text-org5991c3c">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">activation_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="sd">"""A pass-through to the sigmoid"""</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org12a4f4a">
<h3 id="org12a4f4a">Sigmoid</h3>
<div class="outline-text-3" id="text-org12a4f4a">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="sd">"""Calculates the sigmoid of the value"""</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org42e51cf">
<h3 id="org42e51cf">Train</h3>
<div class="outline-text-3" id="text-org42e51cf">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">''' Train the network on batch of features and targets. </span>

<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>

<span class="sd">       features: 2D array, each row is one data record, each column is a feature</span>
<span class="sd">       targets: 1D array of target values</span>

<span class="sd">    '''</span>
    <span class="n">n_records</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">delta_weights_i_h</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">delta_weights_h_o</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> 
   <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>            
        <span class="n">final_outputs</span><span class="p">,</span> <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass_train</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># Implement the backpropagation function below</span>
        <span class="n">delta_weights_i_h</span><span class="p">,</span> <span class="n">delta_weights_h_o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backpropagation</span><span class="p">(</span>
            <span class="n">final_outputs</span><span class="p">,</span> <span class="n">hidden_outputs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
            <span class="n">delta_weights_i_h</span><span class="p">,</span> <span class="n">delta_weights_h_o</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">delta_weights_i_h</span><span class="p">,</span> <span class="n">delta_weights_h_o</span><span class="p">,</span> <span class="n">n_records</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgcbabaf5">
<h3 id="orgcbabaf5">Forward Pass Train</h3>
<div class="outline-text-3" id="text-orgcbabaf5">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">forward_pass_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">''' Implement forward pass here </span>

<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>
<span class="sd">       X: features batch</span>

<span class="sd">    '''</span>
    <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span><span class="p">)</span>
    <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">hidden_inputs</span><span class="p">)</span>

    <span class="n">final_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="p">)</span>
    <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">final_inputs</span>
    <span class="k">return</span> <span class="n">final_outputs</span><span class="p">,</span> <span class="n">hidden_outputs</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgab594d6">
<h3 id="orgab594d6">Back Propagation</h3>
<div class="outline-text-3" id="text-orgab594d6">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_outputs</span><span class="p">,</span> <span class="n">hidden_outputs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">delta_weights_i_h</span><span class="p">,</span> <span class="n">delta_weights_h_o</span><span class="p">):</span>
    <span class="sd">''' Implement backpropagation</span>

<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>
<span class="sd">       final_outputs: output from forward pass</span>
<span class="sd">       y: target (i.e. label) batch</span>
<span class="sd">       delta_weights_i_h: change in weights from input to hidden layers</span>
<span class="sd">       delta_weights_h_o: change in weights from hidden to output layers</span>

<span class="sd">    '''</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">final_outputs</span> <span class="o">-</span> <span class="n">y</span>

    <span class="n">hidden_error</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>

    <span class="n">output_error_term</span> <span class="o">=</span> <span class="n">error</span>

    <span class="n">hidden_error_term</span> <span class="o">=</span> <span class="n">hidden_error</span> <span class="o">*</span> <span class="n">hidden_outputs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">hidden_outputs</span><span class="p">)</span>

    <span class="n">delta_weights_i_h</span> <span class="o">+=</span> <span class="o">-</span><span class="n">hidden_error_term</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span>

    <span class="n">delta_weights_h_o</span> <span class="o">+=</span> <span class="o">-</span><span class="n">output_error_term</span> <span class="o">*</span> <span class="n">hidden_outputs</span><span class="p">[:,</span><span class="bp">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">delta_weights_i_h</span><span class="p">,</span> <span class="n">delta_weights_h_o</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org12a89af">
<h3 id="org12a89af">Update Weights</h3>
<div class="outline-text-3" id="text-org12a89af">
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">update_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">delta_weights_i_h</span><span class="p">,</span> <span class="n">delta_weights_h_o</span><span class="p">,</span> <span class="n">n_records</span><span class="p">):</span>
    <span class="sd">''' Update weights on gradient descent step</span>

<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>
<span class="sd">       delta_weights_i_h: change in weights from input to hidden layers</span>
<span class="sd">       delta_weights_h_o: change in weights from hidden to output layers</span>
<span class="sd">       n_records: number of records</span>

<span class="sd">    '''</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">delta_weights_h_o</span><span class="o">/</span><span class="n">n_records</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">delta_weights_i_h</span><span class="o">/</span><span class="n">n_records</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org35f874e">
<h3 id="org35f874e">Run</h3>
<div class="outline-text-3" id="text-org35f874e">
<p><b>Warning:</b> The MSE function defined in the jupyter notebook won't work if you use <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html">numpy.dot</a> instead of <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html">numpy.matmul</a>. You can make it work by passing in <code>axis=1</code> to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html">numpy.mean</a> but I don't think you're allowed to change the things in the jupyter notebook.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
    <span class="sd">''' Run a forward pass through the network with input features </span>

<span class="sd">       Arguments</span>
<span class="sd">       ---------</span>
<span class="sd">       features: 1D array of feature values</span>
<span class="sd">    '''</span>

    <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_input_to_hidden</span><span class="p">)</span>
    <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_function</span><span class="p">(</span><span class="n">hidden_inputs</span><span class="p">)</span> 

    <span class="n">final_inputs</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_hidden_to_output</span><span class="p">)</span>
    <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">final_inputs</span>        
    <span class="k">return</span> <span class="n">final_outputs</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org7d6a19e">
<h2 id="org7d6a19e">The Hyper Parameters</h2>
<div class="outline-text-2" id="text-org7d6a19e">
<div class="highlight">
<pre><span></span><span class="n">iterations</span> <span class="o">=</span> <span class="mi">7500</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">hidden_nodes</span> <span class="o">=</span> <span class="mi">28</span>
<span class="n">output_nodes</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="index-4.html" rel="prev">Newer posts</a></li>
<li class="next"><a href="index-2.html" rel="next">Older posts</a></li>
</ul>
<!--End of body content-->
<footer id="footer"><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img alt="Creative Commons License" id="license-image" src="https://i.creativecommons.org/l/by/4.0/80x15.png" style="border-width:0"></a>This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>. <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script>
</body>
</html>
